{"2025-11-21T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2511.17502v1","updated":"2025-11-21T18:59:32Z","published":"2025-11-21T18:59:32Z","title":"RynnVLA-002: A Unified Vision-Language-Action and World Model","summary":"We introduce RynnVLA-002, a unified Vision-Language-Action (VLA) and world model. The world model leverages action and visual inputs to predict future image states, learning the underlying physics of the environment to refine action generation. Conversely, the VLA model produces subsequent actions from image observations, enhancing visual understanding and supporting the world model's image generation. The unified framework of RynnVLA-002 enables joint learning of environmental dynamics and action planning. Our experiments show that RynnVLA-002 surpasses individual VLA and world models, demonstrating their mutual enhancement. We evaluate RynnVLA-002 in both simulation and real-world robot tasks. RynnVLA-002 achieves 97.4% success rate on the LIBERO simulation benchmark without pretraining, while in real-world LeRobot experiments, its integrated world model boosts the overall success rate by 50%.","authors":["Jun Cen","Siteng Huang","Yuqian Yuan","Hangjie Yuan","Chaohui Yu","Yuming Jiang","Jiayan Guo","Kehan Li","Hao Luo","Fan Wang","Xin Li","Deli Zhao","Hao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17497v1","updated":"2025-11-21T18:55:02Z","published":"2025-11-21T18:55:02Z","title":"HALO: High-Altitude Language-Conditioned Monocular Aerial Exploration and Navigation","summary":"We demonstrate real-time high-altitude aerial metric-semantic mapping and exploration using a monocular camera paired with a global positioning system (GPS) and an inertial measurement unit (IMU). Our system, named HALO, addresses two key challenges: (i) real-time dense 3D reconstruction using vision at large distances, and (ii) mapping and exploration of large-scale outdoor environments with accurate scene geometry and semantics. We demonstrate that HALO can plan informative paths that exploit this information to complete missions with multiple tasks specified in natural language. In simulation-based evaluation across large-scale environments of size up to 78,000 sq. m., HALO consistently completes tasks with less exploration time and achieves up to 68% higher competitive ratio in terms of the distance traveled compared to the state-of-the-art semantic exploration baseline. We use real-world experiments on a custom quadrotor platform to demonstrate that (i) all modules can run onboard the robot, and that (ii) in diverse environments HALO can support effective autonomous execution of missions covering up to 24,600 sq. m. area at an altitude of 40 m. Experiment videos and more details can be found on our project page: https://tyuezhan.github.io/halo/.","authors":["Yuezhan Tao","Dexter Ong","Fernando Cladera","Jason Hughes","Camillo J. Taylor","Pratik Chaudhari","Vijay Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17496v1","updated":"2025-11-21T18:53:11Z","published":"2025-11-21T18:53:11Z","title":"MDG: Masked Denoising Generation for Multi-Agent Behavior Modeling in Traffic Environments","summary":"Modeling realistic and interactive multi-agent behavior is critical to autonomous driving and traffic simulation. However, existing diffusion and autoregressive approaches are limited by iterative sampling, sequential decoding, or task-specific designs, which hinder efficiency and reuse. We propose Masked Denoising Generation (MDG), a unified generative framework that reformulates multi-agent behavior modeling as the reconstruction of independently noised spatiotemporal tensors. Instead of relying on diffusion time steps or discrete tokenization, MDG applies continuous, per-agent and per-timestep noise masks that enable localized denoising and controllable trajectory generation in a single or few forward passes. This mask-driven formulation generalizes across open-loop prediction, closed-loop simulation, motion planning, and conditional generation within one model. Trained on large-scale real-world driving datasets, MDG achieves competitive closed-loop performance on the Waymo Sim Agents and nuPlan Planning benchmarks, while providing efficient, consistent, and controllable open-loop multi-agent trajectory generation. These results position MDG as a simple yet versatile paradigm for multi-agent behavior modeling.","authors":["Zhiyu Huang","Zewei Zhou","Tianhui Cai","Yun Zhang","Jiaqi Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17441v1","updated":"2025-11-21T17:39:22Z","published":"2025-11-21T17:39:22Z","title":"RoboCOIN: An Open-Sourced Bimanual Robotic Data COllection for INtegrated Manipulation","summary":"Bimanual manipulation is essential for achieving human-like dexterity in robots, but the large-scale and diverse bimanual robot datasets remain scarce due to hardware heterogeneity across robotic platforms. To address the challenge, we present RoboCOIN, a comprehensive multi-embodiment bimanual manipulation dataset with over 180,000 demonstrations collected from 15 distinct robotic platforms. The dataset covers 16 scenarios, including residential, commercial, and working environments, with 421 tasks systematically organized by bimanual coordination patterns and object properties. Our key innovation is a hierarchical capability pyramid that provides multi-level annotations, spanning trajectory-level concepts, segment-level subtasks, and frame-level kinematics. We further develop CoRobot, a comprehensive processing framework featuring Robot Trajectory Markup Language (RTML) for quality assessment, automated annotation generation, and unified multi-embodiment management. Extensive experiments demonstrate the reliability and effectiveness of RoboCOIN in multi-embodiment bimanual learning, with significant performance improvements across various model architectures and robotic platforms. The complete dataset and framework are open-sourced and publicly available for further research purposes. Project website: https://FlagOpen.github.io/RoboCOIN/.","authors":["Shihan Wu","Xuecheng Liu","Shaoxuan Xie","Pengwei Wang","Xinghang Li","Bowen Yang","Zhe Li","Kai Zhu","Hongyu Wu","Yiheng Liu","Zhaoye Long","Yue Wang","Chong Liu","Dihan Wang","Ziqiang Ni","Xiang Yang","You Liu","Ruoxuan Feng","Runtian Xu","Lei Zhang","Denghang Huang","Chenghao Jin","Anlan Yin","Xinlong Wang","Zhenguo Sun","Junkai Zhao","Mengfei Du","Mingyu Cao","Xiansheng Chen","Hongyang Cheng","Xiaojie Zhang","Yankai Fu","Ning Chen","Cheng Chi","Sixiang Chen","Huaihai Lyu","Xiaoshuai Hao","Yankai Fu","Yequan Wang","Bo Lei","Dong Liu","Xi Yang","Yance Jiao","Tengfei Pan","Yunyan Zhang","Songjing Wang","Ziqian Zhang","Xu Liu","Ji Zhang","Caowei Meng","Zhizheng Zhang","Jiyang Gao","Song Wang","Xiaokun Leng","Zhiqiang Xie","Zhenzhen Zhou","Peng Huang","Wu Yang","Yandong Guo","Yichao Zhu","Suibing Zheng","Hao Cheng","Xinmin Ding","Yang Yue","Huanqian Wang","Chi Chen","Jingrui Pang","YuXi Qian","Haoran Geng","Lianli Gao","Haiyuan Li","Bin Fang","Gao Huang","Yaodong Yang","Hao Dong","He Wang","Hang Zhao","Yadong Mu","Di Hu","Hao Zhao","Tiejun Huang","Shanghang Zhang","Yonghua Lin","Zhongyuan Wang","Guocai Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17411v1","updated":"2025-11-21T17:09:43Z","published":"2025-11-21T17:09:43Z","title":"SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding","summary":"Robotic Foundation Models (RFMs) hold great promise as generalist, end-to-end systems for robot control. Yet their ability to generalize across new environments, tasks, and embodiments remains limited. We argue that a major bottleneck lies in their foundations: most RFMs are built by fine-tuning internet-pretrained Vision-Language Models (VLMs). However, these VLMs are trained on 2D image-language tasks and lack the 3D spatial reasoning inherently required for embodied control in the 3D world. Bridging this gap directly with large-scale robotic data is costly and difficult to scale. Instead, we propose to enrich easy-to-collect non-robotic image data with 3D annotations and enhance a pretrained VLM with 3D understanding capabilities. Following this strategy, we train SPEAR-VLM, a 3D-aware VLM that infers object coordinates in 3D space from a single 2D image. Building on SPEAR-VLM, we introduce our main contribution, $~\\textbf{SPEAR-1}$: a robotic foundation model that integrates grounded 3D perception with language-instructed embodied control. Trained on $\\sim$45M frames from 24 Open X-Embodiment datasets, SPEAR-1 outperforms or matches state-of-the-art models such as $π_0$-FAST and $π_{0.5}$, while it uses 20$\\times$ fewer robot demonstrations. This carefully-engineered training strategy unlocks new VLM capabilities and as a consequence boosts the reliability of embodied control beyond what is achievable with only robotic data. We make our model weights and 3D-annotated datasets publicly available.","authors":["Nikolay Nikolov","Giuliano Albanese","Sombit Dey","Aleksandar Yanev","Luc Van Gool","Jan-Nico Zaech","Danda Pani Paudel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17401v1","updated":"2025-11-21T17:00:48Z","published":"2025-11-21T17:00:48Z","title":"Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment","summary":"Non-invasive electroencephalography (EEG)-based brain-computer interfaces (BCIs) offer an intuitive means for individuals with severe motor impairments to independently operate assistive robotic wheelchairs and navigate built environments. Despite considerable progress in BCI research, most current motion control systems are limited to discrete commands, rather than supporting continuous pursuit, where users can freely adjust speed and direction in real time. Such natural mobility control is, however, essential for wheelchair users to navigate complex public spaces, such as transit stations, airports, hospitals, and indoor corridors, to interact socially with the dynamic populations with agility, and to move flexibly and comfortably as autonomous driving is refined to allow movement at will. In this study, we address the gap of continuous pursuit motion control in BCIs by proposing and validating a brain-inspired Bayesian inference framework, where embodied dynamics in acceleration-based motor representations are decoded. This approach contrasts with conventional kinematics-level decoding and deep learning-based methods. Using a public dataset with sixteen hours of EEG from four subjects performing motor imagery-based target-following, we demonstrate that our method, utilizing Automatic Relevance Determination for feature selection and continual online learning, reduces the normalized mean squared error between predicted and true velocities by 72% compared to autoregressive and EEGNet-based methods in a session-accumulative transfer learning setting. Theoretically, these findings empirically support embodied cognition theory and reveal the brain's intrinsic motor control dynamics in an embodied and predictive nature. Practically, grounding EEG decoding in the same dynamical principles that govern biological motion offers a promising path toward more stable and intuitive BCI control.","authors":["Xiaoshan Zhou","Carol C. Menassa","Vineet R. Kamat"],"pdf_url":"","comment":"37 pages, 9 figures, and 7 tables"},{"id":"http://arxiv.org/abs/2511.17387v1","updated":"2025-11-21T16:50:00Z","published":"2025-11-21T16:50:00Z","title":"Human Imitated Bipedal Locomotion with Frequency Based Gait Generator Network","summary":"Learning human-like, robust bipedal walking remains difficult due to hybrid dynamics and terrain variability. We propose a lightweight framework that combines a gait generator network learned from human motion with Proximal Policy Optimization (PPO) controller for torque control. Despite being trained only on flat or mildly sloped ground, the learned policies generalize to steeper ramps and rough surfaces. Results suggest that pairing spectral motion priors with Deep Reinforcement Learning (DRL) offers a practical path toward natural and robust bipedal locomotion with modest training cost.","authors":["Yusuf Baran Ates","Omer Morgul"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17384v1","updated":"2025-11-21T16:48:49Z","published":"2025-11-21T16:48:49Z","title":"IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation","summary":"While Visual Large Language Models (VLLMs) show great promise as embodied agents, they continue to face substantial challenges in spatial reasoning. Existing embodied benchmarks largely focus on passive, static household environments and evaluate only isolated capabilities, failing to capture holistic performance in dynamic, real-world complexity. To fill this gap, we present IndustryNav, the first dynamic industrial navigation benchmark for active spatial reasoning. IndustryNav leverages 12 manually created, high-fidelity Unity warehouse scenarios featuring dynamic objects and human movement. Our evaluation employs a PointGoal navigation pipeline that effectively combines egocentric vision with global odometry to assess holistic local-global planning. Crucially, we introduce the \"collision rate\" and \"warning rate\" metrics to measure safety-oriented behaviors and distance estimation. A comprehensive study of nine state-of-the-art VLLMs (including models such as GPT-5-mini, Claude-4.5, and Gemini-2.5) reveals that closed-source models maintain a consistent advantage; however, all agents exhibit notable deficiencies in robust path planning, collision avoidance and active exploration. This highlights a critical need for embodied research to move beyond passive perception and toward tasks that demand stable planning, active exploration, and safe behavior in dynamic, real-world environment.","authors":["Yifan Li","Lichi Li","Anh Dao","Xinyu Zhou","Yicheng Qiao","Zheda Mai","Daeun Lee","Zichen Chen","Zhen Tan","Mohit Bansal","Yu Kong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17375v1","updated":"2025-11-21T16:37:50Z","published":"2025-11-21T16:37:50Z","title":"Vector Cost Behavioral Planning for Autonomous Robotic Systems with Contemporary Validation Strategies","summary":"The vector cost bimatrix game is a method for multi-objective decision making that enables autonomous robotic systems to optimize for multiple goals at once while avoiding worst-case scenarios in neglected objectives. We expand this approach to arbitrary numbers of objectives and compare its performance to scalar weighted sum methods during competitive motion planning. Explainable Artificial Intelligence (XAI) software is used to aid in the analysis of high dimensional decision-making data. State-space Exploration of Multidimensional Boundaries using Adherence Strategies (SEMBAS) is applied to explore performance modes in the parameter space as a sensitivity study for the baseline and proposed frameworks. While some works have explored aspects of game theoretic planning and intelligent systems validation separately, we combine each of these into a novel and comprehensive simulation pipeline. This integration demonstrates a dramatic improvement of the vector cost method over scalarization and offers an interpretable and generalizable framework for robotic behavioral planning. Code available at https://github.com/toazbenj/race_simulation. The video companion to this work is available at https://tinyurl.com/vectorcostvideo.","authors":["Benjamin R. Toaz","Quentin Goss","John Thompson","Seta Boğosyan","Shaunak D. Bopardikar","Mustafa İlhan Akbaş","Metin Gökaşan"],"pdf_url":"","comment":"Technical report associated with submission to Journal of Intelligent & Robotic Systems, currently under review"},{"id":"http://arxiv.org/abs/2511.17373v1","updated":"2025-11-21T16:37:24Z","published":"2025-11-21T16:37:24Z","title":"Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data","summary":"Humanoid robots are envisioned to perform a wide range of tasks in human-centered environments, requiring controllers that combine agility with robust balance. Recent advances in locomotion and whole-body tracking have enabled impressive progress in either agile dynamic skills or stability-critical behaviors, but existing methods remain specialized, focusing on one capability while compromising the other. In this work, we introduce AMS (Agility Meets Stability), the first framework that unifies both dynamic motion tracking and extreme balance maintenance in a single policy. Our key insight is to leverage heterogeneous data sources: human motion capture datasets that provide rich, agile behaviors, and physically constrained synthetic balance motions that capture stability configurations. To reconcile the divergent optimization goals of agility and stability, we design a hybrid reward scheme that applies general tracking objectives across all data while injecting balance-specific priors only into synthetic motions. Further, an adaptive learning strategy with performance-driven sampling and motion-specific reward shaping enables efficient training across diverse motion distributions. We validate AMS extensively in simulation and on a real Unitree G1 humanoid. Experiments demonstrate that a single policy can execute agile skills such as dancing and running, while also performing zero-shot extreme balance motions like Ip Man's Squat, highlighting AMS as a versatile control paradigm for future humanoid applications.","authors":["Yixuan Pan","Ruoyi Qiao","Li Chen","Kashyap Chitta","Liang Pan","Haoguang Mai","Qingwen Bu","Hao Zhao","Cunyuan Zheng","Ping Luo","Hongyang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17366v1","updated":"2025-11-21T16:32:36Z","published":"2025-11-21T16:32:36Z","title":"METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model","summary":"Building a generalist robot that can perceive, reason, and act across diverse tasks remains an open challenge, especially for dexterous manipulation. A major bottleneck lies in the scarcity of large-scale, action-annotated data for dexterous skills, as teleoperation is difficult and costly. Human data, with its vast scale and diverse manipulation behaviors, provides rich priors for learning robotic actions. While prior works have explored leveraging human demonstrations, they are often constrained by limited scenarios and a large visual gap between human and robots. To eliminate these limitations, we propose METIS, a vision-language-action (VLA) model for dexterous manipulation pretrained on multi-source egocentric datasets. We first construct EgoAtlas, which integrates large-scale human and robotic data from multiple sources, all unified under a consistent action space. We further extract motion-aware dynamics, a compact and discretized motion representation, which provides efficient and expressive supervision for VLA training. Built upon them, METIS integrates reasoning and acting into a unified framework, enabling effective deployment to downstream dexterous manipulation tasks. Our method demonstrates exceptional dexterous manipulation capabilities, achieving highest average success rate in six real-world tasks. Experimental results also highlight the superior generalization and robustness to out-of-distribution scenarios. These findings emphasize METIS as a promising step toward a generalist model for dexterous manipulation.","authors":["Yankai Fu","Ning Chen","Junkai Zhao","Shaozhe Shan","Guocai Yao","Pengwei Wang","Zhongyuan Wang","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17335v1","updated":"2025-11-21T15:55:25Z","published":"2025-11-21T15:55:25Z","title":"Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM","summary":"Human-robot collaboration towards a shared goal requires robots to understand human action and interaction with the surrounding environment. This paper focuses on human-robot interaction (HRI) based on human-robot dialogue that relies on the robot action confirmation and action step generation using multimodal scene understanding. The state-of-the-art approach uses multimodal transformers to generate robot action steps aligned with robot action confirmation from a single clip showing a task composed of multiple micro steps. Although actions towards a long-horizon task depend on each other throughout an entire video, the current approaches mainly focus on clip-level processing and do not leverage long-context information. This paper proposes a long-context Q-former incorporating left and right context dependency in full videos. Furthermore, this paper proposes a text-conditioning approach to feed text embeddings directly into the LLM decoder to mitigate the high abstraction of the information in text by Q-former. Experiments with the YouCook2 corpus show that the accuracy of confirmation generation is a major factor in the performance of action planning. Furthermore, we demonstrate that the long-context Q-former improves the confirmation and action planning by integrating VideoLLaMA3.","authors":["Chiori Hori","Yoshiki Masuyama","Siddarth Jain","Radu Corcodel","Devesh Jha","Diego Romeres","Jonathan Le Roux"],"pdf_url":"","comment":"Accepted to ASRU 2025"},{"id":"http://arxiv.org/abs/2511.17318v1","updated":"2025-11-21T15:36:41Z","published":"2025-11-21T15:36:41Z","title":"FORWARD: Dataset of a forwarder operating in rough terrain","summary":"We present FORWARD, a high-resolution multimodal dataset of a cut-to-length forwarder operating in rough terrain on two harvest sites in the middle part of Sweden. The forwarder is a large Komatsu model equipped with a variety of sensors, including RTK-GNSS, 360-camera, operator vibration sensors, internal CAN-bus signal recording, and multiple IMUs. The data includes event time logs recorded in 5 Hz with e.g., driving speed, fuel consumption, vehicle position with centimeter accuracy, and crane use while the vehicle operates in forest areas laser-scanned with very high-resolution, $\\sim$1500 points per square meter. Production log files (StanForD standard) with time-stamped machine events, extensive video material, and terrain data in various formats are included as well. About 18 hours of regular wood extraction work during three days is annotated from 360-video material into individual work elements and included in the dataset. We also include scenario specifications of conducted experiments on forest roads and in terrain. Scenarios include repeatedly driving the same routes with and without steel tracks, different load weight, and different target driving speeds. The dataset is intended for developing models and algorithms for trafficability, perception, and autonomous control of forest machines using artificial intelligence, simulation, and experiments on physical testbeds. In part, we focus on forwarders traversing terrain, avoiding obstacles, and loading or unloading logs, with consideration for efficiency, fuel consumption, safety, and environmental impact. Other benefits of the open dataset include the ability to explore auto-generation and calibration of forestry machine simulators and automation scenario descriptions using the data recorded in the field.","authors":["Mikael Lundbäck","Erik Wallin","Carola Häggström","Mattias Nyström","Andreas Grönlund","Mats Richardson","Petrus Jönsson","William Arnvik","Lucas Hedström","Arvid Fälldin","Martin Servin"],"pdf_url":"","comment":"25 pages, 22 figures"},{"id":"http://arxiv.org/abs/2511.17299v1","updated":"2025-11-21T15:11:15Z","published":"2025-11-21T15:11:15Z","title":"MonoSpheres: Large-Scale Monocular SLAM-Based UAV Exploration through Perception-Coupled Mapping and Planning","summary":"Autonomous exploration of unknown environments is a key capability for mobile robots, but it is largely unsolved for robots equipped with only a single monocular camera and no dense range sensors. In this paper, we present a novel approach to monocular vision-based exploration that can safely cover large-scale unstructured indoor and outdoor 3D environments by explicitly accounting for the properties of a sparse monocular SLAM frontend in both mapping and planning. The mapping module solves the problems of sparse depth data, free-space gaps, and large depth uncertainty by oversampling free space in texture-sparse areas and keeping track of obstacle position uncertainty. The planning module handles the added free-space uncertainty through rapid replanning and perception-aware heading control. We further show that frontier-based exploration is possible with sparse monocular depth data when parallax requirements and the possibility of textureless surfaces are taken into account. We evaluate our approach extensively in diverse real-world and simulated environments, including ablation studies. To the best of the authors' knowledge, the proposed method is the first to achieve 3D monocular exploration in real-world unstructured outdoor environments. We open-source our implementation to support future research.","authors":["Tomáš Musil","Matěj Petrlík","Martin Saska"],"pdf_url":"","comment":"8 pages, 9 figures, submitted to RA-L"},{"id":"http://arxiv.org/abs/2511.17276v1","updated":"2025-11-21T14:31:39Z","published":"2025-11-21T14:31:39Z","title":"Leveraging CVAE for Joint Configuration Estimation of Multifingered Grippers from Point Cloud Data","summary":"This paper presents an efficient approach for determining the joint configuration of a multifingered gripper solely from the point cloud data of its poly-articulated chain, as generated by visual sensors, simulations or even generative neural networks. Well-known inverse kinematics (IK) techniques can provide mathematically exact solutions (when they exist) for joint configuration determination based solely on the fingertip pose, but often require post-hoc decision-making by considering the positions of all intermediate phalanges in the gripper's fingers, or rely on algorithms to numerically approximate solutions for more complex kinematics. In contrast, our method leverages machine learning to implicitly overcome these challenges. This is achieved through a Conditional Variational Auto-Encoder (CVAE), which takes point cloud data of key structural elements as input and reconstructs the corresponding joint configurations. We validate our approach on the MultiDex grasping dataset using the Allegro Hand, operating within 0.05 milliseconds and achieving accuracy comparable to state-of-the-art methods. This highlights the effectiveness of our pipeline for joint configuration estimation within the broader context of AI-driven techniques for grasp planning.","authors":["Julien Merand","Boris Meden","Mathieu Grossard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17266v1","updated":"2025-11-21T14:13:34Z","published":"2025-11-21T14:13:34Z","title":"Simulation of Active Soft Nets for Capture of Space Debris","summary":"In this work, we propose a simulator, based on the open-source physics engine MuJoCo, for the design and control of soft robotic nets for the autonomous removal of space debris. The proposed simulator includes net dynamics, contact between the net and the debris, self-contact of the net, orbital mechanics, and a controller that can actuate thrusters on the four satellites at the corners of the net. It showcases the case of capturing Envisat, a large ESA satellite that remains in orbit as space debris following the end of its mission. This work investigates different mechanical models, which can be used to simulate the net dynamics, simulating various degrees of compliance, and different control strategies to achieve the capture of the debris, depending on the relative position of the net and the target. Unlike previous works on this topic, we do not assume that the net has been previously ballistically thrown toward the target, and we start from a relatively static configuration. The results show that a more compliant net achieves higher performance when attempting the capture of Envisat. Moreover, when paired with a sliding mode controller, soft nets are able to achieve successful capture in 100% of the tested cases, whilst also showcasing a higher effective area at contact and a higher number of contact points between net and Envisat.","authors":["Leone Costi","Dario Izzo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.19660v2","updated":"2025-11-21T13:36:38Z","published":"2024-10-25T16:10:32Z","title":"Perception, Control and Hardware for In-Hand Slip-Aware Object Manipulation with Parallel Grippers","summary":"Dexterous in-hand manipulation offers significant potential to enhance robotic manipulator capabilities. This paper presents a sensori-motor architecture for in-hand slip-aware control, being embodied in a sensorized gripper. The gripper in our architecture features rapid closed-loop, low-level force control, and is equipped with sensors capable of independently measuring contact forces and sliding velocities. Our system can quickly estimate essential object properties during pick-up using only in-hand sensing, without relying on prior object information. We introduce four distinct slippage controllers: gravity-assisted trajectory following for both rotational and linear slippage, a hinge controller that maintains the object's orientation while the gripper rotates, and a slip-avoidance controller. The gripper is mounted on a robot arm and validated through extensive experiments involving a diverse range of objects, demonstrating the architecture's novel capabilities for manipulating objects with flat surfaces.","authors":["Gabriel Arslan Waltersson","Yiannis Karayiannidis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17237v1","updated":"2025-11-21T13:29:23Z","published":"2025-11-21T13:29:23Z","title":"A ROS2 Interface for Universal Robots Collaborative Manipulators Based on ur_rtde","summary":"In this paper a novel ROS2 driver for UR robot manipulators is presented, based on the ur_rtde C++ library. The proposed driver aims to be a flexible solution, adaptable to a wide range of applications. The driver exposes the high-level commands of Universal Robots URScripts, and custom commands can be added using a plugin system. Several commands have been implemented, including motion execution along a waypoint-based path. The driver is published as open source.","authors":["Alessio Saccuti","Riccardo Monica","Jacopo Aleotti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17225v1","updated":"2025-11-21T13:12:13Z","published":"2025-11-21T13:12:13Z","title":"TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making","summary":"In daily life, people often move through spaces to find objects that meet their needs, posing a key challenge in embodied AI. Traditional Demand-Driven Navigation (DDN) handles one need at a time but does not reflect the complexity of real-world tasks involving multiple needs and personal choices. To bridge this gap, we introduce Task-Preferenced Multi-Demand-Driven Navigation (TP-MDDN), a new benchmark for long-horizon navigation involving multiple sub-demands with explicit task preferences. To solve TP-MDDN, we propose AWMSystem, an autonomous decision-making system composed of three key modules: BreakLLM (instruction decomposition), LocateLLM (goal selection), and StatusMLLM (task monitoring). For spatial memory, we design MASMap, which combines 3D point cloud accumulation with 2D semantic mapping for accurate and efficient environmental understanding. Our Dual-Tempo action generation framework integrates zero-shot planning with policy-based fine control, and is further supported by an Adaptive Error Corrector that handles failure cases in real time. Experiments demonstrate that our approach outperforms state-of-the-art baselines in both perception accuracy and navigation robustness.","authors":["Shanshan Li","Da Huang","Yu He","Yanwei Fu","Yu-Gang Jiang","Xiangyang Xue"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.17221v1","updated":"2025-11-21T13:05:42Z","published":"2025-11-21T13:05:42Z","title":"QueryOcc: Query-based Self-Supervision for 3D Semantic Occupancy","summary":"Learning 3D scene geometry and semantics from images is a core challenge in computer vision and a key capability for autonomous driving. Since large-scale 3D annotation is prohibitively expensive, recent work explores self-supervised learning directly from sensor data without manual labels. Existing approaches either rely on 2D rendering consistency, where 3D structure emerges only implicitly, or on discretized voxel grids from accumulated lidar point clouds, limiting spatial precision and scalability. We introduce QueryOcc, a query-based self-supervised framework that learns continuous 3D semantic occupancy directly through independent 4D spatio-temporal queries sampled across adjacent frames. The framework supports supervision from either pseudo-point clouds derived from vision foundation models or raw lidar data. To enable long-range supervision and reasoning under constant memory, we introduce a contractive scene representation that preserves near-field detail while smoothly compressing distant regions. QueryOcc surpasses previous camera-based methods by 26% in semantic RayIoU on the self-supervised Occ3D-nuScenes benchmark while running at 11.6 FPS, demonstrating that direct 4D query supervision enables strong self-supervised occupancy learning. https://research.zenseact.com/publications/queryocc/","authors":["Adam Lilja","Ji Lan","Junsheng Fu","Lars Hammarstrand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.09878v4","updated":"2025-11-21T12:54:49Z","published":"2025-03-12T22:18:29Z","title":"CleverDistiller: Simple and Spatially Consistent Cross-modal Distillation","summary":"Vision foundation models (VFMs) such as DINO have led to a paradigm shift in 2D camera-based perception towards extracting generalized features to support many downstream tasks. Recent works introduce self-supervised cross-modal knowledge distillation (KD) as a way to transfer these powerful generalization capabilities into 3D LiDAR-based models. However, they either rely on highly complex distillation losses, pseudo-semantic maps, or limit KD to features useful for semantic segmentation only. In this work, we propose CleverDistiller, a self-supervised, cross-modal 2D-to-3D KD framework introducing a set of simple yet effective design choices: Unlike contrastive approaches relying on complex loss design choices, our method employs a direct feature similarity loss in combination with a multi layer perceptron (MLP) projection head to allow the 3D network to learn complex semantic dependencies throughout the projection. Crucially, our approach does not depend on pseudo-semantic maps, allowing for direct knowledge transfer from a VFM without explicit semantic supervision. Additionally, we introduce the auxiliary self-supervised spatial task of occupancy prediction to enhance the semantic knowledge, obtained from a VFM through KD, with 3D spatial reasoning capabilities. Experiments on standard autonomous driving benchmarks for 2D-to-3D KD demonstrate that CleverDistiller achieves state-of-the-art performance in both semantic segmentation and 3D object detection (3DOD) by up to 10% mIoU, especially when fine tuning on really low data amounts, showing the effectiveness of our simple yet powerful KD strategy","authors":["Hariprasath Govindarajan","Maciej K. Wozniak","Marvin Klingner","Camille Maurice","B Ravi Kiran","Senthil Yogamani"],"pdf_url":"","comment":"Accepted to BMVC 2025"},{"id":"http://arxiv.org/abs/2511.17207v1","updated":"2025-11-21T12:40:55Z","published":"2025-11-21T12:40:55Z","title":"SING3R-SLAM: Submap-based Indoor Monocular Gaussian SLAM with 3D Reconstruction Priors","summary":"Recent advances in dense 3D reconstruction enable the accurate capture of local geometry; however, integrating them into SLAM is challenging due to drift and redundant point maps, which limit efficiency and downstream tasks, such as novel view synthesis. To address these issues, we propose SING3R-SLAM, a globally consistent and compact Gaussian-based dense RGB SLAM framework. The key idea is to combine locally consistent 3D reconstructions with a unified global Gaussian representation that jointly refines scene geometry and camera poses, enabling efficient and versatile 3D mapping for multiple downstream applications. SING3R-SLAM first builds locally consistent submaps through our lightweight tracking and reconstruction module, and then progressively aligns and fuses them into a global Gaussian map that enforces cross-view geometric consistency. This global map, in turn, provides feedback to correct local drift and enhance the robustness of tracking. Extensive experiments demonstrate that SING3R-SLAM achieves state-of-the-art tracking, 3D reconstruction, and novel view rendering, resulting in over 12% improvement in tracking and producing finer, more detailed geometry, all while maintaining a compact and memory-efficient global representation on real-world datasets.","authors":["Kunyi Li","Michael Niemeyer","Sen Wang","Stefano Gasperini","Nassir Navab","Federico Tombari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00423v2","updated":"2025-11-21T12:39:02Z","published":"2025-11-01T06:33:04Z","title":"Bootstrap Off-policy with World Model","summary":"Online planning has proven effective in reinforcement learning (RL) for improving sample efficiency and final performance. However, using planning for environment interaction inevitably introduces a divergence between the collected data and the policy's actual behaviors, degrading both model learning and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy with WOrld Model), a framework that tightly integrates planning and off-policy learning through a bootstrap loop: the policy initializes the planner, and the planner refines actions to bootstrap the policy through behavior alignment. This loop is supported by a jointly learned world model, which enables the planner to simulate future trajectories and provides value targets to facilitate policy improvement. The core of BOOM is a likelihood-free alignment loss that bootstraps the policy using the planner's non-parametric action distribution, combined with a soft value-weighted mechanism that prioritizes high-return behaviors and mitigates variability in the planner's action quality within the replay buffer. Experiments on the high-dimensional DeepMind Control Suite and Humanoid-Bench show that BOOM achieves state-of-the-art results in both training stability and final performance. The code is accessible at https://github.com/molumitu/BOOM_MBRL.","authors":["Guojian Zhan","Likun Wang","Xiangteng Zhang","Jiaxin Gao","Masayoshi Tomizuka","Shengbo Eben Li"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2506.08708v2","updated":"2025-11-21T12:13:42Z","published":"2025-06-10T11:46:06Z","title":"PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly","summary":"While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.","authors":["Liang Ma","Jiajun Wen","Min Lin","Rongtao Xu","Xiwen Liang","Bingqian Lin","Jun Ma","Yongxin Wang","Ziming Wei","Haokun Lin","Mingfei Han","Meng Cao","Bokui Chen","Ivan Laptev","Xiaodan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17178v1","updated":"2025-11-21T11:56:52Z","published":"2025-11-21T11:56:52Z","title":"Efficient Robot Design with Multi-Objective Black-Box Optimization and Large Language Models","summary":"Various methods for robot design optimization have been developed so far. These methods are diverse, ranging from numerical optimization to black-box optimization. While numerical optimization is fast, it is not suitable for cases involving complex structures or discrete values, leading to frequent use of black-box optimization instead. However, black-box optimization suffers from low sampling efficiency and takes considerable sampling iterations to obtain good solutions. In this study, we propose a method to enhance the efficiency of robot body design based on black-box optimization by utilizing large language models (LLMs). In parallel with the sampling process based on black-box optimization, sampling is performed using LLMs, which are provided with problem settings and extensive feedback. We demonstrate that this method enables more efficient exploration of design solutions and discuss its characteristics and limitations.","authors":["Kento Kawaharazuka","Yoshiki Obinata","Naoaki Kanazawa","Haoyu Jia","Kei Okada"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17166v1","updated":"2025-11-21T11:34:08Z","published":"2025-11-21T11:34:08Z","title":"Reflection-Based Relative Localization for Cooperative UAV Teams Using Active Markers","summary":"Reflections of active markers in the environment are a common source of ambiguity in onboard visual relative localization. This work presents a novel approach for onboard relative localization in multi-robot teams that exploits these typically unwanted reflections of active markers in the environment. It operates without prior knowledge of robot size or predefined marker configurations and remains independent of surface properties, an essential feature for heterogeneous micro-aerial swarms cooperating in unknown environments. It explicitly accounts for uncertainties caused by non-flat surfaces, with a particular focus on dynamic water surfaces, which are especially relevant for marine deployments. We validated the approach in both indoor and outdoor experiments, demonstrating that the proposed reflection-based localization system operates reliably without prior knowledge of team member size and achieves greater effective range (above 30 m) and accuracy than state-of-the-art methods. The video and source code of this work will be made publicly available after publication.","authors":["Tim Lakemann","Daniel Bonilla Licea","Viktor Walter","Martin Saska"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17097v1","updated":"2025-11-21T09:52:07Z","published":"2025-11-21T09:52:07Z","title":"Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation","summary":"Vision-Language Navigation requires agents to act coherently over long horizons by understanding not only local visual context but also how far they have advanced within a multi-step instruction. However, recent Vision-Language-Action models focus on direct action prediction and earlier progress methods predict numeric achievements; both overlook the monotonic co-progression property of the observation and instruction sequences. Building on this insight, Progress-Think introduces semantic progress reasoning, predicting instruction-style progress from visual observations to enable more accurate navigation. To achieve this without expensive annotations, we propose a three-stage framework. In the initial stage, Self-Aligned Progress Pretraining bootstraps a reasoning module via a novel differentiable alignment between visual history and instruction prefixes. Then, Progress-Guided Policy Pretraining injects learned progress states into the navigation context, guiding the policy toward consistent actions. Finally, Progress-Policy Co-Finetuning jointly optimizes both modules with tailored progress-aware reinforcement objectives. Experiments on R2R-CE and RxR-CE show state-of-the-art success and efficiency, demonstrating that semantic progress yields a more consistent representation of navigation advancement.","authors":["Shuo Wang","Yucheng Wang","Guoxin Lian","Yongcai Wang","Maiyue Chen","Kaihui Wang","Bo Zhang","Zhizhong Su","Yutian Zhou","Wanting Li","Deying Li","Zhaoxin Fan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17079v1","updated":"2025-11-21T09:34:57Z","published":"2025-11-21T09:34:57Z","title":"H-GAR: A Hierarchical Interaction Framework via Goal-Driven Observation-Action Refinement for Robotic Manipulation","summary":"Unified video and action prediction models hold great potential for robotic manipulation, as future observations offer contextual cues for planning, while actions reveal how interactions shape the environment. However, most existing approaches treat observation and action generation in a monolithic and goal-agnostic manner, often leading to semantically misaligned predictions and incoherent behaviors. To this end, we propose H-GAR, a Hierarchical interaction framework via Goal-driven observation-Action Refinement.To anchor prediction to the task objective, H-GAR first produces a goal observation and a coarse action sketch that outline a high-level route toward the goal. To enable explicit interaction between observation and action under the guidance of the goal observation for more coherent decision-making, we devise two synergistic modules. (1) Goal-Conditioned Observation Synthesizer (GOS) synthesizes intermediate observations based on the coarse-grained actions and the predicted goal observation. (2) Interaction-Aware Action Refiner (IAAR) refines coarse actions into fine-grained, goal-consistent actions by leveraging feedback from the intermediate observations and a Historical Action Memory Bank that encodes prior actions to ensure temporal consistency. By integrating goal grounding with explicit action-observation interaction in a coarse-to-fine manner, H-GAR enables more accurate manipulation. Extensive experiments on both simulation and real-world robotic manipulation tasks demonstrate that H-GAR achieves state-of-the-art performance.","authors":["Yijie Zhu","Rui Shao","Ziyang Liu","Jie He","Jizhihui Liu","Jiuru Wang","Zitong Yu"],"pdf_url":"","comment":"Accepted to AAAI 2026 (Oral), Project Page: https://github.com/JiuTian-VL/H-GAR"},{"id":"http://arxiv.org/abs/2511.17076v1","updated":"2025-11-21T09:28:31Z","published":"2025-11-21T09:28:31Z","title":"A segment anchoring-based balancing algorithm for agricultural multi-robot task allocation with energy constraints","summary":"Multi-robot systems have emerged as a key technology for addressing the efficiency and cost challenges in labor-intensive industries. In the representative scenario of smart farming, planning efficient harvesting schedules for a fleet of electric robots presents a highly challenging frontier problem. The complexity arises not only from the need to find Pareto-optimal solutions for the conflicting objectives of makespan and transportation cost, but also from the necessity to simultaneously manage payload constraints and finite battery capacity. When robot loads are dynamically updated during planned multi-trip operations, a mandatory recharge triggered by energy constraints introduces an unscheduled load reset. This interaction creates a complex cascading effect that disrupts the entire schedule and renders traditional optimization methods ineffective. To address this challenge, this paper proposes the segment anchoring-based balancing algorithm (SABA). The core of SABA lies in the organic combination of two synergistic mechanisms: the sequential anchoring and balancing mechanism, which leverages charging decisions as `anchors' to systematically reconstruct disrupted routes, while the proportional splitting-based rebalancing mechanism is responsible for the fine-grained balancing and tuning of the final solutions' makespans. Extensive comparative experiments, conducted on a real-world case study and a suite of benchmark instances, demonstrate that SABA comprehensively outperforms 6 state-of-the-art algorithms in terms of both solution convergence and diversity. This research provides a novel theoretical perspective and an effective solution for the multi-robot task allocation problem under energy constraints.","authors":["Peng Chen","Jing Liang","Kang-Jia Qiao","Hui Song","Tian-lei Ma","Kun-Jie Yu","Cai-Tong Yue","Ponnuthurai Nagaratnam Suganthan","Witold Pedryc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03135v2","updated":"2025-11-21T08:32:29Z","published":"2025-10-03T16:04:33Z","title":"Mask2IV: Interaction-Centric Video Generation via Mask Trajectories","summary":"Generating interaction-centric videos, such as those depicting humans or robots interacting with objects, is crucial for embodied intelligence, as they provide rich and diverse visual priors for robot learning, manipulation policy training, and affordance reasoning. However, existing methods often struggle to model such complex and dynamic interactions. While recent studies show that masks can serve as effective control signals and enhance generation quality, obtaining dense and precise mask annotations remains a major challenge for real-world use. To overcome this limitation, we introduce Mask2IV, a novel framework specifically designed for interaction-centric video generation. It adopts a decoupled two-stage pipeline that first predicts plausible motion trajectories for both actor and object, then generates a video conditioned on these trajectories. This design eliminates the need for dense mask inputs from users while preserving the flexibility to manipulate the interaction process. Furthermore, Mask2IV supports versatile and intuitive control, allowing users to specify the target object of interaction and guide the motion trajectory through action descriptions or spatial position cues. To support systematic training and evaluation, we curate two benchmarks covering diverse action and object categories across both human-object interaction and robotic manipulation scenarios. Extensive experiments demonstrate that our method achieves superior visual realism and controllability compared to existing baselines.","authors":["Gen Li","Bo Zhao","Jianfei Yang","Laura Sevilla-Lara"],"pdf_url":"","comment":"AAAI 2026. Project page: https://reagan1311.github.io/mask2iv"},{"id":"http://arxiv.org/abs/2506.13428v2","updated":"2025-11-21T07:56:03Z","published":"2025-06-16T12:44:45Z","title":"VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation","summary":"Dual-arm cooperative manipulation holds great promise for tackling complex real-world tasks that demand seamless coordination and adaptive dynamics. Despite substantial progress in learning-based motion planning, most approaches struggle to generalize across diverse manipulation tasks and adapt to dynamic, unstructured environments, particularly in scenarios involving interactions between two objects such as assembly, tool use, and bimanual grasping. To address these challenges, we introduce a novel VLM-Assisted Siamese Flow Diffusion (VLM-SFD) framework for efficient imitation learning in dual-arm cooperative manipulation. The proposed VLM-SFD framework exhibits outstanding adaptability, significantly enhancing the ability to rapidly adapt and generalize to diverse real-world tasks from only a minimal number of human demonstrations. Specifically, we propose a Siamese Flow Diffusion Network (SFDNet) employs a dual-encoder-decoder Siamese architecture to embed two target objects into a shared latent space, while a diffusion-based conditioning process - conditioned by task instructions - generates two-stream object-centric motion flows that guide dual-arm coordination. We further design a dynamic task assignment strategy that seamlessly maps the predicted 2D motion flows into 3D space and incorporates a pre-trained vision-language model (VLM) to adaptively assign the optimal motion to each robotic arm over time. Experiments validate the effectiveness of the proposed method, demonstrating its ability to generalize to diverse manipulation tasks while maintaining high efficiency and adaptability. The code and demo videos are publicly available on our project website https://sites.google.com/view/vlm-sfd/.","authors":["Jiaming Chen","Yiyu Jiang","Aoshen Huang","Yang Li","Wei Pan"],"pdf_url":"","comment":"Accepted by IEEE RA-L"},{"id":"http://arxiv.org/abs/2511.17013v1","updated":"2025-11-21T07:30:24Z","published":"2025-11-21T07:30:24Z","title":"MfNeuPAN: Proactive End-to-End Navigation in Dynamic Environments via Direct Multi-Frame Point Constraints","summary":"Obstacle avoidance in complex and dynamic environments is a critical challenge for real-time robot navigation. Model-based and learning-based methods often fail in highly dynamic scenarios because traditional methods assume a static environment and cannot adapt to real-time changes, while learning-based methods rely on single-frame observations for motion constraint estimation, limiting their adaptability. To overcome these limitations, this paper proposes a novel framework that leverages multi-frame point constraints, including current and future frames predicted by a dedicated module, to enable proactive end-to-end navigation. By incorporating a prediction module that forecasts the future path of moving obstacles based on multi-frame observations, our method allows the robot to proactively anticipate and avoid potential dangers. This proactive planning capability significantly enhances navigation robustness and efficiency in unknown dynamic environments. Simulations and real-world experiments validate the effectiveness of our approach.","authors":["Yiwen Ying","Hanjing Ye","Senzi Luo","Luyao Liu","Yu Zhan","Li He","Hong Zhang"],"pdf_url":"","comment":"6 pages, 9 figures, accepted at IEEE ROBIO 2025"},{"id":"http://arxiv.org/abs/2511.17001v1","updated":"2025-11-21T07:10:31Z","published":"2025-11-21T07:10:31Z","title":"Stable Offline Hand-Eye Calibration for any Robot with Just One Mark","summary":"Imitation learning has achieved remarkable success in a variety of robotic tasks by learning a mapping function from camera-space observations to robot-space actions. Recent work indicates that the use of robot-to-camera transformation information ({\\ie}, camera extrinsics) benefits the learning process and produces better results. However, camera extrinsics are oftentimes unavailable and estimation methods usually suffer from local minima and poor generalizations. In this paper, we present CalibAll, a simple yet effective method that \\textbf{requires only a single mark} and performs training-free, stable, and accurate camera extrinsic estimation across diverse robots and datasets through a coarse-to-fine calibration pipeline. In particular, we annotate a single mark on an end-effector (EEF), and leverage the correspondence ability emerged from vision foundation models (VFM) to automatically localize the corresponding mark across robots in diverse datasets. Using this mark, together with point tracking and the 3D EEF trajectory, we obtain a coarse camera extrinsic via temporal Perspective-n-Point (PnP). This estimate is further refined through a rendering-based optimization that aligns rendered and ground-true masks, yielding accurate and stable camera extrinsic. Experimental results demonstrate that our method outperforms state-of-the-art approaches, showing strong robustness and general effectiveness across three robot platforms. It also produces useful auxiliary annotations such as depth maps, link-wise masks, and end-effector 2D trajectories, which can further support downstream tasks.","authors":["Sicheng Xie","Lingchen Meng","Zhiying Du","Shuyuan Tu","Haidong Cao","Jiaqi Leng","Zuxuan Wu","Yu-Gang Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16949v1","updated":"2025-11-21T04:53:21Z","published":"2025-11-21T04:53:21Z","title":"MobileOcc: A Human-Aware Semantic Occupancy Dataset for Mobile Robots","summary":"Dense 3D semantic occupancy perception is critical for mobile robots operating in pedestrian-rich environments, yet it remains underexplored compared to its application in autonomous driving. To address this gap, we present MobileOcc, a semantic occupancy dataset for mobile robots operating in crowded human environments. Our dataset is built using an annotation pipeline that incorporates static object occupancy annotations and a novel mesh optimization framework explicitly designed for human occupancy modeling. It reconstructs deformable human geometry from 2D images and subsequently refines and optimizes it using associated LiDAR point data. Using MobileOcc, we establish benchmarks for two tasks, i) Occupancy prediction and ii) Pedestrian velocity prediction, using different methods including monocular, stereo, and panoptic occupancy, with metrics and baseline implementations for reproducible comparison. Beyond occupancy prediction, we further assess our annotation method on 3D human pose estimation datasets. Results demonstrate that our method exhibits robust performance across different datasets.","authors":["Junseo Kim","Guido Dumont","Xinyu Gao","Gang Chen","Holger Caesar","Javier Alonso-Mora"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.18694v2","updated":"2025-11-21T04:30:13Z","published":"2025-08-26T05:39:47Z","title":"AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot","summary":"Advances in AI and Robotics have accelerated significant initiatives in agriculture, particularly in the areas of robot navigation and 3D digital twin creation. A significant bottleneck impeding this progress is the critical lack of \"in-the-wild\" datasets that capture the full complexities of real farmland, including non-rigid motion from wind, drastic illumination variance, and morphological changes resulting from growth. This data gap fundamentally limits research on robust AI models for autonomous field navigation and scene-level dynamic 3D reconstruction. In this paper, we present AgriChrono, a modular robotic data collection platform and multi-modal dataset designed to capture these dynamic farmland conditions. Our platform integrates multiple sensors, enabling remote, time-synchronized acquisition of RGB, Depth, LiDAR, IMU, and Pose data for efficient and repeatable long-term data collection in real-world agricultural environments. We successfully collected 18TB of data over one month, documenting the entire growth cycle of Canola under diverse illumination conditions. We benchmark state-of-the-art 3D reconstruction methods on AgriChrono, revealing the profound challenge of reconstructing high-fidelity, dynamic non-rigid scenes in such farmland settings. This benchmark validates AgriChrono as a critical asset for advancing model generalization, and its public release is expected to significantly accelerate research and development in precision agriculture. The code and dataset are publicly available at: https://github.com/StructuresComp/agri-chrono","authors":["Jaehwan Jeong","Tuan-Anh Vu","Mohammad Jony","Shahab Ahmad","Md. Mukhlesur Rahman","Sangpil Kim","M. Khalid Jawed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16911v1","updated":"2025-11-21T02:48:32Z","published":"2025-11-21T02:48:32Z","title":"Multi-UAV Swarm Obstacle Avoidance Based on Potential Field Optimization","summary":"In multi UAV scenarios,the traditional Artificial Potential Field (APF) method often leads to redundant flight paths and frequent abrupt heading changes due to unreasonable obstacle avoidance path planning,and is highly prone to inter UAV collisions during the obstacle avoidance process.To address these issues,this study proposes a novel hybrid algorithm that combines the improved Multi-Robot Formation Obstacle Avoidance (MRF IAPF) algorithm with an enhanced APF optimized for single UAV path planning.Its core ideas are as follows:first,integrating three types of interaction forces from MRF IAPF obstacle repulsion force,inter UAV interaction force,and target attraction force;second,incorporating a refined single UAV path optimization mechanism,including collision risk assessment and an auxiliary sub goal strategy.When a UAV faces a high collision threat,temporary waypoints are generated to guide obstacle avoidance,ensuring eventual precise arrival at the actual target.Simulation results demonstrate that compared with traditional APF based formation algorithms,the proposed algorithm achieves significant improvements in path length optimization and heading stability,can effectively avoid obstacles and quickly restore the formation configuration,thus verifying its applicability and effectiveness in static environments with unknown obstacles.","authors":["Yendo Hu","Yiliang Wu","Weican Chen"],"pdf_url":"","comment":"12 pages, 13 figures, and 2 tables"},{"id":"http://arxiv.org/abs/2511.16898v1","updated":"2025-11-21T02:24:24Z","published":"2025-11-21T02:24:24Z","title":"Single-Pixel Tactile Skin via Compressive Sampling","summary":"Development of large-area, high-speed electronic skins is a grand challenge for robotics, prosthetics, and human-machine interfaces, but is fundamentally limited by wiring complexity and data bottlenecks. Here, we introduce Single-Pixel Tactile Skin (SPTS), a paradigm that uses compressive sampling to reconstruct rich tactile information from an entire sensor array via a single output channel. This is achieved through a direct circuit-level implementation where each sensing element, equipped with a miniature microcontroller, contributes a dynamically weighted analog signal to a global sum, performing distributed compressed sensing in hardware. Our flexible, daisy-chainable design simplifies wiring to a few input lines and one output, and significantly reduces measurement requirements compared to raster scanning methods. We demonstrate the system's performance by achieving object classification at an effective 3500 FPS and by capturing transient dynamics, resolving an 8 ms projectile impact into 23 frames. A key feature is the support for adaptive reconstruction, where sensing fidelity scales with measurement time. This allows for rapid contact localization using as little as 7% of total data, followed by progressive refinement to a high-fidelity image - a capability critical for responsive robotic systems. This work offers an efficient pathway towards large-scale tactile intelligence for robotics and human-machine interfaces.","authors":["Ariel Slepyan","Laura Xing","Rudy Zhang","Nitish Thakor"],"pdf_url":"","comment":"24 pages, 6 main figures, 6 supplemental figures"},{"id":"http://arxiv.org/abs/2511.06182v2","updated":"2025-11-21T00:57:14Z","published":"2025-11-09T01:50:53Z","title":"OpenVLN: Open-world Aerial Vision-Language Navigation","summary":"Vision-language models (VLMs) have been widely-applied in ground-based vision-language navigation (VLN). However, the vast complexity of outdoor aerial environments compounds data acquisition challenges and imposes long-horizon trajectory planning requirements on Unmanned Aerial Vehicles (UAVs), introducing novel complexities for aerial VLN. To address these challenges, we propose a data-efficient Open-world aerial Vision-Language Navigation (i.e., OpenVLN) framework, which could execute language-guided flight with limited data constraints and enhance long-horizon trajectory planning capabilities in complex aerial environments. Specifically, we reconfigure a reinforcement learning framework to optimize the VLM for UAV navigation tasks, which can efficiently fine-tune VLM by using rule-based policies under limited training data. Concurrently, we introduce a long-horizon planner for trajectory synthesis that dynamically generates precise UAV actions via value-based rewards. To the end, we conduct sufficient navigation experiments on the TravelUAV benchmark with dataset scaling across diverse reward settings. Our method demonstrates consistent performance gains of up to 4.34% in Success Rate, 6.19% in Oracle Success Rate, and 4.07% in Success weighted by Path Length over baseline methods, validating its deployment efficacy for long-horizon UAV navigation in complex aerial environments.","authors":["Peican Lin","Gan Sun","Chenxi Liu","Fazeng Li","Weihong Ren","Yang Cong"],"pdf_url":"","comment":"Content: 8 pages 4 figures, conference paper under review"},{"id":"http://arxiv.org/abs/2505.05592v3","updated":"2025-11-21T23:01:58Z","published":"2025-05-08T18:43:39Z","title":"Learning to Drive Anywhere with Model-Based Reannotation","summary":"Developing broadly generalizable visual navigation policies for robots is a significant challenge, primarily constrained by the availability of large-scale, diverse training data. While curated datasets collected by researchers offer high quality, their limited size restricts policy generalization. To overcome this, we explore leveraging abundant, passively collected data sources, including large volumes of crowd-sourced teleoperation data and unlabeled YouTube videos, despite their potential for lower quality or missing action labels. We propose Model-Based ReAnnotation (MBRA), a framework that utilizes a learned short-horizon, model-based expert model to relabel or generate high-quality actions for these passive datasets. This relabeled data is then distilled into LogoNav, a long-horizon navigation policy conditioned on visual goals or GPS waypoints. We demonstrate that LogoNav, trained using MBRA-processed data, achieves state-of-the-art performance, enabling robust navigation over distances exceeding 300 meters in previously unseen indoor and outdoor environments. Our extensive real-world evaluations, conducted across a fleet of robots (including quadrupeds) in six cities on three continents, validate the policy's ability to generalize and navigate effectively even amidst pedestrians in crowded settings.","authors":["Noriaki Hirose","Lydia Ignatova","Kyle Stachowicz","Catherine Glossop","Sergey Levine","Dhruv Shah"],"pdf_url":"","comment":"9 pages, 8 figures, 6 tables"},{"id":"http://arxiv.org/abs/2511.17824v1","updated":"2025-11-21T22:38:16Z","published":"2025-11-21T22:38:16Z","title":"QAL: A Loss for Recall Precision Balance in 3D Reconstruction","summary":"Volumetric learning underpins many 3D vision tasks such as completion, reconstruction, and mesh generation, yet training objectives still rely on Chamfer Distance (CD) or Earth Mover's Distance (EMD), which fail to balance recall and precision. We propose Quality-Aware Loss (QAL), a drop-in replacement for CD/EMD that combines a coverage-weighted nearest-neighbor term with an uncovered-ground-truth attraction term, explicitly decoupling recall and precision into tunable components.\n  Across diverse pipelines, QAL achieves consistent coverage gains, improving by an average of +4.3 pts over CD and +2.8 pts over the best alternatives. Though modest in percentage, these improvements reliably recover thin structures and under-represented regions that CD/EMD overlook. Extensive ablations confirm stable performance across hyperparameters and across output resolutions, while full retraining on PCN and ShapeNet demonstrates generalization across datasets and backbones. Moreover, QAL-trained completions yield higher grasp scores under GraspNet evaluation, showing that improved coverage translates directly into more reliable robotic manipulation.\n  QAL thus offers a principled, interpretable, and practical objective for robust 3D vision and safety-critical robotics pipelines","authors":["Pranay Meshram","Yash Turkar","Kartikeya Singh","Praveen Raj Masilamani","Charuvahan Adhivarahan","Karthik Dantu"],"pdf_url":"","comment":"Accepted to WACV 2026. Camera-ready version to appear"},{"id":"http://arxiv.org/abs/2505.01383v3","updated":"2025-11-21T22:11:10Z","published":"2025-05-02T16:47:05Z","title":"FalconWing: An Ultra-Light Indoor Fixed-Wing UAV Platform for Vision-Based Autonomy","summary":"We introduce FalconWing, an ultra-light (150 g) indoor fixed-wing UAV platform for vision-based autonomy. Controlled indoor environment enables year-round repeatable UAV experiment but imposes strict weight and maneuverability limits on the UAV, motivating our ultra-light FalconWing design. FalconWing couples a lightweight hardware stack (137g airframe with a 9g camera) and offboard computation with a software stack featuring a photorealistic 3D Gaussian Splat (GSplat) simulator for developing and evaluating vision-based controllers. We validate FalconWing on two challenging vision-based aerial case studies. In the leader-follower case study, our best vision-based controller, trained via imitation learning on GSplat-rendered data augmented with domain randomization, achieves 100% tracking success across 3 types of leader maneuvers over 30 trials and shows robustness to leader's appearance shifts in simulation. In the autonomous landing case study, our vision-based controller trained purely in simulation transfers zero-shot to real hardware, achieving an 80% success rate over ten landing trials. We will release hardware designs, GSplat scenes, and dynamics models upon publication to make FalconWing an open-source flight kit for engineering students and research labs.","authors":["Yan Miao","Will Shen","Hang Cui","Sayan Mitra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17798v1","updated":"2025-11-21T21:42:59Z","published":"2025-11-21T21:42:59Z","title":"SM$^2$ITH: Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control","summary":"Mobile manipulators are designed to perform complex sequences of navigation and manipulation tasks in human-centered environments. While recent optimization-based methods such as Hierarchical Task Model Predictive Control (HTMPC) enable efficient multitask execution with strict task priorities, they have so far been applied mainly to static or structured scenarios. Extending these approaches to dynamic human-centered environments requires predictive models that capture how humans react to the actions of the robot. This work introduces Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control (SM$^2$ITH), a unified framework that combines HTMPC with interactive human motion prediction through bilevel optimization that jointly accounts for robot and human dynamics. The framework is validated on two different mobile manipulators, the Stretch 3 and the Ridgeback-UR10, across three experimental settings: (i) delivery tasks with different navigation and manipulation priorities, (ii) sequential pick-and-place tasks with different human motion prediction models, and (iii) interactions involving adversarial human behavior. Our results highlight how interactive prediction enables safe and efficient coordination, outperforming baselines that rely on weighted objectives or open-loop human models.","authors":["Francesco D'Orazio","Sepehr Samavi","Xintong Du","Siqi Zhou","Giuseppe Oriolo","Angela P. Schoellig"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17792v1","updated":"2025-11-21T21:36:02Z","published":"2025-11-21T21:36:02Z","title":"Target-Bench: Can World Models Achieve Mapless Path Planning with Semantic Targets?","summary":"While recent world models generate highly realistic videos, their ability to perform robot path planning remains unclear and unquantified. We introduce Target-Bench, the first benchmark specifically designed to evaluate world models on mapless path planning toward semantic targets in real-world environments. Target-Bench provides 450 robot-collected video sequences spanning 45 semantic categories with SLAM-based ground truth trajectories. Our evaluation pipeline recovers camera motion from generated videos and measures planning performance using five complementary metrics that quantify target-reaching capability, trajectory accuracy, and directional consistency. We evaluate state-of-the-art models including Sora 2, Veo 3.1, and the Wan series. The best off-the-shelf model (Wan2.2-Flash) achieves only 0.299 overall score, revealing significant limitations in current world models for robotic planning tasks. We show that fine-tuning an open-source 5B-parameter model on only 325 scenarios from our dataset achieves 0.345 overall score -- an improvement of more than 400% over its base version (0.066) and 15% higher than the best off-the-shelf model. We will open-source the code and dataset.","authors":["Dingrui Wang","Hongyuan Ye","Zhihao Liang","Zhexiao Sun","Zhaowei Lu","Yuchen Zhang","Yuyu Zhao","Yuan Gao","Marvin Seegert","Finn Schäfer","Haotong Qin","Wei Li","Luigi Palmieri","Felix Jahncke","Mattia Piccinini","Johannes Betz"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2511.17781v1","updated":"2025-11-21T20:58:27Z","published":"2025-11-21T20:58:27Z","title":"SAFE-SMART: Safety Analysis and Formal Evaluation using STL Metrics for Autonomous RoboTs","summary":"We present a novel, regulator-driven approach for post hoc safety evaluation of learning-based, black-box autonomous mobile robots, ensuring ongoing compliance with evolving, human-defined safety rules. In our iterative workflow, human safety requirements are translated by regulators into Signal Temporal Logic (STL) specifications. Rollout traces from the black-box model are externally verified for compliance, yielding quantitative safety metrics, Total Robustness Value (TRV) and Largest Robustness Value (LRV), which measure average and worst-case specification adherence. These metrics inform targeted retraining and iterative improvement by model designers. We apply our method across two different applications: a virtual driving scenario and an autonomous mobile robot navigating a complex environment, and observe statistically significant improvements across both scenarios. In the virtual driving scenario, we see a 177% increase in traces adhering to the simulation speed limit, a 1138% increase in traces minimizing off-road driving, and a 16% increase in traces successfully reaching the goal within the time limit. In the autonomous navigation scenario, there is a 300% increase in traces avoiding sharp turns, a 200% increase in traces reaching the goal within the time limit, and a 49% increase in traces minimizing time spent near obstacles. Finally, we validate our approach on a TurtleBot3 robot in the real world, and demonstrate improved obstacle navigation with safety buffers.","authors":["Kristy Sakano","Jianyu An","Dinesh Manocha","Huan Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17777v1","updated":"2025-11-21T20:48:05Z","published":"2025-11-21T20:48:05Z","title":"See, Plan, Cut: MPC-Based Autonomous Volumetric Robotic Laser Surgery with OCT Guidance","summary":"Robotic laser systems offer the potential for sub-millimeter, non-contact, high-precision tissue resection, yet existing platforms lack volumetric planning and intraoperative feedback. We present RATS (Robot-Assisted Tissue Surgery), an intelligent opto-mechanical, optical coherence tomography (OCT)-guided robotic platform designed for autonomous volumetric soft tissue resection in surgical applications. RATS integrates macro-scale RGB-D imaging, micro-scale OCT, and a fiber-coupled surgical laser, calibrated through a novel multistage alignment pipeline that achieves OCT-to-laser calibration accuracy of 0.161+-0.031mm on tissue phantoms and ex vivo porcine tissue. A super-Gaussian laser-tissue interaction (LTI) model characterizes ablation crater morphology with an average RMSE of 0.231+-0.121mm, outperforming Gaussian baselines. A sampling-based model predictive control (MPC) framework operates directly on OCT voxel data to generate constraint-aware resection trajectories with closed-loop feedback, achieving 0.842mm RMSE and improving intersection-over-union agreement by 64.8% compared to feedforward execution. With OCT, RATS detects subsurface structures and modifies the planner's objective to preserve them, demonstrating clinical feasibility.","authors":["Ravi Prakash","Vincent Y. Wang","Arpit Mishra","Devi Yuliarti","Pei Zhong","Ryan P. McNabb","Patrick J. Codd","Leila J. Bridgeman"],"pdf_url":"","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.17774v1","updated":"2025-11-21T20:43:46Z","published":"2025-11-21T20:43:46Z","title":"Learning Diffusion Policies for Robotic Manipulation of Timber Joinery under Fabrication Uncertainty","summary":"Construction uncertainties such as fabrication inaccuracies and material imperfections pose a significant challenge to contact-rich robotic manipulation by hindering precise and robust assembly. In this paper, we explore the performance and robustness of diffusion policy learning as a promising solution for contact-sensitive robotic assembly at construction scale, using timber mortise and tenon joints as a case study. A two-phase study is conducted: first, to evaluate policy performance and applicability; second, to assess robustness in handling fabrication uncertainties simulated as randomized perturbations to the mortise position. The best-performing policy achieved a total average success rate of 75% with perturbations up to 10 mm, including 100% success in unperturbed cases. The results demonstrate the potential of sensory-motor diffusion policies to generalize to a wide range of complex, contact-rich assembly tasks across construction and manufacturing, advancing robotic construction under uncertainty and contributing to safer, more efficient building practices.","authors":["Salma Mozaffari","Daniel Ruan","William van den Bogert","Nima Fazeli","Sigrid Adriaenssens","Arash Adel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17765v1","updated":"2025-11-21T20:29:03Z","published":"2025-11-21T20:29:03Z","title":"LEARN: Learning End-to-End Aerial Resource-Constrained Multi-Robot Navigation","summary":"Nano-UAV teams offer great agility yet face severe navigation challenges due to constrained onboard sensing, communication, and computation. Existing approaches rely on high-resolution vision or compute-intensive planners, rendering them infeasible for these platforms. We introduce LEARN, a lightweight, two-stage safety-guided reinforcement learning (RL) framework for multi-UAV navigation in cluttered spaces. Our system combines low-resolution Time-of-Flight (ToF) sensors and a simple motion planner with a compact, attention-based RL policy. In simulation, LEARN outperforms two state-of-the-art planners by $10\\%$ while using substantially fewer resources. We demonstrate LEARN's viability on six Crazyflie quadrotors, achieving fully onboard flight in diverse indoor and outdoor environments at speeds up to $2.0 m/s$ and traversing $0.2 m$ gaps.","authors":["Darren Chiu","Zhehui Huang","Ruohai Ge","Gaurav S. Sukhatme"],"pdf_url":"","comment":"20 pages, 15 figures"},{"id":"http://arxiv.org/abs/2508.08574v2","updated":"2025-11-21T20:24:20Z","published":"2025-08-12T02:19:15Z","title":"DeepFleet: Multi-Agent Foundation Models for Mobile Robots","summary":"We introduce DeepFleet, a suite of foundation models designed to support coordination and planning for large-scale mobile robot fleets. These models are trained on fleet movement data, including robot positions, goals, and interactions, from hundreds of thousands of robots in Amazon warehouses worldwide. DeepFleet consists of four architectures that each embody a distinct inductive bias and collectively explore key points in the design space for multi-agent foundation models: the robot-centric (RC) model is an autoregressive decision transformer operating on neighborhoods of individual robots; the robot-floor (RF) model uses a transformer with cross-attention between robots and the warehouse floor; the image-floor (IF) model applies convolutional encoding to a multi-channel image representation of the full fleet; and the graph-floor (GF) model combines temporal attention with graph neural networks for spatial relationships. In this paper, we describe these models and present our evaluation of the impact of these design choices on prediction task performance. We find that the robot-centric and graph-floor models, which both use asynchronous robot state updates and incorporate the localized structure of robot interactions, show the most promise. We also present experiments that show that these two models can make effective use of larger warehouses operation datasets as the models are scaled up.","authors":["Ameya Agaskar","Sriram Siva","William Pickering","Kyle O'Brien","Charles Kekeh","Ang Li","Brianna Gallo Sarker","Alicia Chua","Mayur Nemade","Charun Thattai","Jiaming Di","Isaac Iyengar","Ramya Dharoor","Dino Kirouani","Jimmy Erskine","Tamir Hegazy","Scott Niekum","Usman A. Khan","Federico Pecora","Joseph W. Durham"],"pdf_url":"","comment":"27 pages, 10 figures, 2 tables"},{"id":"http://arxiv.org/abs/2511.17720v1","updated":"2025-11-21T19:16:37Z","published":"2025-11-21T19:16:37Z","title":"Vision-Guided Optic Flow Navigation for Small Lunar Missions","summary":"Private lunar missions are faced with the challenge of robust autonomous navigation while operating under stringent constraints on mass, power, and computational resources. This work proposes a motion-field inversion framework that uses optical flow and rangefinder-based depth estimation as a lightweight CPU-based solution for egomotion estimation during lunar descent. We extend classical optical flow formulations by integrating them with depth modeling strategies tailored to the geometry for lunar/planetary approach, descent, and landing, specifically, planar and spherical terrain approximations parameterized by a laser rangefinder. Motion field inversion is performed through a least-squares framework, using sparse optical flow features extracted via the pyramidal Lucas-Kanade algorithm. We verify our approach using synthetically generated lunar images over the challenging terrain of the lunar south pole, using CPU budgets compatible with small lunar landers. The results demonstrate accurate velocity estimation from approach to landing, with sub-10% error for complex terrain and on the order of 1% for more typical terrain, as well as performances suitable for real-time applications. This framework shows promise for enabling robust, lightweight on-board navigation for small lunar missions.","authors":["Sean Cowan","Pietro Fanti","Leon B. S. Williams","Chit Hong Yam","Kaneyasu Asakuma","Yuichiro Nada","Dario Izzo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10059v2","updated":"2025-11-21T19:06:33Z","published":"2025-10-11T06:53:01Z","title":"Ionospheric and Plasmaspheric Delay Characterization for Lunar Terrestrial GNSS Receivers with Global Core Plasma Model","summary":"Recent advancements in lunar positioning, navigation, and timing (PNT) have demonstrated that terrestrial GNSS signals, including weak sidelobe transmissions, can be exploited for lunar spacecraft positioning and timing. While GNSS-based navigation at the Moon has been validated recently, unmodeled ionospheric and plasmaspheric delays remain a significant error source, particularly given the unique signal geometry and extended propagation paths. This paper characterizes these delays using the Global Core Plasma Model (GCPM) and a custom low-cost ray-tracing algorithm that iteratively solves for bent signal paths. We simulate first-, second-, and third-order group delays, as well as excess path length from ray bending, for GNSS signals received at both lunar orbit and the lunar south pole under varying solar and geomagnetic conditions. Results show that mean group delays are typically on the order of 1 m, but can exceed 100 m for low-altitude ray paths during high solar activity, while bending delays are generally smaller but non-negligible for low-altitude ray paths. We also quantify the influence of signal frequency, geomagnetic $K_p$ index, and solar R12 index. These findings inform the design of robust positioning and timing algorithms that utilize terrestrial GNSS signals.","authors":["Keidai Iiyama","Grace Gao"],"pdf_url":"","comment":"Submitted NAVIGATION: Journal of the Institute of Navigation"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2511.17501v1","updated":"2025-11-21T18:59:26Z","published":"2025-11-21T18:59:26Z","title":"Native 3D Editing with Full Attention","summary":"Instruction-guided 3D editing is a rapidly emerging field with the potential to broaden access to 3D content creation. However, existing methods face critical limitations: optimization-based approaches are prohibitively slow, while feed-forward approaches relying on multi-view 2D editing often suffer from inconsistent geometry and degraded visual quality. To address these issues, we propose a novel native 3D editing framework that directly manipulates 3D representations in a single, efficient feed-forward pass. Specifically, we create a large-scale, multi-modal dataset for instruction-guided 3D editing, covering diverse addition, deletion, and modification tasks. This dataset is meticulously curated to ensure that edited objects faithfully adhere to the instructional changes while preserving the consistency of unedited regions with the source object. Building upon this dataset, we explore two distinct conditioning strategies for our model: a conventional cross-attention mechanism and a novel 3D token concatenation approach. Our results demonstrate that token concatenation is more parameter-efficient and achieves superior performance. Extensive evaluations show that our method outperforms existing 2D-lifting approaches, setting a new benchmark in generation quality, 3D consistency, and instruction fidelity.","authors":["Weiwei Cai","Shuangkang Fang","Weicai Ye","Xin Dong","Yunhan Yang","Xuanyang Zhang","Wei Cheng","Yanpei Cao","Gang Yu","Tao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17492v1","updated":"2025-11-21T18:49:18Z","published":"2025-11-21T18:49:18Z","title":"EvDiff: High Quality Video with an Event Camera","summary":"As neuromorphic sensors, event cameras asynchronously record changes in brightness as streams of sparse events with the advantages of high temporal resolution and high dynamic range. Reconstructing intensity images from events is a highly ill-posed task due to the inherent ambiguity of absolute brightness. Early methods generally follow an end-to-end regression paradigm, directly mapping events to intensity frames in a deterministic manner. While effective to some extent, these approaches often yield perceptually inferior results and struggle to scale up in model capacity and training data. In this work, we propose EvDiff, an event-based diffusion model that follows a surrogate training framework to produce high-quality videos. To reduce the heavy computational cost of high-frame-rate video generation, we design an event-based diffusion model that performs only a single forward diffusion step, equipped with a temporally consistent EvEncoder. Furthermore, our novel Surrogate Training Framework eliminates the dependence on paired event-image datasets, allowing the model to leverage large-scale image datasets for higher capacity. The proposed EvDiff is capable of generating high-quality colorful videos solely from monochromatic event streams. Experiments on real-world datasets demonstrate that our method strikes a sweet spot between fidelity and realism, outperforming existing approaches on both pixel-level and perceptual metrics.","authors":["Weilun Li","Lei Sun","Ruixi Gao","Qi Jiang","Yuqin Ma","Kaiwei Wang","Ming-Hsuan Yang","Luc Van Gool","Danda Pani Paudel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17490v1","updated":"2025-11-21T18:47:09Z","published":"2025-11-21T18:47:09Z","title":"Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination","summary":"Understanding text-rich videos requires reading small, transient textual cues that often demand repeated inspection. Yet most video QA models rely on single-pass perception over fixed frames, leading to hallucinations and failures on fine-grained evidence. Inspired by how humans pause, zoom, and re-read critical regions, we introduce Video-R4 (Reinforcing Text-Rich Video Reasoning with Visual Rumination), a video reasoning LMM that performs visual rumination: iteratively selecting frames, zooming into informative regions, re-encoding retrieved pixels, and updating its reasoning state. We construct two datasets with executable rumination trajectories: Video-R4-CoT-17k for supervised practice and Video-R4-RL-30k for reinforcement learning. We propose a multi-stage rumination learning framework that progressively finetunes a 7B LMM to learn atomic and mixing visual operations via SFT and GRPO-based RL. Video-R4-7B achieves state-of-the-art results on M4-ViteVQA and further generalizes to multi-page document QA, slides QA, and generic video QA, demonstrating that iterative rumination is an effective paradigm for pixel-grounded multimodal reasoning.","authors":["Yolo Yunlong Tang","Daiki Shimada","Hang Hua","Chao Huang","Jing Bi","Rogerio Feris","Chenliang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17487v1","updated":"2025-11-21T18:43:01Z","published":"2025-11-21T18:43:01Z","title":"Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models","summary":"Scaling up multimodal models has enabled remarkable advances in visual understanding and reasoning, but practical demands call for smaller, efficient systems. In this work, we conduct a principled analysis of downscaling intelligence in multimodal models, examining how reduced large language model (LLM) capacity affects multimodal capabilities. Our initial findings reveal an interesting trend: LLM downscaling disproportionately affects visual capabilities, rather than abilities inherited from the LLM. We then examine whether this drop mainly reflects the expected decline in visual reasoning or a more fundamental loss of perceptual abilities. Isolating the effect of LLM downscaling on perception, we find performance still drops sharply, often matching or exceeding the impact on reasoning. To address this bottleneck, we introduce visual extraction tuning, which explicitly trains the model to extract instruction-relevant visual details consistently across tasks. With these extracted visual details, we then apply step-by-step reasoning to generate answers. Together, these components form our Extract+Think approach, setting a new standard for efficiency and performance in this space.","authors":["Mark Endo","Serena Yeung-Levy"],"pdf_url":"","comment":"Website at https://web.stanford.edu/~markendo/projects/downscaling_intelligence"},{"id":"http://arxiv.org/abs/2511.17485v1","updated":"2025-11-21T18:40:21Z","published":"2025-11-21T18:40:21Z","title":"An Artificial Intelligence Framework for Measuring Human Spine Aging Using MRI","summary":"The human spine is a complex structure composed of 33 vertebrae. It holds the body and is important for leading a healthy life. The spine is vulnerable to age-related degenerations that can be identified through magnetic resonance imaging (MRI). In this paper we propose a novel computer-vison-based deep learning method to estimate spine age using images from over 18,000 MRI series. Data are restricted to subjects with only age-related spine degeneration. Eligibility criteria are created by identifying common age-based clusters of degenerative spine conditions using uniform manifold approximation and projection (UMAP) and hierarchical density-based spatial clustering of applications with noise (HDBSCAN). Model selection is determined using a detailed ablation study on data size, loss, and the effect of different spine regions. We evaluate the clinical utility of our model by calculating the difference between actual spine age and model-predicted age, the spine age gap (SAG), and examining the association between these differences and spine degenerative conditions and lifestyle factors. We find that SAG is associated with conditions including disc bulges, disc osteophytes, spinal stenosis, and fractures, as well as lifestyle factors like smoking and physically demanding work, and thus may be a useful biomarker for measuring overall spine health.","authors":["Roozbeh Bazargani","Saqib Abdullah Basar","Daniel Daly-Grafstein","Rodrigo Solis Pompa","Soojin Lee","Saurabh Garg","Yuntong Ma","John A. Carrino","Siavash Khallaghi","Sam Hashemi"],"pdf_url":"","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.17484v1","updated":"2025-11-21T18:40:03Z","published":"2025-11-21T18:40:03Z","title":"Radar2Shape: 3D Shape Reconstruction from High-Frequency Radar using Multiresolution Signed Distance Functions","summary":"Determining the shape of 3D objects from high-frequency radar signals is analytically complex but critical for commercial and aerospace applications. Previous deep learning methods have been applied to radar modeling; however, they often fail to represent arbitrary shapes or have difficulty with real-world radar signals which are collected over limited viewing angles. Existing methods in optical 3D reconstruction can generate arbitrary shapes from limited camera views, but struggle when they naively treat the radar signal as a camera view. In this work, we present Radar2Shape, a denoising diffusion model that handles a partially observable radar signal for 3D reconstruction by correlating its frequencies with multiresolution shape features. Our method consists of a two-stage approach: first, Radar2Shape learns a regularized latent space with hierarchical resolutions of shape features, and second, it diffuses into this latent space by conditioning on the frequencies of the radar signal in an analogous coarse-to-fine manner. We demonstrate that Radar2Shape can successfully reconstruct arbitrary 3D shapes even from partially-observed radar signals, and we show robust generalization to two different simulation methods and real-world data. Additionally, we release two synthetic benchmark datasets to encourage future research in the high-frequency radar domain so that models like Radar2Shape can safely be adapted into real-world radar systems.","authors":["Neel Sortur","Justin Goodwin","Purvik Patel","Luis Enrique Martinez","Tzofi Klinghoffer","Rajmonda S. Caceres","Robin Walters"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17481v1","updated":"2025-11-21T18:37:23Z","published":"2025-11-21T18:37:23Z","title":"Counterfactual World Models via Digital Twin-conditioned Video Diffusion","summary":"World models learn to predict the temporal evolution of visual observations given a control signal, potentially enabling agents to reason about environments through forward simulation. Because of the focus on forward simulation, current world models generate predictions based on factual observations. For many emerging applications, such as comprehensive evaluations of physical AI behavior under varying conditions, the ability of world models to answer counterfactual queries, such as \"what would happen if this object was removed?\", is of increasing importance. We formalize counterfactual world models that additionally take interventions as explicit inputs, predicting temporal sequences under hypothetical modifications to observed scene properties. Traditional world models operate directly on entangled pixel-space representations where object properties and relationships cannot be selectively modified. This modeling choice prevents targeted interventions on specific scene properties. We introduce CWMDT, a framework to overcome those limitations, turning standard video diffusion models into effective counterfactual world models. First, CWMDT constructs digital twins of observed scenes to explicitly encode objects and their relationships, represented as structured text. Second, CWMDT applies large language models to reason over these representations and predict how a counterfactual intervention propagates through time to alter the observed scene. Third, CWMDT conditions a video diffusion model with the modified representation to generate counterfactual visual sequences. Evaluations on two benchmarks show that the CWMDT approach achieves state-of-the-art performance, suggesting that alternative representations of videos, such as the digital twins considered here, offer powerful control signals for video forward simulation-based world models.","authors":["Yiqing Shen","Aiza Maksutova","Chenjia Li","Mathias Unberath"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00511v3","updated":"2025-11-21T18:35:34Z","published":"2025-11-01T11:29:14Z","title":"ID-Crafter: VLM-Grounded Online RL for Compositional Multi-Subject Video Generation","summary":"Significant progress has been achieved in high-fidelity video synthesis, yet current paradigms often fall short in effectively integrating identity information from multiple subjects. This leads to semantic conflicts and suboptimal performance in preserving identities and interactions, limiting controllability and applicability. To tackle this issue, we introduce ID-Crafter, a framework for multi-subject video generation that achieves superior identity preservation and semantic coherence. ID-Crafter integrates three key components: (i) a hierarchical identity-preserving attention mechanism that progressively aggregates features at intra-subject, inter-subject, and cross-modal levels; (ii) a semantic understanding module powered by a pretrained Vision-Language Model (VLM) to provide fine-grained guidance and capture complex inter-subject relationships; and (iii) an online reinforcement learning phase to further refine the model for critical concepts. Furthermore, we construct a new dataset to facilitate robust training and evaluation. Extensive experiments demonstrate that ID-Crafter establishes new state-of-the-art performance on multi-subject video generation benchmarks, excelling in identity preservation, temporal consistency, and overall video quality.","authors":["Panwang Pan","Jingjing Zhao","Yuchen Lin","Chenguo Lin","Chenxin Li","Hengyu Liu","Tingting Shen","Yadong MU"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13344v3","updated":"2025-11-21T18:33:16Z","published":"2025-11-17T13:11:11Z","title":"YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection","summary":"This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.","authors":["Ori Meiraz","Sharon Shalev","Avishai Weizman"],"pdf_url":"","comment":"1 figure, 1 table"},{"id":"http://arxiv.org/abs/2511.15675v2","updated":"2025-11-21T18:28:30Z","published":"2025-11-19T18:18:53Z","title":"MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features","summary":"Depression is a prevalent global mental health disorder, characterised by persistent low mood and anhedonia. However, it remains underdiagnosed because current diagnostic methods depend heavily on subjective clinical assessments. To enable objective detection, we introduce a gold standard dataset of 103 clinically assessed participants collected through a tripartite data approach which uniquely integrated eye tracking data with audio and video to give a comprehensive representation of depressive symptoms. Eye tracking data quantifies the attentional bias towards negative stimuli that is frequently observed in depressed groups. Audio and video data capture the affective flattening and psychomotor retardation characteristic of depression. Statistical validation confirmed their significant discriminative power in distinguishing depressed from non depressed groups. We address a critical limitation of existing graph-based models that focus on low-frequency information and propose a Multi-Frequency Graph Convolutional Network (MF-GCN). This framework consists of a novel Multi-Frequency Filter Bank Module (MFFBM), which can leverage both low and high frequency signals. Extensive evaluation against traditional machine learning algorithms and deep learning frameworks demonstrates that MF-GCN consistently outperforms baselines. In binary classification, the model achieved a sensitivity of 0.96 and F2 score of 0.94. For the 3 class classification task, the proposed method achieved a sensitivity of 0.79 and specificity of 0.87 and siginificantly suprassed other models. To validate generalizability, the model was also evaluated on the Chinese Multimodal Depression Corpus (CMDC) dataset and achieved a sensitivity of 0.95 and F2 score of 0.96. These results confirm that our trimodal, multi frequency framework effectively captures cross modal interaction for accurate depression detection.","authors":["Sejuti Rahman","Swakshar Deb","MD. Sameer Iqbal Chowdhury","MD. Jubair Ahmed Sourov","Mohammad Shamsuddin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.17995v2","updated":"2025-11-21T18:16:26Z","published":"2025-08-25T13:04:21Z","title":"Topology Aware Neural Interpolation of Scalar Fields","summary":"This paper presents a neural scheme for the topology-aware interpolation of time-varying scalar fields. Given a time-varying sequence of persistence diagrams, along with a sparse temporal sampling of the corresponding scalar fields, denoted as keyframes, our interpolation approach aims at \"inverting\" the non-keyframe diagrams to produce plausible estimations of the corresponding, missing data. For this, we rely on a neural architecture which learns the relation from a time value to the corresponding scalar field, based on the keyframe examples, and reliably extends this relation to the non-keyframe time steps. We show how augmenting this architecture with specific topological losses exploiting the input diagrams both improves the geometrical and topological reconstruction of the non-keyframe time steps. At query time, given an input time value for which an interpolation is desired, our approach instantaneously produces an output, via a single propagation of the time input through the network. Experiments interpolating 2D and 3D time-varying datasets show our approach superiority, both in terms of data and topological fitting, with regard to reference interpolation schemes. Our implementation is available at this GitHub link : https://github.com/MohamedKISSI/Topology-Aware-Neural-Interpolation-of-Scalar-Fields.git.","authors":["Mohamed Kissi","Keanu Sisouk","Joshua A. Levine","Julien Tierny"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02558v2","updated":"2025-11-21T18:11:50Z","published":"2025-11-04T13:19:58Z","title":"Forecasting Future Anatomies: Longitudinal Brain Mri-to-Mri Prediction","summary":"Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.","authors":["Ali Farki","Elaheh Moradi","Deepika Koundal","Jussi Tohka"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15946v2","updated":"2025-11-21T18:09:32Z","published":"2025-11-20T00:40:43Z","title":"Automated Interpretable 2D Video Extraction from 3D Echocardiography","summary":"Although the heart has complex three-dimensional (3D) anatomy, conventional medical imaging with cardiac ultrasound relies on a series of 2D videos showing individual cardiac structures. 3D echocardiography is a developing modality that now offers adequate image quality for clinical use, with potential to streamline acquisition and improve assessment of off-axis features. We propose an automated method to select standard 2D views from 3D cardiac ultrasound volumes, allowing physicians to interpret the data in their usual format while benefiting from the speed and usability of 3D scanning. Applying a deep learning view classifier and downstream heuristics based on anatomical landmarks together with heuristics provided by cardiologists, we reconstruct standard echocardiography views. This approach was validated by three cardiologists in blinded evaluation (96\\% accuracy in 1,600 videos from 2 hospitals). The downstream 2D videos were also validated in their ability to detect cardiac abnormalities using AI echocardiography models (EchoPrime and PanEcho) as well as ability to generate clinical-grade measurements of cardiac anatomy (EchoNet-Measurement). We demonstrated that the extracted 2D videos preserve spatial calibration and diagnostic features, allowing clinicians to obtain accurate real-world interpretations from 3D volumes. We release the code and a dataset of 29 3D echocardiography videos https://github.com/echonet/3d-echo .","authors":["Milos Vukadinovic","Hirotaka Ieki","Yuki Sahashi","David Ouyang","Bryan He"],"pdf_url":"","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.17457v1","updated":"2025-11-21T17:59:17Z","published":"2025-11-21T17:59:17Z","title":"GPR-OdomNet: Difference and Similarity-Driven Odometry Estimation Network for Ground Penetrating Radar-Based Localization","summary":"When performing robot/vehicle localization using ground penetrating radar (GPR) to handle adverse weather and environmental conditions, existing techniques often struggle to accurately estimate distances when processing B-scan images with minor distinctions. This study introduces a new neural network-based odometry method that leverages the similarity and difference features of GPR B-scan images for precise estimation of the Euclidean distances traveled between the B-scan images. The new custom neural network extracts multi-scale features from B-scan images taken at consecutive moments and then determines the Euclidean distance traveled by analyzing the similarities and differences between these features. To evaluate our method, an ablation study and comparison experiments have been conducted using the publicly available CMU-GPR dataset. The experimental results show that our method consistently outperforms state-of-the-art counterparts in all tests. Specifically, our method achieves a root mean square error (RMSE), and achieves an overall weighted RMSE of 0.449 m across all data sets, which is a 10.2\\% reduction in RMSE when compared to the best state-of-the-art method.","authors":["Huaichao Wang","Xuanxin Fan","Ji Liu","Haifeng Li","Dezhen Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17455v1","updated":"2025-11-21T17:57:43Z","published":"2025-11-21T17:57:43Z","title":"Improving Multimodal Distillation for 3D Semantic Segmentation under Domain Shift","summary":"Semantic segmentation networks trained under full supervision for one type of lidar fail to generalize to unseen lidars without intervention. To reduce the performance gap under domain shifts, a recent trend is to leverage vision foundation models (VFMs) providing robust features across domains. In this work, we conduct an exhaustive study to identify recipes for exploiting VFMs in unsupervised domain adaptation for semantic segmentation of lidar point clouds. Building upon unsupervised image-to-lidar knowledge distillation, our study reveals that: (1) the architecture of the lidar backbone is key to maximize the generalization performance on a target domain; (2) it is possible to pretrain a single backbone once and for all, and use it to address many domain shifts; (3) best results are obtained by keeping the pretrained backbone frozen and training an MLP head for semantic segmentation. The resulting pipeline achieves state-of-the-art results in four widely-recognized and challenging settings. The code will be available at: https://github.com/valeoai/muddos.","authors":["Björn Michele","Alexandre Boulch","Gilles Puy","Tuan-Hung Vu","Renaud Marlet","Nicolas Courty"],"pdf_url":"","comment":"Accepted at BMVC 2025"},{"id":"http://arxiv.org/abs/2511.17454v1","updated":"2025-11-21T17:56:43Z","published":"2025-11-21T17:56:43Z","title":"Illustrator's Depth: Monocular Layer Index Prediction for Image Decomposition","summary":"We introduce Illustrator's Depth, a novel definition of depth that addresses a key challenge in digital content creation: decomposing flat images into editable, ordered layers. Inspired by an artist's compositional process, illustrator's depth infers a layer index to each pixel, forming an interpretable image decomposition through a discrete, globally consistent ordering of elements optimized for editability. We also propose and train a neural network using a curated dataset of layered vector graphics to predict layering directly from raster inputs. Our layer index inference unlocks a range of powerful downstream applications. In particular, it significantly outperforms state-of-the-art baselines for image vectorization while also enabling high-fidelity text-to-vector-graphics generation, automatic 3D relief generation from 2D images, and intuitive depth-aware editing. By reframing depth from a physical quantity to a creative abstraction, illustrator's depth prediction offers a new foundation for editable image decomposition.","authors":["Nissim Maruani","Peiying Zhang","Siddhartha Chaudhuri","Matthew Fisher","Nanxuan Zhao","Vladimir G. Kim","Pierre Alliez","Mathieu Desbrun","Wang Yifan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17450v1","updated":"2025-11-21T17:48:02Z","published":"2025-11-21T17:48:02Z","title":"Planning with Sketch-Guided Verification for Physics-Aware Video Generation","summary":"Recent video generation approaches increasingly rely on planning intermediate control signals such as object trajectories to improve temporal coherence and motion fidelity. However, these methods mostly employ single-shot plans that are typically limited to simple motions, or iterative refinement which requires multiple calls to the video generator, incuring high computational cost. To overcome these limitations, we propose SketchVerify, a training-free, sketch-verification-based planning framework that improves motion planning quality with more dynamically coherent trajectories (i.e., physically plausible and instruction-consistent motions) prior to full video generation by introducing a test-time sampling and verification loop. Given a prompt and a reference image, our method predicts multiple candidate motion plans and ranks them using a vision-language verifier that jointly evaluates semantic alignment with the instruction and physical plausibility. To efficiently score candidate motion plans, we render each trajectory as a lightweight video sketch by compositing objects over a static background, which bypasses the need for expensive, repeated diffusion-based synthesis while achieving comparable performance. We iteratively refine the motion plan until a satisfactory one is identified, which is then passed to the trajectory-conditioned generator for final synthesis. Experiments on WorldModelBench and PhyWorldBench demonstrate that our method significantly improves motion quality, physical realism, and long-term consistency compared to competitive baselines while being substantially more efficient. Our ablation study further shows that scaling up the number of trajectory candidates consistently enhances overall performance.","authors":["Yidong Huang","Zun Wang","Han Lin","Dong-Ki Kim","Shayegan Omidshafiei","Jaehong Yoon","Yue Zhang","Mohit Bansal"],"pdf_url":"","comment":"website: https://sketchverify.github.io/"},{"id":"http://arxiv.org/abs/2511.17448v1","updated":"2025-11-21T17:46:44Z","published":"2025-11-21T17:46:44Z","title":"MMT-ARD: Multimodal Multi-Teacher Adversarial Distillation for Robust Vision-Language Models","summary":"Vision-Language Models (VLMs) are increasingly deployed in safety-critical applications, making their adversarial robustness a crucial concern. While adversarial knowledge distillation has shown promise in transferring robustness from teacher to student models, traditional single-teacher approaches suffer from limited knowledge diversity, slow convergence, and difficulty in balancing robustness and accuracy. To address these challenges, we propose MMT-ARD: a Multimodal Multi-Teacher Adversarial Robust Distillation framework. Our key innovation is a dual-teacher knowledge fusion architecture that collaboratively optimizes clean feature preservation and robust feature enhancement. To better handle challenging adversarial examples, we introduce a dynamic weight allocation strategy based on teacher confidence, enabling adaptive focus on harder samples. Moreover, to mitigate bias among teachers, we design an adaptive sigmoid-based weighting function that balances the strength of knowledge transfer across modalities. Extensive experiments on ImageNet and zero-shot benchmarks demonstrate that MMT-ARD improves robust accuracy by +4.32% and zero-shot accuracy by +3.5% on the ViT-B-32 model, while achieving a 2.3x increase in training efficiency over traditional single-teacher methods. These results highlight the effectiveness and scalability of MMT-ARD in enhancing the adversarial robustness of multimodal large models. Our codes are available at https://github.com/itsnotacie/MMT-ARD.","authors":["Yuqi Li","Junhao Dong","Chuanguang Yang","Shiping Wen","Piotr Koniusz","Tingwen Huang","Yingli Tian","Yew-Soon Ong"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2511.17442v1","updated":"2025-11-21T17:41:26Z","published":"2025-11-21T17:41:26Z","title":"REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing","summary":"Foundation Models (FMs) are increasingly used in remote sensing (RS) for tasks such as environmental monitoring, disaster assessment, and land-use mapping. These models include unimodal vision encoders trained on a single data modality and multimodal architectures trained on combinations of SAR, multispectral, hyperspectral, and image-text data. They support diverse RS tasks including semantic segmentation, image classification, change detection, and visual question answering. However, selecting an appropriate remote sensing foundation model (RSFM) remains difficult due to scattered documentation, heterogeneous formats, and varied deployment constraints. We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms. Built on RS-FMD, we present REMSA, the first LLM-based agent for automated RSFM selection from natural language queries. REMSA interprets user requirements, resolves missing constraints, ranks candidate models using in-context learning, and provides transparent justifications. We also propose a benchmark of 75 expert-verified RS query scenarios, producing 900 configurations under an expert-centered evaluation protocol. REMSA outperforms several baselines, including naive agents, dense retrieval, and unstructured RAG-based LLMs. It operates entirely on publicly available metadata and does not access private or sensitive data.","authors":["Binger Chen","Tacettin Emre Bök","Behnood Rasti","Volker Markl","Begüm Demir"],"pdf_url":"","comment":"Code and data available at https://github.com/be-chen/REMSA"},{"id":"http://arxiv.org/abs/2511.17432v1","updated":"2025-11-21T17:30:18Z","published":"2025-11-21T17:30:18Z","title":"SMILE: A Composite Lexical-Semantic Metric for Question-Answering Evaluation","summary":"Traditional evaluation metrics for textual and visual question answering, like ROUGE, METEOR, and Exact Match (EM), focus heavily on n-gram based lexical similarity, often missing the deeper semantic understanding needed for accurate assessment. While measures like BERTScore and MoverScore leverage contextual embeddings to address this limitation, they lack flexibility in balancing sentence-level and keyword-level semantics and ignore lexical similarity, which remains important. Large Language Model (LLM) based evaluators, though powerful, come with drawbacks like high costs, bias, inconsistency, and hallucinations. To address these issues, we introduce SMILE: Semantic Metric Integrating Lexical Exactness, a novel approach that combines sentence-level semantic understanding with keyword-level semantic understanding and easy keyword matching. This composite method balances lexical precision and semantic relevance, offering a comprehensive evaluation. Extensive benchmarks across text, image, and video QA tasks show SMILE is highly correlated with human judgments and computationally lightweight, bridging the gap between lexical and semantic evaluation.","authors":["Shrikant Kendre","Austin Xu","Honglu Zhou","Michael Ryoo","Shafiq Joty","Juan Carlos Niebles"],"pdf_url":"","comment":"23 pages, 6 tables, 9 figures"},{"id":"http://arxiv.org/abs/2502.19800v3","updated":"2025-11-21T17:27:18Z","published":"2025-02-27T06:16:04Z","title":"TrackGS: Optimizing COLMAP-Free 3D Gaussian Splatting with Global Track Constraints","summary":"We present TrackGS, a novel method to integrate global feature tracks with 3D Gaussian Splatting (3DGS) for COLMAP-free novel view synthesis. While 3DGS delivers impressive rendering quality, its reliance on accurate precomputed camera parameters remains a significant limitation. Existing COLMAP-free approaches depend on local constraints that fail in complex scenarios. Our key innovation lies in leveraging feature tracks to establish global geometric constraints, enabling simultaneous optimization of camera parameters and 3D Gaussians. Specifically, we: (1) introduce track-constrained Gaussians that serve as geometric anchors, (2) propose novel 2D and 3D track losses to enforce multi-view consistency, and (3) derive differentiable formulations for camera intrinsics optimization. Extensive experiments on challenging real-world and synthetic datasets demonstrate state-of-the-art performance, with much lower pose error than previous methods while maintaining superior rendering quality. Our approach eliminates the need for COLMAP preprocessing, making 3DGS more accessible for practical applications.","authors":["Dongbo Shi","Shen Cao","Lubin Fan","Bojian Wu","Jinhui Guo","Ligang Liu","Renjie Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17426v1","updated":"2025-11-21T17:22:31Z","published":"2025-11-21T17:22:31Z","title":"Self-Supervised Learning by Curvature Alignment","summary":"Self-supervised learning (SSL) has recently advanced through non-contrastive methods that couple an invariance term with variance, covariance, or redundancy-reduction penalties. While such objectives shape first- and second-order statistics of the representation, they largely ignore the local geometry of the underlying data manifold. In this paper, we introduce CurvSSL, a curvature-regularized self-supervised learning framework, and its RKHS extension, kernel CurvSSL. Our approach retains a standard two-view encoder-projector architecture with a Barlow Twins-style redundancy-reduction loss on projected features, but augments it with a curvature-based regularizer. Each embedding is treated as a vertex whose $k$ nearest neighbors define a discrete curvature score via cosine interactions on the unit hypersphere; in the kernel variant, curvature is computed from a normalized local Gram matrix in an RKHS. These scores are aligned and decorrelated across augmentations by a Barlow-style loss on a curvature-derived matrix, encouraging both view invariance and consistency of local manifold bending. Experiments on MNIST and CIFAR-10 datasets with a ResNet-18 backbone show that curvature-regularized SSL yields competitive or improved linear evaluation performance compared to Barlow Twins and VICReg. Our results indicate that explicitly shaping local geometry is a simple and effective complement to purely statistical SSL regularizers.","authors":["Benyamin Ghojogh","M. Hadi Sepanj","Paul Fieguth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17421v1","updated":"2025-11-21T17:18:35Z","published":"2025-11-21T17:18:35Z","title":"Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers","summary":"Deep learning models are prone to learning shortcut solutions to problems using spuriously correlated yet irrelevant features of their training data. In high-risk applications such as medical image analysis, this phenomenon may prevent models from using clinically meaningful features when making predictions, potentially leading to poor robustness and harm to patients. We demonstrate that different types of shortcuts (those that are diffuse and spread throughout the image, as well as those that are localized to specific areas) manifest distinctly across network layers and can, therefore, be more effectively targeted through mitigation strategies that target the intermediate layers. We propose a novel knowledge distillation framework that leverages a teacher network fine-tuned on a small subset of task-relevant data to mitigate shortcut learning in a student network trained on a large dataset corrupted with a bias feature. Through extensive experiments on CheXpert, ISIC 2017, and SimBA datasets using various architectures (ResNet-18, AlexNet, DenseNet-121, and 3D CNNs), we demonstrate consistent improvements over traditional Empirical Risk Minimization, augmentation-based bias-mitigation, and group-based bias-mitigation approaches. In many cases, we achieve comparable performance with a baseline model trained on bias-free data, even on out-of-distribution test data. Our results demonstrate the practical applicability of our approach to real-world medical imaging scenarios where bias annotations are limited and shortcut features are difficult to identify a priori.","authors":["Christopher Boland","Sotirios Tsaftaris","Sonia Dahdouh"],"pdf_url":"","comment":"Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:020"},{"id":"http://arxiv.org/abs/2511.11910v2","updated":"2025-11-21T17:08:33Z","published":"2025-11-14T22:41:27Z","title":"Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video Multimodal Language Models","summary":"Despite the recent advances in the video understanding ability of multimodal large language models (MLLMs), long video understanding remains a challenge. One of the main issues is that the number of vision tokens grows linearly with video length, which causes an explosion in attention cost, memory, and latency. To solve this challenge, we present Query-aware Token Selector (\\textbf{QTSplus}), a lightweight yet powerful visual token selection module that serves as an information gate between the vision encoder and LLMs. Given a text query and video tokens, QTSplus dynamically selects the most important visual evidence for the input text query by (i) scoring visual tokens via cross-attention, (ii) \\emph{predicting} an instance-specific retention budget based on the complexity of the query, and (iii) \\emph{selecting} Top-$n$ tokens with a differentiable straight-through estimator during training and a hard gate at inference. Furthermore, a small re-encoder preserves temporal order using absolute time information, enabling second-level localization while maintaining global coverage.\n  Integrated into Qwen2.5-VL, QTSplus compresses the vision stream by up to \\textbf{89\\%} and reduces end-to-end latency by \\textbf{28\\%} on long videos. The evaluation on eight long video understanding benchmarks shows near-parity accuracy overall when compared with the original Qwen models and outperforms the original model by \\textbf{+20.5} and \\textbf{+5.6} points respectively on TempCompass direction and order accuracies. These results show that QTSplus is an effective, general mechanism for scaling MLLMs to real-world long-video scenarios while preserving task-relevant evidence.","authors":["Siyou Li","Huanan Wu","Juexi Shao","Yinghao Ma","Yujian Gan","Yihao Luo","Yuwei Wang","Dong Nie","Lu Wang","Wengqing Wu","Le Zhang","Massimo Poesio","Juntao Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17400v1","updated":"2025-11-21T17:00:02Z","published":"2025-11-21T17:00:02Z","title":"Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?","summary":"Vision Transformers ($\\text{ViTs}$) have become the backbone of vision foundation models, yet their optimization for multi-channel domains - such as cell painting or satellite imagery - remains underexplored. A key challenge in these domains is capturing interactions between channels, as each channel carries different information. While existing works have shown efficacy by treating each channel independently during tokenization, this approach naturally introduces a major computational bottleneck in the attention block - channel-wise comparisons leads to a quadratic growth in attention, resulting in excessive $\\text{FLOPs}$ and high training cost. In this work, we shift focus from efficacy to the overlooked efficiency challenge in cross-channel attention and ask: \"Is it necessary to model all channel interactions?\". Inspired by the philosophy of Sparse Mixture-of-Experts ($\\text{MoE}$), we propose MoE-ViT, a Mixture-of-Experts architecture for multi-channel images in $\\text{ViTs}$, which treats each channel as an expert and employs a lightweight router to select only the most relevant experts per patch for attention. Proof-of-concept experiments on real-world datasets - JUMP-CP and So2Sat - demonstrate that $\\text{MoE-ViT}$ achieves substantial efficiency gains without sacrificing, and in some cases enhancing, performance, making it a practical and attractive backbone for multi-channel imaging.","authors":["Sukwon Yun","Heming Yao","Burkhard Hoeckendorf","David Richmond","Aviv Regev","Russell Littman"],"pdf_url":"","comment":"This has been accepted at the NeurIPS AI4Science Workshop 2025"},{"id":"http://arxiv.org/abs/2511.17397v1","updated":"2025-11-21T16:56:25Z","published":"2025-11-21T16:56:25Z","title":"MCMoE: Completing Missing Modalities with Mixture of Experts for Incomplete Multimodal Action Quality Assessment","summary":"Multimodal Action Quality Assessment (AQA) has recently emerged as a promising paradigm. By leveraging complementary information across shared contextual cues, it enhances the discriminative evaluation of subtle intra-class variations in highly similar action sequences. However, partial modalities are frequently unavailable at the inference stage in reality. The absence of any modality often renders existing multimodal models inoperable. Furthermore, it triggers catastrophic performance degradation due to interruptions in cross-modal interactions. To address this issue, we propose a novel Missing Completion Framework with Mixture of Experts (MCMoE) that unifies unimodal and joint representation learning in single-stage training. Specifically, we propose an adaptive gated modality generator that dynamically fuses available information to reconstruct missing modalities. We then design modality experts to learn unimodal knowledge and dynamically mix the knowledge of all experts to extract cross-modal joint representations. With a mixture of experts, missing modalities are further refined and complemented. Finally, in the training phase, we mine the complete multimodal features and unimodal expert knowledge to guide modality generation and generation-based joint representation extraction. Extensive experiments demonstrate that our MCMoE achieves state-of-the-art results in both complete and incomplete multimodal learning on three public AQA benchmarks. Code is available at https://github.com/XuHuangbiao/MCMoE.","authors":["Huangbiao Xu","Huanqi Wu","Xiao Ke","Junyi Wu","Rui Xu","Jinglin Xu"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.17393v1","updated":"2025-11-21T16:53:08Z","published":"2025-11-21T16:53:08Z","title":"Designing and Generating Diverse, Equitable Face Image Datasets for Face Verification Tasks","summary":"Face verification is a significant component of identity authentication in various applications including online banking and secure access to personal devices. The majority of the existing face image datasets often suffer from notable biases related to race, gender, and other demographic characteristics, limiting the effectiveness and fairness of face verification systems. In response to these challenges, we propose a comprehensive methodology that integrates advanced generative models to create varied and diverse high-quality synthetic face images. This methodology emphasizes the representation of a diverse range of facial traits, ensuring adherence to characteristics permissible in identity card photographs. Furthermore, we introduce the Diverse and Inclusive Faces for Verification (DIF-V) dataset, comprising 27,780 images of 926 unique identities, designed as a benchmark for future research in face verification. Our analysis reveals that existing verification models exhibit biases toward certain genders and races, and notably, applying identity style modifications negatively impacts model performance. By tackling the inherent inequities in existing datasets, this work not only enriches the discussion on diversity and ethics in artificial intelligence but also lays the foundation for developing more inclusive and reliable face verification technologies","authors":["Georgia Baltsou","Ioannis Sarridis","Christos Koutlis","Symeon Papadopoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17392v1","updated":"2025-11-21T16:52:20Z","published":"2025-11-21T16:52:20Z","title":"MorphSeek: Fine-grained Latent Representation-Level Policy Optimization for Deformable Image Registration","summary":"Deformable image registration (DIR) remains a fundamental yet challenging problem in medical image analysis, largely due to the prohibitively high-dimensional deformation space of dense displacement fields and the scarcity of voxel-level supervision. Existing reinforcement learning frameworks often project this space into coarse, low-dimensional representations, limiting their ability to capture spatially variant deformations. We propose MorphSeek, a fine-grained representation-level policy optimization paradigm that reformulates DIR as a spatially continuous optimization process in the latent feature space. MorphSeek introduces a stochastic Gaussian policy head atop the encoder to model a distribution over latent features, facilitating efficient exploration and coarse-to-fine refinement. The framework integrates unsupervised warm-up with weakly supervised fine-tuning through Group Relative Policy Optimization, where multi-trajectory sampling stabilizes training and improves label efficiency. Across three 3D registration benchmarks (OASIS brain MRI, LiTS liver CT, and Abdomen MR-CT), MorphSeek achieves consistent Dice improvements over competitive baselines while maintaining high label efficiency with minimal parameter cost and low step-level latency overhead. Beyond optimizer specifics, MorphSeek advances a representation-level policy learning paradigm that achieves spatially coherent and data-efficient deformation optimization, offering a principled, backbone-agnostic, and optimizer-agnostic solution for scalable visual alignment in high-dimensional settings.","authors":["Runxun Zhang","Yizhou Liu","Li Dongrui","Bo XU","Jingwei Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17384v1","updated":"2025-11-21T16:48:49Z","published":"2025-11-21T16:48:49Z","title":"IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation","summary":"While Visual Large Language Models (VLLMs) show great promise as embodied agents, they continue to face substantial challenges in spatial reasoning. Existing embodied benchmarks largely focus on passive, static household environments and evaluate only isolated capabilities, failing to capture holistic performance in dynamic, real-world complexity. To fill this gap, we present IndustryNav, the first dynamic industrial navigation benchmark for active spatial reasoning. IndustryNav leverages 12 manually created, high-fidelity Unity warehouse scenarios featuring dynamic objects and human movement. Our evaluation employs a PointGoal navigation pipeline that effectively combines egocentric vision with global odometry to assess holistic local-global planning. Crucially, we introduce the \"collision rate\" and \"warning rate\" metrics to measure safety-oriented behaviors and distance estimation. A comprehensive study of nine state-of-the-art VLLMs (including models such as GPT-5-mini, Claude-4.5, and Gemini-2.5) reveals that closed-source models maintain a consistent advantage; however, all agents exhibit notable deficiencies in robust path planning, collision avoidance and active exploration. This highlights a critical need for embodied research to move beyond passive perception and toward tasks that demand stable planning, active exploration, and safe behavior in dynamic, real-world environment.","authors":["Yifan Li","Lichi Li","Anh Dao","Xinyu Zhou","Yicheng Qiao","Zheda Mai","Daeun Lee","Zichen Chen","Zhen Tan","Mohit Bansal","Yu Kong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17380v1","updated":"2025-11-21T16:44:01Z","published":"2025-11-21T16:44:01Z","title":"Non-Parametric Probabilistic Robustness: A Conservative Metric with Optimized Perturbation Distributions","summary":"Deep learning (DL) models, despite their remarkable success, remain vulnerable to small input perturbations that can cause erroneous outputs, motivating the recent proposal of probabilistic robustness (PR) as a complementary alternative to adversarial robustness (AR). However, existing PR formulations assume a fixed and known perturbation distribution, an unrealistic expectation in practice. To address this limitation, we propose non-parametric probabilistic robustness (NPPR), a more practical PR metric that does not rely on any predefined perturbation distribution. Following the non-parametric paradigm in statistical modeling, NPPR learns an optimized perturbation distribution directly from data, enabling conservative PR evaluation under distributional uncertainty. We further develop an NPPR estimator based on a Gaussian Mixture Model (GMM) with Multilayer Perceptron (MLP) heads and bicubic up-sampling, covering various input-dependent and input-independent perturbation scenarios. Theoretical analyses establish the relationships among AR, PR, and NPPR. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet across ResNet18/50, WideResNet50 and VGG16 validate NPPR as a more practical robustness metric, showing up to 40\\% more conservative (lower) PR estimates compared to assuming those common perturbation distributions used in state-of-the-arts.","authors":["Zheng Wang","Yi Zhang","Siddartha Khastgir","Carsten Maple","Xingyu Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17366v1","updated":"2025-11-21T16:32:36Z","published":"2025-11-21T16:32:36Z","title":"METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model","summary":"Building a generalist robot that can perceive, reason, and act across diverse tasks remains an open challenge, especially for dexterous manipulation. A major bottleneck lies in the scarcity of large-scale, action-annotated data for dexterous skills, as teleoperation is difficult and costly. Human data, with its vast scale and diverse manipulation behaviors, provides rich priors for learning robotic actions. While prior works have explored leveraging human demonstrations, they are often constrained by limited scenarios and a large visual gap between human and robots. To eliminate these limitations, we propose METIS, a vision-language-action (VLA) model for dexterous manipulation pretrained on multi-source egocentric datasets. We first construct EgoAtlas, which integrates large-scale human and robotic data from multiple sources, all unified under a consistent action space. We further extract motion-aware dynamics, a compact and discretized motion representation, which provides efficient and expressive supervision for VLA training. Built upon them, METIS integrates reasoning and acting into a unified framework, enabling effective deployment to downstream dexterous manipulation tasks. Our method demonstrates exceptional dexterous manipulation capabilities, achieving highest average success rate in six real-world tasks. Experimental results also highlight the superior generalization and robustness to out-of-distribution scenarios. These findings emphasize METIS as a promising step toward a generalist model for dexterous manipulation.","authors":["Yankai Fu","Ning Chen","Junkai Zhao","Shaozhe Shan","Guocai Yao","Pengwei Wang","Zhongyuan Wang","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17364v1","updated":"2025-11-21T16:32:01Z","published":"2025-11-21T16:32:01Z","title":"SVRecon: Sparse Voxel Rasterization for Surface Reconstruction","summary":"We extend the recently proposed sparse voxel rasterization paradigm to the task of high-fidelity surface reconstruction by integrating Signed Distance Function (SDF), named SVRecon. Unlike 3D Gaussians, sparse voxels are spatially disentangled from their neighbors and have sharp boundaries, which makes them prone to local minima during optimization. Although SDF values provide a naturally smooth and continuous geometric field, preserving this smoothness across independently parameterized sparse voxels is nontrivial. To address this challenge, we promote coherent and smooth voxel-wise structure through (1) robust geometric initialization using a visual geometry model and (2) a spatial smoothness loss that enforces coherent relationships across parent-child and sibling voxel groups. Extensive experiments across various benchmarks show that our method achieves strong reconstruction accuracy while having consistently speedy convergence. The code will be made public.","authors":["Seunghun Oh","Jaesung Choe","Dongjae Lee","Daeun Lee","Seunghoon Jeong","Yu-Chiang Frank Wang","Jaesik Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17362v1","updated":"2025-11-21T16:30:06Z","published":"2025-11-21T16:30:06Z","title":"ATAC: Augmentation-Based Test-Time Adversarial Correction for CLIP","summary":"Despite its remarkable success in zero-shot image-text matching, CLIP remains highly vulnerable to adversarial perturbations on images. As adversarial fine-tuning is prohibitively costly, recent works explore various test-time defense strategies; however, these approaches still exhibit limited robustness. In this work, we revisit this problem and propose a simple yet effective strategy: Augmentation-based Test-time Adversarial Correction (ATAC). Our method operates directly in the embedding space of CLIP, calculating augmentation-induced drift vectors to infer a semantic recovery direction and correcting the embedding based on the angular consistency of these latent drifts. Across a wide range of benchmarks, ATAC consistently achieves remarkably high robustness, surpassing that of previous state-of-the-art methods by nearly 50\\% on average, all while requiring minimal computational overhead. Furthermore, ATAC retains state-of-the-art robustness in unconventional and extreme settings and even achieves nontrivial robustness against adaptive attacks. Our results demonstrate that ATAC is an efficient method in a novel paradigm for test-time adversarial defenses in the embedding space of CLIP.","authors":["Linxiang Su","András Balogh"],"pdf_url":"","comment":"16 pages"},{"id":"http://arxiv.org/abs/2511.17361v1","updated":"2025-11-21T16:26:31Z","published":"2025-11-21T16:26:31Z","title":"SuperQuadricOcc: Multi-Layer Gaussian Approximation of Superquadrics for Real-Time Self-Supervised Occupancy Estimation","summary":"Semantic occupancy estimation enables comprehensive scene understanding for automated driving, providing dense spatial and semantic information essential for perception and planning. While Gaussian representations have been widely adopted in self-supervised occupancy estimation, the deployment of a large number of Gaussian primitives drastically increases memory requirements and is not suitable for real-time inference. In contrast, superquadrics permit reduced primitive count and lower memory requirements due to their diverse shape set. However, implementation into a self-supervised occupancy model is nontrivial due to the absence of a superquadric rasterizer to enable model supervision. Our proposed method, SuperQuadricOcc, employs a superquadric-based scene representation. By leveraging a multi-layer icosphere-tessellated Gaussian approximation of superquadrics, we enable Gaussian rasterization for supervision during training. On the Occ3D dataset, SuperQuadricOcc achieves a 75\\% reduction in memory footprint, 124\\% faster inference, and a 5.9\\% improvement in mIoU compared to previous Gaussian-based methods, without the use of temporal labels. To our knowledge, this is the first occupancy model to enable real-time inference while maintaining competitive performance. The use of superquadrics reduces the number of primitives required for scene modeling by 84\\% relative to Gaussian-based approaches. Finally, evaluation against prior methods is facilitated by our fast superquadric voxelization module. The code will be released as open source.","authors":["Seamie Hayes","Reenu Mohandas","Tim Brophy","Alexandre Boulch","Ganesh Sistu","Ciaran Eising"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04482v2","updated":"2025-11-21T16:25:35Z","published":"2025-07-06T17:42:11Z","title":"A Training-Free Style-Personalization via SVD-Based Feature Decomposition","summary":"We present a training-free framework for style-personalized image generation that operates during inference using a scale-wise autoregressive model. Our method generates a stylized image guided by a single reference style while preserving semantic consistency and mitigating content leakage. Through a detailed step-wise analysis of the generation process, we identify a pivotal step where the dominant singular values of the internal feature encode style-related components. Building upon this insight, we introduce two lightweight control modules: Principal Feature Blending, which enables precise modulation of style through SVD-based feature reconstruction, and Structural Attention Correction, which stabilizes structural consistency by leveraging content-guided attention correction across fine stages. Without any additional training, extensive experiments demonstrate that our method achieves competitive style fidelity and prompt fidelity compared to fine-tuned baselines, while offering faster inference and greater deployment flexibility.","authors":["Kyoungmin Lee","Jihun Park","Jongmin Gim","Wonhyeok Choi","Kyumin Hwang","Jaeyeul Kim","Sunghoon Im"],"pdf_url":"","comment":"21 pages, 14 figures"},{"id":"http://arxiv.org/abs/2511.17355v1","updated":"2025-11-21T16:18:55Z","published":"2025-11-21T16:18:55Z","title":"UAM: A Unified Attention-Mamba Backbone of Multimodal Framework for Tumor Cell Classification","summary":"Cell-level radiomics features provide fine-grained insights into tumor phenotypes and have the potential to significantly enhance diagnostic accuracy on hematoxylin and eosin (H&E) images. By capturing micro-level morphological and intensity patterns, these features support more precise tumor identification and improve AI interpretability by highlighting diagnostically relevant cells for pathologist review. However, most existing studies focus on slide-level or patch-level tumor classification, leaving cell-level radiomics analysis largely unexplored. Moreover, there is currently no dedicated backbone specifically designed for radiomics data. Inspired by the recent success of the Mamba architecture in vision and language domains, we introduce a Unified Attention-Mamba (UAM) backbone for cell-level classification using radiomics features. Unlike previous hybrid approaches that integrate Attention and Mamba modules in fixed proportions, our unified design flexibly combines their capabilities within a single cohesive architecture, eliminating the need for manual ratio tuning and improving encode capability. We develop two UAM variants to comprehensively evaluate the benefits of this unified structure. Building on this backbone, we further propose a multimodal UAM framework that jointly performs cell-level classification and image segmentation. Experimental results demonstrate that UAM achieves state-of-the-art performance across both tasks on public benchmarks, surpassing leading image-based foundation models. It improves cell classification accuracy from 74% to 78% ($n$=349,882 cells), and tumor segmentation precision from 75% to 80% ($n$=406 patches). These findings highlight the effectiveness and promise of UAM as a unified and extensible multimodal foundation for radiomics-driven cancer diagnosis.","authors":["Taixi Chen","Jingyun Chen","Nancy Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17354v1","updated":"2025-11-21T16:18:50Z","published":"2025-11-21T16:18:50Z","title":"DSeq-JEPA: Discriminative Sequential Joint-Embedding Predictive Architecture","summary":"Image-based Joint-Embedding Predictive Architecture (I-JEPA) learns visual representations by predicting latent embeddings of masked regions from visible context. However, it treats all regions uniformly and independently, lacking an explicit notion of where or in what order predictions should be made. Inspired by human visual perception, which deploys attention selectively and sequentially from the most informative to secondary regions, we propose DSeq-JEPA, a Discriminative Sequential Joint-Embedding Predictive Architecture that bridges predictive and autoregressive self-supervised learning, integrating JEPA-style latent prediction with GPT-style sequential reasoning. Specifically, DSeq-JEPA (i) first identifies primary discriminative regions based on a transformer-derived saliency map, emphasizing the distribution of visual importance, and then (ii) predicts subsequent regions in this discriminative order, progressively forming a curriculum-like semantic progression from primary to secondary cues -- a form of GPT-style pre-training. Extensive experiments across diverse tasks, including image classification (ImageNet), fine-grained visual categorization (iNaturalist21, CUB-200-2011, Stanford-Cars), detection and segmentation (MS-COCO, ADE20K), and low-level reasoning tasks (Clevr/Count, Clevr/Dist), demonstrate that DSeq-JEPA consistently focuses on more discriminative and generalizable representations than I-JEPA variants. Project page: https://github.com/SkyShunsuke/DSeq-JEPA.","authors":["Xiangteng He","Shunsuke Sakai","Kun Yuan","Nicolas Padoy","Tatsuhito Hasegawa","Leonid Sigal"],"pdf_url":"","comment":"Project page: https://github.com/SkyShunsuke/DSeq-JEPA"},{"id":"http://arxiv.org/abs/2511.17353v1","updated":"2025-11-21T16:16:30Z","published":"2025-11-21T16:16:30Z","title":"Learning Latent Transmission and Glare Maps for Lens Veiling Glare Removal","summary":"Beyond the commonly recognized optical aberrations, the imaging performance of compact optical systems-including single-lens and metalens designs-is often further degraded by veiling glare caused by stray-light scattering from non-ideal optical surfaces and coatings, particularly in complex real-world environments. This compound degradation undermines traditional lens aberration correction yet remains underexplored. A major challenge is that conventional scattering models (e.g., for dehazing) fail to fit veiling glare due to its spatial-varying and depth-independent nature. Consequently, paired high-quality data are difficult to prepare via simulation, hindering application of data-driven veiling glare removal models. To this end, we propose VeilGen, a generative model that learns to simulate veiling glare by estimating its underlying optical transmission and glare maps in an unsupervised manner from target images, regularized by Stable Diffusion (SD)-based priors. VeilGen enables paired dataset generation with realistic compound degradation of optical aberrations and veiling glare, while also providing the estimated latent optical transmission and glare maps to guide the veiling glare removal process. We further introduce DeVeiler, a restoration network trained with a reversibility constraint, which utilizes the predicted latent maps to guide an inverse process of the learned scattering model. Extensive experiments on challenging compact optical systems demonstrate that our approach delivers superior restoration quality and physical fidelity compared with existing methods. These suggest that VeilGen reliably synthesizes realistic veiling glare, and its learned latent maps effectively guide the restoration process in DeVeiler. All code and datasets will be publicly released at https://github.com/XiaolongQian/DeVeiler.","authors":["Xiaolong Qian","Qi Jiang","Lei Sun","Zongxi Yu","Kailun Yang","Peixuan Wu","Jiacheng Zhou","Yao Gao","Yaoguang Ma","Ming-Hsuan Yang","Kaiwei Wang"],"pdf_url":"","comment":"All code and datasets will be publicly released at https://github.com/XiaolongQian/DeVeiler"},{"id":"http://arxiv.org/abs/2508.16069v2","updated":"2025-11-21T16:08:58Z","published":"2025-08-22T03:44:21Z","title":"A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection","summary":"Recent advances in point cloud object detection have increasingly adopted Transformer-based and State Space Models (SSMs), demonstrating strong performance. However, voxelbased representations in these models require strict consistency in input and output dimensions due to their serialized processing, which limits the spatial diffusion capability typically offered by convolutional operations. This limitation significantly affects detection accuracy. Inspired by CNN-based object detection architectures, we propose a novel Voxel Diffusion Module (VDM) to enhance voxel-level representation and diffusion in point cloud data. VDM is composed of sparse 3D convolutions, submanifold sparse convolutions, and residual connections. To ensure computational efficiency, the output feature maps are downsampled to one-fourth of the original input resolution. VDM serves two primary functions: (1) diffusing foreground voxel features through sparse 3D convolutions to enrich spatial context, and (2) aggregating fine-grained spatial information to strengthen voxelwise feature representation. The enhanced voxel features produced by VDM can be seamlessly integrated into mainstream Transformer- or SSM-based detection models for accurate object classification and localization, highlighting the generalizability of our method. We evaluate VDM on several benchmark datasets by embedding it into both Transformerbased and SSM-based models. Experimental results show that our approach consistently improves detection accuracy over baseline models. Specifically, VDM-SSMs achieve 74.7 mAPH (L2) on Waymo, 72.9 NDS on nuScenes, 42.3 mAP on Argoverse 2, and 67.6 mAP on ONCE, setting new stateof-the-art performance across all datasets. Our code will be made publicly available.","authors":["Qifeng Liu","Dawei Zhao","Yabo Dong","Linzhi Shang","Liang Xiao","Juan Wang","Kunkong Zhao","Dongming Lu","Qi Zhu"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2511.17345v1","updated":"2025-11-21T16:06:53Z","published":"2025-11-21T16:06:53Z","title":"Label-Efficient Skeleton-based Recognition with Stable-Invertible Graph Convolutional Networks","summary":"Skeleton-based action recognition is a hotspot in image processing. A key challenge of this task lies in its dependence on large, manually labeled datasets whose acquisition is costly and time-consuming. This paper devises a novel, label-efficient method for skeleton-based action recognition using graph convolutional networks (GCNs). The contribution of the proposed method resides in learning a novel acquisition function -- scoring the most informative subsets for labeling -- as the optimum of an objective function mixing data representativity, diversity and uncertainty. We also extend this approach by learning the most informative subsets using an invertible GCN which allows mapping data from ambient to latent spaces where the inherent distribution of the data is more easily captured. Extensive experiments, conducted on two challenging skeleton-based recognition datasets, show the effectiveness and the outperformance of our label-frugal GCNs against the related work.","authors":["Hichem Sahbi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17344v1","updated":"2025-11-21T16:06:32Z","published":"2025-11-21T16:06:32Z","title":"Loomis Painter: Reconstructing the Painting Process","summary":"Step-by-step painting tutorials are vital for learning artistic techniques, but existing video resources (e.g., YouTube) lack interactivity and personalization. While recent generative models have advanced artistic image synthesis, they struggle to generalize across media and often show temporal or structural inconsistencies, hindering faithful reproduction of human creative workflows. To address this, we propose a unified framework for multi-media painting process generation with a semantics-driven style control mechanism that embeds multiple media into a diffusion models conditional space and uses cross-medium style augmentation. This enables consistent texture evolution and process transfer across styles. A reverse-painting training strategy further ensures smooth, human-aligned generation. We also build a large-scale dataset of real painting processes and evaluate cross-media consistency, temporal coherence, and final-image fidelity, achieving strong results on LPIPS, DINO, and CLIP metrics. Finally, our Perceptual Distance Profile (PDP) curve quantitatively models the creative sequence, i.e., composition, color blocking, and detail refinement, mirroring human artistic progression.","authors":["Markus Pobitzer","Chang Liu","Chenyi Zhuang","Teng Long","Bin Ren","Nicu Sebe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17340v1","updated":"2025-11-21T16:02:44Z","published":"2025-11-21T16:02:44Z","title":"Refracting Reality: Generating Images with Realistic Transparent Objects","summary":"Generative image models can produce convincingly real images, with plausible shapes, textures, layouts and lighting. However, one domain in which they perform notably poorly is in the synthesis of transparent objects, which exhibit refraction, reflection, absorption and scattering. Refraction is a particular challenge, because refracted pixel rays often intersect with surfaces observed in other parts of the image, providing a constraint on the color. It is clear from inspection that generative models have not distilled the laws of optics sufficiently well to accurately render refractive objects. In this work, we consider the problem of generating images with accurate refraction, given a text prompt. We synchronize the pixels within the object's boundary with those outside by warping and merging the pixels using Snell's Law of Refraction, at each step of the generation trajectory. For those surfaces that are not directly observed in the image, but are visible via refraction or reflection, we recover their appearance by synchronizing the image with a second generated image -- a panorama centered at the object -- using the same warping and merging procedure. We demonstrate that our approach generates much more optically-plausible images that respect the physical constraints.","authors":["Yue Yin","Enze Tao","Dylan Campbell"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.09327v2","updated":"2025-11-21T15:55:52Z","published":"2025-08-12T20:30:50Z","title":"Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion Probabilistic Model","summary":"Generative artificial intelligence (AI) has been playing an important role in various domains. Leveraging its high capability to generate high-fidelity and diverse synthetic data, generative AI is widely applied in diagnostic tasks, such as lung cancer diagnosis using computed tomography (CT). However, existing generative models for lung cancer diagnosis suffer from low efficiency and anatomical imprecision, which limit their clinical applicability. To address these drawbacks, we propose Lung-DDPM+, an improved version of our previous model, Lung-DDPM. This novel approach is a denoising diffusion probabilistic model (DDPM) guided by nodule semantic layouts and accelerated by a pulmonary DPM-solver, enabling the method to focus on lesion areas while achieving a better trade-off between sampling efficiency and quality. Evaluation results on the public LIDC-IDRI dataset suggest that the proposed method achieves 8$\\times$ fewer FLOPs (floating point operations per second), 6.8$\\times$ lower GPU memory consumption, and 14$\\times$ faster sampling compared to Lung-DDPM. Moreover, it maintains comparable sample quality to both Lung-DDPM and other state-of-the-art (SOTA) generative models in two downstream segmentation tasks. We also conducted a Visual Turing Test by an experienced radiologist, showing the advanced quality and fidelity of synthetic samples generated by the proposed method. These experimental results demonstrate that Lung-DDPM+ can effectively generate high-quality thoracic CT images with lung nodules, highlighting its potential for broader applications, such as general tumor synthesis and lesion generation in medical imaging. The code and pretrained models are available at https://github.com/Manem-Lab/Lung-DDPM-PLUS.","authors":["Yifan Jiang","Ahmad Shariftabrizi","Venkata SK. Manem"],"pdf_url":"","comment":"Accepted by Computers in Biology and Medicine (CIBM)"},{"id":"http://arxiv.org/abs/2511.17335v1","updated":"2025-11-21T15:55:25Z","published":"2025-11-21T15:55:25Z","title":"Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM","summary":"Human-robot collaboration towards a shared goal requires robots to understand human action and interaction with the surrounding environment. This paper focuses on human-robot interaction (HRI) based on human-robot dialogue that relies on the robot action confirmation and action step generation using multimodal scene understanding. The state-of-the-art approach uses multimodal transformers to generate robot action steps aligned with robot action confirmation from a single clip showing a task composed of multiple micro steps. Although actions towards a long-horizon task depend on each other throughout an entire video, the current approaches mainly focus on clip-level processing and do not leverage long-context information. This paper proposes a long-context Q-former incorporating left and right context dependency in full videos. Furthermore, this paper proposes a text-conditioning approach to feed text embeddings directly into the LLM decoder to mitigate the high abstraction of the information in text by Q-former. Experiments with the YouCook2 corpus show that the accuracy of confirmation generation is a major factor in the performance of action planning. Furthermore, we demonstrate that the long-context Q-former improves the confirmation and action planning by integrating VideoLLaMA3.","authors":["Chiori Hori","Yoshiki Masuyama","Siddarth Jain","Radu Corcodel","Devesh Jha","Diego Romeres","Jonathan Le Roux"],"pdf_url":"","comment":"Accepted to ASRU 2025"},{"id":"http://arxiv.org/abs/2511.17322v1","updated":"2025-11-21T15:41:51Z","published":"2025-11-21T15:41:51Z","title":"NoPe-NeRF++: Local-to-Global Optimization of NeRF with No Pose Prior","summary":"In this paper, we introduce NoPe-NeRF++, a novel local-to-global optimization algorithm for training Neural Radiance Fields (NeRF) without requiring pose priors. Existing methods, particularly NoPe-NeRF, which focus solely on the local relationships within images, often struggle to recover accurate camera poses in complex scenarios. To overcome the challenges, our approach begins with a relative pose initialization with explicit feature matching, followed by a local joint optimization to enhance the pose estimation for training a more robust NeRF representation. This method significantly improves the quality of initial poses. Additionally, we introduce global optimization phase that incorporates geometric consistency constraints through bundle adjustment, which integrates feature trajectories to further refine poses and collectively boost the quality of NeRF. Notably, our method is the first work that seamlessly combines the local and global cues with NeRF, and outperforms state-of-the-art methods in both pose estimation accuracy and novel view synthesis. Extensive evaluations on benchmark datasets demonstrate our superior performance and robustness, even in challenging scenes, thus validating our design choices.","authors":["Dongbo Shi","Shen Cao","Bojian Wu","Jinhui Guo","Lubin Fan","Renjie Chen","Ligang Liu","Jieping Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.22397v5","updated":"2025-11-21T15:31:44Z","published":"2025-06-27T17:10:43Z","title":"HazeMatching: Dehazing Light Microscopy Images with Guided Conditional Flow Matching","summary":"Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 11 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.","authors":["Anirban Ray"," Ashesh","Florian Jug"],"pdf_url":"","comment":"4 figures, 8 pages + refs, 45 pages total (including supplement), 28 supplementary figures"},{"id":"http://arxiv.org/abs/2511.17309v1","updated":"2025-11-21T15:25:47Z","published":"2025-11-21T15:25:47Z","title":"MuM: Multi-View Masked Image Modeling for 3D Vision","summary":"Self-supervised learning on images seeks to extract meaningful visual representations from unlabeled data. When scaled to large datasets, this paradigm has achieved state-of-the-art performance and the resulting trained models such as DINOv3 have seen widespread adoption. However, most prior efforts are optimized for semantic understanding rather than geometric reasoning. One important exception is Cross-View Completion, CroCo, which is a form of masked autoencoding (MAE) tailored for 3D understanding. In this work, we continue on the path proposed by CroCo and focus on learning features tailored for 3D vision. In a nutshell, we extend MAE to arbitrarily many views of the same scene. By uniformly masking all views and employing a lightweight decoder with inter-frame attention, our approach is inherently simpler and more scalable than CroCo. We evaluate the resulting model, MuM, extensively on downstream tasks including feedforward reconstruction, dense image matching and relative pose estimation, finding that it outperforms the state-of-the-art visual encoders DINOv3 and CroCo v2.","authors":["David Nordström","Johan Edstedt","Fredrik Kahl","Georg Bökman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26601v2","updated":"2025-11-21T15:25:30Z","published":"2025-10-30T15:29:20Z","title":"ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching","summary":"Computational Super-Resolution (CSR) in fluorescence microscopy has, despite being an ill-posed problem, a long history. At its very core, CSR is about finding a prior that can be used to extrapolate frequencies in a micrograph that have never been imaged by the image-generating microscope. It stands to reason that, with the advent of better data-driven machine learning techniques, stronger prior can be learned and hence CSR can lead to better results. Here, we present ResMatching, a novel CSR method that uses guided conditional flow matching to learn such improved data-priors. We evaluate ResMatching on 4 diverse biological structures from the BioSR dataset and compare its results against 7 baselines. ResMatching consistently achieves competitive results, demonstrating in all cases the best trade-off between data fidelity and perceptual realism. We observe that CSR using ResMatching is particularly effective in cases where a strong prior is hard to learn, e.g. when the given low-resolution images contain a lot of noise. Additionally, we show that ResMatching can be used to sample from an implicitly learned posterior distribution and that this distribution is calibrated for all tested use-cases, enabling our method to deliver a pixel-wise data-uncertainty term that can guide future users to reject uncertain predictions.","authors":["Anirban Ray","Vera Galinova","Florian Jug"],"pdf_url":"","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.17308v1","updated":"2025-11-21T15:24:33Z","published":"2025-11-21T15:24:33Z","title":"SpatialGeo:Boosting Spatial Reasoning in Multimodal LLMs via Geometry-Semantics Fusion","summary":"Multimodal large language models (MLLMs) have achieved significant progress in image and language tasks due to the strong reasoning capability of large language models (LLMs). Nevertheless, most MLLMs suffer from limited spatial reasoning ability to interpret and infer spatial arrangements in three-dimensional space. In this work, we propose a novel vision encoder based on hierarchical fusion of geometry and semantics features, generating spatial-aware visual embedding and boosting the spatial grounding capability of MLLMs. Specifically, we first unveil that the spatial ambiguity shortcoming stems from the lossy embedding of the vision encoder utilized in most existing MLLMs (e.g., CLIP), restricted to instance-level semantic features. This motivates us to complement CLIP with the geometry features from vision-only self-supervised learning via a hierarchical adapter, enhancing the spatial awareness in the proposed SpatialGeo. The network is efficiently trained using pretrained LLaVA model and optimized with random feature dropping to avoid trivial solutions relying solely on the CLIP encoder. Experimental results show that SpatialGeo improves the accuracy in spatial reasoning tasks, enhancing state-of-the-art models by at least 8.0% in SpatialRGPT-Bench with approximately 50% less memory cost during inference. The source code is available via https://ricky-plus.github.io/SpatialGeoPages/.","authors":["Jiajie Guo","Qingpeng Zhu","Jin Zeng","Xiaolong Wu","Changyong He","Weida Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17306v1","updated":"2025-11-21T15:21:28Z","published":"2025-11-21T15:21:28Z","title":"BiFingerPose: Bimodal Finger Pose Estimation for Touch Devices","summary":"Finger pose offers promising opportunities to expand human computer interaction capability of touchscreen devices. Existing finger pose estimation algorithms that can be implemented in portable devices predominantly rely on capacitive images, which are currently limited to estimating pitch and yaw angles and exhibit reduced accuracy when processing large-angle inputs (especially when it is greater than 45 degrees). In this paper, we propose BiFingerPose, a novel bimodal based finger pose estimation algorithm capable of simultaneously and accurately predicting comprehensive finger pose information. A bimodal input is explored, including a capacitive image and a fingerprint patch obtained from the touchscreen with an under-screen fingerprint sensor. Our approach leads to reliable estimation of roll angle, which is not achievable using only a single modality. In addition, the prediction performance of other pose parameters has also been greatly improved. The evaluation of a 12-person user study on continuous and discrete interaction tasks further validated the advantages of our approach. Specifically, BiFingerPose outperforms previous SOTA methods with over 21% improvement in prediction performance, 2.5 times higher task completion efficiency, and 23% better user operation accuracy, demonstrating its practical superiority. Finally, we delineate the application space of finger pose with respect to enhancing authentication security and improving interactive experiences, and develop corresponding prototypes to showcase the interaction potential. Our code will be available at https://github.com/XiongjunGuan/DualFingerPose.","authors":["Xiongjun Guan","Zhiyu Pan","Jianjiang Feng","Jie Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.03725v2","updated":"2025-11-21T15:12:29Z","published":"2025-11-05T18:59:35Z","title":"Disentangled Concepts Speak Louder Than Words: Explainable Video Action Recognition","summary":"Effective explanations of video action recognition models should disentangle how movements unfold over time from the surrounding spatial context. However, existing methods based on saliency produce entangled explanations, making it unclear whether predictions rely on motion or spatial context. Language-based approaches offer structure but often fail to explain motions due to their tacit nature -- intuitively understood but difficult to verbalize. To address these challenges, we propose Disentangled Action aNd Context concept-based Explainable (DANCE) video action recognition, a framework that predicts actions through disentangled concept types: motion dynamics, objects, and scenes. We define motion dynamics concepts as human pose sequences. We employ a large language model to automatically extract object and scene concepts. Built on an ante-hoc concept bottleneck design, DANCE enforces prediction through these concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101 -- demonstrate that DANCE significantly improves explanation clarity with competitive performance. We validate the superior interpretability of DANCE through a user study. Experimental results also show that DANCE is beneficial for model debugging, editing, and failure analysis.","authors":["Jongseo Lee","Wooil Lee","Gyeong-Moon Park","Seong Tae Kim","Jinwoo Choi"],"pdf_url":"","comment":"NeurIPS 2025 Spotlight paper. Project page: https://jong980812.github.io/DANCE/"},{"id":"http://arxiv.org/abs/2511.17300v1","updated":"2025-11-21T15:11:47Z","published":"2025-11-21T15:11:47Z","title":"MolSight: Optical Chemical Structure Recognition with SMILES Pretraining, Multi-Granularity Learning and Reinforcement Learning","summary":"Optical Chemical Structure Recognition (OCSR) plays a pivotal role in modern chemical informatics, enabling the automated conversion of chemical structure images from scientific literature, patents, and educational materials into machine-readable molecular representations. This capability is essential for large-scale chemical data mining, drug discovery pipelines, and Large Language Model (LLM) applications in related domains. However, existing OCSR systems face significant challenges in accurately recognizing stereochemical information due to the subtle visual cues that distinguish stereoisomers, such as wedge and dash bonds, ring conformations, and spatial arrangements. To address these challenges, we propose MolSight, a comprehensive learning framework for OCSR that employs a three-stage training paradigm. In the first stage, we conduct pre-training on large-scale but noisy datasets to endow the model with fundamental perception capabilities for chemical structure images. In the second stage, we perform multi-granularity fine-tuning using datasets with richer supervisory signals, systematically exploring how auxiliary tasks-specifically chemical bond classification and atom localization-contribute to molecular formula recognition. Finally, we employ reinforcement learning for post-training optimization and introduce a novel stereochemical structure dataset. Remarkably, we find that even with MolSight's relatively compact parameter size, the Group Relative Policy Optimization (GRPO) algorithm can further enhance the model's performance on stereomolecular. Through extensive experiments across diverse datasets, our results demonstrate that MolSight achieves state-of-the-art performance in (stereo)chemical optical structure recognition.","authors":["Wenrui Zhang","Xinggang Wang","Bin Feng","Wenyu Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.23463v2","updated":"2025-11-21T14:50:41Z","published":"2025-03-30T14:45:54Z","title":"OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model","summary":"We present OpenDriveVLA, a Vision Language Action model designed for end-to-end autonomous driving, built upon open-source large language models. OpenDriveVLA generates spatially grounded driving actions by leveraging multimodal inputs, including 2D and 3D instance-aware visual representations, ego vehicle states, and language commands. To bridge the modality gap between driving visual representations and language embeddings, we introduce a hierarchical vision language alignment process, projecting both 2D and 3D structured visual tokens into a unified semantic space. Furthermore, we incorporate structured agent environment ego interaction modeling into the autoregressive decoding process, enabling the model to capture fine-grained spatial dependencies and behavior-aware dynamics critical for reliable trajectory planning. Extensive experiments on the nuScenes dataset demonstrate that OpenDriveVLA achieves state-of-the-art results across open-loop trajectory planning and driving-related question answering tasks. Qualitative analyses further illustrate its capability to follow high-level driving commands and generate trajectories under challenging scenarios, highlighting its potential for next-generation end-to-end autonomous driving.","authors":["Xingcheng Zhou","Xuyuan Han","Feng Yang","Yunpu Ma","Volker Tresp","Alois Knoll"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.08318v2","updated":"2025-11-21T14:45:09Z","published":"2025-10-09T15:03:39Z","title":"LinVideo: A Post-Training Framework towards O(n) Attention in Efficient Video Generation","summary":"Video diffusion models (DMs) have enabled high-quality video synthesis. However, their computation costs scale quadratically with sequence length because self-attention has quadratic complexity. While linear attention lowers the cost, fully replacing quadratic attention requires expensive pretraining due to the limited expressiveness of linear attention and the complexity of spatiotemporal modeling in video generation. In this paper, we present LinVideo, an efficient data-free post-training framework that replaces a target number of self-attention modules with linear attention while preserving the original model's performance. First, we observe a significant disparity in the replaceability of different layers. Instead of manual or heuristic choices, we frame layer selection as a binary classification problem and propose selective transfer, which automatically and progressively converts layers to linear attention with minimal performance impact. Additionally, to overcome the ineffectiveness and inefficiency of existing objectives for this transfer process, we introduce an anytime distribution matching (ADM) objective that aligns the distributions of samples across any timestep along the sampling trajectory. This objective is efficient and recovers model performance. Extensive experiments show that our method achieves a 1.25-2.00x speedup while preserving generation quality, and our 4-step distilled model further delivers a 15.92x latency reduction with minimal visual quality drop.","authors":["Yushi Huang","Xingtong Ge","Ruihao Gong","Chengtao Lv","Jun Zhang"],"pdf_url":"","comment":"Code will be released upon acceptance"},{"id":"http://arxiv.org/abs/2511.17282v1","updated":"2025-11-21T14:40:50Z","published":"2025-11-21T14:40:50Z","title":"Where Culture Fades: Revealing the Cultural Gap in Text-to-Image Generation","summary":"Multilingual text-to-image (T2I) models have advanced rapidly in terms of visual realism and semantic alignment, and are now widely utilized. Yet outputs vary across cultural contexts: because language carries cultural connotations, images synthesized from multilingual prompts should preserve cross-lingual cultural consistency. We conduct a comprehensive analysis showing that current T2I models often produce culturally neutral or English-biased results under multilingual prompts. Analyses of two representative models indicate that the issue stems not from missing cultural knowledge but from insufficient activation of culture-related representations. We propose a probing method that localizes culture-sensitive signals to a small set of neurons in a few fixed layers. Guided by this finding, we introduce two complementary alignment strategies: (1) inference-time cultural activation that amplifies the identified neurons without backbone fine-tuned; and (2) layer-targeted cultural enhancement that updates only culturally relevant layers. Experiments on our CultureBench demonstrate consistent improvements over strong baselines in cultural consistency while preserving fidelity and diversity.","authors":["Chuancheng Shi","Shangze Li","Shiming Guo","Simiao Xie","Wenhua Wu","Jingtong Dou","Chao Wu","Canran Xiao","Cong Wang","Zifeng Cheng","Fei Shen","Tat-Seng Chua"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.10629v2","updated":"2025-11-21T14:39:42Z","published":"2025-11-13T18:54:18Z","title":"One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models","summary":"Diffusion models struggle to scale beyond their training resolutions, as direct high-resolution sampling is slow and costly, while post-hoc image super-resolution (ISR) introduces artifacts and additional latency by operating after decoding. We present the Latent Upscaler Adapter (LUA), a lightweight module that performs super-resolution directly on the generator's latent code before the final VAE decoding step. LUA integrates as a drop-in component, requiring no modifications to the base model or additional diffusion stages, and enables high-resolution synthesis through a single feed-forward pass in latent space. A shared Swin-style backbone with scale-specific pixel-shuffle heads supports 2x and 4x factors and remains compatible with image-space SR baselines, achieving comparable perceptual quality with nearly 3x lower decoding and upscaling time (adding only +0.42 s for 1024 px generation from 512 px, compared to 1.87 s for pixel-space SR using the same SwinIR architecture). Furthermore, LUA shows strong generalization across the latent spaces of different VAEs, making it easy to deploy without retraining from scratch for each new decoder. Extensive experiments demonstrate that LUA closely matches the fidelity of native high-resolution generation while offering a practical and efficient path to scalable, high-fidelity image synthesis in modern diffusion pipelines.","authors":["Aleksandr Razin","Danil Kazantsev","Ilya Makarov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.14001v4","updated":"2025-11-21T14:33:03Z","published":"2025-09-17T14:13:20Z","title":"MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment","summary":"Personalized object detection aims to adapt a general-purpose detector to recognize user-specific instances from only a few examples. Lightweight models often struggle in this setting due to their weak semantic priors, while large vision-language models (VLMs) offer strong object-level understanding but are too computationally demanding for real-time or on-device applications. We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment), a distillation framework that transfers multimodal region-level knowledge from a frozen VLM teacher into a lightweight vision-only detector. MOCHA extracts fused visual and textual teacher's embeddings and uses them to guide student training through a dual-objective loss that enforces accurate local alignment and global relational consistency across regions. This process enables efficient transfer of semantics without the need for teacher modifications or textual input at inference. MOCHA consistently outperforms prior baselines across four personalized detection benchmarks under strict few-shot regimes, yielding a +10.1 average improvement, with minimal inference cost.","authors":["Elena Camuffo","Francesco Barbato","Mete Ozay","Simone Milani","Umberto Michieli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17276v1","updated":"2025-11-21T14:31:39Z","published":"2025-11-21T14:31:39Z","title":"Leveraging CVAE for Joint Configuration Estimation of Multifingered Grippers from Point Cloud Data","summary":"This paper presents an efficient approach for determining the joint configuration of a multifingered gripper solely from the point cloud data of its poly-articulated chain, as generated by visual sensors, simulations or even generative neural networks. Well-known inverse kinematics (IK) techniques can provide mathematically exact solutions (when they exist) for joint configuration determination based solely on the fingertip pose, but often require post-hoc decision-making by considering the positions of all intermediate phalanges in the gripper's fingers, or rely on algorithms to numerically approximate solutions for more complex kinematics. In contrast, our method leverages machine learning to implicitly overcome these challenges. This is achieved through a Conditional Variational Auto-Encoder (CVAE), which takes point cloud data of key structural elements as input and reconstructs the corresponding joint configurations. We validate our approach on the MultiDex grasping dataset using the Allegro Hand, operating within 0.05 milliseconds and achieving accuracy comparable to state-of-the-art methods. This highlights the effectiveness of our pipeline for joint configuration estimation within the broader context of AI-driven techniques for grasp planning.","authors":["Julien Merand","Boris Meden","Mathieu Grossard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11313v3","updated":"2025-11-21T14:18:23Z","published":"2025-11-14T13:56:39Z","title":"DocSLM: A Small Vision-Language Model for Long Multimodal Document Understanding","summary":"Large Vision-Language Models (LVLMs) have demonstrated strong multimodal reasoning capabilities on long and complex documents. However, their high memory footprint makes them impractical for deployment on resource-constrained edge devices. We present DocSLM, an efficient Small Vision-Language Model designed for long-document understanding under constrained memory resources. DocSLM incorporates a Hierarchical Multimodal Compressor that jointly encodes visual, textual, and layout information from each page into a fixed-length sequence, greatly reducing memory consumption while preserving both local and global semantics. To enable scalable processing over arbitrarily long inputs, we introduce a Streaming Abstention mechanism that operates on document segments sequentially and filters low-confidence responses using an entropy-based uncertainty calibrator. Across multiple long multimodal document benchmarks, DocSLM matches or surpasses state-of-the-art methods while using 82\\% fewer visual tokens, 75\\% fewer parameters, and 71\\% lower latency, delivering reliable multimodal document understanding on lightweight edge devices. Code and Model are available in https://github.com/Tanveer81/DocSLM.git.","authors":["Tanveer Hannan","Dimitrios Mallios","Parth Pathak","Faegheh Sardari","Thomas Seidl","Gedas Bertasius","Mohsen Fayyaz","Sunando Sengupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17269v1","updated":"2025-11-21T14:16:27Z","published":"2025-11-21T14:16:27Z","title":"Range-Edit: Semantic Mask Guided Outdoor LiDAR Scene Editing","summary":"Training autonomous driving and navigation systems requires large and diverse point cloud datasets that capture complex edge case scenarios from various dynamic urban settings. Acquiring such diverse scenarios from real-world point cloud data, especially for critical edge cases, is challenging, which restricts system generalization and robustness. Current methods rely on simulating point cloud data within handcrafted 3D virtual environments, which is time-consuming, computationally expensive, and often fails to fully capture the complexity of real-world scenes. To address some of these issues, this research proposes a novel approach that addresses the problem discussed by editing real-world LiDAR scans using semantic mask-based guidance to generate novel synthetic LiDAR point clouds. We incorporate range image projection and semantic mask conditioning to achieve diffusion-based generation. Point clouds are transformed to 2D range view images, which are used as an intermediate representation to enable semantic editing using convex hull-based semantic masks. These masks guide the generation process by providing information on the dimensions, orientations, and locations of objects in the real environment, ensuring geometric consistency and realism. This approach demonstrates high-quality LiDAR point cloud generation, capable of producing complex edge cases and dynamic scenes, as validated on the KITTI-360 dataset. This offers a cost-effective and scalable solution for generating diverse LiDAR data, a step toward improving the robustness of autonomous driving systems.","authors":["Suchetan G. Uppur","Hemant Kumar","Vaibhav Kumar"],"pdf_url":"","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.17255v1","updated":"2025-11-21T14:01:36Z","published":"2025-11-21T14:01:36Z","title":"A Little More Like This: Text-to-Image Retrieval with Vision-Language Models Using Relevance Feedback","summary":"Large vision-language models (VLMs) enable intuitive visual search using natural language queries. However, improving their performance often requires fine-tuning and scaling to larger model variants. In this work, we propose a mechanism inspired by traditional text-based search to improve retrieval performance at inference time: relevance feedback. While relevance feedback can serve as an alternative to fine-tuning, its model-agnostic design also enables use with fine-tuned VLMs. Specifically, we introduce and evaluate four feedback strategies for VLM-based retrieval. First, we revise classical pseudo-relevance feedback (PRF), which refines query embeddings based on top-ranked results. To address its limitations, we propose generative relevance feedback (GRF), which uses synthetic captions for query refinement. Furthermore, we introduce an attentive feedback summarizer (AFS), a custom transformer-based model that integrates multimodal fine-grained features from relevant items. Finally, we simulate explicit feedback using ground-truth captions as an upper-bound baseline. Experiments on Flickr30k and COCO with the VLM backbones show that GRF, AFS, and explicit feedback improve retrieval performance by 3-5% in MRR@5 for smaller VLMs, and 1-3% for larger ones, compared to retrieval with no feedback. Moreover, AFS, similarly to explicit feedback, mitigates query drift and is more robust than GRF in iterative, multi-turn retrieval settings. Our findings demonstrate that relevance feedback can consistently enhance retrieval across VLMs and open up opportunities for interactive and adaptive visual search.","authors":["Bulat Khaertdinov","Mirela Popa","Nava Tintarev"],"pdf_url":"","comment":"Accepted to WACV'26"},{"id":"http://arxiv.org/abs/2407.07026v2","updated":"2025-11-21T14:01:14Z","published":"2024-07-09T16:46:58Z","title":"Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition","summary":"With the proliferation of social media posts in recent years, the need to detect sentiments in multimodal (image-text) content has grown rapidly. Since posts are user-generated, the image and text from the same post can express different or even contradictory sentiments, leading to potential \\textbf{sentiment discrepancy}. However, existing works mainly adopt a single-branch fusion structure that primarily captures the consistent sentiment between image and text. The ignorance or implicit modeling of discrepant sentiment results in compromised unimodal encoding and limited performance. In this paper, we propose a semantics Completion and Decomposition (CoDe) network to resolve the above issue. In the semantics completion module, we complement image and text representations with the semantics of the in-image text, helping bridge the sentiment gap. In the semantics decomposition module, we decompose image and text representations with exclusive projection and contrastive learning, thereby explicitly capturing the discrepant sentiment between modalities. Finally, we fuse image and text representations by cross-attention and combine them with the learned discrepant sentiment for final classification. Extensive experiments on four datasets demonstrate the superiority of CoDe and the effectiveness of each proposed module.","authors":["Daiqing Wu","Dongbao Yang","Huawen Shen","Can Ma","Yu Zhou"],"pdf_url":"","comment":"Accepted by Pattern Recognition"},{"id":"http://arxiv.org/abs/2511.17254v1","updated":"2025-11-21T13:57:38Z","published":"2025-11-21T13:57:38Z","title":"Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats","summary":"Despite their impressive performance across a wide range of tasks, Large Vision-Language Models (LVLMs) remain prone to hallucination. In this study, we propose a comprehensive intervention framework aligned with the transformer's causal architecture in LVLMs, integrating the effects of different intervention paths on hallucination. We find that hallucinations in LVLMs do not arise from a single causal path, but rather from the interplay among image-to-input-text, image-to-output-text, and text-to-text pathways. For the first time, we also find that LVLMs rely on different pathways depending on the question-answer alignment format. Building on these insights, we propose simple yet effective methods to identify and intervene on critical hallucination heads within each pathway, tailored to discriminative and generative formats. Experiments across multiple benchmarks demonstrate that our approach consistently reduces hallucinations across diverse alignment types.","authors":["Jiaye Qian","Ge Zheng","Yuchen Zhu","Sibei Yang"],"pdf_url":"","comment":"Accepted to NeurIPS 2025, Project Page: https://github.com/SooLab/AllPath"},{"id":"http://arxiv.org/abs/2511.17253v1","updated":"2025-11-21T13:57:23Z","published":"2025-11-21T13:57:23Z","title":"Blind Deconvolution for Color Images Using Normalized Quaternion Kernels","summary":"In this work, we address the challenging problem of blind deconvolution for color images. Existing methods often convert color images to grayscale or process each color channel separately, which overlooking the relationships between color channels. To handle this issue, we formulate a novel quaternion fidelity term designed specifically for color image blind deconvolution. This fidelity term leverages the properties of quaternion convolution kernel, which consists of four kernels: one that functions similarly to a non-negative convolution kernel to capture the overall blur, and three additional convolution kernels without constraints corresponding to red, green and blue channels respectively model their unknown interdependencies. In order to preserve image intensity, we propose to use the normalized quaternion kernel in the blind deconvolution process. Extensive experiments on real datasets of blurred color images show that the proposed method effectively removes artifacts and significantly improves deblurring effect, demonstrating its potential as a powerful tool for color image deconvolution.","authors":["Yuming Yang","Michael K. Ng","Zhigang Jia","Wei Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.13120v6","updated":"2025-11-21T13:56:18Z","published":"2024-07-18T02:58:06Z","title":"HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration","summary":"Recently, the degenerate preconditioned proximal point (PPP) method provides a unified and flexible framework for designing and analyzing operator-splitting algorithms such as Douglas-Rachford (DR). However, the degenerate PPP method exhibits weak convergence in the infinite-dimensional Hilbert space and lacks accelerated variants. To address these issues, we propose a Halpern-type PPP (HPPP) algorithm, which leverages the strong convergence and acceleration properties of Halpern's iteration method. Moreover, we propose a novel algorithm for image restoration by combining HPPP with denoiser priors such as Plug-and-Play (PnP) prior, which can be viewed as an accelerated PnP method. Finally, numerical experiments including several toy examples and image restoration validate the effectiveness of our proposed algorithms.","authors":["Shuchang Zhang","Hui Zhang","Hongxia Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17242v1","updated":"2025-11-21T13:41:47Z","published":"2025-11-21T13:41:47Z","title":"Equivariant-Aware Structured Pruning for Efficient Edge Deployment: A Comprehensive Framework with Adaptive Fine-Tuning","summary":"This paper presents a novel framework combining group equivariant convolutional neural networks (G-CNNs) with equivariant-aware structured pruning to produce compact, transformation-invariant models for resource-constrained environments. Equivariance to rotations is achieved through the C4 cyclic group via the e2cnn library,enabling consistent performance under geometric transformations while reducing computational overhead.\n  Our approach introduces structured pruning that preserves equivariant properties by analyzing e2cnn layer structure and applying neuron-level pruning to fully connected components. To mitigate accuracy degradation, we implement adaptive fine-tuning that automatically triggers when accuracy drop exceeds 2%, using early stopping and learning rate scheduling for efficient recovery. The framework includes dynamic INT8 quantization and a comprehensive pipeline encompassing training, knowledge distillation, structured pruning, fine-tuning, and quantization.\n  We evaluate our method on satellite imagery (EuroSAT) and standard benchmarks (CIFAR-10, Rotated MNIST) demonstrating effectiveness across diverse domains. Experimental results show 29.3% parameter reduction with significant accuracy recovery, demonstrating that structured pruning of equivariant networks achieves substantial compression while maintaining geometric robustness. Our pipeline provides a reproducible framework for optimizing equivariant models, bridging the gap between group-theoretic network design and practical deployment constraints, with particular relevance to satellite imagery analysis and geometric vision tasks.","authors":["Mohammed Alnemari"],"pdf_url":"","comment":"8 pages, 5 tables, 1 figure. Accepted at IEEE EdgeCom 2025 (11th IEEE International Conference on Edge Computing and Scalable Cloud)"},{"id":"http://arxiv.org/abs/2511.17238v1","updated":"2025-11-21T13:32:56Z","published":"2025-11-21T13:32:56Z","title":"Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables","summary":"The impressive performance of VLMs is largely measured on benchmarks that fail to capture the complexities of real-world scenarios. Existing datasets for tabular QA, such as WikiTableQuestions and FinQA, are overwhelmingly monolingual (English) and present tables in a digitally perfect, clean format. This creates a significant gap between research and practice. To address this, we present \\textbf{MirageTVQA}, a new benchmark designed to evaluate VLMs on these exact dimensions. Featuring nearly 60,000 QA pairs across 24 languages, MirageTVQA challenges models with tables that are not only multilingual but also visually imperfect, incorporating realistic noise to mimic scanned documents. Our evaluation of the leading VLMs reveals two primary failure points: a severe degradation in performance (over 35\\% drop for the best models) when faced with visual noise and a consistent English-first bias where reasoning abilities fail to transfer to other languages. MirageTVQA provides a benchmark for measuring and driving progress towards more robust VLM models for table reasoning. The dataset and the code are available at: https://github.com/anshulsc/MirageTVQA.","authors":["Anshul Singh","Rohan Chaudhary","Gagneet Singh","Abhay Kumary"],"pdf_url":"","comment":"Accepted as Spotligh Talk at EurIPS 2025 Workshop on AI For Tabular Data"},{"id":"http://arxiv.org/abs/2502.17429v3","updated":"2025-11-21T13:32:04Z","published":"2025-02-24T18:58:58Z","title":"CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation","summary":"While 3D instance segmentation (3DIS) has advanced significantly, most existing methods assume that all object classes are known in advance and uniformly distributed. However, this assumption is unrealistic in dynamic, real-world environments where new classes emerge gradually and exhibit natural imbalance. Although some approaches address the emergence of new classes, they often overlook class imbalance, which leads to suboptimal performance, particularly on rare categories. To tackle this, we propose \\ourmethodbf, a unified framework for \\textbf{CL}ass-incremental \\textbf{Imb}alance-aware \\textbf{3D}IS. Building upon established exemplar replay (ER) strategies, we show that ER alone is insufficient to achieve robust performance under memory constraints. To mitigate this, we introduce a novel pseudo-label generator (PLG) that extends supervision to previously learned categories by leveraging predictions from a frozen model trained on prior tasks. Despite its promise, PLG tends to be biased towards frequent classes. Therefore, we propose a class-balanced re-weighting (CBR) scheme that estimates object frequencies from pseudo-labels and dynamically adjusts training bias, without requiring access to past data. We design and evaluate three incremental scenarios for 3DIS on the challenging ScanNet200 dataset and additionally validate our method for semantic segmentation on ScanNetV2. Our approach achieves state-of-the-art results, surpassing prior work by up to 16.76\\% mAP for instance segmentation and approximately 30\\% mIoU for semantic segmentation, demonstrating strong generalisation across both frequent and rare classes. Code is available at: https://github.com/vgthengane/CLIMB3D","authors":["Vishal Thengane","Jean Lahoud","Hisham Cholakkal","Rao Muhammad Anwer","Lu Yin","Xiatian Zhu","Salman Khan"],"pdf_url":"","comment":"Accepted at BMVC 2025"},{"id":"http://arxiv.org/abs/2511.17225v1","updated":"2025-11-21T13:12:13Z","published":"2025-11-21T13:12:13Z","title":"TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making","summary":"In daily life, people often move through spaces to find objects that meet their needs, posing a key challenge in embodied AI. Traditional Demand-Driven Navigation (DDN) handles one need at a time but does not reflect the complexity of real-world tasks involving multiple needs and personal choices. To bridge this gap, we introduce Task-Preferenced Multi-Demand-Driven Navigation (TP-MDDN), a new benchmark for long-horizon navigation involving multiple sub-demands with explicit task preferences. To solve TP-MDDN, we propose AWMSystem, an autonomous decision-making system composed of three key modules: BreakLLM (instruction decomposition), LocateLLM (goal selection), and StatusMLLM (task monitoring). For spatial memory, we design MASMap, which combines 3D point cloud accumulation with 2D semantic mapping for accurate and efficient environmental understanding. Our Dual-Tempo action generation framework integrates zero-shot planning with policy-based fine control, and is further supported by an Adaptive Error Corrector that handles failure cases in real time. Experiments demonstrate that our approach outperforms state-of-the-art baselines in both perception accuracy and navigation robustness.","authors":["Shanshan Li","Da Huang","Yu He","Yanwei Fu","Yu-Gang Jiang","Xiangyang Xue"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.17221v1","updated":"2025-11-21T13:05:42Z","published":"2025-11-21T13:05:42Z","title":"QueryOcc: Query-based Self-Supervision for 3D Semantic Occupancy","summary":"Learning 3D scene geometry and semantics from images is a core challenge in computer vision and a key capability for autonomous driving. Since large-scale 3D annotation is prohibitively expensive, recent work explores self-supervised learning directly from sensor data without manual labels. Existing approaches either rely on 2D rendering consistency, where 3D structure emerges only implicitly, or on discretized voxel grids from accumulated lidar point clouds, limiting spatial precision and scalability. We introduce QueryOcc, a query-based self-supervised framework that learns continuous 3D semantic occupancy directly through independent 4D spatio-temporal queries sampled across adjacent frames. The framework supports supervision from either pseudo-point clouds derived from vision foundation models or raw lidar data. To enable long-range supervision and reasoning under constant memory, we introduce a contractive scene representation that preserves near-field detail while smoothly compressing distant regions. QueryOcc surpasses previous camera-based methods by 26% in semantic RayIoU on the self-supervised Occ3D-nuScenes benchmark while running at 11.6 FPS, demonstrating that direct 4D query supervision enables strong self-supervised occupancy learning. https://research.zenseact.com/publications/queryocc/","authors":["Adam Lilja","Ji Lan","Junsheng Fu","Lars Hammarstrand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17217v1","updated":"2025-11-21T12:57:23Z","published":"2025-11-21T12:57:23Z","title":"Dual-domain Adaptation Networks for Realistic Image Super-resolution","summary":"Realistic image super-resolution (SR) focuses on transforming real-world low-resolution (LR) images into high-resolution (HR) ones, handling more complex degradation patterns than synthetic SR tasks. This is critical for applications like surveillance, medical imaging, and consumer electronics. However, current methods struggle with limited real-world LR-HR data, impacting the learning of basic image features. Pre-trained SR models from large-scale synthetic datasets offer valuable prior knowledge, which can improve generalization, speed up training, and reduce the need for extensive real-world data in realistic SR tasks. In this paper, we introduce a novel approach, Dual-domain Adaptation Networks, which is able to efficiently adapt pre-trained image SR models from simulated to real-world datasets. To achieve this target, we first set up a spatial-domain adaptation strategy through selectively updating parameters of pre-trained models and employing the low-rank adaptation technique to adjust frozen parameters. Recognizing that image super-resolution involves recovering high-frequency components, we further integrate a frequency domain adaptation branch into the adapted model, which combines the spectral data of the input and the spatial-domain backbone's intermediate features to infer HR frequency maps, enhancing the SR result. Experimental evaluations on public realistic image SR benchmarks, including RealSR, D2CRealSR, and DRealSR, demonstrate the superiority of our proposed method over existing state-of-the-art models. Codes are available at: https://github.com/dummerchen/DAN.","authors":["Chaowei Fang","Bolin Fu","De Cheng","Lechao Cheng","Guanbin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.09878v4","updated":"2025-11-21T12:54:49Z","published":"2025-03-12T22:18:29Z","title":"CleverDistiller: Simple and Spatially Consistent Cross-modal Distillation","summary":"Vision foundation models (VFMs) such as DINO have led to a paradigm shift in 2D camera-based perception towards extracting generalized features to support many downstream tasks. Recent works introduce self-supervised cross-modal knowledge distillation (KD) as a way to transfer these powerful generalization capabilities into 3D LiDAR-based models. However, they either rely on highly complex distillation losses, pseudo-semantic maps, or limit KD to features useful for semantic segmentation only. In this work, we propose CleverDistiller, a self-supervised, cross-modal 2D-to-3D KD framework introducing a set of simple yet effective design choices: Unlike contrastive approaches relying on complex loss design choices, our method employs a direct feature similarity loss in combination with a multi layer perceptron (MLP) projection head to allow the 3D network to learn complex semantic dependencies throughout the projection. Crucially, our approach does not depend on pseudo-semantic maps, allowing for direct knowledge transfer from a VFM without explicit semantic supervision. Additionally, we introduce the auxiliary self-supervised spatial task of occupancy prediction to enhance the semantic knowledge, obtained from a VFM through KD, with 3D spatial reasoning capabilities. Experiments on standard autonomous driving benchmarks for 2D-to-3D KD demonstrate that CleverDistiller achieves state-of-the-art performance in both semantic segmentation and 3D object detection (3DOD) by up to 10% mIoU, especially when fine tuning on really low data amounts, showing the effectiveness of our simple yet powerful KD strategy","authors":["Hariprasath Govindarajan","Maciej K. Wozniak","Marvin Klingner","Camille Maurice","B Ravi Kiran","Senthil Yogamani"],"pdf_url":"","comment":"Accepted to BMVC 2025"},{"id":"http://arxiv.org/abs/2407.05650v5","updated":"2025-11-21T12:45:04Z","published":"2024-07-08T06:22:10Z","title":"The Cooperative Network Architecture: Learning Structured Networks as Representation of Sensory Patterns","summary":"We introduce the Cooperative Network Architecture (CNA), a model that represents sensory signals using structured, recurrently connected networks of neurons, termed \"nets.\" Nets are dynamically assembled from overlapping net fragments, which are learned based on statistical regularities in sensory input. This architecture offers robustness to noise, deformation, and generalization to out-of-distribution data, addressing challenges in current vision systems from a novel perspective. We demonstrate that net fragments can be learned without supervision and flexibly recombined to encode novel patterns, enabling figure completion and resilience to noise. Our findings establish CNA as a promising paradigm for developing neural representations that integrate local feature processing with global structure formation, providing a foundation for future research on invariant object recognition.","authors":["Pascal J. Sager","Jan M. Deriu","Benjamin F. Grewe","Thilo Stadelmann","Christoph von der Malsburg"],"pdf_url":"","comment":"Accepted at Neural Computation"},{"id":"http://arxiv.org/abs/2511.17210v1","updated":"2025-11-21T12:42:07Z","published":"2025-11-21T12:42:07Z","title":"FisheyeGaussianLift: BEV Feature Lifting for Surround-View Fisheye Camera Perception","summary":"Accurate BEV semantic segmentation from fisheye imagery remains challenging due to extreme non-linear distortion, occlusion, and depth ambiguity inherent to wide-angle projections. We present a distortion-aware BEV segmentation framework that directly processes multi-camera high-resolution fisheye images,utilizing calibrated geometric unprojection and per-pixel depth distribution estimation. Each image pixel is lifted into 3D space via Gaussian parameterization, predicting spatial means and anisotropic covariances to explicitly model geometric uncertainty. The projected 3D Gaussians are fused into a BEV representation via differentiable splatting, producing continuous, uncertainty-aware semantic maps without requiring undistortion or perspective rectification. Extensive experiments demonstrate strong segmentation performance on complex parking and urban driving scenarios, achieving IoU scores of 87.75% for drivable regions and 57.26% for vehicles under severe fisheye distortion and diverse environmental conditions.","authors":["Shubham Sonarghare","Prasad Deshpande","Ciaran Hogan","Deepika-Rani Kaliappan-Mahalingam","Ganesh Sistu"],"pdf_url":"","comment":"8 pages, 3 figures, published in IMVIP 2025 conference"},{"id":"http://arxiv.org/abs/2511.17209v1","updated":"2025-11-21T12:41:27Z","published":"2025-11-21T12:41:27Z","title":"Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT Transformers","summary":"We introduce SPECTRE, a fully transformer-based foundation model for volumetric computed tomography (CT). Our Self-Supervised & Cross-Modal Pretraining for CT Representation Extraction (SPECTRE) approach utilizes scalable 3D Vision Transformer architectures and modern self-supervised and vision-language pretraining strategies to learn general-purpose CT representations. Volumetric CT poses unique challenges, such as extreme token scaling, geometric anisotropy, and weak or noisy clinical supervision, that make standard transformer and contrastive learning recipes ineffective out of the box. The framework jointly optimizes a local transformer for high-resolution volumetric feature extraction and a global transformer for whole-scan context modeling, making large-scale 3D attention computationally tractable. Notably, SPECTRE is trained exclusively on openly available CT datasets, demonstrating that high-performing, generalizable representations can be achieved without relying on private data. Pretraining combines DINO-style self-distillation with SigLIP-based vision-language alignment using paired radiology reports, yielding features that are both geometrically consistent and clinically meaningful. Across multiple CT benchmarks, SPECTRE consistently outperforms prior CT foundation models in both zero-shot and fine-tuned settings, establishing SPECTRE as a scalable, open, and fully transformer-based foundation model for 3D medical imaging.","authors":["Cris Claessens","Christiaan Viviers","Giacomo D'Amicantonio","Egor Bondarev","Fons van der Sommen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17207v1","updated":"2025-11-21T12:40:55Z","published":"2025-11-21T12:40:55Z","title":"SING3R-SLAM: Submap-based Indoor Monocular Gaussian SLAM with 3D Reconstruction Priors","summary":"Recent advances in dense 3D reconstruction enable the accurate capture of local geometry; however, integrating them into SLAM is challenging due to drift and redundant point maps, which limit efficiency and downstream tasks, such as novel view synthesis. To address these issues, we propose SING3R-SLAM, a globally consistent and compact Gaussian-based dense RGB SLAM framework. The key idea is to combine locally consistent 3D reconstructions with a unified global Gaussian representation that jointly refines scene geometry and camera poses, enabling efficient and versatile 3D mapping for multiple downstream applications. SING3R-SLAM first builds locally consistent submaps through our lightweight tracking and reconstruction module, and then progressively aligns and fuses them into a global Gaussian map that enforces cross-view geometric consistency. This global map, in turn, provides feedback to correct local drift and enhance the robustness of tracking. Extensive experiments demonstrate that SING3R-SLAM achieves state-of-the-art tracking, 3D reconstruction, and novel view rendering, resulting in over 12% improvement in tracking and producing finer, more detailed geometry, all while maintaining a compact and memory-efficient global representation on real-world datasets.","authors":["Kunyi Li","Michael Niemeyer","Sen Wang","Stefano Gasperini","Nassir Navab","Federico Tombari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.06869v3","updated":"2025-11-21T12:37:49Z","published":"2025-08-09T07:38:48Z","title":"VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding","summary":"Multimodal large language models (MLLMs) demonstrate exceptional performance in vision-language tasks, yet their processing of long videos is constrained by input context length and high computational costs. Sparse frame sampling thus becomes a necessary preprocessing step, with sampled frame quality directly impacting downstream performance. Existing keyframe search algorithms achieve a balance between efficiency and sampled frame quality but heavily rely on the visual modality alone. This makes them difficult to adapt to text-related tasks and often leads to retrieval results deviating from core semantic content. To address this, we propose the VISUAL-SUBTITLE INTEGRATION (VSI), a multimodal keyframe retrieval framework. It employs a dual-branch collaborative retrieval approach combining Video Search and Subtitle Match to fuse complementary visual and textual information for precise localization. Experiments on LongVideoBench and VideoMME demonstrate that VSI achieves state-of-the-art accuracy in keyframe retrieval while delivering breakthrough performance in text-related tasks and exhibiting strong generalization across other tasks.","authors":["Jianxiang He","Meisheng Hong","Jungang Li","Ziyang Chen","Weiyu Guo","Xuming Hu","Hui Xiong"],"pdf_url":"","comment":"9 pages,3 figures"},{"id":"http://arxiv.org/abs/2511.17201v1","updated":"2025-11-21T12:27:49Z","published":"2025-11-21T12:27:49Z","title":"Continual Alignment for SAM: Rethinking Foundation Models for Medical Image Segmentation in Continual Learning","summary":"In medical image segmentation, heterogeneous privacy policies across institutions often make joint training on pooled datasets infeasible, motivating continual image segmentation-learning from data streams without catastrophic forgetting. While the Segment Anything Model (SAM) offers strong zero-shot priors and has been widely fine-tuned across downstream tasks, its large parameter count and computational overhead challenge practical deployment. This paper demonstrates that the SAM paradigm is highly promising once its computational efficiency and performance can be balanced. To this end, we introduce the Alignment Layer, a lightweight, plug-and-play module which aligns encoder-decoder feature distributions to efficiently adapt SAM to specific medical images, improving accuracy while reducing computation. Building on SAM and the Alignment Layer, we then propose Continual Alignment for SAM (CA-SAM), a continual learning strategy that automatically adapts the appropriate Alignment Layer to mitigate catastrophic forgetting, while leveraging SAM's zero-shot priors to preserve strong performance on unseen medical datasets. Experimented across nine medical segmentation datasets under continual-learning scenario, CA-SAM achieves state-of-the-art performance. Our code, models and datasets will be released on \\mbox{https://github.com/azzzzyo/Continual-Alignment-for-SAM.}","authors":["Jiayi Wang","Wei Dai","Haoyu Wang","Sihan Yang","Haixia Bi","Jian Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17199v1","updated":"2025-11-21T12:26:30Z","published":"2025-11-21T12:26:30Z","title":"VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation","summary":"Vision-language-action (VLA) models show potential for general robotic tasks, but remain challenging in spatiotemporally coherent manipulation, which requires fine-grained representations. Typically, existing methods embed 3D positions into visual representations to enhance the spatial precision of actions. However, these methods struggle to achieve temporally coherent control over action execution. In this work, we propose VLA-4D, a general VLA model with 4D awareness for spatiotemporally coherent robotic manipulation. Our model is guided by two key designs: 1) 4D-aware visual representation. We extract visual features, embed 1D time into 3D positions for 4D embeddings, and fuse them into a unified visual representation via a cross-attention mechanism. 2) Spatiotemporal action representation. We extend conventional spatial action representations with temporal information to enable the spatiotemporal planning, and align the multimodal representations into the LLM for spatiotemporal action prediction. Within this unified framework, the designed visual and action representations jointly make robotic manipulation spatially-smooth and temporally-coherent. In addition, we extend the VLA dataset with temporal action annotations for fine-tuning our model. Extensive experiments have been conducted to verify the superiority of our method across different tasks of robotic manipulation.","authors":["Hanyu Zhou","Chuanhao Ma","Gim Hee Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17198v1","updated":"2025-11-21T12:25:47Z","published":"2025-11-21T12:25:47Z","title":"Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism","summary":"LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.","authors":["Kaiyu Li","Jiayu Wang","Zhi Wang","Hui Qiao","Weizhan Zhang","Deyu Meng","Xiangyong Cao"],"pdf_url":"","comment":"Page: https://earth-insights.github.io/EarthAgent"},{"id":"http://arxiv.org/abs/2511.17196v1","updated":"2025-11-21T12:23:07Z","published":"2025-11-21T12:23:07Z","title":"Real Noise Decoupling for Hyperspectral Image Denoising","summary":"Hyperspectral image (HSI) denoising is a crucial step in enhancing the quality of HSIs. Noise modeling methods can fit noise distributions to generate synthetic HSIs to train denoising networks. However, the noise in captured HSIs is usually complex and difficult to model accurately, which significantly limits the effectiveness of these approaches. In this paper, we propose a multi-stage noise-decoupling framework that decomposes complex noise into explicitly modeled and implicitly modeled components. This decoupling reduces the complexity of noise and enhances the learnability of HSI denoising methods when applied to real paired data. Specifically, for explicitly modeled noise, we utilize an existing noise model to generate paired data for pre-training a denoising network, equipping it with prior knowledge to handle the explicitly modeled noise effectively. For implicitly modeled noise, we introduce a high-frequency wavelet guided network. Leveraging the prior knowledge from the pre-trained module, this network adaptively extracts high-frequency features to target and remove the implicitly modeled noise from real paired HSIs. Furthermore, to effectively eliminate all noise components and mitigate error accumulation across stages, a multi-stage learning strategy, comprising separate pre-training and joint fine-tuning, is employed to optimize the entire framework. Extensive experiments on public and our captured datasets demonstrate that our proposed framework outperforms state-of-the-art methods, effectively handling complex real-world noise and significantly enhancing HSI quality.","authors":["Yingkai Zhang","Tao Zhang","Jing Nie","Ying Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14137v2","updated":"2025-11-21T12:17:52Z","published":"2025-11-18T04:54:39Z","title":"Attention Via Convolutional Nearest Neighbors","summary":"The shift from Convolutional Neural Networks to Transformers has reshaped computer vision, yet these two architectural families are typically viewed as fundamentally distinct. We argue that convolution and self-attention, despite their apparent differences, can be unified within a single k-nearest neighbor aggregation framework. The critical insight is that both operations are special cases of neighbor selection and aggregation; convolution selects neighbors by spatial proximity, while attention selects by feature similarity, revealing they exist on a continuous spectrum. We introduce Convolutional Nearest Neighbors (ConvNN), a unified framework that formalizes this connection. Crucially, ConvNN serves as a drop-in replacement for convolutional and attention layers, enabling systematic exploration of the intermediate spectrum between these two extremes. We validate the framework's coherence on CIFAR-10 and CIFAR-100 classification tasks across two complementary architectures: (1) Hybrid branching in VGG improves accuracy on both CIFAR datasets by combining spatial-proximity and feature-similarity selection; and (2) ConvNN in ViT outperforms standard attention and other attention variants on both datasets. Extensive ablations on $k$ values and architectural variants reveal that interpolating along this spectrum provides regularization benefits by balancing local and global receptive fields. Our work provides a unifying framework that dissolves the apparent distinction between convolution and attention, with implications for designing more principled and interpretable vision architectures.","authors":["Mingi Kang","Jeová Farias Sales Rocha Neto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08708v2","updated":"2025-11-21T12:13:42Z","published":"2025-06-10T11:46:06Z","title":"PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly","summary":"While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.","authors":["Liang Ma","Jiajun Wen","Min Lin","Rongtao Xu","Xiwen Liang","Bingqian Lin","Jun Ma","Yongxin Wang","Ziming Wei","Haokun Lin","Mingfei Han","Meng Cao","Bokui Chen","Ivan Laptev","Xiaodan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.14550v2","updated":"2025-11-21T12:12:05Z","published":"2025-09-18T02:31:24Z","title":"EatGAN: An Edge-Attention Guided Generative Adversarial Network for Single Image Super-Resolution","summary":"Single-image super-resolution (SISR) is an important task in image processing, aiming to enhance the resolution of imaging systems. Recently, SISR has made a significant leap and achieved promising results with deep learning. GAN-based models stand out among all the deep learning models because of their excellent performance in perceiving quality. However, it is rather difficult for them to reconstruct realistic high-frequency details and achieve stable training. To solve these issues, we introduce an Edge-Attention guided Generative Adversarial Network (EatGAN), the first GAN-based SISR model that simultaneously leverages edge priors both explicitly and implicitly inside the generator, which (i) proposes a Normalized Edge Attention (NEA) mechanism based on channel-affine and spatial gating that transforms edge prior into lightweight, learnable modulation parameters and injects and fuses them multiple times in a (ii) edge-guided hybrid residual block, which progressively enforces structural consistency across scales; and (iii) a composite generator objective combining pixel, perceptual, edge-gradient, and adversarial terms. Experiments show consistent state-of-the-art across distortion-oriented benchmarks and perception oriented benchmarks. Notably, our model achieves 40.87 dB and 0.073 (LPIPS) on Manga 109, which indicates that reframing image priors from passive guidance into a controllable modulation primitive for generators can chart a practical path toward trustworthy, high-fidelity Super-Resolution.","authors":["Penghao Rao","Tieyong Zeng"],"pdf_url":"","comment":"17 pages (8 pages of main text + 3 pages of reference + 6 pages of supplementary material)"},{"id":"http://arxiv.org/abs/2508.04270v2","updated":"2025-11-21T12:07:29Z","published":"2025-08-06T09:53:39Z","title":"TDSNNs: Competitive Topographic Deep Spiking Neural Networks for Visual Cortex Modeling","summary":"The primate visual cortex exhibits topographic organization, where functionally similar neurons are spatially clustered, a structure widely believed to enhance neural processing efficiency. While prior works have demonstrated that conventional deep ANNs can develop topographic representations, these models largely neglect crucial temporal dynamics. This oversight often leads to significant performance degradation in tasks like object recognition and compromises their biological fidelity. To address this, we leverage spiking neural networks (SNNs), which inherently capture spike-based temporal dynamics and offer enhanced biological plausibility. We propose a novel Spatio-Temporal Constraints (STC) loss function for topographic deep spiking neural networks (TDSNNs), successfully replicating the hierarchical spatial functional organization observed in the primate visual cortex from low-level sensory input to high-level abstract representations. Our results show that STC effectively generates representative topographic features across simulated visual cortical areas. While introducing topography typically leads to significant performance degradation in ANNs, our spiking architecture exhibits a remarkably small performance drop (No drop in ImageNet top-1 accuracy, compared to a 3% drop observed in TopoNet, which is the best-performing topographic ANN so far) and outperforms topographic ANNs in brain-likeness. We also reveal that topographic organization facilitates efficient and stable temporal information processing via the spike mechanism in TDSNNs, contributing to model robustness. These findings suggest that TDSNNs offer a compelling balance between computational performance and brain-like features, providing not only a framework for interpreting neural science phenomena but also novel insights for designing more efficient and robust deep learning models.","authors":["Deming Zhou","Yuetong Fang","Zhaorui Wang","Renjing Xu"],"pdf_url":"","comment":"AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2511.17185v1","updated":"2025-11-21T12:05:46Z","published":"2025-11-21T12:05:46Z","title":"PostCam: Camera-Controllable Novel-View Video Generation with Query-Shared Cross-Attention","summary":"We propose PostCam, a framework for novel-view video generation that enables post-capture editing of camera trajectories in dynamic scenes. We find that existing video recapture methods suffer from suboptimal camera motion injection strategies; such suboptimal designs not only limit camera control precision but also result in generated videos that fail to preserve fine visual details from the source video. To achieve more accurate and flexible motion manipulation, PostCam introduces a query-shared cross-attention module. It integrates two distinct forms of control signals: the 6-DoF camera poses and the 2D rendered video frames. By fusing them into a unified representation within a shared feature space, our model can extract underlying motion cues, which enhances both control precision and generation quality. Furthermore, we adopt a two-stage training strategy: the model first learns coarse camera control from pose inputs, and then incorporates visual information to refine motion accuracy and enhance visual fidelity. Experiments on both real-world and synthetic datasets demonstrate that PostCam outperforms state-of-the-art methods by over 20% in camera control precision and view consistency, while achieving the highest video generation quality. Our project webpage is publicly available at: https://cccqaq.github.io/PostCam.github.io/","authors":["Yipeng Chen","Zhichao Ye","Zhenzhou Fang","Xinyu Chen","Xiaoyu Zhang","Jialing Liu","Nan Wang","Haomin Liu","Guofeng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17183v1","updated":"2025-11-21T12:04:53Z","published":"2025-11-21T12:04:53Z","title":"Navigating in the Dark: A Multimodal Framework and Dataset for Nighttime Traffic Sign Recognition","summary":"Traffic signboards are vital for road safety and intelligent transportation systems, enabling navigation and autonomous driving. Yet, recognizing traffic signs at night remains challenging due to visual noise and scarcity of public nighttime datasets. Despite advances in vision architectures, existing methods struggle with robustness under low illumination and fail to leverage complementary mutlimodal cues effectively. To overcome these limitations, firstly, we introduce INTSD, a large-scale dataset comprising street-level night-time images of traffic signboards collected across diverse regions of India. The dataset spans 41 traffic signboard classes captured under varying lighting and weather conditions, providing a comprehensive benchmark for both detection and classification tasks. To benchmark INTSD for night-time sign recognition, we conduct extensive evaluations using state-of-the-art detection and classification models. Secondly, we propose LENS-Net, which integrates an adaptive image enhancement detector for joint illumination correction and sign localization, followed by a structured multimodal CLIP-GCNN classifier that leverages cross-modal attention and graph-based reasoning for robust and semantically consistent recognition. Our method surpasses existing frameworks, with ablation studies confirming the effectiveness of its key components. The dataset and code for LENS-Net is publicly available for research.","authors":["Aditya Mishra","Akshay Agarwal","Haroon Lone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17181v1","updated":"2025-11-21T12:04:00Z","published":"2025-11-21T12:04:00Z","title":"Investigating self-supervised representations for audio-visual deepfake detection","summary":"Self-supervised representations excel at many vision and speech tasks, but their potential for audio-visual deepfake detection remains underexplored. Unlike prior work that uses these features in isolation or buried within complex architectures, we systematically evaluate them across modalities (audio, video, multimodal) and domains (lip movements, generic visual content). We assess three key dimensions: detection effectiveness, interpretability of encoded information, and cross-modal complementarity. We find that most self-supervised features capture deepfake-relevant information, and that this information is complementary. Moreover, models primarily attend to semantically meaningful regions rather than spurious artifacts. Yet none generalize reliably across datasets. This generalization failure likely stems from dataset characteristics, not from the features themselves latching onto superficial patterns. These results expose both the promise and fundamental challenges of self-supervised representations for deepfake detection: while they learn meaningful patterns, achieving robust cross-domain performance remains elusive.","authors":["Dragos-Alexandru Boldisor","Stefan Smeu","Dan Oneata","Elisabeta Oneata"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.09110v3","updated":"2025-11-21T12:01:11Z","published":"2025-10-10T08:04:30Z","title":"Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding","summary":"Visual grouping -- operationalized through tasks such as instance segmentation, visual grounding, and object detection -- enables applications ranging from robotic perception to photo editing. These fundamental problems in computer vision are powered by large-scale, painstakingly annotated datasets. Despite their impact, these datasets are costly to build, biased in coverage, and difficult to scale. Synthetic datasets offer a promising alternative but struggle with flexibility, accuracy, and compositional diversity.\n  We introduce Synthetic Object Compositions (SOC), an accurate and scalable data synthesis pipeline via a novel object-centric composition strategy. It composes high-quality synthetic object segments into new images using 3D geometric layout augmentation and camera configuration augmentation with generative harmonization and mask-area-weighted blending, yielding accurate and diverse masks, boxes, and referring expressions.\n  Models trained on just 100K of our synthetic images outperform those trained on larger real datasets (GRIT 20M, V3Det 200K) and synthetic pipelines (Copy-Paste, X-Paste, SynGround, SegGen) by +24-36% -- achieving +10.9 AP on LVIS and +8.4 NAcc on gRefCOCO. Beyond the general open-vocabulary setup, SOC also enables controllable dataset construction for different use cases and boosts performance in both low-data and closed-vocabulary scenarios.\n  Augmenting LVIS and COCO with synthetic object segments delivers strong performance across different real-data scales and yields even greater improvements under extremely limited real-data conditions, including +6.59 AP on a 1% COCO data setup. Furthermore, this controllability enables targeted data generation for intra-class referring, a diagnostic grounding task we propose that requires fine-grained attribute discrimination.","authors":["Weikai Huang","Jieyu Zhang","Taoyang Jia","Chenhao Zheng","Ziqi Gao","Jae Sung Park","Winson Han","Ranjay Krishna"],"pdf_url":"","comment":"Project website: https://github.com/weikaih04/Synthetic-Detection-Segmentation-Grounding-Data"},{"id":"http://arxiv.org/abs/2511.16449v2","updated":"2025-11-21T11:57:47Z","published":"2025-11-20T15:16:09Z","title":"VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference","summary":"Vision-Language-Action (VLA) models have shown great promise for embodied AI, yet the heavy computational cost of processing continuous visual streams severely limits their real-time deployment. Token pruning (keeping salient visual tokens and dropping redundant ones) has emerged as an effective approach for accelerating Vision-Language Models (VLMs), offering a solution for efficient VLA. However, these VLM-specific token pruning methods select tokens based solely on semantic salience metrics (e.g., prefill attention), while overlooking the VLA's intrinsic dual-system nature of high-level semantic understanding and low-level action execution. Consequently, these methods bias token retention toward semantic cues, discard critical information for action generation, and significantly degrade VLA performance. To bridge this gap, we propose VLA-Pruner, a versatile plug-and-play VLA-specific token prune method that aligns with the dual-system nature of VLA models and exploits the temporal continuity in robot manipulation. Specifically, VLA-Pruner adopts a dual-level importance criterion for visual token retention: vision-language prefill attention for semantic-level relevance and action decode attention, estimated via temporal smoothing, for action-level importance. Based on this criterion, VLA-Pruner proposes a novel dual-level token selection strategy that adaptively preserves a compact, informative set of visual tokens for both semantic understanding and action execution under given compute budget. Experiments show that VLA-Pruner achieves state-of-the-art performance across multiple VLA architectures and diverse robotic tasks.","authors":["Ziyan Liu","Yeqiu Chen","Hongyi Cai","Tao Lin","Shuo Yang","Zheng Liu","Bo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12233v2","updated":"2025-11-21T11:52:36Z","published":"2025-11-15T14:21:16Z","title":"Model Inversion Attack Against Deep Hashing","summary":"Deep hashing improves retrieval efficiency through compact binary codes, yet it introduces severe and often overlooked privacy risks. The ability to reconstruct original training data from hash codes could lead to serious threats such as biometric forgery and privacy breaches. However, model inversion attacks specifically targeting deep hashing models remain unexplored, leaving their security implications unexamined. This research gap stems from the inaccessibility of genuine training hash codes and the highly discrete Hamming space, which prevents existing methods from adapting to deep hashing. To address these challenges, we propose DHMI, the first diffusion-based model inversion framework designed for deep hashing. DHMI first clusters an auxiliary dataset to derive semantic hash centers as surrogate anchors. It then introduces a surrogate-guided denoising optimization method that leverages a novel attack metric (fusing classification consistency and hash proximity) to dynamically select candidate samples. A cluster of surrogate models guides the refinement of these candidates, ensuring the generation of high-fidelity and semantically consistent images. Experiments on multiple datasets demonstrate that DHMI successfully reconstructs high-resolution, high-quality images even under the most challenging black-box setting, where no training hash codes are available. Our method outperforms the existing state-of-the-art model inversion attacks in black-box scenarios, confirming both its practical efficacy and the critical privacy risks inherent in deep hashing systems.","authors":["Dongdong Zhao","Qiben Xu","Ranxin Fang","Baogang Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17171v1","updated":"2025-11-21T11:45:22Z","published":"2025-11-21T11:45:22Z","title":"FireScope: Wildfire Risk Prediction with a Chain-of-Thought Oracle","summary":"Predicting wildfire risk is a reasoning-intensive spatial problem that requires the integration of visual, climatic, and geographic factors to infer continuous risk maps. Existing methods lack the causal reasoning and multimodal understanding required for reliable generalization. We introduce $\\textbf{FireScope-Bench}$, a large-scale dataset and benchmark that couples Sentinel-2 imagery and climate data with expert-defined risk rasters across the USA, and real wildfire events in Europe for cross-continental evaluation. Building on this dataset, we propose $\\textbf{FireScope}$, a VLM-based reasoning-to-generation framework that learns from both reinforcement learning and visual supervision to predict risk rasters with complementary reasoning traces. When trained in the USA and tested in Europe, $\\textbf{FireScope}$ achieves substantial performance gains, while expert feedback and automated analysis confirm that its reasoning traces are faithful and semantically meaningful. Our findings demonstrate that reasoning can ground raster prediction models, improving both generalization and interpretability. To our knowledge, this is the first framework to (1) demonstrate that language-based reasoning can improve generalization in visual generation, (2) propose a high-resolution wildfire risk model that can be applied across continents, and (3) enable systematic studies of robust cross-continental generalization for multimodal fire risk models. We believe that $\\textbf{FireScope-Bench}$ has the potential to serve as a foundation for advancing reasoning-driven, interpretable and generalizable spatial modeling. Data and source code will be made publicly available.","authors":["Mario Markov","Stefan Maria Ailuro","Luc Van Gool","Konrad Schindler","Danda Pani Paudel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.07160v3","updated":"2025-11-21T11:38:45Z","published":"2025-02-11T00:56:44Z","title":"HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates","summary":"Image compression under ultra-low bitrates remains challenging for both conventional learned image compression (LIC) and generative vector-quantized (VQ) modeling. Conventional LIC suffers from severe artifacts due to heavy quantization, while generative VQ modeling gives poor fidelity due to the mismatch between learned generative priors and specific inputs. In this work, we propose Hybrid-Diffusion Image Compression (HDCompression), a dual-stream framework that utilizes both generative VQ-modeling and diffusion models, as well as conventional LIC, to achieve both high fidelity and high perceptual quality. Different from previous hybrid methods that directly use pre-trained LIC models to generate low-quality fidelity-preserving information from heavily quantized latent, we use diffusion models to extract high-quality complementary fidelity information from the ground-truth input, which can enhance the system performance in several aspects: improving index map prediction, enhancing the fidelity-preserving output of the LIC stream, and refining conditioned image reconstruction with VQ-latent correction. In addition, our diffusion model is based on a dense representative vector (DRV), which is lightweight with very simple sampling schedulers. Extensive experiments demonstrate that our HDCompression outperforms the previous conventional LIC, generative VQ-modeling, and hybrid frameworks in both quantitative metrics and qualitative visualization, providing balanced robust compression performance at ultra-low bitrates.","authors":["Lei Lu","Yize Li","Yanzhi Wang","Wei Wang","Wei Jiang"],"pdf_url":"","comment":"Accepted by PRICAI 2025 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2511.17158v1","updated":"2025-11-21T11:25:32Z","published":"2025-11-21T11:25:32Z","title":"Exploring the added value of pretherapeutic MR descriptors in predicting breast cancer pathologic complete response to neoadjuvant chemotherapy","summary":"Objectives: To evaluate the association between pretreatment MRI descriptors and breast cancer (BC) pathological complete response (pCR) to neoadjuvant chemotherapy (NAC). Materials \\& Methods: Patients with BC treated by NAC with a breast MRI between 2016 and 2020 were included in this retrospective observational single-center study. MR studies were described using the standardized BI-RADS and breast edema score on T2-weighted MRI. Univariable and multivariable logistic regression analyses were performed to assess variables association with pCR according to residual cancer burden. Random forest classifiers were trained to predict pCR on a random split including 70% of the database and were validated on the remaining cases. Results: Among 129 BC, 59 (46%) achieved pCR after NAC (luminal (n=7/37, 19%), triple negative (TN) (n=30/55, 55%), HER2+ (n=22/37, 59%). Clinical and biological items associated with pCR were BC subtype (p<0.001), T stage 0/I/II (p=0.008), higher Ki67 (p=0.005) and higher tumor-infiltrating lymphocytes levels (p=0.016). Univariate analysis showed that the following MRI features, oval or round shape (p=0.047), unifocality (p=0.026), non-spiculated margins (p=0.018), no associated non-mass enhancement (NME) (p = 0.024) and a lower MRI size (p = 0.031) were significantly associated with pCR. Unifocality and non-spiculated margins remained independently associated with pCR at multivariable analysis. Adding significant MRI features to clinicobiological variables in random forest classifiers significantly increased sensitivity (0.67 versus 0.62), specificity (0.69 versus 0.67) and precision (0.71 versus 0.67) for pCR prediction. Conclusion: Non-spiculated margins and unifocality are independently associated with pCR and can increase models performance to predict BC response to NAC. Clinical Relevance Statement: A multimodal approach integrating pretreatment MRI features with clinicobiological predictors, including TILs, could be employed to develop machine learning models for identifying patients at risk of non-response. This may enable consideration of alternative therapeutic strategies to optimize treatment outcomes","authors":["Caroline Malhaire","Fatine Selhane","Marie-Judith Saint-Martin","Vincent Cockenpot","Pia Akl","Enora Laas","Audrey Bellesoeur","Catherine Ala Eddine","Melodie Bereby-Kahane","Julie Manceau","Delphine Sebbag-Sfez","Jean-Yves Pierga","Fabien Reyal","Anne Vincent-Salomon","Herve Brisse","Frederique Frouin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17155v1","updated":"2025-11-21T11:19:57Z","published":"2025-11-21T11:19:57Z","title":"UI-Styler: Ultrasound Image Style Transfer with Class-Aware Prompts for Cross-Device Diagnosis Using a Frozen Black-Box Inference Network","summary":"The appearance of ultrasound images varies across acquisition devices, causing domain shifts that degrade the performance of fixed black-box downstream inference models when reused. To mitigate this issue, it is practical to develop unpaired image translation (UIT) methods that effectively align the statistical distributions between source and target domains, particularly under the constraint of a reused inference-blackbox setting. However, existing UIT approaches often overlook class-specific semantic alignment during domain adaptation, resulting in misaligned content-class mappings that can impair diagnostic accuracy. To address this limitation, we propose UI-Styler, a novel ultrasound-specific, class-aware image style transfer framework. UI-Styler leverages a pattern-matching mechanism to transfer texture patterns embedded in the target images onto source images while preserving the source structural content. In addition, we introduce a class-aware prompting strategy guided by pseudo labels of the target domain, which enforces accurate semantic alignment with diagnostic categories. Extensive experiments on ultrasound cross-device tasks demonstrate that UI-Styler consistently outperforms existing UIT methods, achieving state-of-the-art performance in distribution distance and downstream tasks, such as classification and segmentation.","authors":["Nhat-Tuong Do-Tran","Ngoc-Hoang-Lam Le","Ching-Chun Huang"],"pdf_url":"","comment":"Project page: https://dotrannhattuong.github.io/UIStyler, Accepted to WACV 2026"},{"id":"http://arxiv.org/abs/2511.01588v2","updated":"2025-11-21T11:16:04Z","published":"2025-11-03T13:57:08Z","title":"Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization","summary":"Embedding models are a cornerstone of modern AI. Driven by Multimodal Large Language Models (MLLMs), they have made great progress in architecture and data curation, while the holistic paradigm is still limited to SSC, i.e., single input, singular embedding, contrastive supervision, which collapses rich, multifaceted inputs into monolithic embeddings and fails to fully exploit MLLM capabilities. In this paper, we tailor one Parallel Decoupling Framework (PDF) for multimodal embedding learning, by utilizing the proprietary steerability of MLLMs, i.e., their ability to flexibly generate quite differentiated response under explicit instructions. Concretely, PDF conditions a shared MLLM backbone on distinct, learnable prefixes to roll out multiple parallel paths for one input, then relies on these paths to obtain parallel embeddings. To promote full parallel diversity, we employ Mutual Information Minimization (MIM) as an explicit constraint, coupled with per-path contrastive supervision to maintain semantic alignment. Such dual-objectives force PDF to yield robust semantic coverage and a generalizable embedding space. Ultimately, the remarkable embedding space are accessible at inference via one single forward pass, incurring negligible computational overhead. We instantiate PDF on multiple MLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains are consistently achieved across various resolutions and model sizes, e.g., boosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9% (7B), while the VLM2Vec-Qwen2VL models by +4.2% (2B) and +3.1% (7B). In terms of efficiency, our 2B model surpasses its baseline by +2.6% using only half the computational budget.","authors":["Zhicheng Wang","Chen Ju","Xu Chen","Shuai Xiao","Jinsong Lan","Xiaoyong Zhu","Ying Chen","Zhiguo Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17150v1","updated":"2025-11-21T11:16:00Z","published":"2025-11-21T11:16:00Z","title":"DiffRefiner: Coarse to Fine Trajectory Planning via Diffusion Refinement with Semantic Interaction for End to End Autonomous Driving","summary":"Unlike discriminative approaches in autonomous driving that predict a fixed set of candidate trajectories of the ego vehicle, generative methods, such as diffusion models, learn the underlying distribution of future motion, enabling more flexible trajectory prediction. However, since these methods typically rely on denoising human-crafted trajectory anchors or random noise, there remains significant room for improvement. In this paper, we propose DiffRefiner, a novel two-stage trajectory prediction framework. The first stage uses a transformer-based Proposal Decoder to generate coarse trajectory predictions by regressing from sensor inputs using predefined trajectory anchors. The second stage applies a Diffusion Refiner that iteratively denoises and refines these initial predictions. In this way, we enhance the performance of diffusion-based planning by incorporating a discriminative trajectory proposal module, which provides strong guidance for the generative refinement process. Furthermore, we design a fine-grained denoising decoder to enhance scene compliance, enabling more accurate trajectory prediction through enhanced alignment with the surrounding environment. Experimental results demonstrate that DiffRefiner achieves state-of-the-art performance, attaining 87.4 EPDMS on NAVSIM v2, and 87.1 DS along with 71.4 SR on Bench2Drive, thereby setting new records on both public benchmarks. The effectiveness of each component is validated via ablation studies as well.","authors":["Liuhan Yin","Runkun Ju","Guodong Guo","Erkang Cheng"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2511.17147v1","updated":"2025-11-21T11:11:04Z","published":"2025-11-21T11:11:04Z","title":"A lightweight detector for real-time detection of remote sensing images","summary":"Remote sensing imagery is widely used across various fields, yet real-time detection remains challenging due to the prevalence of small objects and the need to balance accuracy with efficiency. To address this, we propose DMG-YOLO, a lightweight real-time detector tailored for small object detection in remote sensing images. Specifically, we design a Dual-branch Feature Extraction (DFE) module in the backbone, which partitions feature maps into two parallel branches: one extracts local features via depthwise separable convolutions, and the other captures global context using a vision transformer with a gating mechanism. Additionally, a Multi-scale Feature Fusion (MFF) module with dilated convolutions enhances multi-scale integration while preserving fine details. In the neck, we introduce the Global and Local Aggregate Feature Pyramid Network (GLAFPN) to further boost small object detection through global-local feature fusion. Extensive experiments on the VisDrone2019 and NWPU VHR-10 datasets show that DMG-YOLO achieves competitive performance in terms of mAP, model size, and other key metrics.","authors":["Qianyi Wang","Guoqiang Ren"],"pdf_url":"","comment":"none"},{"id":"http://arxiv.org/abs/2511.17146v1","updated":"2025-11-21T11:10:05Z","published":"2025-11-21T11:10:05Z","title":"Learning to Look Closer: A New Instance-Wise Loss for Small Cerebral Lesion Segmentation","summary":"Traditional loss functions in medical image segmentation, such as Dice, often under-segment small lesions because their small relative volume contributes negligibly to the overall loss. To address this, instance-wise loss functions and metrics have been proposed to evaluate segmentation quality on a per-lesion basis. We introduce CC-DiceCE, a loss function based on the CC-Metrics framework, and compare it with the existing blob loss. Both are benchmarked against a DiceCE baseline within the nnU-Net framework, which provides a robust and standardized setup. We find that CC-DiceCE loss increases detection (recall) with minimal to no degradation in segmentation performance, albeit at the cost of slightly more false positives. Furthermore, our multi-dataset study shows that CC-DiceCE generally outperforms blob loss.","authors":["Luc Bouteille","Alexander Jaus","Jens Kleesiek","Rainer Stiefelhagen","Lukas Heine"],"pdf_url":"","comment":"5 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2511.16567v2","updated":"2025-11-21T11:07:49Z","published":"2025-11-20T17:22:51Z","title":"POMA-3D: The Point Map Way to 3D Scene Understanding","summary":"In this paper, we introduce POMA-3D, the first self-supervised 3D representation model learned from point maps. Point maps encode explicit 3D coordinates on a structured 2D grid, preserving global 3D geometry while remaining compatible with the input format of 2D foundation models. To transfer rich 2D priors into POMA-3D, a view-to-scene alignment strategy is designed. Moreover, as point maps are view-dependent with respect to a canonical space, we introduce POMA-JEPA, a joint embedding-predictive architecture that enforces geometrically consistent point map features across multiple views. Additionally, we introduce ScenePoint, a point map dataset constructed from 6.5K room-level RGB-D scenes and 1M 2D image scenes to facilitate large-scale POMA-3D pretraining. Experiments show that POMA-3D serves as a strong backbone for both specialist and generalist 3D understanding. It benefits diverse tasks, including 3D question answering, embodied navigation, scene retrieval, and embodied localization, all achieved using only geometric inputs (i.e., 3D coordinates). Overall, our POMA-3D explores a point map way to 3D scene understanding, addressing the scarcity of pretrained priors and limited data in 3D representation learning. Project Page: https://matchlab-imperial.github.io/poma3d/","authors":["Ye Mao","Weixun Luo","Ranran Huang","Junpeng Jing","Krystian Mikolajczyk"],"pdf_url":"","comment":"11 pages, 6 tables, 5 figures"},{"id":"http://arxiv.org/abs/2511.17138v1","updated":"2025-11-21T11:00:59Z","published":"2025-11-21T11:00:59Z","title":"One-Step Diffusion Transformer for Controllable Real-World Image Super-Resolution","summary":"Recent advances in diffusion-based real-world image super-resolution (Real-ISR) have demonstrated remarkable perceptual quality, yet the balance between fidelity and controllability remains a problem: multi-step diffusion-based methods suffer from generative diversity and randomness, resulting in low fidelity, while one-step methods lose control flexibility due to fidelity-specific finetuning. In this paper, we present ODTSR, a one-step diffusion transformer based on Qwen-Image that performs Real-ISR considering fidelity and controllability simultaneously: a newly introduced visual stream receives low-quality images (LQ) with adjustable noise (Control Noise), and the original visual stream receives LQs with consistent noise (Prior Noise), forming the Noise-hybrid Visual Stream (NVS) design. ODTSR further employs Fidelity-aware Adversarial Training (FAA) to enhance controllability and achieve one-step inference. Extensive experiments demonstrate that ODTSR not only achieves state-of-the-art (SOTA) performance on generic Real-ISR, but also enables prompt controllability on challenging scenarios such as real-world scene text image super-resolution (STISR) of Chinese characters without training on specific datasets.","authors":["Yushun Fang","Yuxiang Chen","Shibo Yin","Qiang Hu","Jiangchao Yao","Ya Zhang","Xiaoyun Zhang","Yanfeng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17135v1","updated":"2025-11-21T10:55:44Z","published":"2025-11-21T10:55:44Z","title":"A Multi-Stage Optimization Framework for Deploying Learned Image Compression on FPGAs","summary":"Deep learning-based image compression (LIC) has achieved state-of-the-art rate-distortion (RD) performance, yet deploying these models on resource-constrained FPGAs remains a major challenge. This work presents a complete, multi-stage optimization framework to bridge the gap between high-performance floating-point models and efficient, hardware-friendly integer-based implementations. First, we address the fundamental problem of quantization-induced performance degradation. We propose a Dynamic Range-Aware Quantization (DRAQ) method that uses statistically-calibrated activation clipping and a novel weight regularization scheme to counteract the effects of extreme data outliers and large dynamic ranges, successfully creating a high-fidelity 8-bit integer model. Second, building on this robust foundation, we introduce two hardware-aware optimization techniques tailored for FPGAs. A progressive mixed-precision search algorithm exploits FPGA flexibility to assign optimal, non-uniform bit-widths to each layer, minimizing complexity while preserving performance. Concurrently, a channel pruning method, adapted to work with the Generalized Divisive Normalization (GDN) layers common in LIC, removes model redundancy by eliminating inactive channels. Our comprehensive experiments show that the foundational DRAQ method reduces the BD-rate overhead of a GDN-based model from $30\\%$ to $6.3\\%$. The subsequent hardware-aware optimizations further reduce computational complexity by over $20\\%$ with negligible impact on RD performance, yielding a final model that is both state-of-the-art in efficiency and superior in quality to existing FPGA-based LIC implementations.","authors":["Jiaxun Fang","Li Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17133v1","updated":"2025-11-21T10:49:04Z","published":"2025-11-21T10:49:04Z","title":"Off the Planckian Locus: Using 2D Chromaticity to Improve In-Camera Color","summary":"Traditional in-camera colorimetric mapping relies on correlated color temperature (CCT)-based interpolation between pre-calibrated transforms optimized for Planckian illuminants such as CIE A and D65. However, modern lighting technologies such as LEDs can deviate substantially from the Planckian locus, exposing the limitations of relying on conventional one-dimensional CCT for illumination characterization. This paper demonstrates that transitioning from 1D CCT (on the Planckian locus) to a 2D chromaticity space (off the Planckian locus) improves colorimetric accuracy across various mapping approaches. In addition, we replace conventional CCT interpolation with a lightweight multi-layer perceptron (MLP) that leverages 2D chromaticity features for robust colorimetric mapping under non-Planckian illuminants. A lightbox-based calibration procedure incorporating representative LED sources is used to train our MLP. Validated across diverse LED lighting, our method reduces angular reproduction error by 22% on average in LED-lit scenes, maintains backward compatibility with traditional illuminants, accommodates multi-illuminant scenes, and supports real-time in-camera deployment with negligible additional computational cost.","authors":["SaiKiran Tedla","Joshua E. Little","Hakki Can Karaimer","Michael S. Brown"],"pdf_url":"","comment":"Project page: https://cst-mlp.github.io"},{"id":"http://arxiv.org/abs/2511.17126v1","updated":"2025-11-21T10:41:54Z","published":"2025-11-21T10:41:54Z","title":"OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation","summary":"Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2.","authors":["Qi Jiang","Xiaolong Qian","Yao Gao","Lei Sun","Kailun Yang","Zhonghua Yi","Wenyong Li","Ming-Hsuan Yang","Luc Van Gool","Kaiwei Wang"],"pdf_url":"","comment":"The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2"},{"id":"http://arxiv.org/abs/2511.17116v1","updated":"2025-11-21T10:27:51Z","published":"2025-11-21T10:27:51Z","title":"PEGS: Physics-Event Enhanced Large Spatiotemporal Motion Reconstruction via 3D Gaussian Splatting","summary":"Reconstruction of rigid motion over large spatiotemporal scales remains a challenging task due to limitations in modeling paradigms, severe motion blur, and insufficient physical consistency. In this work, we propose PEGS, a framework that integrates Physical priors with Event stream enhancement within a 3D Gaussian Splatting pipeline to perform deblurred target-focused modeling and motion recovery. We introduce a cohesive triple-level supervision scheme that enforces physical plausibility via an acceleration constraint, leverages event streams for high-temporal resolution guidance, and employs a Kalman regularizer to fuse multi-source observations. Furthermore, we design a motion-aware simulated annealing strategy that adaptively schedules the training process based on real-time kinematic states. We also contribute the first RGB-Event paired dataset targeting natural, fast rigid motion across diverse scenarios. Experiments show PEGS's superior performance in reconstructing motion over large spatiotemporal scales compared to mainstream dynamic methods.","authors":["Yijun Xu","Jingrui Zhang","Hongyi Liu","Yuhan Chen","Yuanyang Wang","Qingyao Guo","Dingwen Wang","Lei Yu","Chu He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.21692v4","updated":"2025-11-21T10:26:45Z","published":"2025-03-27T16:57:33Z","title":"RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose Triangulation in a Millisecond","summary":"The integration of multi-view imaging and pose estimation represents a significant advance in computer vision applications, offering new possibilities for understanding human movement and interactions. This work presents a new algorithm that improves multi-view multi-person pose estimation, focusing on fast triangulation speeds and good generalization capabilities. The approach extends to whole-body pose estimation, capturing details from facial expressions to finger movements across multiple individuals and viewpoints. Adaptability to different settings is demonstrated through strong performance across unseen datasets and configurations. To support further progress in this field, all of this work is publicly accessible.","authors":["Daniel Bermuth","Alexander Poeppel","Wolfgang Reif"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17106v1","updated":"2025-11-21T10:11:17Z","published":"2025-11-21T10:11:17Z","title":"ChainV: Atomic Visual Hints Make Multimodal Reasoning Shorter and Better","summary":"Recent advances in multimodal reasoning models have demonstrated impressive capabilities across text and vision. However, even leading models exhibit redundant self-reflection when generating lengthy reasoning chains. While training-free CoT compression methods have emerged in the LLMs domain, they rely on static visual references and thus provide limited gains for multimodal reasoning. Therefore, we propose ChainV, a framework that dynamically integrates visual hints into the reasoning process, thereby making multimodal reasoning shorter and better. Specifically, ChainV first performs a coarse visual patch selection based on the previous reasoning step, then refines it by identifying the most representative atomic visual hint according to the averaged attention intensity. Additionally, ChainV introduces a consistency-based evaluation mechanism to assess the reliability of the chosen hint, guiding the model to adaptively adjust its level of self-reflection. Eventually, the pixel coordinates of the selected visual hint and its reliability are incorporated into thinking with a Bernoulli stochastic process. Experiments indicate that our method significantly improves reasoning accuracy and efficiency, especially on math-intensive benchmarks where visual hints are crucial for multi-step symbolic reasoning. For example, ChainV achieves $2.3\\%$ improvement on the MathVista within MIMO-VL-RL, while reducing inference latency by $51.4\\%$ and shortening output token length by $24.5\\%$.","authors":["Yuan Zhang","Ming Lu","Junwen Pan","Tao Huang","Kuan Cheng","Qi She","Shanghang Zhang"],"pdf_url":"","comment":"16 pages"},{"id":"http://arxiv.org/abs/2511.17103v1","updated":"2025-11-21T10:06:32Z","published":"2025-11-21T10:06:32Z","title":"Bridging Visual Affective Gap: Borrowing Textual Knowledge by Learning from Noisy Image-Text Pairs","summary":"Visual emotion recognition (VER) is a longstanding field that has garnered increasing attention with the advancement of deep neural networks. Although recent studies have achieved notable improvements by leveraging the knowledge embedded within pre-trained visual models, the lack of direct association between factual-level features and emotional categories, called the \"affective gap\", limits the applicability of pre-training knowledge for VER tasks. On the contrary, the explicit emotional expression and high information density in textual modality eliminate the \"affective gap\". Therefore, we propose borrowing the knowledge from the pre-trained textual model to enhance the emotional perception of pre-trained visual models. We focus on the factual and emotional connections between images and texts in noisy social media data, and propose Partitioned Adaptive Contrastive Learning (PACL) to leverage these connections. Specifically, we manage to separate different types of samples and devise distinct contrastive learning strategies for each type. By dynamically constructing negative and positive pairs, we fully exploit the potential of noisy samples. Through comprehensive experiments, we demonstrate that bridging the \"affective gap\" significantly improves the performance of various pre-trained visual models in downstream emotion-related tasks. Our code is released on https://github.com/wdqqdw/PACL.","authors":["Daiqing Wu","Dongbao Yang","Yu Zhou","Can Ma"],"pdf_url":"","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2503.06677v5","updated":"2025-11-21T10:01:42Z","published":"2025-03-09T16:05:36Z","title":"REArtGS: Reconstructing and Generating Articulated Objects via 3D Gaussian Splatting with Geometric and Motion Constraints","summary":"Articulated objects, as prevalent entities in human life, their 3D representations play crucial roles across various applications. However, achieving both high-fidelity textured surface reconstruction and dynamic generation for articulated objects remains challenging for existing methods. In this paper, we present REArtGS, a novel framework that introduces additional geometric and motion constraints to 3D Gaussian primitives, enabling realistic surface reconstruction and generation for articulated objects. Specifically, given multi-view RGB images of arbitrary two states of articulated objects, we first introduce an unbiased Signed Distance Field (SDF) guidance to regularize Gaussian opacity fields, enhancing geometry constraints and improving surface reconstruction quality. Then we establish deformable fields for 3D Gaussians constrained by the kinematic structures of articulated objects, achieving unsupervised generation of surface meshes in unseen states. Extensive experiments on both synthetic and real datasets demonstrate our approach achieves high-quality textured surface reconstruction for given states, and enables high-fidelity surface generation for unseen states. Project site: https://sites.google.com/view/reartgs/home.","authors":["Di Wu","Liu Liu","Zhou Linli","Anran Huang","Liangtu Song","Qiaojun Yu","Qi Wu","Cewu Lu"],"pdf_url":"","comment":"11pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.17094v1","updated":"2025-11-21T09:50:21Z","published":"2025-11-21T09:50:21Z","title":"Sparse Reasoning is Enough: Biological-Inspired Framework for Video Anomaly Detection with Large Pre-trained Models","summary":"Video anomaly detection (VAD) plays a vital role in real-world applications such as security surveillance, autonomous driving, and industrial monitoring. Recent advances in large pre-trained models have opened new opportunities for training-free VAD by leveraging rich prior knowledge and general reasoning capabilities. However, existing studies typically rely on dense frame-level inference, incurring high computational costs and latency. This raises a fundamental question: Is dense reasoning truly necessary when using powerful pre-trained models in VAD systems? To answer this, we propose ReCoVAD, a novel framework inspired by the dual reflex and conscious pathways of the human nervous system, enabling selective frame processing to reduce redundant computation. ReCoVAD consists of two core pathways: (i) a Reflex pathway that uses a lightweight CLIP-based module to fuse visual features with prototype prompts and produce decision vectors, which query a dynamic memory of past frames and anomaly scores for fast response; and (ii) a Conscious pathway that employs a medium-scale vision-language model to generate textual event descriptions and refined anomaly scores for novel frames. It continuously updates the memory and prototype prompts, while an integrated large language model periodically reviews accumulated descriptions to identify unseen anomalies, correct errors, and refine prototypes. Extensive experiments show that ReCoVAD achieves state-of-the-art training-free performance while processing only 28.55\\% and 16.04\\% of the frames used by previous methods on the UCF-Crime and XD-Violence datasets, demonstrating that sparse reasoning is sufficient for effective large-model-based VAD.","authors":["He Huang","Zixuan Hu","Dongxiao Li","Yao Xiao","Ling-Yu Duan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17092v1","updated":"2025-11-21T09:49:53Z","published":"2025-11-21T09:49:53Z","title":"SPAGS: Sparse-View Articulated Object Reconstruction from Single State via Planar Gaussian Splatting","summary":"Articulated objects are ubiquitous in daily environments, and their 3D reconstruction holds great significance across various fields. However, existing articulated object reconstruction methods typically require costly inputs such as multi-stage and multi-view observations. To address the limitations, we propose a category-agnostic articulated object reconstruction framework via planar Gaussian Splatting, which only uses sparse-view RGB images from a single state. Specifically, we first introduce a Gaussian information field to perceive the optimal sparse viewpoints from candidate camera poses. Then we compress 3D Gaussians into planar Gaussians to facilitate accurate estimation of normal and depth. The planar Gaussians are optimized in a coarse-to-fine manner through depth smooth regularization and few-shot diffusion. Moreover, we introduce a part segmentation probability for each Gaussian primitive and update them by back-projecting part segmentation masks of renderings. Extensive experimental results demonstrate that our method achieves higher-fidelity part-level surface reconstruction on both synthetic and real-world data than existing methods. Codes will be made publicly available.","authors":["Di Wu","Liu Liu","Xueyu Yuan","Qiaoyu Jun","Wenxiao Chen","Ruilong Yan","Yiming Tang","Liangtu Song"],"pdf_url":"","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2506.16112v2","updated":"2025-11-21T09:49:21Z","published":"2025-06-19T08:02:53Z","title":"Loss-Oriented Ranking for Automated Visual Prompting in LVLMs","summary":"Inspired by text prompts in large language models (LLMs), visual prompts have been explored to enhance the reasoning capabilities of large vision-language models (LVLMs). Current methods design heuristic visual prompts, such as overlaying a text-query-guided attention heatmap on the original input image. However, designing effective prompts manually is challenging and time-consuming, and it often fails to explore the benefits of different visual prompts, leading to sub-optimal performance. To this end, we propose \\textbf{AutoV} that learns to automatically select the optimal visual prompt from various candidates based on given textual queries and the input image. To train AutoV, we develop an automatic data collection and labeling pipeline that evaluates various visual prompts with a pre-trained LVLM. We input a set of visual prompts into the LVLM and rank them according to the prediction losses generated by the model. Using the ranking as a supervision signal, we train AutoV to automatically choose the optimal visual prompt from various visual prompts for LVLMs. Experiments indicate that AutoV enhances the performance of various LVLMs across multiple image understanding tasks. For instance, LLaVA-OV with AutoV achieves $\\textbf{10.2}\\%$ accuracy gain on VizWiz, and AutoV boosts Qwen2.5-VL by $\\textbf{3.8}\\%$ on MMMU, highlighting its potential as an optimal visual prompting method.","authors":["Yuan Zhang","Chun-Kai Fan","Tao Huang","Ming Lu","Sicheng Yu","Junwen Pan","Kuan Cheng","Qi She","Shanghang Zhang"],"pdf_url":"","comment":"17 pages"},{"id":"http://arxiv.org/abs/2508.04424v2","updated":"2025-11-21T09:48:34Z","published":"2025-08-06T13:11:40Z","title":"Composed Object Retrieval: Object-level Retrieval via Composed Expressions","summary":"Retrieving fine-grained visual content based on user intent remains a challenge in multi-modal systems. Although current Composed Image Retrieval (CIR) methods combine reference images with retrieval texts, they are constrained to image-level matching and cannot localize specific objects. To this end, we propose Composed Object Retrieval (COR), a brand-new task that goes beyond image-level retrieval to achieve object-level precision, allowing the retrieval and segmentation of target objects based on composed expressions combining reference objects and retrieval texts. COR presents significant challenges in retrieval flexibility, which requires systems to identify arbitrary objects satisfying composed expressions while avoiding semantically similar but irrelevant negative objects within the same scene. We construct COR127K, the first large-scale COR benchmark that contains 127,166 retrieval triplets with various semantic transformations in 408 categories. We also present CORE, a unified end-to-end model that integrates reference region encoding, adaptive visual-textual interaction, and region-level contrastive learning. Extensive experiments demonstrate that CORE significantly outperforms existing models in both base and novel categories, establishing a simple and effective baseline for this challenging task while opening new directions for fine-grained multi-modal retrieval research. We will publicly release both the dataset and the model at https://github.com/wangtong627/COR.","authors":["Tong Wang","Guanyu Yang","Nian Liu","Zongyan Han","Jinxing Zhou","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17089v1","updated":"2025-11-21T09:45:17Z","published":"2025-11-21T09:45:17Z","title":"Spanning Tree Autoregressive Visual Generation","summary":"We present Spanning Tree Autoregressive (STAR) modeling, which can incorporate prior knowledge of images, such as center bias and locality, to maintain sampling performance while also providing sufficiently flexible sequence orders to accommodate image editing at inference. Approaches that expose randomly permuted sequence orders to conventional autoregressive (AR) models in visual generation for bidirectional context either suffer from a decline in performance or compromise the flexibility in sequence order choice at inference. Instead, STAR utilizes traversal orders of uniform spanning trees sampled in a lattice defined by the positions of image patches. Traversal orders are obtained through breadth-first search, allowing us to efficiently construct a spanning tree whose traversal order ensures that the connected partial observation of the image appears as a prefix in the sequence through rejection sampling. Through the tailored yet structured randomized strategy compared to random permutation, STAR preserves the capability of postfix completion while maintaining sampling performance without any significant changes to the model architecture widely adopted in the language AR modeling.","authors":["Sangkyu Lee","Changho Lee","Janghoon Han","Hosung Song","Tackgeun You","Hwasup Lim","Stanley Jungkyu Choi","Honglak Lee","Youngjae Yu"],"pdf_url":"","comment":"Preprint; Under review"},{"id":"http://arxiv.org/abs/2509.05826v2","updated":"2025-11-21T09:36:19Z","published":"2025-09-06T20:41:55Z","title":"Performance of Conformal Prediction in Capturing Aleatoric Uncertainty","summary":"Conformal prediction is a model-agnostic approach to generating prediction sets that cover the true class with a high probability. Although its prediction set size is expected to capture aleatoric uncertainty, there is a lack of evidence regarding its effectiveness. The literature presents that prediction set size can upper-bound aleatoric uncertainty or that prediction sets are larger for difficult instances and smaller for easy ones, but a validation of this attribute of conformal predictors is missing. This work investigates how effectively conformal predictors quantify aleatoric uncertainty, specifically the inherent ambiguity in datasets caused by overlapping classes. We perform this by measuring the correlation between prediction set sizes and the number of distinct labels assigned by human annotators per instance. We further assess the similarity between prediction sets and human-provided annotations. We use three conformal prediction approaches to generate prediction sets for eight deep learning models trained on four datasets. The datasets contain annotations from multiple human annotators (ranging from five to fifty participants) per instance, enabling the identification of class overlap. We show that the vast majority of the conformal prediction outputs show a very weak to weak correlation with human annotations, with only a few showing moderate correlation. These findings underscore the necessity of critically reassessing the prediction sets generated using conformal predictors. While they can provide a higher coverage of the true classes, their capability in capturing aleatoric uncertainty and generating sets that align with human annotations remains limited.","authors":["Misgina Tsighe Hagos","Claes Lundström"],"pdf_url":"","comment":"Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2026"},{"id":"http://arxiv.org/abs/2503.12972v3","updated":"2025-11-21T09:26:05Z","published":"2025-03-17T09:31:14Z","title":"Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning","summary":"Multimodal reasoning in Large Language Models (LLMs) struggles with incomplete knowledge and hallucination artifacts, challenges that textual Knowledge Graphs (KGs) only partially mitigate due to their modality isolation. While Multimodal Knowledge Graphs (MMKGs) promise enhanced cross-modal understanding, their practical construction is impeded by semantic narrowness of manual text annotations and inherent noise in visual-semantic entity linkages. In this paper, we propose Vision-align-to-Language integrated Knowledge Graph (VaLiK), a novel approach for constructing MMKGs that enhances LLMs reasoning through cross-modal information supplementation. Specifically, we cascade pre-trained Vision-Language Models (VLMs) to align image features with text, transforming them into descriptions that encapsulate image-specific information. Furthermore, we developed a cross-modal similarity verification mechanism to quantify semantic consistency, effectively filtering out noise introduced during feature alignment. Even without manually annotated image captions, the refined descriptions alone suffice to construct the MMKG. Compared to conventional MMKGs construction paradigms, our approach achieves substantial storage efficiency gains while maintaining direct entity-to-image linkage capability. Experimental results on multimodal reasoning tasks demonstrate that LLMs augmented with VaLiK outperform previous state-of-the-art models. Our code is published at https://github.com/Wings-Of-Disaster/VaLiK.","authors":["Junming Liu","Siyuan Meng","Yanting Gao","Song Mao","Pinlong Cai","Guohang Yan","Yirong Chen","Zilin Bian","Ding Wang","Botian Shi"],"pdf_url":"","comment":"14 pages, 7 figures, 6 tables; Accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2511.17074v1","updated":"2025-11-21T09:24:09Z","published":"2025-11-21T09:24:09Z","title":"Diversity Has Always Been There in Your Visual Autoregressive Models","summary":"Visual Autoregressive (VAR) models have recently garnered significant attention for their innovative next-scale prediction paradigm, offering notable advantages in both inference efficiency and image quality compared to traditional multi-step autoregressive (AR) and diffusion models. However, despite their efficiency, VAR models often suffer from the diversity collapse i.e., a reduction in output variability, analogous to that observed in few-step distilled diffusion models. In this paper, we introduce DiverseVAR, a simple yet effective approach that restores the generative diversity of VAR models without requiring any additional training. Our analysis reveals the pivotal component of the feature map as a key factor governing diversity formation at early scales. By suppressing the pivotal component in the model input and amplifying it in the model output, DiverseVAR effectively unlocks the inherent generative potential of VAR models while preserving high-fidelity synthesis. Empirical results demonstrate that our approach substantially enhances generative diversity with only neglectable performance influences. Our code will be publicly released at https://github.com/wangtong627/DiverseVAR.","authors":["Tong Wang","Guanyu Yang","Nian Liu","Kai Wang","Yaxing Wang","Abdelrahman M Shaker","Salman Khan","Fahad Shahbaz Khan","Senmao Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13278v2","updated":"2025-11-21T09:21:15Z","published":"2025-11-17T11:50:52Z","title":"SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting","summary":"Lightweight building surface models are crucial for digital city, navigation, and fast geospatial analytics, yet conventional multi-view geometry pipelines remain cumbersome and quality-sensitive due to their reliance on dense reconstruction, meshing, and subsequent simplification. This work presents SF-Recon, a method that directly reconstructs lightweight building surfaces from multi-view images without post-hoc mesh simplification. We first train an initial 3D Gaussian Splatting (3DGS) field to obtain a view-consistent representation. Building structure is then distilled by a normal-gradient-guided Gaussian optimization that selects primitives aligned with roof and wall boundaries, followed by multi-view edge-consistency pruning to enhance structural sharpness and suppress non-structural artifacts without external supervision. Finally, a multi-view depth-constrained Delaunay triangulation converts the structured Gaussian field into a lightweight, structurally faithful building mesh. Based on a proposed SF dataset, the experimental results demonstrate that our SF-Recon can directly reconstruct lightweight building models from multi-view imagery, achieving substantially fewer faces and vertices while maintaining computational efficiency. Website:https://lzh282140127-cell.github.io/SF-Recon-project/","authors":["Zihan Li","Tengfei Wang","Wentian Gan","Hao Zhan","Xin Wang","Zongqian Zhan"],"pdf_url":"","comment":"This paper has been submitted to the 2026 ISPRS Congress"},{"id":"http://arxiv.org/abs/2511.17068v1","updated":"2025-11-21T09:18:35Z","published":"2025-11-21T09:18:35Z","title":"ReBrain: Brain MRI Reconstruction from Sparse CT Slice via Retrieval-Augmented Diffusion","summary":"Magnetic Resonance Imaging (MRI) plays a crucial role in brain disease diagnosis, but it is not always feasible for certain patients due to physical or clinical constraints. Recent studies attempt to synthesize MRI from Computed Tomography (CT) scans; however, low-dose protocols often result in highly sparse CT volumes with poor through-plane resolution, making accurate reconstruction of the full brain MRI volume particularly challenging. To address this, we propose ReBrain, a retrieval-augmented diffusion framework for brain MRI reconstruction. Given any 3D CT scan with limited slices, we first employ a Brownian Bridge Diffusion Model (BBDM) to synthesize MRI slices along the 2D dimension. Simultaneously, we retrieve structurally and pathologically similar CT slices from a comprehensive prior database via a fine-tuned retrieval model. These retrieved slices are used as references, incorporated through a ControlNet branch to guide the generation of intermediate MRI slices and ensure structural continuity. We further account for rare retrieval failures when the database lacks suitable references and apply spherical linear interpolation to provide supplementary guidance. Extensive experiments on SynthRAD2023 and BraTS demonstrate that ReBrain achieves state-of-the-art performance in cross-modal reconstruction under sparse conditions.","authors":["Junming Liu","Yifei Sun","Weihua Cheng","Yujin Kang","Yirong Chen","Ding Wang","Guosun Zeng"],"pdf_url":"","comment":"16 pages, 12 figures, 7 tables; Accepted by WACV 2026"},{"id":"http://arxiv.org/abs/2511.12932v2","updated":"2025-11-21T09:15:09Z","published":"2025-11-17T03:39:13Z","title":"Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic Scenes","summary":"With the rapid advancement of intelligent transportation systems, text-driven image generation and editing techniques have demonstrated significant potential in providing rich, controllable visual scene data for applications such as traffic monitoring and autonomous driving. However, several challenges remain, including insufficient semantic richness of generated traffic elements, limited camera viewpoints, low visual fidelity of synthesized images, and poor alignment between textual descriptions and generated content. To address these issues, we propose a unified text-driven framework for both image generation and editing, leveraging a controllable mask mechanism to seamlessly integrate the two tasks. Furthermore, we incorporate both vehicle-side and roadside multi-view data to enhance the geometric diversity of traffic scenes. Our training strategy follows a two-stage paradigm: first, we perform conceptual learning using large-scale coarse-grained text-image data; then, we fine-tune with fine-grained descriptive data to enhance text-image alignment and detail quality. Additionally, we introduce a mask-region-weighted loss that dynamically emphasizes small yet critical regions during training, thereby substantially enhancing the generation fidelity of small-scale traffic elements. Extensive experiments demonstrate that our method achieves leading performance in text-based image generation and editing within traffic scenes.","authors":["Feng Lv","Haoxuan Feng","Zilu Zhang","Chunlong Xia","Yanfeng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.20973v2","updated":"2025-11-21T09:12:45Z","published":"2025-07-28T16:36:13Z","title":"Model-Agnostic Gender Bias Control for Text-to-Image Generation via Sparse Autoencoder","summary":"Text-to-image (T2I) diffusion models often exhibit gender bias, particularly by generating stereotypical associations between professions and gendered subjects. This paper presents SAE Debias, a lightweight and model-agnostic framework for mitigating such bias in T2I generation. Unlike prior approaches that rely on CLIP-based filtering or prompt engineering, which often require model-specific adjustments and offer limited control, SAE Debias operates directly within the feature space without retraining or architectural modifications. By leveraging a k-sparse autoencoder pre-trained on a gender bias dataset, the method identifies gender-relevant directions within the sparse latent space, capturing professional stereotypes. Specifically, a biased direction per profession is constructed from sparse latents and suppressed during inference to steer generations toward more gender-balanced outputs. Trained only once, the sparse autoencoder provides a reusable debiasing direction, offering effective control and interpretable insight into biased subspaces. Extensive evaluations across multiple T2I models, including Stable Diffusion 1.4, 1.5, 2.1, and SDXL, demonstrate that SAE Debias substantially reduces gender bias while preserving generation quality. To the best of our knowledge, this is the first work to apply sparse autoencoders for identifying and intervening in gender bias within T2I models. These findings contribute toward building socially responsible generative AI, providing an interpretable and model-agnostic tool to support fairness in text-to-image generation.","authors":["Chao Wu","Zhenyi Wang","Kangxian Xie","Naresh Kumar Devulapally","Vishnu Suresh Lokhande","Mingchen Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17059v1","updated":"2025-11-21T09:07:56Z","published":"2025-11-21T09:07:56Z","title":"REArtGS++: Generalizable Articulation Reconstruction with Temporal Geometry Constraint via Planar Gaussian Splatting","summary":"Articulated objects are pervasive in daily environments, such as drawers and refrigerators. Towards their part-level surface reconstruction and joint parameter estimation, REArtGS~\\cite{wu2025reartgs} introduces a category-agnostic approach using multi-view RGB images at two different states. However, we observe that REArtGS still struggles with screw-joint or multi-part objects and lacks geometric constraints for unseen states. In this paper, we propose REArtGS++, a novel method towards generalizable articulated object reconstruction with temporal geometry constraint and planar Gaussian splatting. We first model a decoupled screw motion for each joint without type prior, and jointly optimize part-aware Gaussians with joint parameters through part motion blending. To introduce time-continuous geometric constraint for articulated modeling, we encourage Gaussians to be planar and propose a temporally consistent regularization between planar normal and depth through Taylor first-order expansion. Extensive experiments on both synthetic and real-world articulated objects demonstrate our superiority in generalizable part-level surface reconstruction and joint parameter estimation, compared to existing approaches. Project Site: https://sites.google.com/view/reartgs2/home.","authors":["Di Wu","Liu Liu","Anran Huang","Yuyan Liu","Qiaoyu Jun","Shaofan Liu","Liangtu Song","Cewu Lu"],"pdf_url":"","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.17054v1","updated":"2025-11-21T08:55:55Z","published":"2025-11-21T08:55:55Z","title":"RL-AD-Net: Reinforcement Learning Guided Adaptive Displacement in Latent Space for Refined Point Cloud Completion","summary":"Recent point cloud completion models, including transformer-based, denoising-based, and other state-of-the-art approaches, generate globally plausible shapes from partial inputs but often leave local geometric inconsistencies. We propose RL-AD-Net, a reinforcement learning (RL) refinement framework that operates in the latent space of a pretrained point autoencoder. The autoencoder encodes completions into compact global feature vectors (GFVs), which are selectively adjusted by an RL agent to improve geometric fidelity. To ensure robustness, a lightweight non-parametric PointNN selector evaluates the geometric consistency of both the original completion and the RL-refined output, retaining the better reconstruction. When ground truth is available, both Chamfer Distance and geometric consistency metrics guide refinement. Training is performed separately per category, since the unsupervised and dynamic nature of RL makes convergence across highly diverse categories challenging. Nevertheless, the framework can be extended to multi-category refinement in future work. Experiments on ShapeNetCore-2048 demonstrate that while baseline completion networks perform reasonable under their training-style cropping, they struggle in random cropping scenarios. In contrast, RL-AD-Net consistently delivers improvements across both settings, highlighting the effectiveness of RL-guided ensemble refinement. The approach is lightweight, modular, and model-agnostic, making it applicable to a wide range of completion networks without requiring retraining.","authors":["Bhanu Pratap Paregi","Vaibhav Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17053v1","updated":"2025-11-21T08:54:49Z","published":"2025-11-21T08:54:49Z","title":"OmniPT: Unleashing the Potential of Large Vision Language Models for Pedestrian Tracking and Understanding","summary":"LVLMs have been shown to perform excellently in image-level tasks such as VQA and caption. However, in many instance-level tasks, such as visual grounding and object detection, LVLMs still show performance gaps compared to previous expert models. Meanwhile, although pedestrian tracking is a classical task, there have been a number of new topics in combining object tracking and natural language, such as Referring MOT, Cross-view Referring MOT, and Semantic MOT. These tasks emphasize that models should understand the tracked object at an advanced semantic level, which is exactly where LVLMs excel. In this paper, we propose a new unified Pedestrian Tracking framework, namely OmniPT, which can track, track based on reference and generate semantic understanding of tracked objects interactively. We address two issues: how to model the tracking task into a task that foundation models can perform, and how to make the model output formatted answers. To this end, we implement a training phase consisting of RL-Mid Training-SFT-RL. Based on the pre-trained weights of the LVLM, we first perform a simple RL phase to enable the model to output fixed and supervisable bounding box format. Subsequently, we conduct a mid-training phase using a large number of pedestrian-related datasets. Finally, we perform supervised fine-tuning on several pedestrian tracking datasets, and then carry out another RL phase to improve the model's tracking performance and enhance its ability to follow instructions. We conduct experiments on tracking benchmarks and the experimental results demonstrate that the proposed method can perform better than the previous methods.","authors":["Teng Fu","Mengyang Zhao","Ke Niu","Kaixin Peng","Bin Li"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.17052v1","updated":"2025-11-21T08:50:14Z","published":"2025-11-21T08:50:14Z","title":"PathAgent: Toward Interpretable Analysis of Whole-slide Pathology Images via Large Language Model-based Agentic Reasoning","summary":"Analyzing whole-slide images (WSIs) requires an iterative, evidence-driven reasoning process that parallels how pathologists dynamically zoom, refocus, and self-correct while collecting the evidence. However, existing computational pipelines often lack this explicit reasoning trajectory, resulting in inherently opaque and unjustifiable predictions. To bridge this gap, we present PathAgent, a training-free, large language model (LLM)-based agent framework that emulates the reflective, stepwise analytical approach of human experts. PathAgent can autonomously explore WSI, iteratively and precisely locating significant micro-regions using the Navigator module, extracting morphology visual cues using the Perceptor, and integrating these findings into the continuously evolving natural language trajectories in the Executor. The entire sequence of observations and decisions forms an explicit chain-of-thought, yielding fully interpretable predictions. Evaluated across five challenging datasets, PathAgent exhibits strong zero-shot generalization, surpassing task-specific baselines in both open-ended and constrained visual question-answering tasks. Moreover, a collaborative evaluation with human pathologists confirms PathAgent's promise as a transparent and clinically grounded diagnostic assistant.","authors":["Jingyun Chen","Linghan Cai","Zhikang Wang","Yi Huang","Songhan Jiang","Shenjin Huang","Hongpeng Wang","Yongbing Zhang"],"pdf_url":"","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.09460v2","updated":"2025-11-21T08:50:02Z","published":"2025-06-11T07:07:14Z","title":"Open-Set Domain Generalization through Spectral-Spatial Uncertainty Disentanglement for Hyperspectral Image Classification","summary":"Open-set domain generalization (OSDG) tackles the dual challenge of recognizing unknown classes while simultaneously striving to generalize across unseen domains without using target data during training. In this article, an OSDG framework for hyperspectral image classification is proposed, centered on a new Spectral-Spatial Uncertainty Disentanglement mechanism. It has been designed to address the domain shift influencing both spectral, spatial and combined feature extraction pathways using evidential deep learning, after which the most reliable pathway for each sample is adaptively selected. The proposed framework is further integrated with frequency-domain feature extraction for domain-invariant representation learning, dual-channel residual networks for spectral-spatial feature extraction, and evidential deep learning based uncertainty quantification. Experiments conducted on three cross scene hyperspectral datasets, show that performance comparable to state-of-the-art domain adaptation methods can be achieved despite no access to target data, while high unknown-class rejection and known-class accuracy levels are maintained. The implementation will be available at github.com/amir-khb/UGOSDG upon acceptance.","authors":["Amirreza Khoshbakht","Erchan Aptoula"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17048v1","updated":"2025-11-21T08:47:32Z","published":"2025-11-21T08:47:32Z","title":"RoomPlanner: Explicit Layout Planner for Easier LLM-Driven 3D Room Generation","summary":"In this paper, we propose RoomPlanner, the first fully automatic 3D room generation framework for painlessly creating realistic indoor scenes with only short text as input. Without any manual layout design or panoramic image guidance, our framework can generate explicit layout criteria for rational spatial placement. We begin by introducing a hierarchical structure of language-driven agent planners that can automatically parse short and ambiguous prompts into detailed scene descriptions. These descriptions include raw spatial and semantic attributes for each object and the background, which are then used to initialize 3D point clouds. To position objects within bounded environments, we implement two arrangement constraints that iteratively optimize spatial arrangements, ensuring a collision-free and accessible layout solution. In the final rendering stage, we propose a novel AnyReach Sampling strategy for camera trajectory, along with the Interval Timestep Flow Sampling (ITFS) strategy, to efficiently optimize the coarse 3D Gaussian scene representation. These approaches help reduce the total generation time to under 30 minutes. Extensive experiments demonstrate that our method can produce geometrically rational 3D indoor scenes, surpassing prior approaches in both rendering speed and visual quality while preserving editability. The code will be available soon.","authors":["Wenzhuo Sun","Mingjian Liang","Wenxuan Song","Xuelian Cheng","Zongyuan Ge"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17045v1","updated":"2025-11-21T08:44:33Z","published":"2025-11-21T08:44:33Z","title":"RacketVision: A Multiple Racket Sports Benchmark for Unified Ball and Racket Analysis","summary":"We introduce RacketVision, a novel dataset and benchmark for advancing computer vision in sports analytics, covering table tennis, tennis, and badminton. The dataset is the first to provide large-scale, fine-grained annotations for racket pose alongside traditional ball positions, enabling research into complex human-object interactions. It is designed to tackle three interconnected tasks: fine-grained ball tracking, articulated racket pose estimation, and predictive ball trajectory forecasting. Our evaluation of established baselines reveals a critical insight for multi-modal fusion: while naively concatenating racket pose features degrades performance, a CrossAttention mechanism is essential to unlock their value, leading to trajectory prediction results that surpass strong unimodal baselines. RacketVision provides a versatile resource and a strong starting point for future research in dynamic object tracking, conditional motion forecasting, and multimodal analysis in sports. Project page at https://github.com/OrcustD/RacketVision","authors":["Linfeng Dong","Yuchen Yang","Hao Wu","Wei Wang","Yuenan HouZhihang Zhong","Xiao Sun"],"pdf_url":"","comment":"Accepted to AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2511.16541v2","updated":"2025-11-21T08:44:06Z","published":"2025-11-20T16:53:24Z","title":"Supervised Contrastive Learning for Few-Shot AI-Generated Image Detection and Attribution","summary":"The rapid advancement of generative artificial intelligence has enabled the creation of synthetic images that are increasingly indistinguishable from authentic content, posing significant challenges for digital media integrity. This problem is compounded by the accelerated release cycle of novel generative models, which renders traditional detection approaches (reliant on periodic retraining) computationally infeasible and operationally impractical.\n  This work proposes a novel two-stage detection framework designed to address the generalization challenge inherent in synthetic image detection. The first stage employs a vision deep learning model trained via supervised contrastive learning to extract discriminative embeddings from input imagery. Critically, this model was trained on a strategically partitioned subset of available generators, with specific architectures withheld from training to rigorously ablate cross-generator generalization capabilities. The second stage utilizes a k-nearest neighbors (k-NN) classifier operating on the learned embedding space, trained in a few-shot learning paradigm incorporating limited samples from previously unseen test generators.\n  With merely 150 images per class in the few-shot learning regime, which are easily obtainable from current generation models, the proposed framework achieves an average detection accuracy of 91.3%, representing a 5.2 percentage point improvement over existing approaches . For the source attribution task, the proposed approach obtains improvements of of 14.70% and 4.27% in AUC and OSCR respectively on an open set classification context, marking a significant advancement toward robust, scalable forensic attribution systems capable of adapting to the evolving generative AI landscape without requiring exhaustive retraining protocols.","authors":["Jaime Álvarez Urueña","David Camacho","Javier Huertas Tato"],"pdf_url":"","comment":"17 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2511.17043v1","updated":"2025-11-21T08:42:20Z","published":"2025-11-21T08:42:20Z","title":"MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays","summary":"Chest radiography remains one of the most widely used imaging modalities for thoracic diagnosis, yet increasing imaging volumes and radiologist workload continue to challenge timely interpretation. In this work, we investigate the use of MedImageInsight, a medical imaging foundational model, for automated binary classification of chest X-rays into Normal and Abnormal categories. Two approaches were evaluated: (1) fine-tuning MedImageInsight for end-to-end classification, and (2) employing the model as a feature extractor for a transfer learning pipeline using traditional machine learning classifiers. Experiments were conducted using a combination of the ChestX-ray14 dataset and real-world clinical data sourced from partner hospitals. The fine-tuned classifier achieved the highest performance, with an ROC-AUC of 0.888 and superior calibration compared to the transfer learning models, demonstrating performance comparable to established architectures such as CheXNet. These results highlight the effectiveness of foundational medical imaging models in reducing task-specific training requirements while maintaining diagnostic reliability. The system is designed for integration into web-based and hospital PACS workflows to support triage and reduce radiologist burden. Future work will extend the model to multi-label pathology classification to provide preliminary diagnostic interpretation in clinical environments.","authors":["Rama Krishna Boya","Mohan Kireeti Magalanadu","Azaruddin Palavalli","Rupa Ganesh Tekuri","Amrit Pattanayak","Prasanthi Enuga","Vignesh Esakki Muthu","Vivek Aditya Boya"],"pdf_url":"","comment":"9 pages, 5 figures and 3 tables"},{"id":"http://arxiv.org/abs/2511.11989v2","updated":"2025-11-21T08:39:43Z","published":"2025-11-15T01:56:14Z","title":"BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial Close-ups","summary":"Identity-Preserving Personalized Generation (IPPG) has advanced film production and artistic creation, yet existing approaches overemphasize facial regions, resulting in outputs dominated by facial close-ups.These methods suffer from weak visual narrativity and poor semantic consistency under complex text prompts, with the core limitation rooted in identity (ID) feature embeddings undermining the semantic expressiveness of generative models. To address these issues, this paper presents an IPPG method that breaks the constraint of facial close-ups, achieving synergistic optimization of identity fidelity and scene semantic creation. Specifically, we design a Dual-Line Inference (DLI) pipeline with identity-semantic separation, resolving the representation conflict between ID and semantics inherent in traditional single-path architectures. Further, we propose an Identity Adaptive Fusion (IdAF) strategy that defers ID-semantic fusion to the noise prediction stage, integrating adaptive attention fusion and noise decision masking to avoid ID embedding interference on semantics without manual masking. Finally, an Identity Aggregation Prepending (IdAP) module is introduced to aggregate ID information and replace random initializations, further enhancing identity preservation. Experimental results validate that our method achieves stable and effective performance in IPPG tasks beyond facial close-ups, enabling efficient generation without manual masking or fine-tuning. As a plug-and-play component, it can be rapidly deployed in existing IPPG frameworks, addressing the over-reliance on facial close-ups, facilitating film-level character-scene creation, and providing richer personalized generation capabilities for related domains.","authors":["Songsong Zhang","Chuanqi Tang","Hongguang Zhang","Guijian Tang","Minglong Li","Xueqiong Li","Shaowu Yang","Yuanxi Peng","Wenjing Yang","Jing Zhao"],"pdf_url":"","comment":"16 pages, 16 figures"},{"id":"http://arxiv.org/abs/2510.03135v2","updated":"2025-11-21T08:32:29Z","published":"2025-10-03T16:04:33Z","title":"Mask2IV: Interaction-Centric Video Generation via Mask Trajectories","summary":"Generating interaction-centric videos, such as those depicting humans or robots interacting with objects, is crucial for embodied intelligence, as they provide rich and diverse visual priors for robot learning, manipulation policy training, and affordance reasoning. However, existing methods often struggle to model such complex and dynamic interactions. While recent studies show that masks can serve as effective control signals and enhance generation quality, obtaining dense and precise mask annotations remains a major challenge for real-world use. To overcome this limitation, we introduce Mask2IV, a novel framework specifically designed for interaction-centric video generation. It adopts a decoupled two-stage pipeline that first predicts plausible motion trajectories for both actor and object, then generates a video conditioned on these trajectories. This design eliminates the need for dense mask inputs from users while preserving the flexibility to manipulate the interaction process. Furthermore, Mask2IV supports versatile and intuitive control, allowing users to specify the target object of interaction and guide the motion trajectory through action descriptions or spatial position cues. To support systematic training and evaluation, we curate two benchmarks covering diverse action and object categories across both human-object interaction and robotic manipulation scenarios. Extensive experiments demonstrate that our method achieves superior visual realism and controllability compared to existing baselines.","authors":["Gen Li","Bo Zhao","Jianfei Yang","Laura Sevilla-Lara"],"pdf_url":"","comment":"AAAI 2026. Project page: https://reagan1311.github.io/mask2iv"},{"id":"http://arxiv.org/abs/2511.17036v1","updated":"2025-11-21T08:28:02Z","published":"2025-11-21T08:28:02Z","title":"Do Vision-Language Models Understand Visual Persuasiveness?","summary":"Recent advances in vision-language models (VLMs) have enabled impressive multi-modal reasoning and understanding. Yet, whether these models truly grasp visual persuasion-how visual cues shape human attitudes and decisions-remains unclear. To probe this question, we construct a high-consensus dataset for binary persuasiveness judgment and introduce the taxonomy of Visual Persuasive Factors (VPFs), encompassing low-level perceptual, mid-level compositional, and high-level semantic cues. We also explore cognitive steering and knowledge injection strategies for persuasion-relevant reasoning. Empirical analysis across VLMs reveals a recall-oriented bias-models over-predict high persuasiveness-and weak discriminative power for low/mid-level features. In contrast, high-level semantic alignment between message and object presence emerges as the strongest predictor of human judgment. Among intervention strategies, simple instruction or unguided reasoning scaffolds yield marginal or negative effects, whereas concise, object-grounded rationales significantly improve precision and F1 scores. These results indicate that VLMs core limitation lies not in recognizing persuasive objects but in linking them to communicative intent.","authors":["Gyuwon Park"],"pdf_url":"","comment":"8 pages (except for reference and appendix), 5 figures, 7 tables, to be published in NeurIPS 2025 Workshop: VLM4RWD"},{"id":"http://arxiv.org/abs/2511.17031v1","updated":"2025-11-21T08:12:47Z","published":"2025-11-21T08:12:47Z","title":"Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation","summary":"The rapidly growing computational demands of diffusion models for image generation have raised significant concerns about energy consumption and environmental impact. While existing approaches to energy optimization focus on architectural improvements or hardware acceleration, there is a lack of principled methods to predict energy consumption across different model configurations and hardware setups. We propose an adaptation of Kaplan scaling laws to predict GPU energy consumption for diffusion models based on computational complexity (FLOPs). Our approach decomposes diffusion model inference into text encoding, iterative denoising, and decoding components, with the hypothesis that denoising operations dominate energy consumption due to their repeated execution across multiple inference steps. We conduct comprehensive experiments across four state-of-the-art diffusion models (Stable Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures (NVIDIA A100, A4000, A6000), spanning various inference configurations including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts (10-50), and classifier-free guidance settings. Our energy scaling law achieves high predictive accuracy within individual architectures (R-squared > 0.9) and exhibits strong cross-architecture generalization, maintaining high rank correlations across models and enabling reliable energy estimation for unseen model-hardware combinations. These results validate the compute-bound nature of diffusion inference and provide a foundation for sustainable AI deployment planning and carbon footprint estimation.","authors":["Aniketh Iyengar","Jiaqi Han","Boris Ruf","Vincent Grari","Marcin Detyniecki","Stefano Ermon"],"pdf_url":"","comment":"Accepted at EurIPS 2025 workshop \"Rethinking AI: Efficiency, Frugality, and Sustainability\""},{"id":"http://arxiv.org/abs/2511.16672v2","updated":"2025-11-21T07:47:18Z","published":"2025-11-20T18:59:54Z","title":"EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards","summary":"Recent advances in large multimodal models (LMMs) have enabled impressive reasoning and perception abilities, yet most existing training pipelines still depend on human-curated data or externally verified reward models, limiting their autonomy and scalability. In this work, we strive to improve LMM reasoning capabilities in a purely unsupervised fashion (without any annotated data or reward distillation). To this end, we propose a self-evolving framework, named EvoLMM, that instantiates two cooperative agents from a single backbone model: a Proposer, which generates diverse, image-grounded questions, and a Solver, which solves them through internal consistency, where learning proceeds through a continuous self-rewarding process. This dynamic feedback encourages both the generation of informative queries and the refinement of structured reasoning without relying on ground-truth or human judgments. When using the popular Qwen2.5-VL as the base model, our EvoLMM yields consistent gains upto $\\sim$3\\% on multimodal math-reasoning benchmarks, including ChartQA, MathVista, and MathVision, using only raw training images. We hope our simple yet effective approach will serve as a solid baseline easing future research in self-improving LMMs in a fully-unsupervised fashion. Our code and models are available at https://github.com/mbzuai-oryx/EvoLMM.","authors":["Omkar Thawakar","Shravan Venkatraman","Ritesh Thawkar","Abdelrahman Shaker","Hisham Cholakkal","Rao Muhammad Anwer","Salman Khan","Fahad Khan"],"pdf_url":"","comment":"9 Pages, 6 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2511.17014v1","updated":"2025-11-21T07:32:05Z","published":"2025-11-21T07:32:05Z","title":"Parameter-Free Neural Lens Blur Rendering for High-Fidelity Composites","summary":"Consistent and natural camera lens blur is important for seamlessly blending 3D virtual objects into photographed real-scenes. Since lens blur typically varies with scene depth, the placement of virtual objects and their corresponding blur levels significantly affect the visual fidelity of mixed reality compositions. Existing pipelines often rely on camera parameters (e.g., focal length, focus distance, aperture size) and scene depth to compute the circle of confusion (CoC) for realistic lens blur rendering. However, such information is often unavailable to ordinary users, limiting the accessibility and generalizability of these methods. In this work, we propose a novel compositing approach that directly estimates the CoC map from RGB images, bypassing the need for scene depth or camera metadata. The CoC values for virtual objects are inferred through a linear relationship between its signed CoC map and depth, and realistic lens blur is rendered using a neural reblurring network. Our method provides flexible and practical solution for real-world applications. Experimental results demonstrate that our method achieves high-fidelity compositing with realistic defocus effects, outperforming state-of-the-art techniques in both qualitative and quantitative evaluations.","authors":["Lingyan Ruan","Bin Chen","Taehyun Rhee"],"pdf_url":"","comment":"Accepted by ISMAR 2025 with oral presentation. 10 pages, 11 figures"},{"id":"http://arxiv.org/abs/2402.16126v2","updated":"2025-11-21T07:20:20Z","published":"2024-02-25T15:55:24Z","title":"A statistical method for crack pre-detection in 3D concrete images","summary":"In practical applications, effectively segmenting cracks in large-scale computed tomography (CT) images holds significant importance for understanding the structural integrity of materials. Classical image-processing techniques and modern deep-learning models both face substantial computational challenges when applied directly to high resolution big data volumes. This paper introduces a statistical framework for crack pre-localization, whose purpose is not to replace or compete with segmentation networks, but to identify, with controlled error rates, the regions of a 3D CT image that are most likely to contain cracks. The method combines a simple Hessian-based filter, geometric descriptors computed on a regular spatial partition, and a spatial multiple testing procedure to detect anomalous regions while relying only on minimal calibration data, rather than large annotated datasets. Experiments on semi-synthetic and real 3D CT scans demonstrate that the proposed approach reliably highlights regions likely to contain cracks while preserving linear computational complexity. By restricting subsequent high resolution segmentation to these localized regions, deep-learning models can be trained and operate more efficiently, reducing both training runtime as well as resource consumption. The framework thus offers a practical and interpretable preprocessing step for large-scale CT inspection pipelines.","authors":["Vitalii Makogin","Duc Nguyen","Evgeny Spodarev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17005v1","updated":"2025-11-21T07:18:37Z","published":"2025-11-21T07:18:37Z","title":"FLUID: Training-Free Face De-identification via Latent Identity Substitution","summary":"We present FLUID (Face de-identification in the Latent space via Utility-preserving Identity Displacement), a training-free framework that directly substitutes identity in the latent space of pretrained diffusion models. Inspired by substitution mechanisms in chemistry, we reinterpret identity editing as semantic displacement in the latent h-space of a pretrained unconditional diffusion model. Our framework discovers identity-editing directions through optimization guided by novel reagent losses, which supervise for attribute preservation and identity suppression. We further propose both linear and geodesic (tangent-based) editing schemes to effectively navigate the latent manifold. Experimental results on CelebA-HQ and FFHQ demonstrate that FLUID achieves a superior trade-off between identity suppression and attribute preservation, outperforming state-of-the-art de-identification methods in both qualitative and quantitative metrics.","authors":["Jinhyeong Park","Shaheryar Muhammad","Seangmin Lee","Jong Taek Lee","Soon Ki Jung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17004v1","updated":"2025-11-21T07:14:46Z","published":"2025-11-21T07:14:46Z","title":"Vision Language Models are Confused Tourists","summary":"Although the cultural dimension has been one of the key aspects in evaluating Vision-Language Models (VLMs), their ability to remain stable across diverse cultural inputs remains largely untested, despite being crucial to support diversity and multicultural societies. Existing evaluations often rely on benchmarks featuring only a singular cultural concept per image, overlooking scenarios where multiple, potentially unrelated cultural cues coexist. To address this gap, we introduce ConfusedTourist, a novel cultural adversarial robustness suite designed to assess VLMs' stability against perturbed geographical cues. Our experiments reveal a critical vulnerability, where accuracy drops heavily under simple image-stacking perturbations and even worsens with its image-generation-based variant. Interpretability analyses further show that these failures stem from systematic attention shifts toward distracting cues, diverting the model from its intended focus. These findings highlight a critical challenge: visual cultural concept mixing can substantially impair even state-of-the-art VLMs, underscoring the urgent need for more culturally robust multimodal understanding.","authors":["Patrick Amadeus Irawan","Ikhlasul Akmal Hanif","Muhammad Dehan Al Kautsar","Genta Indra Winata","Fajri Koto","Alham Fikri Aji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16998v1","updated":"2025-11-21T07:06:48Z","published":"2025-11-21T07:06:48Z","title":"VLM-Augmented Degradation Modeling for Image Restoration Under Adverse Weather Conditions","summary":"Reliable visual perception under adverse weather conditions, such as rain, haze, snow, or a mixture of them, is desirable yet challenging for autonomous driving and outdoor robots. In this paper, we propose a unified Memory-Enhanced Visual-Language Recovery (MVLR) model that restores images from different degradation levels under various weather conditions. MVLR couples a lightweight encoder-decoder backbone with a Visual-Language Model (VLM) and an Implicit Memory Bank (IMB). The VLM performs chain-of-thought inference to encode weather degradation priors and the IMB stores continuous latent representations of degradation patterns. The VLM-generated priors query the IMB to retrieve fine-grained degradation prototypes. These prototypes are then adaptively fused with multi-scale visual features via dynamic cross-attention mechanisms, enhancing restoration accuracy while maintaining computational efficiency. Extensive experiments on four severe-weather benchmarks show that MVLR surpasses single-branch and Mixture-of-Experts baselines in terms of Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM). These results indicate that MVLR offers a practical balance between model compactness and expressiveness for real-time deployment in diverse outdoor conditions.","authors":["Qianyi Shao","Yuanfan Zhang","Renxiang Xiao","Liang Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16993v1","updated":"2025-11-21T06:59:54Z","published":"2025-11-21T06:59:54Z","title":"DepthFocus: Controllable Depth Estimation for See-Through Scenes","summary":"Depth in the real world is rarely singular. Transmissive materials create layered ambiguities that confound conventional perception systems. Existing models remain passive, attempting to estimate static depth maps anchored to the nearest surface, while humans actively shift focus to perceive a desired depth. We introduce DepthFocus, a steerable Vision Transformer that redefines stereo depth estimation as intent-driven control. Conditioned on a scalar depth preference, the model dynamically adapts its computation to focus on the intended depth, enabling selective perception within complex scenes. The training primarily leverages our newly constructed 500k multi-layered synthetic dataset, designed to capture diverse see-through effects. DepthFocus not only achieves state-of-the-art performance on conventional single-depth benchmarks like BOOSTER, a dataset notably rich in transparent and reflective objects, but also quantitatively demonstrates intent-aligned estimation on our newly proposed real and synthetic multi-depth datasets. Moreover, it exhibits strong generalization capabilities on unseen see-through scenes, underscoring its robustness as a significant step toward active and human-like 3D perception.","authors":["Junhong Min","Jimin Kim","Cheol-Hui Min","Minwook Kim","Youngpil Jeon","Minyong Choi"],"pdf_url":"","comment":"8pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2511.11005v2","updated":"2025-11-21T06:58:21Z","published":"2025-11-14T06:50:14Z","title":"Draft and Refine with Visual Experts","summary":"While recent Large Vision-Language Models (LVLMs) exhibit strong multimodal reasoning abilities, they often produce ungrounded or hallucinated responses because they rely too heavily on linguistic priors instead of visual evidence. This limitation highlights the absence of a quantitative measure of how much these models actually use visual information during reasoning. We propose Draft and Refine (DnR), an agent framework driven by a question-conditioned utilization metric. The metric quantifies the model's reliance on visual evidence by first constructing a query-conditioned relevance map to localize question-specific cues and then measuring dependence through relevance-guided probabilistic masking. Guided by this metric, the DnR agent refines its initial draft using targeted feedback from external visual experts. Each expert's output (such as boxes or masks) is rendered as visual cues on the image, and the model is re-queried to select the response that yields the largest improvement in utilization. This process strengthens visual grounding without retraining or architectural changes. Experiments across VQA and captioning benchmarks show consistent accuracy gains and reduced hallucination, demonstrating that measuring visual utilization provides a principled path toward more interpretable and evidence-driven multimodal agent systems. Code is available at https://github.com/EavnJeong/Draft-and-Refine-with-Visual-Experts.","authors":["Sungheon Jeong","Ryozo Masukawa","Jihong Park","Sanggeon Yun","Wenjun Huang","Hanning Chen","Mahdi Imani","Mohsen Imani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16991v1","updated":"2025-11-21T06:57:33Z","published":"2025-11-21T06:57:33Z","title":"DReX: Pure Vision Fusion of Self-Supervised and Convolutional Representations for Image Complexity Prediction","summary":"Visual complexity prediction is a fundamental problem in computer vision with applications in image compression, retrieval, and classification. Understanding what makes humans perceive an image as complex is also a long-standing question in cognitive science. Recent approaches have leveraged multimodal models that combine visual and linguistic representations, but it remains unclear whether language information is necessary for this task. We propose DReX (DINO-ResNet Fusion), a vision-only model that fuses self-supervised and convolutional representations through a learnable attention mechanism to predict image complexity. Our architecture integrates multi-scale hierarchical features from ResNet-50 with semantically rich representations from DINOv3 ViT-S/16, enabling the model to capture both low-level texture patterns and high-level semantic structure. DReX achieves state-of-the-art performance on the IC9600 benchmark (Pearson r = 0.9581), surpassing previous methods--including those trained on multimodal image-text data--while using approximately 21.5x fewer learnable parameters. Furthermore, DReX generalizes robustly across multiple datasets and metrics, achieving superior results on Pearson and Spearman correlation, Root Mean Square Error (RMSE), and Mean Absolute Error (MAE). Ablation and attention analyses confirm that DReX leverages complementary cues from both backbones, with the DINOv3 [CLS] token enhancing sensitivity to visual complexity. Our findings suggest that visual features alone can be sufficient for human-aligned complexity prediction and that, when properly fused, self-supervised transformers and supervised deep convolutional neural networks offer complementary and synergistic benefits for this task.","authors":["Jonathan Skaza","Parsa Madinei","Ziqi Wen","Miguel Eckstein"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2511.16986v1","updated":"2025-11-21T06:45:46Z","published":"2025-11-21T06:45:46Z","title":"RadioKMoE: Knowledge-Guided Radiomap Estimation with Kolmogorov-Arnold Networks and Mixture-of-Experts","summary":"Radiomap serves as a vital tool for wireless network management and deployment by providing powerful spatial knowledge of signal propagation and coverage. However, increasingly complex radio propagation behavior and surrounding environments pose strong challenges for radiomap estimation (RME). In this work, we propose a knowledge-guided RME framework that integrates Kolmogorov-Arnold Networks (KAN) with Mixture-of-Experts (MoE), namely RadioKMoE. Specifically, we design a KAN module to predict an initial coarse coverage map, leveraging KAN's strength in approximating physics models and global radio propagation patterns. The initial coarse map, together with environmental information, drives our MoE network for precise radiomap estimation. Unlike conventional deep learning models, the MoE module comprises expert networks specializing in distinct radiomap patterns to improve local details while preserving global consistency. Experimental results in both multi- and single-band RME demonstrate the enhanced accuracy and robustness of the proposed RadioKMoE in radiomap estimation.","authors":["Fupei Guo","Kerry Pan","Songyang Zhang","Yue Wang","Zhi Ding"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.14528v3","updated":"2025-11-21T06:39:47Z","published":"2025-10-16T10:18:48Z","title":"PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model","summary":"In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. Code is available at https://github.com/PaddlePaddle/PaddleOCR .","authors":["Cheng Cui","Ting Sun","Suyin Liang","Tingquan Gao","Zelun Zhang","Jiaxuan Liu","Xueqing Wang","Changda Zhou","Hongen Liu","Manhui Lin","Yue Zhang","Yubo Zhang","Handong Zheng","Jing Zhang","Jun Zhang","Yi Liu","Dianhai Yu","Yanjun Ma"],"pdf_url":"","comment":"Github Repo: https://github.com/PaddlePaddle/PaddleOCR"},{"id":"http://arxiv.org/abs/2511.12861v3","updated":"2025-11-21T06:39:29Z","published":"2025-11-17T01:22:37Z","title":"From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models","summary":"With the remarkable success of Multimodal Large Language Models (MLLMs) in perception tasks, enhancing their complex reasoning capabilities has emerged as a critical research focus. Existing models still suffer from challenges such as opaque reasoning paths and insufficient generalization ability. Chain-of-Thought (CoT) reasoning, which has demonstrated significant efficacy in language models by enhancing reasoning transparency and output interpretability, holds promise for improving model reasoning capabilities when extended to the multimodal domain. This paper provides a systematic review centered on \"Multimodal Chain-of-Thought\" (MCoT). First, it analyzes the background and theoretical motivations for its inception from the perspectives of technical evolution and task demands. Then, it introduces mainstream MCoT methods from three aspects: CoT paradigms, the post-training stage, and the inference stage, while also analyzing their underlying mechanisms. Furthermore, the paper summarizes existing evaluation benchmarks and metrics, and discusses the application scenarios of MCoT. Finally, it analyzes the challenges currently facing MCoT and provides an outlook on its future research directions.","authors":["Wenxin Zhu","Andong Chen","Yuchen Song","Kehai Chen","Conghui Zhu","Ziyan Chen","Tiejun Zhao"],"pdf_url":"","comment":"Survey; 7 figures, 3 tables, 44 pages"},{"id":"http://arxiv.org/abs/2511.16982v1","updated":"2025-11-21T06:29:52Z","published":"2025-11-21T06:29:52Z","title":"A Diversity-optimized Deep Ensemble Approach for Accurate Plant Leaf Disease Detection","summary":"Plant diseases pose a significant threat to global agriculture, causing over $220 billion in annual economic losses and jeopardizing food security. The timely and accurate detection of these diseases from plant leaf images is critical to mitigating their adverse effects. Deep neural network Ensembles (Deep Ensembles) have emerged as a powerful approach to enhancing prediction accuracy by leveraging the strengths of diverse Deep Neural Networks (DNNs). However, selecting high-performing ensemble member models is challenging due to the inherent difficulty in measuring ensemble diversity. In this paper, we introduce the Synergistic Diversity (SQ) framework to enhance plant disease detection accuracy. First, we conduct a comprehensive analysis of the limitations of existing ensemble diversity metrics (denoted as Q metrics), which often fail to identify optimal ensemble teams. Second, we present the SQ metric, a novel measure that captures the synergy between ensemble members and consistently aligns with ensemble accuracy. Third, we validate our SQ approach through extensive experiments on a plant leaf image dataset, which demonstrates that our SQ metric substantially improves ensemble selection and enhances detection accuracy. Our findings pave the way for a more reliable and efficient image-based plant disease detection.","authors":["Sai Nath Chowdary Medikonduru","Hongpeng Jin","Yanzhao Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.09779v4","updated":"2025-11-21T06:28:16Z","published":"2025-02-13T21:27:10Z","title":"Automated Muscle and Fat Segmentation in Computed Tomography for Comprehensive Body Composition Analysis","summary":"Body composition assessment using CT images can potentially be used for a number of clinical applications, including the prognostication of cardiovascular outcomes, evaluation of metabolic health, monitoring of disease progression, assessment of nutritional status, prediction of treatment response in oncology, and risk stratification for surgical and critical care outcomes. While multiple groups have developed in-house segmentation tools for this analysis, there are very limited publicly available tools that could be consistently used across different applications. To mitigate this gap, we present a publicly accessible, end-to-end segmentation and feature calculation model specifically for CT body composition analysis. Our model performs segmentation of skeletal muscle, subcutaneous adipose tissue (SAT), and visceral adipose tissue (VAT) across the chest, abdomen, and pelvis area in axial CT images. It also provides various body composition metrics, including muscle density, visceral-to-subcutaneous fat (VAT/SAT) ratio, muscle area/volume, and skeletal muscle index (SMI), supporting both 2D and 3D assessments. To evaluate the model, the segmentation was applied to both internal and external datasets, with body composition metrics analyzed across different age, sex, and race groups. The model achieved high dice coefficients on both internal and external datasets, exceeding 89% for skeletal muscle, SAT, and VAT segmentation. The model outperforms the benchmark by 2.10% on skeletal muscle and 8.6% on SAT compared to the manual annotations given by the publicly available dataset. Body composition metrics show mean relative absolute errors (MRAEs) under 10% for all measures. Our model with weights is publicly available at https://github.com/mazurowski-lab/CT-Muscle-and-Fat-Segmentation.git.","authors":["Yaqian Chen","Hanxue Gu","Yuwen Chen","Jichen Yang","Haoyu Dong","Joseph Y. Cao","Adrian Camarena","Christopher Mantyh","Roy Colglazier","Maciej A. Mazurowski"],"pdf_url":"","comment":"Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:026"},{"id":"http://arxiv.org/abs/2511.16980v1","updated":"2025-11-21T06:27:46Z","published":"2025-11-21T06:27:46Z","title":"Gradient-Driven Natural Selection for Compact 3D Gaussian Splatting","summary":"3DGS employs a large number of Gaussian primitives to fit scenes, resulting in substantial storage and computational overhead. Existing pruning methods rely on manually designed criteria or introduce additional learnable parameters, yielding suboptimal results. To address this, we propose an natural selection inspired pruning framework that models survival pressure as a regularization gradient field applied to opacity, allowing the optimization gradients--driven by the goal of maximizing rendering quality--to autonomously determine which Gaussians to retain or prune. This process is fully learnable and requires no human intervention. We further introduce an opacity decay technique with a finite opacity prior, which accelerates the selection process without compromising pruning effectiveness. Compared to 3DGS, our method achieves over 0.6 dB PSNR gain under 15\\% budgets, establishing state-of-the-art performance for compact 3DGS. Project page https://xiaobin2001.github.io/GNS-web.","authors":["Xiaobin Deng","Qiuli Yu","Changyu Diao","Min Li","Duanqing Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21502v2","updated":"2025-11-21T06:23:38Z","published":"2025-05-27T17:59:47Z","title":"Generalizable and Relightable Gaussian Splatting for Human Novel View Synthesis","summary":"We propose GRGS, a generalizable and relightable 3D Gaussian framework for high-fidelity human novel view synthesis under diverse lighting conditions. Unlike existing methods that rely on per-character optimization or ignore physical constraints, GRGS adopts a feed-forward, fully supervised strategy projecting geometry, material, and illumination cues from multi-view 2D observations into 3D Gaussian representations. To recover accurate geometry under diverse lighting conditions, we introduce a Lighting-robust Geometry Refinement (LGR) module trained on synthetically relit data to predict precise depth and surface normals. Based on the high-quality geometry, a Physically Grounded Neural Rendering (PGNR) module is further proposed to integrate neural prediction with physics-based shading, supporting editable relighting with shadows and indirect illumination. Moreover, we design a 2D-to-3D projection training scheme leveraging differentiable supervision from ambient occlusion, direct, and indirect lighting maps, alleviating the computational cost of ray tracing. Extensive experiments demonstrate that GRGS achieves superior visual quality, geometric consistency, and generalization across characters and lighting conditions.","authors":["Yipengjing Sun","Shengping Zhang","Chenyang Wang","Shunyuan Zheng","Zonglin Li","Xiangyang Ji"],"pdf_url":"","comment":"Project Webpage: https://sypj-98.github.io/grgs/"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2511.17489v1","updated":"2025-11-21T18:45:53Z","published":"2025-11-21T18:45:53Z","title":"Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization","summary":"It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.","authors":["Vinay Kanakeri","Shivam Bajaj","Ashwin Verma","Vijay Gupta","Aritra Mitra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17464v1","updated":"2025-11-21T18:09:25Z","published":"2025-11-21T18:09:25Z","title":"A Patient-Centric Blockchain Framework for Secure Electronic Health Record Management: Decoupling Data Storage from Access Control","summary":"We present a patient-centric architecture for electronic health record (EHR) sharing that separates content storage from authorization and audit. Encrypted FHIR resources are stored off-chain; a public blockchain records only cryptographic commitments and patient-signed, time-bounded permissions using EIP-712. Keys are distributed via public-key wrapping, enabling storage providers to remain honest-but-curious without risking confidentiality. We formalize security goals (confidentiality, integrity, cryptographically attributable authorization, and auditability of authorization events) and provide a Solidity reference implementation deployed as single-patient contracts. On-chain costs for permission grants average 78,000 gas (L1), and end-to-end access latency for 1 MB records is 0.7--1.4s (mean values for S3 and IPFS respectively), dominated by storage retrieval. Layer-2 deployment reduces gas usage by 10--13x, though data availability charges dominate actual costs. We discuss metadata privacy, key registry requirements, and regulatory considerations (HIPAA/GDPR), demonstrating a practical route to restoring patient control while preserving security properties required for sensitive clinical data.","authors":["Tanzim Hossain Romel","Kawshik Kumar Paul","Tanberul Islam Ruhan","Maisha Rahman Mim","Abu Sayed Md. Latiful Hoque"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17440v1","updated":"2025-11-21T17:39:09Z","published":"2025-11-21T17:39:09Z","title":"Incorporating Bayesian Transfer Learning into Particle Filter for Dual-Tracking System with Asymmetric Noise Intensities","summary":"Using Bayesian transfer learning, we develop a particle filter approach for tracking a nonlinear dynamical model in a dual-tracking system where intensities of measurement noise for both sensors are asymmetric. The densities for Bayesian transfer learning are approximated with the sum of weighted particles to improve the tracking performance of the primary sensor, which experiences a higher noise intensity compared to the source sensor. We present simulation results that validate the effectiveness of the proposed approach compared to an isolated particle filter and transfer learning applied to the unscented Kalman filter and the cubature Kalman filter. Furthermore, increasing the number of particles shows an improvement in the performance of transfer learning applied to the particle filter with a higher rate compared to the isolated particle filter. However, increasing the number of particles raises computational time per step. Moreover, the performance gain from incorporating Bayesian transfer learning is approximately linearly proportional to the absolute difference value between the noise intensities of the sensors in the dual-tracking system.","authors":["Omar A. Alotaibi","Brian L. Mark","Mohammad Reza Fasihi"],"pdf_url":"","comment":"20 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.17436v1","updated":"2025-11-21T17:33:00Z","published":"2025-11-21T17:33:00Z","title":"A Framework for Adaptive Stabilisation of Nonlinear Stochastic Systems","summary":"We consider the adaptive control problem for discrete-time, nonlinear stochastic systems with linearly parameterised uncertainty. Assuming access to a parameterised family of controllers that can stabilise the system in a bounded set within an informative region of the state space when the parameter is well-chosen, we propose a certainty equivalence learning-based adaptive control strategy, and subsequently derive stability bounds on the closed-loop system that hold for some probabilities. We then show that if the entire state space is informative, and the family of controllers is globally stabilising with appropriately chosen parameters, high probability stability guarantees can be derived.","authors":["Seth Siriya","Jingge Zhu","Dragan Nešić","Ye Pu"],"pdf_url":"","comment":"22 pages, 1 figure"},{"id":"http://arxiv.org/abs/2511.17433v1","updated":"2025-11-21T17:30:34Z","published":"2025-11-21T17:30:34Z","title":"The Iberian Blackout: A Black Swan or a Gray Rhino? A Thorough Power System Analysis","summary":"On April 28, 2025, the Iberian power system suffered a full blackout. It was the first documented overvoltage-driven cascade in Europe. The event sparked debate about root causes, including high renewables output, low inertia, and operator actions. This paper presents a thorough power system analysis of the incident to sort signal from noise and explain, step by step, how the blackout unfolded. Specifically, we (i) reconstruct the timeline and causal chain of the incident, (ii) present and summarize contributing factors using factual findings from incident reports, (iii) reproduce the blackout on an IEEE test system, (iv) analyze the incident from a system-theoretic, voltage-control perspective, and (v) translate our analysis into practical, technical measures that aim to mitigate and prevent similar incidents.","authors":["Abdallah Alalem Albustami","Ahmad F. Taha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.09830v2","updated":"2025-11-21T17:23:26Z","published":"2025-11-13T00:25:53Z","title":"Resilient Controller Design with Exponential Reaching Law for Enhanced Load Frequency Stability in Multi-Area Interconnected Microgrids","summary":"We present a load frequency control strategy deploying a decentralized robust global integral terminal sliding mode control (GITSMC) method to maintain stable frequency and tie-line power in multi-area interconnected microgrids with aggregated uncertainties. To achieve this, firstly, we have developed a mathematical model of the multi-area interconnected system incorporating disturbances from solar photovoltaic (PV), wind turbine (WT) generation and load demand, as aggregated uncertainties. Secondly, we have designed a global integral terminal sliding surface with an exponential reaching law for each area to enhance system dynamic performance and suppress chattering within a finite time. Thirdly, the overall stability of the closed-loop system is analyzed using the Lyapunov stability theorem. Finally, extensive simulations are conducted on the IEEE 10-generator New England 39-bus power system, including load disturbances and variable PV and WT generation. The results demonstrate the performance of the proposed GITSMC approach, achieving approximately 94.9% improvement in ITSE and 94.4% improvement in ISE, confirming its superior accuracy and dynamic performance compared to the existing controller.","authors":["Md Saiful Islam","Rahul Bhadani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15477v2","updated":"2025-11-21T16:26:16Z","published":"2025-11-19T14:33:21Z","title":"On the Contraction of Excitable Systems","summary":"We analyze contraction in conductance-based excitable systems and link it to reliable spike timing. For a Hodgkin-Huxley neuron with synaptic input, we prove the unforced dynamics is incrementally exponentially stable on a compact physiological set. With impulsive inputs, contraction persists under an average dwell-time condition, and for periodic spike trains we derive an explicit lower bound on the inter-impulse period. In the high-rate limit the synapse is effectively held open, the conductance is nearly constant, and self-sustained limit-cycle oscillations can arise, so contraction no longer holds. This continuous-time view explains when spike times extracted by an event detector remain robust across trials, and simulations confirm both regimes.","authors":["Alessandro Cecconi","Michelangelo Bin","Lorenzo Marconi","Rodolphe Sepulchre"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17351v1","updated":"2025-11-21T16:13:53Z","published":"2025-11-21T16:13:53Z","title":"Convergence and stability of Q-learning in Hierarchical Reinforcement Learning","summary":"Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.","authors":["Massimiliano Manenti","Andrea Iannelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17297v1","updated":"2025-11-21T15:10:57Z","published":"2025-11-21T15:10:57Z","title":"Computing the Hard Scaled Relative Graph of LTI Systems","summary":"Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain method for the analysis of nonlinear systems, where Linear Time-Invariant (LTI) systems are the fundamental building block. To analyze feedback loops with unstable LTI components, the hard SRG is required, since it aptly captures the input/output behavior on the extended $L_2$ space. In this paper, we develop a systematic computational method to exactly compute the hard SRG of LTI systems, which may be unstable and contain integrators. We also study its connection to the Nyquist criterion, including the multivariable case, and demonstrate our method on several examples.","authors":["Julius P. J. Krebbekx","Eder Baron-Prada","Roland Tóth","Amritam Das"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2511.17252v1","updated":"2025-11-21T13:57:04Z","published":"2025-11-21T13:57:04Z","title":"Chance constrained optimization of energy intensive production as beneficial power units","summary":"We study linear policy approximations for the risk-conscious operation of an industrial energy system with uncertain wind power, significant and variable electricity demand, and high thermal output, as found in a modern foundry. The system incorporates thermal storage and operates under rolling forecasts, leading to a sequential decision-making framework. To address uncertainty in key parameters, we formulate chance-constrained optimization problems that limit the probability of critical constraint violations, such as unmet demand requirements or the exceedance of system boundaries. To reduce computational effort, we replace direct uncertainty handling with a parameter-modified cost function that approximates the underlying risk structure. We validate our method through a numerical case study, demonstrating the trade-offs between operational efficiency and reliability in a stochastic environment.","authors":["Johannes Nicklaus","Lea Brass","Gunnar Schubert"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15480v2","updated":"2025-11-21T13:50:30Z","published":"2025-11-19T14:36:44Z","title":"Robust H-infinity control and worst-case search in constrained parametric space","summary":"Standard H-infinity/H2 robust control and analysis tools operate on uncertain parameters assumed to vary independently within prescribed bounds. This paper extends their capabilities in the presence of constraints coupling these parameters and restricting the parametric space. Focusing on the worst-case search, we demonstrate -- based on the theory of upper-C1 functions -- the validity of using standard, readily available smooth optimization algorithms to address this nonsmooth constrained optimization problem. Accordingly, we propose to explore the parametric space with either Monte-Carlo sampling or particle swarm optimization, and to subsequently perform local exploitation with Sequential Quadratic Programming to compute Karush-Kuhn-Tucker points. This worst-case search then enables robust controller synthesis: as in the state-of-art algorithm for standard robust control, identified worst-case configurations are iteratively added to an active set on which a non-smooth multi-models optimization of the controller is performed. The methodology is illustrated on a satellite benchmark with flexible appendages, of order 50 with 43 uncertain parameters. We show that the proposed method largely outperforms Monte-Carlo sampling alone, is able to reliably detect even rare worst-case configurations in minutes on a standard laptop, and that the robust controller optimization converges with less than 10 active configurations. Even in the unconstrained case, the proposed framework complements traditional methods, as it scales to plants with many parameters and states and explores the entire parametric space, albeit without formal guarantees of global optimality.","authors":["Ervan Kassarian","Francesco Sanfedino","Daniel Alazard","Andrea Marrazza"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.19660v2","updated":"2025-11-21T13:36:38Z","published":"2024-10-25T16:10:32Z","title":"Perception, Control and Hardware for In-Hand Slip-Aware Object Manipulation with Parallel Grippers","summary":"Dexterous in-hand manipulation offers significant potential to enhance robotic manipulator capabilities. This paper presents a sensori-motor architecture for in-hand slip-aware control, being embodied in a sensorized gripper. The gripper in our architecture features rapid closed-loop, low-level force control, and is equipped with sensors capable of independently measuring contact forces and sliding velocities. Our system can quickly estimate essential object properties during pick-up using only in-hand sensing, without relying on prior object information. We introduce four distinct slippage controllers: gravity-assisted trajectory following for both rotational and linear slippage, a hinge controller that maintains the object's orientation while the gripper rotates, and a slip-avoidance controller. The gripper is mounted on a robot arm and validated through extensive experiments involving a diverse range of objects, demonstrating the architecture's novel capabilities for manipulating objects with flat surfaces.","authors":["Gabriel Arslan Waltersson","Yiannis Karayiannidis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17233v1","updated":"2025-11-21T13:21:20Z","published":"2025-11-21T13:21:20Z","title":"Algorithmic design and implementation considerations of deep MPC","summary":"Deep Model Predictive Control (Deep MPC) is an evolving field that integrates model predictive control and deep learning. This manuscript is focused on a particular approach, which employs deep neural network in the loop with MPC. This class of approaches distributes control authority between a neural network and an MPC controller, in such a way that the neural network learns the model uncertainties while the MPC handles constraints. The approach is appealing because training data collected while the system is in operation can be used to fine-tune the neural network, and MPC prevents unsafe behavior during those learning transients. This manuscript explains implementation challenges of Deep MPC, algorithmic way to distribute control authority and argues that a poor choice in distributing control authority may lead to poor performance. A reason of poor performance is explained through a numerical experiment on a four-wheeled skid-steer dynamics.","authors":["Prabhat K. Mishra","Mateus V. Gasparino","Girish Chowdhary"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17212v1","updated":"2025-11-21T12:44:29Z","published":"2025-11-21T12:44:29Z","title":"Influence of Transmission Rank on EMF Exposure Measured With Provoked Data Traffic Around 5G Massive MIMO Base Stations","summary":"The introduction of 5G New Radio networks with massive MIMO technology has complicated electromagnetic field exposure assessments for radiation protection. Massive MIMO transmission enables beamforming, beam steering, and spatial multiplexing across multiple transmission layers, with the number of simultaneous transmission paths depending on the rank of the radio channel, further named 'transmission rank'. Since the total transmission power of a base station is shared among these layers, rank variations affect the measured exposure levels, e.g., when assessments use provoked traffic via user equipment. This study investigates the impact of the transmission rank on the measured maximum exposure in the 3.6 GHz (n78) band of a German 5G network employing massive MIMO technology. Field measurements were performed using a spectrum analyzer with isotropic probe, to capture maximum field strengths under full-load traffic conditions. The transmission rank was manipulated by artificially degrading the reception quality of the user equipment with a shielding bag, forcing a single transmission layer (rank-1). The results were compared with unshielded operation allowing up to the maximum number of four independent transmission layers (rank-4). The data reveal exposure differences ranging from 1.7 dB to 5.4 dB, with a median of 4.3 dB at the measurement points studied. These findings highlight the necessity of considering the transmission rank in exposure assessments to electromagnetic fields.","authors":["Lisa-Marie Schilling","Christian Bornkessel","Anna-Malin Schiffarth","Thanh Tam Julian Ta","Dirk Heberling","Matthias Hein"],"pdf_url":"","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.17186v1","updated":"2025-11-21T12:06:58Z","published":"2025-11-21T12:06:58Z","title":"Distributed Switching Model Predictive Control Meets Koopman Operator for Dynamic Obstacle Avoidance","summary":"This paper introduces a Koopman-enhanced distributed switched model predictive control (SMPC) framework for safe and scalable navigation of quadrotor unmanned aerial vehicles (UAVs) in dynamic environments with moving obstacles. The proposed method integrates switched motion modes and data-driven prediction to enable real-time, collision-free coordination. A localized Koopman operator approximates nonlinear obstacle dynamics as linear models based on online measurements, enabling accurate trajectory forecasting. These predictions are embedded into a distributed SMPC structure, where each UAV makes autonomous decisions using local and cluster-based information. This computationally efficient architecture is particularly promising for applications in surface transportation, including coordinated vehicle flows, shared infrastructure with pedestrians or cyclists, and urban UAV traffic. Simulation results demonstrate reliable formation control and real-time obstacle avoidance, highlighting the frameworks broad relevance for intelligent and cooperative mobility systems.","authors":["Ali Azarbahram","Chrystian Pool Yuca Huanca","Gian Paolo Incremona","Patrizio Colaneri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17104v1","updated":"2025-11-21T10:08:50Z","published":"2025-11-21T10:08:50Z","title":"Power Flow Solution in Unbalanced 3-Wire MV and 4-Wire LV Networks Using Symmetrical and Eigen-basis Coordinates","summary":"The large penetration of distributed generations impacts both the secondary low-voltage (LV) and the primary medium-voltage (MV) segments of the distribution network. Optimizing power flow calculations for the integrated MV/LV networks is crucial for the real-time management of modern distribution networks. Traditional methods in symmetrical coordinates are primarily limited to the three-wire model of three-phase networks, often leading to inaccuracies in power flow calculations when applied to three-phase four-wire LV segments. This paper introduces a novel power flow method for integrated three-wire MV and four-wire LV networks. Using eigenvector decomposition to diagonalize the admittance matrix of four-wire LV lines, the proposed method improves the computational efficiency of power flow calculations and accurately calculates the neutral-to-ground voltage. The results of the case studies show over 50\\% reduction in the number of non-zero elements in the LU factors of the bus admittance matrix, and speed-up factors of 2.78 on the IEEE 123-node test system and 3.63 on the IEEE 8500-node test system in execution times for Volt/Var control (VVC), compared to the phase coordinates model.","authors":["Abduljalil S. Aljadani","Firdous U. Nazir","Bikash C. Pal","Izudin Džafić","Rabih A. Jabr"],"pdf_url":"","comment":"10 pages, 7 figures. Submitted to Journal of Modern Power Systems and Clean Energy"},{"id":"http://arxiv.org/abs/2511.17102v1","updated":"2025-11-21T10:02:40Z","published":"2025-11-21T10:02:40Z","title":"KNN and Time Series Based Prediction of Power Generation from Renewable Resources","summary":"As the world shifts towards utilizing natural resources for electricity generation, there is need to enhance forecasting systems to guarantee a stable electricity provision and to incorporate the generated power into the network systems. This work provides a machine learning environment for renewable energy forecasting that prevents the flaws which are usually experienced in the actual process; intermittency, nonlinearity and intricacy in nature which is difficult to grasp by ordinary existing forecasting procedures. Leveraging a comprehensive approximately 30-year dataset encompassing multiple renewable energy sources, our research evaluates two distinct approaches: K-Nearest Neighbors (KNN) model and Non-Linear Autoregressive distributed called with Seasonal Autoregressive Integrated Moving Average (SARIMA) model to forecast total power generation using the solar, wind, and hydroelectric resources. The framework uses high temporal resolution and multiple parameters of the environment to improve the predictions. The fact that both the models in terms of error metrics were equally significant and had some unique tendencies at certain circumstances. The long history allows for better model calibration of temporal fluctuations and seasonal and climatic effects on power generation. The reliability enhancement in the prediction function, which benefits from 30 years of data, has value to grid operators, energy traders, and those establishing renewable energy policies and standards concerning reliability","authors":["Ismum Ul Hossain","Mohammad Nahidul Islam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17025v1","updated":"2025-11-21T07:55:47Z","published":"2025-11-21T07:55:47Z","title":"Comparison of linear observation techniques for robust load torque estimation in actuators","summary":"The paper addresses the problem of estimating robustly the external load torque in rotary actuator systems, when only the generated motor drive torque and angular displacement are the available input and output. We compare, theoretically and experimentally, two sufficiently established linear observation techniques (i) reduced-order Luenberger observer and (ii) disturbance observer, both using the same identified model of a permanent magnet synchronous motor (PMSM)-based actuator. Our goal is to highlight several aspects related to the implementation, relative degree of the input-torque to estimated-load-torque transfer characteristics, observer open-loop transfer function, and the associated sensitivity (respectively stability margins) with respect to inherently uncertain system plants. Apart from the developed analysis, a detailed experimental case study is demonstrated where the load torque sensor provides reference measurements and allows for evaluation of both observers.","authors":["Michael Ruderman","Elia Brescia","Luigi P. Savastio","Paolo R. Massenio","David Naso","Giuseppe L. Cascella"],"pdf_url":"","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.17017v1","updated":"2025-11-21T07:45:43Z","published":"2025-11-21T07:45:43Z","title":"Continuous Resilience in Cyber-Physical Systems of Systems: Extending Architectural Models through Adaptive Coordination and Learning","summary":"Cyber-physical systems of systems (CPSoS) are highly complex, dynamic environments in which technical, cybernetic and organisational subsystems interact closely with one another. Dynamic, continuously adaptable resilience is required to ensure their functionality under variable conditions. However, existing resilience architectures usually only deal with adaptation implicitly and thus remain predominantly static. This paper addresses this gap by introducing a new Adaptive Coordination Layer (ACL) and conceptually redefining the Adaptation & Learning Layer (AL). The ACL acts as an operational control layer that detects risks in real time, prioritises countermeasures and coordinates them dynamically. The AL is reinterpreted as a strategic-cooperative layer that evaluates the operational decisions of the ACL, learns from them, and derives long-term adjustments at the policy, governance, and architecture levels. Together, both layers operationalise the resilience principle of adaptation and combine short-term responsiveness with long-term learning and development capabilities. The paper describes various implementation variants of both levels - from rule-based and KPI-driven approaches to AI-supported and meta-learning mechanisms - and shows how these can be combined depending on system complexity, data availability and degree of regulation. The proposed architecture model no longer understands resilience as a static system property, but as a continuous, data-driven process of mutual coordination and systemic learning. This creates a methodological basis for the next generation of adaptive and resilient CPSoS.","authors":["Elisabeth Vogel","Peter Langendörfer"],"pdf_url":"","comment":"27 pages, 6 tables, 1 figure"},{"id":"http://arxiv.org/abs/2511.17007v1","updated":"2025-11-21T07:25:49Z","published":"2025-11-21T07:25:49Z","title":"Generative MIMO Beam Map Construction for Location Recovery and Beam Tracking","summary":"Machine learning (ML) has greatly advanced data-driven channel modeling and resource optimization in wireless communication systems. However, most existing ML-based methods rely on large, accurately labeled datasets with location information, which are often difficult and costly to obtain. This paper proposes a generative framework to recover location labels directly from sequences of sparse channel state information (CSI) measurements, without explicit location labels for radio map construction. Instead of directly storing raw CSI, we learn a compact low-dimensional radio map embedding and leverage a generative model to reconstruct the high-dimensional CSI. Specifically, to address the uncertainty of sparse CSI, a dual-scale feature extraction scheme is designed to enhance feature representation by jointly exploiting correlations from angular space and across neighboring samples. We develop a hybrid recurrent-convolutional encoder to learn mobility patterns, which combines a truncation strategy and multi-scale convolutions in the recurrent neural network (RNN) to ensure feature robustness against short-term fluctuations. Unlike conventional Gaussian priors in latent space, we embed a learnable radio map to capture the location information by encoding high-level positional features from CSI measurements. Finally, a diffusion-based generative decoder reconstructs the full CSI with high fidelity by conditioning on the positional features in the radio map. Numerical experiments demonstrate that the proposed model can improve localization accuracy by over 30% and achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with model-based Kalman filter approaches.","authors":["Wangqian Chen","Junting Chen","Shuguang Cui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16983v1","updated":"2025-11-21T06:30:59Z","published":"2025-11-21T06:30:59Z","title":"Feature Partitioning and Semantic Equalization for Intrinsic Robustness in Semantic Communication under Packet Loss","summary":"Semantic communication can improve transmission efficiency by focusing on task-relevant information. However, under packet-based communication protocols, any error typically results in the loss of an entire packet, making semantic communication particularly vulnerable to packet loss. Since high-dimensional semantic features must be partitioned into one-dimensional transmission units during packetization. A critical open question is how to partition semantic features to maximize robustness. To address this, we systematically investigate the performance of two mainstream architectures, Transformer and Convolutional neural networks (CNN), under various feature partitioning schemes. The results show that the Transformer architecture exhibits inherent robustness to packet loss when partitioned along the channel dimension. In contrast, the CNN-based baseline exhibits imbalanced channel utilization, causing severe degradation once dominant channels are lost. To enhance the CNN resilience, we propose a lightweight Semantic Equalization Mechanism (SEM) that balances channel contributions and prevents a few channels from dominating. SEM consists of two parallel approaches: a Dynamic Scale module that adaptively adjusts channel importance, and a Broadcast module that facilitates information interaction among channels. Experimental results demonstrate that CNN equipped with SEM achieve graceful degradation under packet loss (retaining about 85% of lossless PSNR at 40% packet loss), comparable to that of Transformer models. Our findings indicate that, under an appropriate partitioning strategy, maintaining a balanced semantic representation is a fundamental condition for achieving intrinsic robustness against packet loss. These insights may also extend to other modalities such as video and support practical semantic communication design.","authors":["Xiao Yang","Shuai Ma","Yong Liang","Guangming Shi"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2511.16974v1","updated":"2025-11-21T06:06:36Z","published":"2025-11-21T06:06:36Z","title":"State-Derivative Feedback Control for Damping Low-Frequency Oscillations in Bulk Power Systems","summary":"Low-frequency oscillations remain a major challenge in bulk power systems with high renewable penetration, long lines, and large loads. Existing damping strategies based on power modulation of high voltage DC (HVDC) or energy storage, are often limited by fixed control architectures, leaving some modes poorly damped. This paper introduces a state-derivative feedback (SDF) damping controller that uses both frequency and its rate of change as feedback signals. Incorporating state derivatives enhances modal damping and accelerates frequency recovery, enabling HVDC and energy storage to effectively stabilize the grid. We evaluate the SDF controller on two- and three-area systems and compare performance with a frequency difference-based damping scheme. Results show that the SDF control reproduces state-feedback performance while providing good damping of both inter- and intra-area oscillations compared to the frequency-difference method, highlighting its potential as a practical solution for stabilizing power-electronics-rich grids.","authors":["MST Rumi Akter","Anamitra Pal","Rajasekhar Anguluri"],"pdf_url":"","comment":"5 pages, 6 figures, 1 table, Submitted to IEEE PES General Meeting 2026"},{"id":"http://arxiv.org/abs/2508.18694v2","updated":"2025-11-21T04:30:13Z","published":"2025-08-26T05:39:47Z","title":"AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot","summary":"Advances in AI and Robotics have accelerated significant initiatives in agriculture, particularly in the areas of robot navigation and 3D digital twin creation. A significant bottleneck impeding this progress is the critical lack of \"in-the-wild\" datasets that capture the full complexities of real farmland, including non-rigid motion from wind, drastic illumination variance, and morphological changes resulting from growth. This data gap fundamentally limits research on robust AI models for autonomous field navigation and scene-level dynamic 3D reconstruction. In this paper, we present AgriChrono, a modular robotic data collection platform and multi-modal dataset designed to capture these dynamic farmland conditions. Our platform integrates multiple sensors, enabling remote, time-synchronized acquisition of RGB, Depth, LiDAR, IMU, and Pose data for efficient and repeatable long-term data collection in real-world agricultural environments. We successfully collected 18TB of data over one month, documenting the entire growth cycle of Canola under diverse illumination conditions. We benchmark state-of-the-art 3D reconstruction methods on AgriChrono, revealing the profound challenge of reconstructing high-fidelity, dynamic non-rigid scenes in such farmland settings. This benchmark validates AgriChrono as a critical asset for advancing model generalization, and its public release is expected to significantly accelerate research and development in precision agriculture. The code and dataset are publicly available at: https://github.com/StructuresComp/agri-chrono","authors":["Jaehwan Jeong","Tuan-Anh Vu","Mohammad Jony","Shahab Ahmad","Md. Mukhlesur Rahman","Sangpil Kim","M. Khalid Jawed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.11381v2","updated":"2025-11-21T03:02:50Z","published":"2025-08-15T10:28:37Z","title":"System Synchronization Based on Complex Frequency","summary":"The increasing penetration of renewable energy leads to a continuous reduction in system inertia, for which conventional synchronization criteria based solely on frequency consistency can no longer accurately capture the coupled dynamics of frequency and voltage during transients. To address this issue, this paper employs the concept of complex frequency and develops an analysis framework that integrates theory, indices, and simulation for assessing synchronization stability in low-inertia power systems. First, the basic concepts and mathematical formulation of complex frequency and complex-frequency synchronization are introduced. Then, dynamic criteria for local and global complex synchronization are established, upon which a complex inertia index is proposed. This index unifies the supporting role of traditional frequency inertia and the voltage support capability associated with voltage inertia, enabling quantitative evaluation of the strength of coordinated frequency-voltage support and disturbance rejection within a region. Finally, transient simulations on a modified IEEE 9-bus system are carried out to validate the proposed method. The results show that the method can clearly reveal the synchronization relationships between subnetworks and the overall system, providing a useful theoretical reference for stability analysis and control strategy design in low-inertia power systems.","authors":["Yusen Wei","Lan Tang","Peidong Li"],"pdf_url":"","comment":"13 pages,11 figures"},{"id":"http://arxiv.org/abs/2510.27187v2","updated":"2025-11-21T02:35:40Z","published":"2025-10-31T05:16:42Z","title":"Solving Infinite-Horizon Optimal Control Problems using the Extreme Theory of Functional Connections","summary":"This paper presents a physics-informed machine learning approach for synthesizing optimal feedback control policy for infinite-horizon optimal control problems by solving the Hamilton-Jacobi-Bellman (HJB) partial differential equation(PDE). The optimal control policy is derived analytically for affine dynamical systems with separable and strictly convex control costs, expressed as a function of the gradient of the value function. The resulting HJB-PDE is then solved by approximating the value function using the Extreme Theory of Functional Connections (X-TFC) - a hybrid approach that combines the Theory of Functional Connections (TFC) with the Extreme Learning Machine (ELM) algorithm. This approach ensures analytical satisfaction of boundary conditions and significantly reduces training cost compared to traditional Physics-Informed Neural Networks (PINNs). We benchmark the method on linear and non-linear systems with known analytical solutions as well as demonstrate its effectiveness on control tasks such as spacecraft optimal de-tumbling control.","authors":["Tanay Raghunandan Srinivasa","Suraj Kumar"],"pdf_url":"","comment":"Accepted to Indian Control Conference (ICC-11), 6 pages, 12 figures"},{"id":"http://arxiv.org/abs/2511.16900v1","updated":"2025-11-21T02:29:09Z","published":"2025-11-21T02:29:09Z","title":"When Motion Learns to Listen: Diffusion-Prior Lyapunov Actor-Critic Framework with LLM Guidance for Stable and Robust AUV Control in Underwater Tasks","summary":"Autonomous Underwater Vehicles (AUVs) are indispensable for marine exploration; yet, their control is hindered by nonlinear hydrodynamics, time-varying disturbances, and localization uncertainty. Traditional controllers provide only limited adaptability, while Reinforcement Learning (RL), though promising, suffers from sample inefficiency, weak long-term planning, and lacks stability guarantees, leading to unreliable behavior. To address these challenges, we propose a diffusion-prior Lyapunov actor-critic framework that unifies exploration, stability, and semantic adaptability. Specifically, a diffusion model generates smooth, multimodal, and disturbance-resilient candidate actions; a Lyapunov critic further imposes dual constraints that ensure stability; and a Large Language Model (LLM)-driven outer loop adaptively selects and refines Lyapunov functions based on task semantics and training feedback. This \"generation-filtering-optimization\" mechanism not only enhances sample efficiency and planning capability but also aligns stability guarantees with diverse mission requirements in the multi-objective optimization task. Extensive simulations under complex ocean dynamics demonstrate that the proposed framework achieves more accurate trajectory tracking, higher task completion rates, improved energy efficiency, faster convergence, and improved robustness compared with conventional RL and diffusion-augmented baselines.","authors":["Jingzehua Xu","Weiyi Liu","Weihang Zhang","Zhuofan Xi","Guanwen Xie","Shuai Zhang","Yi Li"],"pdf_url":"","comment":"This paper is currently under review and does not represent the final version. Jingzehua Xu, Weiyi Liu and Weihang Zhang are co-first authors of this paper, with Zhuofan Xi as the second author"},{"id":"http://arxiv.org/abs/2511.16898v1","updated":"2025-11-21T02:24:24Z","published":"2025-11-21T02:24:24Z","title":"Single-Pixel Tactile Skin via Compressive Sampling","summary":"Development of large-area, high-speed electronic skins is a grand challenge for robotics, prosthetics, and human-machine interfaces, but is fundamentally limited by wiring complexity and data bottlenecks. Here, we introduce Single-Pixel Tactile Skin (SPTS), a paradigm that uses compressive sampling to reconstruct rich tactile information from an entire sensor array via a single output channel. This is achieved through a direct circuit-level implementation where each sensing element, equipped with a miniature microcontroller, contributes a dynamically weighted analog signal to a global sum, performing distributed compressed sensing in hardware. Our flexible, daisy-chainable design simplifies wiring to a few input lines and one output, and significantly reduces measurement requirements compared to raster scanning methods. We demonstrate the system's performance by achieving object classification at an effective 3500 FPS and by capturing transient dynamics, resolving an 8 ms projectile impact into 23 frames. A key feature is the support for adaptive reconstruction, where sensing fidelity scales with measurement time. This allows for rapid contact localization using as little as 7% of total data, followed by progressive refinement to a high-fidelity image - a capability critical for responsive robotic systems. This work offers an efficient pathway towards large-scale tactile intelligence for robotics and human-machine interfaces.","authors":["Ariel Slepyan","Laura Xing","Rudy Zhang","Nitish Thakor"],"pdf_url":"","comment":"24 pages, 6 main figures, 6 supplemental figures"},{"id":"http://arxiv.org/abs/2505.05592v3","updated":"2025-11-21T23:01:58Z","published":"2025-05-08T18:43:39Z","title":"Learning to Drive Anywhere with Model-Based Reannotation","summary":"Developing broadly generalizable visual navigation policies for robots is a significant challenge, primarily constrained by the availability of large-scale, diverse training data. While curated datasets collected by researchers offer high quality, their limited size restricts policy generalization. To overcome this, we explore leveraging abundant, passively collected data sources, including large volumes of crowd-sourced teleoperation data and unlabeled YouTube videos, despite their potential for lower quality or missing action labels. We propose Model-Based ReAnnotation (MBRA), a framework that utilizes a learned short-horizon, model-based expert model to relabel or generate high-quality actions for these passive datasets. This relabeled data is then distilled into LogoNav, a long-horizon navigation policy conditioned on visual goals or GPS waypoints. We demonstrate that LogoNav, trained using MBRA-processed data, achieves state-of-the-art performance, enabling robust navigation over distances exceeding 300 meters in previously unseen indoor and outdoor environments. Our extensive real-world evaluations, conducted across a fleet of robots (including quadrupeds) in six cities on three continents, validate the policy's ability to generalize and navigate effectively even amidst pedestrians in crowded settings.","authors":["Noriaki Hirose","Lydia Ignatova","Kyle Stachowicz","Catherine Glossop","Sergey Levine","Dhruv Shah"],"pdf_url":"","comment":"9 pages, 8 figures, 6 tables"},{"id":"http://arxiv.org/abs/2405.03245v2","updated":"2025-11-21T21:55:16Z","published":"2024-05-06T07:53:40Z","title":"How improving performance may imply losing consistency in event-triggered consensus","summary":"Event-triggered control is often argued to lower the average triggering rate compared to time-triggered control while still achieving a desired control goal, e.g., the same performance level. However, this property, often called consistency, cannot be taken for granted and can be hard to analyze in many settings. In particular, the performance properties of decentralized event-triggered control schemes with respect to time-triggered control remain mostly unexplored. Therefore, in this paper, we examine these performance properties for a consensus problem considering single-integrator agent dynamics, a level-triggering rule, and a complete communication graph. We consider the long-term average quadratic deviation from consensus as a performance measure. For this setting, we show that enriching the information the local controllers use improves the performance of the consensus algorithm but renders a previously consistent event-triggered control scheme inconsistent. In addition, we do so while deploying optimal control inputs which we derive for both information cases and triggering schemes. With this insight, we can furthermore explain the relationship between two seemingly contrasting consistency results from the literature.","authors":["David Meister","Duarte J. Antunes","Frank Allgöwer"],"pdf_url":"","comment":"Accepted for publication in Automatica"},{"id":"http://arxiv.org/abs/2509.05935v2","updated":"2025-11-21T20:43:11Z","published":"2025-09-07T05:51:49Z","title":"Certifying the Nonexistence of Feasible Path Between Power System Operating Points","summary":"By providing the optimal operating point that satisfies both the power flow equations and engineering limits, the optimal power flow (OPF) problem is central to power systems operations. While extensive research has focused on computing high-quality OPF solutions, assessing the feasibility of transitioning between operating points remains challenging since the feasible spaces of OPF problems may consist of multiple disconnected components. It is not possible to transition between operating points in different disconnected components without violating OPF constraints. To identify such situations, this paper introduces an algorithm for certifying the infeasibility of transitioning between two operating points within an OPF feasible space. As an indication of potential disconnectedness, the algorithm first seeks an infeasible point on the line connecting a pair of feasible points. The algorithm then certifies disconnectedness by using convex relaxation and bound tightening techniques to show that all points on the plane that is normal to this line are infeasible. Using this algorithm, we provide the first certifications of disconnected feasible spaces for a variety of OPF test cases.","authors":["Mohammad Rasoul Narimani","Katherine R. Davis","Daniel K. Molzahn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.22867v2","updated":"2025-11-21T20:04:58Z","published":"2025-03-28T20:49:47Z","title":"Markov Potential Game Construction and Multi-Agent Reinforcement Learning with Applications to Autonomous Driving","summary":"Markov games (MGs) provide a mathematical foundation for multi-agent reinforcement learning (MARL), enabling self-interested agents to learn their optimal policies while interacting with others in a shared environment. However, due to the complexities of an MG problem, seeking (Markov perfect) Nash equilibrium (NE) is often very challenging for a general-sum MG. Markov potential games (MPGs), which are a special class of MGs, have appealing properties such as guaranteed existence of pure NEs and guaranteed convergence of gradient play algorithms, thereby leading to desirable properties for many MARL algorithms in their NE-seeking processes. However, the question of how to construct MPGs has remained open. This paper provides sufficient conditions on the reward design and on the Markov decision process (MDP), under which an MG is an MPG. Numerical results on autonomous driving applications are reported.","authors":["Huiwen Yan","Mushuang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17743v1","updated":"2025-11-21T19:51:06Z","published":"2025-11-21T19:51:06Z","title":"AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions","summary":"This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.","authors":["Haytham Younus","Sohag Kabir","Felician Campean","Pascal Bonnaud","David Delaux"],"pdf_url":"","comment":"This manuscript is based on research undertaken by our doctoral student at the University of Bradford. The associated PhD thesis has been formally submitted to the University and is currently awaiting final examination. The review article is being shared on arXiv to make the review accessible to the research community while the thesis examination process is ongoing"},{"id":"http://arxiv.org/abs/2511.17730v1","updated":"2025-11-21T19:29:19Z","published":"2025-11-21T19:29:19Z","title":"Safety and Risk Pathways in Cooperative Generative Multi-Agent Systems: A Telecom Perspective","summary":"Generative multiagent systems are rapidly emerging as transformative tools for scalable automation and adaptive decisionmaking in telecommunications. Despite their promise, these systems introduce novel risks that remain underexplored, particularly when agents operate asynchronously across layered architectures. This paper investigates key safety pathways in telecomfocused Generative MultiAgent Systems (GMAS), emphasizing risks of miscoordination and semantic drift shaped by persona diversity. We propose a modular safety evaluation framework that integrates agentlevel checks on code quality and compliance with systemlevel safety metrics. Using controlled simulations across 32 persona sets, five questions, and multiple iterative runs, we demonstrate progressive improvements in analyzer penalties and AllocatorCoder consistency, alongside persistent vulnerabilities such as policy drift and variability under specific persona combinations. Our findings provide the first domaingrounded evidence that persona design, coding style, and planning orientation directly influence the stability and safety of telecom GMAS, highlighting both promising mitigation strategies and open risks for future deployment.","authors":["Zeinab Nezami","Shehr Bano","Abdelaziz Salama","Maryam Hafeez","Syed Ali Raza Zaidi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17715v1","updated":"2025-11-21T19:11:27Z","published":"2025-11-21T19:11:27Z","title":"Risk-Based Capacity Accreditation of Resource-Colocated Large Loads in Capacity Markets","summary":"We study capacity accreditation of resource-colocated large loads, defined as large demands such as data center and manufacturing loads colocated with behind-the-meter generation and storage resources, synchronously connected to the bulk power system, and capable of participating in the wholesale electricity market as an integrated unit. Because the qualified capacity of a resource portfolio is not equal to the sum of its individual resources' qualified capacities, we propose a novel risk-based capacity accreditation framework that evaluates the collective contribution to system reliability. Grounded in the effective load carrying capability (ELCC) metric, the proposed capacity accreditation employs a convex optimization engine that jointly dispatches colocated resources to minimize reliability risk. We apply the developed methodology to a hydrogen manufacturing facility with colocated renewable generation, storage, and fuel cell resources.","authors":["Siying Li","Lang Tong","Timothy D. Mount"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19460v1","updated":"2025-11-21T14:51:23Z","published":"2025-11-21T14:51:23Z","title":"Systemic approach for modeling a generic smart grid","summary":"Smart grid technological advances present a recent class of complex interdisciplinary modeling and increasingly difficult simulation problems to solve using traditional computational methods. To simulate a smart grid requires a systemic approach to integrated modeling of power systems, energy markets, demand-side management, and much other resources and assets that are becoming part of the current paradigm of the power grid. This paper presents a backbone model of a smart grid to test alternative scenarios for the grid. This tool simulates disparate systems to validate assumptions before the human scale model. Thanks to a distributed optimization of subsystems, the production and consumption scheduling is achieved while maintaining flexibility and scalability.","authors":["Sofiane Ben Amor","Guillaume Guerard","Loup-Noé Levy"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2511.17489v1","updated":"2025-11-21T18:45:53Z","published":"2025-11-21T18:45:53Z","title":"Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization","summary":"It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.","authors":["Vinay Kanakeri","Shivam Bajaj","Ashwin Verma","Vijay Gupta","Aritra Mitra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.05708v2","updated":"2025-11-21T18:40:21Z","published":"2025-02-08T22:03:08Z","title":"Generalizable Radio-Frequency Radiance Fields for Spatial Spectrum Synthesis","summary":"We present GRaF, Generalizable Radio-Frequency (RF) Radiance Fields, a framework that models RF signal propagation to synthesize spatial spectra at arbitrary transmitter or receiver locations, where each spectrum measures signal power across all surrounding directions at the receiver. Unlike state-of-the-art methods that adapt vanilla Neural Radiance Fields (NeRF) to the RF domain with scene-specific training, GRaF generalizes across scenes to synthesize spectra. To enable this, we prove an interpolation theory in the RF domain: the spatial spectrum from a transmitter can be approximated using spectra from geographically proximate transmitters. Building on this theory, GRaF comprises two components: (i) a geometry-aware Transformer encoder that captures spatial correlations from neighboring transmitters to learn a scene-independent latent RF radiance field, and (ii) a neural ray tracing algorithm that estimates spectrum reception at the receiver. Experimental results demonstrate that GRaF outperforms existing methods on single-scene benchmarks and achieves state-of-the-art performance on unseen scene layouts.","authors":["Kang Yang","Yuning Chen","Wan Du"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11381v2","updated":"2025-11-21T18:34:04Z","published":"2025-11-14T15:04:22Z","title":"SoK: Security Evaluation of Wi-Fi CSI Biometrics: Attacks, Metrics, and Open Challenges","summary":"Wi-Fi Channel State Information (CSI) has been repeatedly proposed as a biometric modality, often with reports of high accuracy and operational feasibility. However, the field lacks a consolidated understanding of its security properties, adversarial resilience, and methodological consistency. This Systematization of Knowledge (SoK) examines CSI-based biometric authentication through a security lens, analyzing how existing works diverge in sensing infrastructure, signal representations, feature pipelines, learning models, and evaluation methodologies. Our synthesis reveals systemic inconsistencies: reliance on aggregate accuracy metrics, limited reporting of FAR/FRR/EER, absence of per-user risk analysis, and scarce consideration of threat models or adversarial feasibility.\n  To this end, we construct a unified evaluation framework to expose these issues empirically and demonstrate how security-relevant metrics such as per-class EER, Frequency Count of Scores (FCS), and the Gini Coefficient uncover risk concentration that remains hidden under traditional reporting practices. The resulting analysis highlights concrete attack surfaces--including replay, geometric mimicry, and environmental perturbation--and shows how methodological choices materially influence vulnerability profiles. Based on these findings, we articulate the security boundaries of current CSI biometrics and provide guidelines for rigorous evaluation, reproducible experimentation, and future research directions. This SoK offers the security community a structured, evidence-driven reassessment of Wi-Fi CSI biometrics and their suitability as an authentication primitive.","authors":["Gioliano de Oliveira Braga","Pedro Henrique dos Santos Rocha","Rafael Pimenta de Mattos Paixão","Giovani Hoff da Costa","Gustavo Cavalcanti Morais","Lourenço Alves Pereira Júnior"],"pdf_url":"","comment":"This work was submitted to the 11th IEEE European Symposium on Security and Privacy (IEEE S&P 2026)"},{"id":"http://arxiv.org/abs/2511.17475v1","updated":"2025-11-21T18:24:52Z","published":"2025-11-21T18:24:52Z","title":"Addressing A Posteriori Performance Degradation in Neural Network Subgrid Stress Models","summary":"Neural network subgrid stress models often have a priori performance that is far better than the a posteriori performance, leading to neural network models that look very promising a priori completely failing in a posteriori Large Eddy Simulations (LES). This performance gap can be decreased by combining two different methods, training data augmentation and reducing input complexity to the neural network. Augmenting the training data with two different filters before training the neural networks has no performance degradation a priori as compared to a neural network trained with one filter. A posteriori, neural networks trained with two different filters are far more robust across two different LES codes with different numerical schemes. In addition, by ablating away the higher order terms input into the neural network, the a priori versus a posteriori performance changes become less apparent. When combined, neural networks that use both training data augmentation and a less complex set of inputs have a posteriori performance far more reflective of their a priori evaluation.","authors":["Andy Wu","Sanjiva K. Lele"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.12870v5","updated":"2025-11-21T18:24:08Z","published":"2024-12-17T12:51:24Z","title":"Physically Interpretable World Models via Weakly Supervised Representation Learning","summary":"Learning predictive models from high-dimensional sensory observations is fundamental for cyber-physical systems, yet the latent representations learned by standard world models lack physical interpretability. This limits their reliability, generalizability, and applicability to safety-critical tasks. We introduce Physically Interpretable World Models (PIWM), a framework that aligns latent representations with real-world physical quantities and constrains their evolution through partially known physical dynamics. Physical interpretability in PIWM is defined by two complementary properties: (i) the learned latent state corresponds to meaningful physical variables, and (ii) its temporal evolution follows physically consistent dynamics. To achieve this without requiring ground-truth physical annotations, PIWM employs weak distribution-based supervision that captures state uncertainty naturally arising from real-world sensing pipelines. The architecture integrates a VQ-based visual encoder, a transformer-based physical encoder, and a learnable dynamics model grounded in known physical equations. Across three case studies (Cart Pole, Lunar Lander, and Donkey Car), PIWM achieves accurate long-horizon prediction, recovers true system parameters, and significantly improves physical grounding over purely data-driven models. These results demonstrate the feasibility and advantages of learning physically interpretable world models directly from images under weak supervision.","authors":["Zhenjiang Mao","Mrinall Eashaan Umasudhan","Ivan Ruchkin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17473v1","updated":"2025-11-21T18:23:04Z","published":"2025-11-21T18:23:04Z","title":"Masked-and-Reordered Self-Supervision for Reinforcement Learning from Verifiable Rewards","summary":"Test-time scaling has been shown to substantially improve large language models' (LLMs) mathematical reasoning. However, for a large portion of mathematical corpora, especially theorem proving, RLVR's scalability is limited: intermediate reasoning is crucial, while final answers are difficult to directly and reliably verify. Meanwhile, token-level SFT often degenerates into rote memorization rather than inducing longer chains of thought. Inspired by BERT's self-supervised tasks, we propose MR-RLVR (Masked-and-Reordered RLVR), which constructs process-level self-supervised rewards via \"masked-then-fill\" and \"step reordering\" to extract learnable signals from intermediate reasoning. Our training pipeline comprises two stages: we first perform self-supervised training on sampled mathematical calculation and proof data; we then conduct RLVR fine-tuning on mathematical calculation datasets where only outcomes are verifiable. We implement MR-RLVR on Qwen2.5-3B and DeepSeek-R1-Distill-Qwen-1.5B, and evaluate on AIME24, AIME25, AMC23, and MATH500. Under a fixed sampling and decoding budget, MR-RLVR achieves average relative gains over the original RLVR of +9.86% Pass@1, +5.27% Pass@5, and +4.00% Pass@8. These results indicate that incorporating process-aware self-supervised signals can effectively enhance RLVR's scalability and performance in only outcome-verifiable settings.","authors":["Zhen Wang","Zhifeng Gao","Guolin Ke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.17995v2","updated":"2025-11-21T18:16:26Z","published":"2025-08-25T13:04:21Z","title":"Topology Aware Neural Interpolation of Scalar Fields","summary":"This paper presents a neural scheme for the topology-aware interpolation of time-varying scalar fields. Given a time-varying sequence of persistence diagrams, along with a sparse temporal sampling of the corresponding scalar fields, denoted as keyframes, our interpolation approach aims at \"inverting\" the non-keyframe diagrams to produce plausible estimations of the corresponding, missing data. For this, we rely on a neural architecture which learns the relation from a time value to the corresponding scalar field, based on the keyframe examples, and reliably extends this relation to the non-keyframe time steps. We show how augmenting this architecture with specific topological losses exploiting the input diagrams both improves the geometrical and topological reconstruction of the non-keyframe time steps. At query time, given an input time value for which an interpolation is desired, our approach instantaneously produces an output, via a single propagation of the time input through the network. Experiments interpolating 2D and 3D time-varying datasets show our approach superiority, both in terms of data and topological fitting, with regard to reference interpolation schemes. Our implementation is available at this GitHub link : https://github.com/MohamedKISSI/Topology-Aware-Neural-Interpolation-of-Scalar-Fields.git.","authors":["Mohamed Kissi","Keanu Sisouk","Joshua A. Levine","Julien Tierny"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17467v1","updated":"2025-11-21T18:15:47Z","published":"2025-11-21T18:15:47Z","title":"PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM","summary":"We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's \"persona\" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F","authors":["Siqi Liang","Yudi Zhang","Yue Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02558v2","updated":"2025-11-21T18:11:50Z","published":"2025-11-04T13:19:58Z","title":"Forecasting Future Anatomies: Longitudinal Brain Mri-to-Mri Prediction","summary":"Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.","authors":["Ali Farki","Elaheh Moradi","Deepika Koundal","Jussi Tohka"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17446v1","updated":"2025-11-21T17:45:00Z","published":"2025-11-21T17:45:00Z","title":"Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry","summary":"Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a cornerstone in biomolecular analysis, offering precise identification of pathogens through unique mass spectral signatures. Yet, its reliance on labor-intensive sample preparation and multi-shot spectral averaging restricts its use to laboratory settings, rendering it impractical for real-time environmental monitoring. These limitations are especially pronounced in emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy spectra for unknown aerosol analytes, requiring single-shot detection for effective analysis. Addressing these challenges, we propose the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that redefines spectral analysis by directly processing raw, minimally prepared mass spectral data. MS-DGFormer leverages a transformer architecture, designed to capture the long-range dependencies inherent in these time-series spectra. To enhance feature extraction, we introduce a novel dictionary encoder that integrates denoised spectral information derived from Singular Value Decomposition (SVD), enabling the model to discern critical biomolecular patterns from single-shot spectra with robust performance. This innovation provides a system to achieve superior pathogen identification from aerosol samples, facilitating autonomous, real-time analysis in field conditions. By eliminating the need for extensive preprocessing, our method unlocks the potential for portable, deployable MALDI-MS platforms, revolutionizing environmental pathogen detection and rapid response to biological threats.","authors":["Kyle M. Regan","Michael McLoughlin","Wayne A. Bryden","Gonzalo R. Arce"],"pdf_url":"","comment":"13 pages, 9 figures. Preprint. Submitted to Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2511.17439v1","updated":"2025-11-21T17:36:12Z","published":"2025-11-21T17:36:12Z","title":"InTAct: Interval-based Task Activation Consolidation for Continual Learning","summary":"Continual learning aims to enable neural networks to acquire new knowledge without forgetting previously learned information. While recent prompt-based methods perform strongly in class-incremental settings, they remain vulnerable under domain shifts, where the input distribution changes but the label space remains fixed. This exposes a persistent problem known as representation drift. Shared representations evolve in ways that overwrite previously useful features and cause forgetting even when prompts isolate task-specific parameters. To address this issue, we introduce InTAct, a method that preserves functional behavior in shared layers without freezing parameters or storing past data. InTAct captures the characteristic activation ranges associated with previously learned tasks and constrains updates to ensure the network remains consistent within these regions, while still allowing for flexible adaptation elsewhere. In doing so, InTAct stabilizes the functional role of important neurons rather than directly restricting parameter values. The approach is architecture-agnostic and integrates seamlessly into existing prompt-based continual learning frameworks. By regulating representation changes where past knowledge is encoded, InTAct achieves a principled balance between stability and plasticity. Across diverse domain-incremental benchmarks, including DomainNet and ImageNet-R, InTAct consistently reduces representation drift and improves performance, increasing Average Accuracy by up to 8 percentage points over state-of-the-art baselines.","authors":["Patryk Krukowski","Jan Miksa","Piotr Helm","Jacek Tabor","Paweł Wawrzyński","Przemysław Spurek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17436v1","updated":"2025-11-21T17:33:00Z","published":"2025-11-21T17:33:00Z","title":"A Framework for Adaptive Stabilisation of Nonlinear Stochastic Systems","summary":"We consider the adaptive control problem for discrete-time, nonlinear stochastic systems with linearly parameterised uncertainty. Assuming access to a parameterised family of controllers that can stabilise the system in a bounded set within an informative region of the state space when the parameter is well-chosen, we propose a certainty equivalence learning-based adaptive control strategy, and subsequently derive stability bounds on the closed-loop system that hold for some probabilities. We then show that if the entire state space is informative, and the family of controllers is globally stabilising with appropriately chosen parameters, high probability stability guarantees can be derived.","authors":["Seth Siriya","Jingge Zhu","Dragan Nešić","Ye Pu"],"pdf_url":"","comment":"22 pages, 1 figure"},{"id":"http://arxiv.org/abs/2511.17435v1","updated":"2025-11-21T17:32:10Z","published":"2025-11-21T17:32:10Z","title":"Multi-Agent Pointer Transformer: Seq-to-Seq Reinforcement Learning for Multi-Vehicle Dynamic Pickup-Delivery Problems","summary":"This paper addresses the cooperative Multi-Vehicle Dynamic Pickup and Delivery Problem with Stochastic Requests (MVDPDPSR) and proposes an end-to-end centralized decision-making framework based on sequence-to-sequence, named Multi-Agent Pointer Transformer (MAPT). MVDPDPSR is an extension of the vehicle routing problem and a spatio-temporal system optimization problem, widely applied in scenarios such as on-demand delivery. Classical operations research methods face bottlenecks in computational complexity and time efficiency when handling large-scale dynamic problems. Although existing reinforcement learning methods have achieved some progress, they still encounter several challenges: 1) Independent decoding across multiple vehicles fails to model joint action distributions; 2) The feature extraction network struggles to capture inter-entity relationships; 3) The joint action space is exponentially large. To address these issues, we designed the MAPT framework, which employs a Transformer Encoder to extract entity representations, combines a Transformer Decoder with a Pointer Network to generate joint action sequences in an AutoRegressive manner, and introduces a Relation-Aware Attention module to capture inter-entity relationships. Additionally, we guide the model's decision-making using informative priors to facilitate effective exploration. Experiments on 8 datasets demonstrate that MAPT significantly outperforms existing baseline methods in terms of performance and exhibits substantial computational time advantages compared to classical operations research methods.","authors":["Zengyu Zou","Jingyuan Wang","Yixuan Huang","Junjie Wu"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2511.17427v1","updated":"2025-11-21T17:24:00Z","published":"2025-11-21T17:24:00Z","title":"Towards fully differentiable neural ocean model with Veros","summary":"We present a differentiable extension of the VEROS ocean model, enabling automatic differentiation through its dynamical core. We describe the key modifications required to make the model fully compatible with JAX autodifferentiation framework and evaluate the numerical consistency of the resulting implementation. Two illustrative applications are then demonstrated: (i) the correction of an initial ocean state through gradient-based optimization, and (ii) the calibration of unknown physical parameters directly from model observations. These examples highlight how differentiable programming can facilitate end-to-end learning and parameter tuning in ocean modeling. Our implementation is available online.","authors":["Etienne Meunier","Said Ouala","Hugo Frezat","Julien Le Sommer","Ronan Fablet"],"pdf_url":"","comment":"Accepted to Differentiable Systems and Scientific Machine Learning (workshop, EurIPS 2025)"},{"id":"http://arxiv.org/abs/2511.13646v2","updated":"2025-11-21T17:22:32Z","published":"2025-11-17T17:58:18Z","title":"Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?","summary":"Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that LIVE-SWE-AGENT can achieve an impressive solve rate of 77.4% without test-time scaling, outperforming all existing software agents, including the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%.","authors":["Chunqiu Steven Xia","Zhe Wang","Yan Yang","Yuxiang Wei","Lingming Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17426v1","updated":"2025-11-21T17:22:31Z","published":"2025-11-21T17:22:31Z","title":"Self-Supervised Learning by Curvature Alignment","summary":"Self-supervised learning (SSL) has recently advanced through non-contrastive methods that couple an invariance term with variance, covariance, or redundancy-reduction penalties. While such objectives shape first- and second-order statistics of the representation, they largely ignore the local geometry of the underlying data manifold. In this paper, we introduce CurvSSL, a curvature-regularized self-supervised learning framework, and its RKHS extension, kernel CurvSSL. Our approach retains a standard two-view encoder-projector architecture with a Barlow Twins-style redundancy-reduction loss on projected features, but augments it with a curvature-based regularizer. Each embedding is treated as a vertex whose $k$ nearest neighbors define a discrete curvature score via cosine interactions on the unit hypersphere; in the kernel variant, curvature is computed from a normalized local Gram matrix in an RKHS. These scores are aligned and decorrelated across augmentations by a Barlow-style loss on a curvature-derived matrix, encouraging both view invariance and consistency of local manifold bending. Experiments on MNIST and CIFAR-10 datasets with a ResNet-18 backbone show that curvature-regularized SSL yields competitive or improved linear evaluation performance compared to Barlow Twins and VICReg. Our results indicate that explicitly shaping local geometry is a simple and effective complement to purely statistical SSL regularizers.","authors":["Benyamin Ghojogh","M. Hadi Sepanj","Paul Fieguth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17419v1","updated":"2025-11-21T17:17:51Z","published":"2025-11-21T17:17:51Z","title":"DS-Span: Single-Phase Discriminative Subgraph Mining for Efficient Graph Embeddings","summary":"Graph representation learning seeks to transform complex, high-dimensional graph structures into compact vector spaces that preserve both topology and semantics. Among the various strategies, subgraph-based methods provide an interpretable bridge between symbolic pattern discovery and continuous embedding learning. Yet, existing frequent or discriminative subgraph mining approaches often suffer from redundant multi-phase pipelines, high computational cost, and weak coupling between mined structures and their discriminative relevance. We propose DS-Span, a single-phase discriminative subgraph mining framework that unifies pattern growth, pruning, and supervision-driven scoring within one traversal of the search space. DS-Span introduces a coverage-capped eligibility mechanism that dynamically limits exploration once a graph is sufficiently represented, and an information-gain-guided selection that promotes subgraphs with strong class-separating ability while minimizing redundancy. The resulting subgraph set serves as an efficient, interpretable basis for downstream graph embedding and classification. Extensive experiments across benchmarks demonstrate that DS-Span generates more compact and discriminative subgraph features than prior multi-stage methods, achieving higher or comparable accuracy with significantly reduced runtime. These results highlight the potential of unified, single-phase discriminative mining as a foundation for scalable and interpretable graph representation learning.","authors":["Yeamin Kaiser","Muhammed Tasnim Bin Anwar","Bholanath Das","Chowdhury Farhan Ahmed","Md. Tanvir Alam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17417v1","updated":"2025-11-21T17:16:24Z","published":"2025-11-21T17:16:24Z","title":"CREST: Improving Interpretability and Effectiveness of Troubleshooting at Ericsson through Criterion-Specific Trouble Report Retrieval","summary":"The rapid evolution of the telecommunication industry necessitates efficient troubleshooting processes to maintain network reliability, software maintainability, and service quality. Trouble Reports (TRs), which document issues in Ericsson's production system, play a critical role in facilitating the timely resolution of software faults. However, the complexity and volume of TR data, along with the presence of diverse criteria that reflect different aspects of each fault, present challenges for retrieval systems. Building on prior work at Ericsson, which utilized a two-stage workflow, comprising Initial Retrieval (IR) and Re-Ranking (RR) stages, this study investigates different TR observation criteria and their impact on the performance of retrieval models. We propose \\textbf{CREST} (\\textbf{C}riteria-specific \\textbf{R}etrieval via \\textbf{E}nsemble of \\textbf{S}pecialized \\textbf{T}R models), a criterion-driven retrieval approach that leverages specialized models for different TR fields to improve both effectiveness and interpretability, thereby enabling quicker fault resolution and supporting software maintenance. CREST utilizes specialized models trained on specific TR criteria and aggregates their outputs to capture diverse and complementary signals. This approach leads to enhanced retrieval accuracy, better calibration of predicted scores, and improved interpretability by providing relevance scores for each criterion, helping users understand why specific TRs were retrieved. Using a subset of Ericsson's internal TRs, this research demonstrates that criterion-specific models significantly outperform a single model approach across key evaluation metrics. This highlights the importance of all targeted criteria used in this study for optimizing the performance of retrieval systems.","authors":["Soroush Javdan","Pragash Krishnamoorthy","Olga Baysal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17411v1","updated":"2025-11-21T17:09:43Z","published":"2025-11-21T17:09:43Z","title":"SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding","summary":"Robotic Foundation Models (RFMs) hold great promise as generalist, end-to-end systems for robot control. Yet their ability to generalize across new environments, tasks, and embodiments remains limited. We argue that a major bottleneck lies in their foundations: most RFMs are built by fine-tuning internet-pretrained Vision-Language Models (VLMs). However, these VLMs are trained on 2D image-language tasks and lack the 3D spatial reasoning inherently required for embodied control in the 3D world. Bridging this gap directly with large-scale robotic data is costly and difficult to scale. Instead, we propose to enrich easy-to-collect non-robotic image data with 3D annotations and enhance a pretrained VLM with 3D understanding capabilities. Following this strategy, we train SPEAR-VLM, a 3D-aware VLM that infers object coordinates in 3D space from a single 2D image. Building on SPEAR-VLM, we introduce our main contribution, $~\\textbf{SPEAR-1}$: a robotic foundation model that integrates grounded 3D perception with language-instructed embodied control. Trained on $\\sim$45M frames from 24 Open X-Embodiment datasets, SPEAR-1 outperforms or matches state-of-the-art models such as $π_0$-FAST and $π_{0.5}$, while it uses 20$\\times$ fewer robot demonstrations. This carefully-engineered training strategy unlocks new VLM capabilities and as a consequence boosts the reliability of embodied control beyond what is achievable with only robotic data. We make our model weights and 3D-annotated datasets publicly available.","authors":["Nikolay Nikolov","Giuliano Albanese","Sombit Dey","Aleksandar Yanev","Luc Van Gool","Jan-Nico Zaech","Danda Pani Paudel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17408v1","updated":"2025-11-21T17:08:48Z","published":"2025-11-21T17:08:48Z","title":"That's not natural: The Impact of Off-Policy Training Data on Probe Performance","summary":"Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.","authors":["Nathalie Kirch","Samuel Dower","Adrians Skapars","Ekdeep Singh Lubana","Dmitrii Krasheninnikov"],"pdf_url":"","comment":"10 pages, EurIPS 2025 Workshop on Private AI Governance"},{"id":"http://arxiv.org/abs/2308.01853v3","updated":"2025-11-21T17:03:29Z","published":"2023-08-03T16:19:40Z","title":"Minimax Statistical Estimation under Wasserstein Contamination","summary":"Contaminations are a key concern in modern statistical learning, as small but systematic perturbations of all datapoints can substantially alter estimation results. Here, we study Wasserstein-$r$ contaminations ($r\\ge 1$) in an $\\ell_q$ norm ($q\\in [1,\\infty]$), in which each observation may undergo an adversarial perturbation with bounded cost, complementing the classical Huber model, corresponding to total variation norm, where only a fraction of observations is arbitrarily corrupted. We study both independent and joint (coordinated) contaminations and develop a minimax theory under $\\ell_q^r$ losses.\n  Our analysis encompasses several fundamental problems: location estimation, linear regression, and pointwise nonparametric density estimation. For joint contaminations in location estimation and for prediction in linear regression, we obtain the exact minimax risk, identify least favorable contaminations, and show that the sample mean and least squares predictor are respectively minimax optimal. For location estimation under independent contaminations, we give sharp upper and lower bounds, including exact minimaxity in the Euclidean Wasserstein contamination case, when $q=r=2$. For pointwise density estimation in any dimension, we derive the optimal rate, showing that it is achieved by kernel density estimation with a bandwidth that is possibly larger than the classical one.\n  Our proofs leverage powerful tools from optimal transport developed over the last 20 years, including the dynamic Benamou-Brenier formulation. Taken together, our results suggest that in contrast to the Huber contamination model, for norm-based Wasserstein contaminations, classical estimators may be nearly optimally robust.","authors":["Patrick Chao","Edgar Dobriban"],"pdf_url":"","comment":"A revision, including a changed title. This version extends the results to more general perturbations and loss functions, while also obtaining a new optimal rate for density estimation. Some of the techniques described in the original submission (ambiguity set minimax lower bounds, Bayes lower bounds) are not required anymore and have thus been removed"},{"id":"http://arxiv.org/abs/2511.17399v1","updated":"2025-11-21T17:00:00Z","published":"2025-11-21T17:00:00Z","title":"Stable Coresets via Posterior Sampling: Aligning Induced and Full Loss Landscapes","summary":"As deep learning models continue to scale, the growing computational demands have amplified the need for effective coreset selection techniques. Coreset selection aims to accelerate training by identifying small, representative subsets of data that approximate the performance of the full dataset. Among various approaches, gradient based methods stand out due to their strong theoretical underpinnings and practical benefits, particularly under limited data budgets. However, these methods face challenges such as naive stochastic gradient descent (SGD) acting as a surprisingly strong baseline and the breakdown of representativeness due to loss curvature mismatches over time.\n  In this work, we propose a novel framework that addresses these limitations. First, we establish a connection between posterior sampling and loss landscapes, enabling robust coreset selection even in high data corruption scenarios. Second, we introduce a smoothed loss function based on posterior sampling onto the model weights, enhancing stability and generalization while maintaining computational efficiency. We also present a novel convergence analysis for our sampling-based coreset selection method. Finally, through extensive experiments, we demonstrate how our approach achieves faster training and enhanced generalization across diverse datasets than the current state of the art.","authors":["Wei-Kai Chang","Rajiv Khanna"],"pdf_url":"","comment":"neurips 2025"},{"id":"http://arxiv.org/abs/2506.08255v3","updated":"2025-11-21T16:58:45Z","published":"2025-06-09T21:43:56Z","title":"SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense","summary":"Continual learning under adversarial conditions remains an open problem, as existing methods often compromise either robustness, scalability, or both. We propose a novel framework that integrates Interval Bound Propagation (IBP) with a hypernetwork-based architecture to enable certifiably robust continual learning across sequential tasks. Our method, SHIELD, generates task-specific model parameters via a shared hypernetwork conditioned solely on compact task embeddings, eliminating the need for replay buffers or full model copies and enabling efficient over time. To further enhance robustness, we introduce Interval MixUp, a novel training strategy that blends virtual examples represented as $\\ell_{\\infty}$ balls centered around MixUp points. Leveraging interval arithmetic, this technique guarantees certified robustness while mitigating the wrapping effect, resulting in smoother decision boundaries. We evaluate SHIELD under strong white-box adversarial attacks, including PGD and AutoAttack, across multiple benchmarks. It consistently outperforms existing robust continual learning methods, achieving state-of-the-art average accuracy while maintaining both scalability and certification. These results represent a significant step toward practical and theoretically grounded continual learning in adversarial settings.","authors":["Patryk Krukowski","Łukasz Gorczyca","Piotr Helm","Kamil Książek","Przemysław Spurek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02969v2","updated":"2025-11-21T16:56:52Z","published":"2025-11-04T20:22:58Z","title":"Value of Information-Enhanced Exploration in Bootstrapped DQN","summary":"Efficient exploration in deep reinforcement learning remains a fundamental challenge, especially in environments characterized by high-dimensional states and sparse rewards. Traditional exploration strategies that rely on random local policy noise, such as $ε$-greedy and Boltzmann exploration methods, often struggle to efficiently balance exploration and exploitation. In this paper, we integrate the notion of (expected) value of information (EVOI) within the well-known Bootstrapped DQN algorithmic framework, to enhance the algorithm's deep exploration ability. Specifically, we develop two novel algorithms that incorporate the expected gain from learning the value of information into Bootstrapped DQN. Our methods use value of information estimates to measure the discrepancies of opinions among distinct network heads, and drive exploration towards areas with the most potential. We evaluate our algorithms with respect to performance and their ability to exploit inherent uncertainty arising from random network initialization. Our experiments in complex, sparse-reward Atari games demonstrate increased performance, all the while making better use of uncertainty, and, importantly, without introducing extra hyperparameters.","authors":["Stergios Plataniotis","Charilaos Akasiadis","Georgios Chalkiadakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17388v1","updated":"2025-11-21T16:50:00Z","published":"2025-11-21T16:50:00Z","title":"Selective Rotary Position Embedding","summary":"Position information is essential for language modeling. In softmax transformers, Rotary Position Embeddings (\\textit{RoPE}) encode positions through \\textit{fixed-angle} rotations, while in linear transformers, order is handled via input-dependent (selective) gating that decays past key-value associations. Selectivity has generally been shown to improve language-related tasks. Inspired by this, we introduce \\textit{Selective RoPE}, an \\textit{input-dependent} rotary embedding mechanism, that generalizes \\textit{RoPE}, and enables rotation in \\textit{arbitrary angles} for both linear and softmax transformers. We show that softmax attention already performs a hidden form of these rotations on query-key pairs, uncovering an implicit positional structure. We further show that in state-space models and gated linear transformers, the real part manages forgetting while the imaginary part encodes positions through rotations. We validate our method by equipping gated transformers with \\textit{Selective RoPE}, demonstrating that its input-dependent rotations improve performance in language modeling and on difficult sequence tasks like copying, state tracking, and retrieval.","authors":["Sajad Movahedi","Timur Carstensen","Arshia Afzal","Frank Hutter","Antonio Orvieto","Volkan Cevher"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17380v1","updated":"2025-11-21T16:44:01Z","published":"2025-11-21T16:44:01Z","title":"Non-Parametric Probabilistic Robustness: A Conservative Metric with Optimized Perturbation Distributions","summary":"Deep learning (DL) models, despite their remarkable success, remain vulnerable to small input perturbations that can cause erroneous outputs, motivating the recent proposal of probabilistic robustness (PR) as a complementary alternative to adversarial robustness (AR). However, existing PR formulations assume a fixed and known perturbation distribution, an unrealistic expectation in practice. To address this limitation, we propose non-parametric probabilistic robustness (NPPR), a more practical PR metric that does not rely on any predefined perturbation distribution. Following the non-parametric paradigm in statistical modeling, NPPR learns an optimized perturbation distribution directly from data, enabling conservative PR evaluation under distributional uncertainty. We further develop an NPPR estimator based on a Gaussian Mixture Model (GMM) with Multilayer Perceptron (MLP) heads and bicubic up-sampling, covering various input-dependent and input-independent perturbation scenarios. Theoretical analyses establish the relationships among AR, PR, and NPPR. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet across ResNet18/50, WideResNet50 and VGG16 validate NPPR as a more practical robustness metric, showing up to 40\\% more conservative (lower) PR estimates compared to assuming those common perturbation distributions used in state-of-the-arts.","authors":["Zheng Wang","Yi Zhang","Siddartha Khastgir","Carsten Maple","Xingyu Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17378v1","updated":"2025-11-21T16:41:14Z","published":"2025-11-21T16:41:14Z","title":"A Unified Stability Analysis of SAM vs SGD: Role of Data Coherence and Emergence of Simplicity Bias","summary":"Understanding the dynamics of optimization in deep learning is increasingly important as models scale. While stochastic gradient descent (SGD) and its variants reliably find solutions that generalize well, the mechanisms driving this generalization remain unclear. Notably, these algorithms often prefer flatter or simpler minima, particularly in overparameterized settings. Prior work has linked flatness to generalization, and methods like Sharpness-Aware Minimization (SAM) explicitly encourage flatness, but a unified theory connecting data structure, optimization dynamics, and the nature of learned solutions is still lacking. In this work, we develop a linear stability framework that analyzes the behavior of SGD, random perturbations, and SAM, particularly in two layer ReLU networks. Central to our analysis is a coherence measure that quantifies how gradient curvature aligns across data points, revealing why certain minima are stable and favored during training.","authors":["Wei-Kai Chang","Rajiv Khanna"],"pdf_url":"","comment":"Neurips 2025"},{"id":"http://arxiv.org/abs/2511.17372v1","updated":"2025-11-21T16:37:18Z","published":"2025-11-21T16:37:18Z","title":"Quantum Masked Autoencoders for Vision Learning","summary":"Classical autoencoders are widely used to learn features of input data. To improve the feature learning, classical masked autoencoders extend classical autoencoders to learn the features of the original input sample in the presence of masked-out data. While quantum autoencoders exist, there is no design and implementation of quantum masked autoencoders that can leverage the benefits of quantum computing and quantum autoencoders. In this paper, we propose quantum masked autoencoders (QMAEs) that can effectively learn missing features of a data sample within quantum states instead of classical embeddings. We showcase that our QMAE architecture can learn the masked features of an image and can reconstruct the masked input image with improved visual fidelity in MNIST images. Experimental evaluation highlights that QMAE can significantly outperform (12.86% on average) in classification accuracy compared to state-of-the-art quantum autoencoders in the presence of masks.","authors":["Emma Andrews","Prabhat Mishra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17367v1","updated":"2025-11-21T16:34:00Z","published":"2025-11-21T16:34:00Z","title":"R2PS: Worst-Case Robust Real-Time Pursuit Strategies under Partial Observability","summary":"Computing worst-case robust strategies in pursuit-evasion games (PEGs) is time-consuming, especially when real-world factors like partial observability are considered. While important for general security purposes, real-time applicable pursuit strategies for graph-based PEGs are currently missing when the pursuers only have imperfect information about the evader's position. Although state-of-the-art reinforcement learning (RL) methods like Equilibrium Policy Generalization (EPG) and Grasper provide guidelines for learning graph neural network (GNN) policies robust to different game dynamics, they are restricted to the scenario of perfect information and do not take into account the possible case where the evader can predict the pursuers' actions. This paper introduces the first approach to worst-case robust real-time pursuit strategies (R2PS) under partial observability. We first prove that a traditional dynamic programming (DP) algorithm for solving Markov PEGs maintains optimality under the asynchronous moves by the evader. Then, we propose a belief preservation mechanism about the evader's possible positions, extending the DP pursuit strategies to a partially observable setting. Finally, we embed the belief preservation into the state-of-the-art EPG framework to finish our R2PS learning scheme, which leads to a real-time pursuer policy through cross-graph reinforcement learning against the asynchronous-move DP evasion strategies. After reinforcement learning, our policy achieves robust zero-shot generalization to unseen real-world graph structures and consistently outperforms the policy directly trained on the test graphs by the existing game RL approach.","authors":["Runyu Lu","Ruochuan Shi","Yuanheng Zhu","Dongbin Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.10998v3","updated":"2025-11-21T16:31:02Z","published":"2025-07-15T05:34:44Z","title":"Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data","summary":"Adversarial attacks on tabular data present unique challenges due to the heterogeneous nature of mixed categorical and numerical features. Unlike images where pixel perturbations maintain visual similarity, tabular data lacks intuitive similarity metrics, making it difficult to define imperceptible modifications. Additionally, traditional gradient-based methods prioritise $\\ell_p$-norm constraints, often producing adversarial examples that deviate from the original data distributions. To address this, we propose a latent-space perturbation framework using a mixed-input Variational Autoencoder (VAE) to generate statistically consistent adversarial examples. The proposed VAE integrates categorical embeddings and numerical features into a unified latent manifold, enabling perturbations that preserve statistical consistency. We introduce In-Distribution Success Rate (IDSR) to jointly evaluate attack effectiveness and distributional alignment. Evaluation across six publicly available datasets and three model architectures demonstrates that our method achieves substantially lower outlier rates and more consistent performance compared to traditional input-space attacks and other VAE-based methods adapted from image domain approaches, achieving substantially lower outlier rates and higher IDSR across six datasets and three model architectures. Our comprehensive analyses of hyperparameter sensitivity, sparsity control, and generative architecture demonstrate that the effectiveness of VAE-based attacks depends strongly on reconstruction quality and the availability of sufficient training data. When these conditions are met, the proposed framework achieves superior practical utility and stability compared with input-space methods. This work underscores the importance of maintaining on-manifold perturbations for generating realistic and robust adversarial examples in tabular domains.","authors":["Zhipeng He","Alexander Stevens","Chun Ouyang","Johannes De Smedt","Alistair Barros","Catarina Moreira"],"pdf_url":"","comment":"Final Version"},{"id":"http://arxiv.org/abs/2511.17351v1","updated":"2025-11-21T16:13:53Z","published":"2025-11-21T16:13:53Z","title":"Convergence and stability of Q-learning in Hierarchical Reinforcement Learning","summary":"Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.","authors":["Massimiliano Manenti","Andrea Iannelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17339v1","updated":"2025-11-21T16:00:13Z","published":"2025-11-21T16:00:13Z","title":"ReBaPL: Repulsive Bayesian Prompt Learning","summary":"Prompt learning has emerged as an effective technique for fine-tuning large-scale foundation models for downstream tasks. However, conventional prompt tuning methods are prone to overfitting and can struggle with out-of-distribution generalization. To address these limitations, Bayesian prompt learning has been proposed, which frames prompt optimization as a Bayesian inference problem to enhance robustness. This paper introduces Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for Bayesian prompt learning, designed to efficiently explore the complex and often multimodal posterior landscape of prompts. Our method integrates a cyclical step-size schedule with a stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm, enabling alternating phases of exploration to discover new modes, and exploitation to refine existing modes. Furthermore, we introduce a repulsive force derived from a potential function over probability metrics (including Maximum Mean Discrepancy and Wasserstein distance) computed on the distributions of representations produced by different prompts. This representation-space repulsion diversifies exploration and prevents premature collapse to a single mode. Our approach allows for a more comprehensive characterization of the prompt posterior distribution, leading to improved generalization. In contrast to prior Bayesian prompt learning methods, our method provides a modular plug-and-play Bayesian extension of any existing prompt learning method based on maximum likelihood estimation. We demonstrate the efficacy of ReBaPL on several benchmark datasets, showing superior performance over state-of-the-art methods for prompt learning.","authors":["Yassir Bendou","Omar Ezzahir","Eduardo Fernandes Montesuma","Gabriel Mahuas","Victoria Shevchenko","Mike Gartrell"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2505.11289v2","updated":"2025-11-21T15:53:08Z","published":"2025-05-16T14:24:03Z","title":"Meta-World+: An Improved, Standardized, RL Benchmark","summary":"Meta-World is widely used for evaluating multi-task and meta-reinforcement learning agents, which are challenged to master diverse skills simultaneously. Since its introduction however, there have been numerous undocumented changes which inhibit a fair comparison of algorithms. This work strives to disambiguate these results from the literature, while also leveraging the past versions of Meta-World to provide insights into multi-task and meta-reinforcement learning benchmark design. Through this process we release a new open-source version of Meta-World (https://github.com/Farama-Foundation/Metaworld/) that has full reproducibility of past results, is more technically ergonomic, and gives users more control over the tasks that are included in a task set.","authors":["Reginald McLean","Evangelos Chatzaroulas","Luc McCutcheon","Frank Röder","Tianhe Yu","Zhanpeng He","K. R. Zentner","Ryan Julian","J K Terry","Isaac Woungang","Nariman Farsad","Pablo Samuel Castro"],"pdf_url":"","comment":"Accepted at NeurIPs 2025, Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2511.17318v1","updated":"2025-11-21T15:36:41Z","published":"2025-11-21T15:36:41Z","title":"FORWARD: Dataset of a forwarder operating in rough terrain","summary":"We present FORWARD, a high-resolution multimodal dataset of a cut-to-length forwarder operating in rough terrain on two harvest sites in the middle part of Sweden. The forwarder is a large Komatsu model equipped with a variety of sensors, including RTK-GNSS, 360-camera, operator vibration sensors, internal CAN-bus signal recording, and multiple IMUs. The data includes event time logs recorded in 5 Hz with e.g., driving speed, fuel consumption, vehicle position with centimeter accuracy, and crane use while the vehicle operates in forest areas laser-scanned with very high-resolution, $\\sim$1500 points per square meter. Production log files (StanForD standard) with time-stamped machine events, extensive video material, and terrain data in various formats are included as well. About 18 hours of regular wood extraction work during three days is annotated from 360-video material into individual work elements and included in the dataset. We also include scenario specifications of conducted experiments on forest roads and in terrain. Scenarios include repeatedly driving the same routes with and without steel tracks, different load weight, and different target driving speeds. The dataset is intended for developing models and algorithms for trafficability, perception, and autonomous control of forest machines using artificial intelligence, simulation, and experiments on physical testbeds. In part, we focus on forwarders traversing terrain, avoiding obstacles, and loading or unloading logs, with consideration for efficiency, fuel consumption, safety, and environmental impact. Other benefits of the open dataset include the ability to explore auto-generation and calibration of forestry machine simulators and automation scenario descriptions using the data recorded in the field.","authors":["Mikael Lundbäck","Erik Wallin","Carola Häggström","Mattias Nyström","Andreas Grönlund","Mats Richardson","Petrus Jönsson","William Arnvik","Lucas Hedström","Arvid Fälldin","Martin Servin"],"pdf_url":"","comment":"25 pages, 22 figures"},{"id":"http://arxiv.org/abs/2511.17312v1","updated":"2025-11-21T15:30:44Z","published":"2025-11-21T15:30:44Z","title":"Self-supervised denoising of raw tomography detector data for improved image reconstruction","summary":"Ultrafast electron beam X-ray computed tomography produces noisy data due to short measurement times, causing reconstruction artifacts and limiting overall image quality. To counteract these issues, two self-supervised deep learning methods for denoising of raw detector data were investigated and compared against a non-learning based denoising method. We found that the application of the deep-learning-based methods was able to enhance signal-to-noise ratios in the detector data and also led to consistent improvements of the reconstructed images, outperforming the non-learning based method.","authors":["Israt Jahan Tulin","Sebastian Starke","Dominic Windisch","André Bieberle","Peter Steinbach"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02894v3","updated":"2025-11-21T15:30:31Z","published":"2025-11-04T15:59:10Z","title":"Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models","summary":"The widespread integration of wearable sensing devices in Internet of Things (IoT) ecosystems, particularly in healthcare, smart homes, and industrial applications, has required robust human activity recognition (HAR) techniques to improve functionality and user experience. Although machine learning models have advanced HAR, they are increasingly susceptible to data poisoning attacks that compromise the data integrity and reliability of these systems. Conventional approaches to defending against such attacks often require extensive task-specific training with large, labeled datasets, which limits adaptability in dynamic IoT environments. This work proposes a novel framework that uses large language models (LLMs) to perform poisoning detection and sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot learning paradigms. Our approach incorporates \\textit{role play} prompting, whereby the LLM assumes the role of expert to contextualize and evaluate sensor anomalies, and \\textit{think step-by-step} reasoning, guiding the LLM to infer poisoning indicators in the raw sensor data and plausible clean alternatives. These strategies minimize reliance on curation of extensive datasets and enable robust, adaptable defense mechanisms in real-time. We perform an extensive evaluation of the framework, quantifying detection accuracy, sanitization quality, latency, and communication cost, thus demonstrating the practicality and effectiveness of LLMs in improving the security and reliability of wearable IoT systems.","authors":["W. K. M Mithsara","Ning Yang","Ahmed Imteaj","Hussein Zangoti","Abdur R. Shahid"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17309v1","updated":"2025-11-21T15:25:47Z","published":"2025-11-21T15:25:47Z","title":"MuM: Multi-View Masked Image Modeling for 3D Vision","summary":"Self-supervised learning on images seeks to extract meaningful visual representations from unlabeled data. When scaled to large datasets, this paradigm has achieved state-of-the-art performance and the resulting trained models such as DINOv3 have seen widespread adoption. However, most prior efforts are optimized for semantic understanding rather than geometric reasoning. One important exception is Cross-View Completion, CroCo, which is a form of masked autoencoding (MAE) tailored for 3D understanding. In this work, we continue on the path proposed by CroCo and focus on learning features tailored for 3D vision. In a nutshell, we extend MAE to arbitrarily many views of the same scene. By uniformly masking all views and employing a lightweight decoder with inter-frame attention, our approach is inherently simpler and more scalable than CroCo. We evaluate the resulting model, MuM, extensively on downstream tasks including feedforward reconstruction, dense image matching and relative pose estimation, finding that it outperforms the state-of-the-art visual encoders DINOv3 and CroCo v2.","authors":["David Nordström","Johan Edstedt","Fredrik Kahl","Georg Bökman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17298v1","updated":"2025-11-21T15:11:15Z","published":"2025-11-21T15:11:15Z","title":"SAVeD: Semantic Aware Version Discovery","summary":"Our work introduces SAVeD (Semantically Aware Version Detection), a contrastive learning-based framework for identifying versions of structured datasets without relying on metadata, labels, or integration-based assumptions. SAVeD addresses a common challenge in data science of repeated labor due to a difficulty of similar work or transformations on datasets. SAVeD employs a modified SimCLR pipeline, generating augmented table views through random transformations (e.g., row deletion, encoding perturbations). These views are embedded via a custom transformer encoder and contrasted in latent space to optimize semantic similarity. Our model learns to minimize distances between augmented views of the same dataset and maximize those between unrelated tables. We evaluate performance using validation accuracy and separation, defined respectively as the proportion of correctly classified version/non-version pairs on a hold-out set, and the difference between average similarities of versioned and non-versioned tables (defined by a benchmark, and not provided to the model). Our experiments span five canonical datasets from the Semantic Versioning in Databases Benchmark, and demonstrate substantial gains post-training. SAVeD achieves significantly higher accuracy on completely unseen tables in, and a significant boost in separation scores, confirming its capability to distinguish semantically altered versions. Compared to untrained baselines and prior state-of-the-art dataset-discovery methods like Starmie, our custom encoder achieves competitive or superior results.","authors":["Artem Frenk","Roee Shraga"],"pdf_url":"","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.15738v2","updated":"2025-11-21T15:10:10Z","published":"2025-11-18T14:07:57Z","title":"Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and Turn","summary":"Reasoning reinforcement learning (RL) has recently revealed a new scaling effect: test-time scaling. Thinking models such as R1 and o1 improve their reasoning accuracy at test time as the length of the reasoning context increases. However, compared with training-time scaling, test-time scaling is fundamentally limited by the limited context length of base models, which remains orders of magnitude smaller than the amount of tokens consumed during training. We revisit test-time enhancement techniques through the lens of scaling effect and introduce a unified framework of multi-dimensional test-time scaling to extend the capacity of test-time reasoning. Beyond conventional context-length scaling, we consider two additional dimensions: batch scaling, where accuracy improves with parallel sampling, and turn scaling, where iterative self-refinement enhances reasoning quality. Building on this perspective, we propose 3D test-time scaling, which integrates context, batch, and turn scaling. We show that: (1) each dimension demonstrates a test-time scaling effect, but with a bounded capacity; (2) combining all three dimensions substantially improves the reasoning performance of challenging testbeds, including IOI, IMO, and CPHO, and further benefits from human preference feedback; and (3) the human-in-the-loop framework naturally extends to a more open-ended domain, i.e., embodied learning, which enables the design of humanoid control behaviors.","authors":["Chao Yu","Qixin Tan","Jiaxuan Gao","Shi Yu","Hong Lu","Xinting Yang","Zelai Xu","Yu Wang","Yi Wu","Eugene Vinitsky"],"pdf_url":"","comment":"44 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.01183v3","updated":"2025-11-21T15:08:01Z","published":"2024-06-03T10:39:12Z","title":"Estimating Global Input Relevance and Enforcing Sparse Representations with a Scalable Spectral Neural Network Approach","summary":"In machine learning practice it is often useful to identify relevant input features. Isolating key input elements, ranked according their respective degree of relevance, can help to elaborate on the process of decision making. Here, we propose a novel method to estimate the relative importance of the input components for a Deep Neural Network. This is achieved by leveraging on a spectral re-parametrization of the optimization process. Eigenvalues associated to input nodes provide in fact a robust proxy to gauge the relevance of the supplied entry features. Notably, the spectral features ranking is performed automatically, as a byproduct of the network training, with no additional processing to be carried out. Moreover, by leveraging on the regularization of the eigenvalues, it is possible to enforce solutions making use of a minimum subset of the input components, increasing the explainability of the model and providing sparse input representations. The technique is compared to the most common methods in the literature and is successfully challenged against both synthetic and real data.","authors":["Lorenzo Chicchi","Lorenzo Buffoni","Diego Febbe","Lorenzo Giambagli","Raffaele Marino","Duccio Fanelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17293v1","updated":"2025-11-21T15:06:49Z","published":"2025-11-21T15:06:49Z","title":"A First Full Physics Benchmark for Highly Granular Calorimeter Surrogates","summary":"The physics programs of current and future collider experiments necessitate the development of surrogate simulators for calorimeter showers. While much progress has been made in the development of generative models for this task, they have typically been evaluated in simplified scenarios and for single particles. This is particularly true for the challenging task of highly granular calorimeter simulation. For the first time, this work studies the use of highly granular generative calorimeter surrogates in a realistic simulation application. We introduce DDML, a generic library which enables the combination of generative calorimeter surrogates with realistic detectors implemented using the DD4hep toolkit. We compare two different generative models - one operating on a regular grid representation, and the other using a less common point cloud approach. In order to disentangle methodological details from model performance, we provide comparisons to idealized simulators which directly sample representations of different resolutions from the full simulation ground-truth. We then systematically evaluate model performance on post-reconstruction benchmarks for electromagnetic shower simulation. Beginning with a typical single particle study, we introduce a first multi-particle benchmark based on di-photon separations, before studying a first full-physics benchmark based on hadronic decays of the tau lepton. Our results indicate that models operating on a point cloud can achieve a favorable balance between speed and accuracy for highly granular calorimeter simulation compared to those which operate on a regular grid representation.","authors":["Thorsten Buss","Henry Day-Hall","Frank Gaede","Gregor Kasieczka","Katja Krüger","Anatolii Korol","Thomas Madlener","Peter McKeown"],"pdf_url":"","comment":"26 pages, 15 figures"},{"id":"http://arxiv.org/abs/2408.07724v2","updated":"2025-11-21T14:54:43Z","published":"2024-08-14T13:42:47Z","title":"\"Normalized Stress\" is Not Normalized: How to Interpret Stress Correctly","summary":"Stress is among the most commonly employed quality metrics and optimization criteria for dimension reduction projections of high dimensional data. Complex, high dimensional data is ubiquitous across many scientific disciplines, including machine learning, biology, and the social sciences. One of the primary methods of visualizing these datasets is with two dimensional scatter plots that visually capture some properties of the data. Because visually determining the accuracy of these plots is challenging, researchers often use quality metrics to measure projection accuracy or faithfulness to the full data. One of the most commonly employed metrics, normalized stress, is sensitive to uniform scaling of the projection, despite this act not meaningfully changing anything about the projection. We investigate the effect of scaling on stress and other distance based quality metrics analytically and empirically by showing just how much the values change and how this affects dimension reduction technique evaluations. We introduce a simple technique to make normalized stress scale invariant and show that it accurately captures expected behavior on a small benchmark.","authors":["Kiran Smelser","Jacob Miller","Stephen Kobourov"],"pdf_url":"","comment":"Appeared in the BELIV workshop 2024"},{"id":"http://arxiv.org/abs/2509.14001v4","updated":"2025-11-21T14:33:03Z","published":"2025-09-17T14:13:20Z","title":"MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment","summary":"Personalized object detection aims to adapt a general-purpose detector to recognize user-specific instances from only a few examples. Lightweight models often struggle in this setting due to their weak semantic priors, while large vision-language models (VLMs) offer strong object-level understanding but are too computationally demanding for real-time or on-device applications. We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment), a distillation framework that transfers multimodal region-level knowledge from a frozen VLM teacher into a lightweight vision-only detector. MOCHA extracts fused visual and textual teacher's embeddings and uses them to guide student training through a dual-objective loss that enforces accurate local alignment and global relational consistency across regions. This process enables efficient transfer of semantics without the need for teacher modifications or textual input at inference. MOCHA consistently outperforms prior baselines across four personalized detection benchmarks under strict few-shot regimes, yielding a +10.1 average improvement, with minimal inference cost.","authors":["Elena Camuffo","Francesco Barbato","Mete Ozay","Simone Milani","Umberto Michieli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17275v1","updated":"2025-11-21T14:30:49Z","published":"2025-11-21T14:30:49Z","title":"Automobile demand forecasting: Spatiotemporal and hierarchical modeling, life cycle dynamics, and user-generated online information","summary":"Premium automotive manufacturers face increasingly complex forecasting challenges due to high product variety, sparse variant-level data, and volatile market dynamics. This study addresses monthly automobile demand forecasting across a multi-product, multi-market, and multi-level hierarchy using data from a German premium manufacturer. The methodology combines point and probabilistic forecasts across strategic and operational planning levels, leveraging ensembles of LightGBM models with pooled training sets, quantile regression, and a mixed-integer linear programming reconciliation approach. Results highlight that spatiotemporal dependencies, as well as rounding bias, significantly affect forecast accuracy, underscoring the importance of integer forecasts for operational feasibility. Shapley analysis shows that short-term demand is reactive, shaped by life cycle maturity, autoregressive momentum, and operational signals, whereas medium-term demand reflects anticipatory drivers such as online engagement, planning targets, and competitive indicators, with online behavioral data considerably improving accuracy at disaggregated levels.","authors":["Tom Nahrendorf","Stefan Minner","Helfried Binder","Richard Zinck"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15856v2","updated":"2025-11-21T14:26:08Z","published":"2025-11-19T20:23:51Z","title":"GLOBE: Accurate and Generalizable PDE Surrogates using Domain-Inspired Architectures and Equivariances","summary":"We introduce GLOBE, a new neural surrogate for homogeneous PDEs that draws inductive bias from boundary-element methods and equivariant ML. GLOBE represents solutions as superpositions of learnable Green's-function-like kernels evaluated from boundary faces to targets, composed across multiscale branches and communication hyperlayers. The architecture is translation-, rotation-, and parity-equivariant; discretization-invariant in the fine-mesh limit; and units-invariant via rigorous nondimensionalization. An explicit far-field decay envelope stabilizes extrapolation, boundary-to-boundary hyperlayer communication mediates long-range coupling, and the all-to-all boundary-to-target evaluation yields a global receptive field that respects PDE information flow, even for elliptic PDEs.\n  On AirFRANS (steady incompressible RANS over NACA airfoils), GLOBE achieves substantial accuracy improvements. On the \"Full\" split, it reduces mean-squared error by roughly 200x on all fields relative to the dataset's reference baselines, and roughly 50x relative to the next-best-performing model. In the \"Scarce\" split, it achieves over 100x lower error on velocity and pressure fields and over 600x lower error on surface pressure than Transolver. Qualitative results show sharp near-wall gradients, coherent wakes, and limited errors under modest extrapolation in Reynolds number and angle of attack.\n  In addition to this accuracy, the model is quite compact (117k parameters), and fields can be evaluated at arbitrary points during inference. We also demonstrate the ability to train and predict with non-watertight meshes, which has strong practical implications.\n  These results show that rigorous physics- and domain-inspired inductive biases can achieve large gains in accuracy, generalizability, and practicality for ML-based PDE surrogates for industrial computer-aided engineering (CAE).","authors":["Peter Sharpe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2207.07250v3","updated":"2025-11-21T14:16:08Z","published":"2022-07-15T01:41:53Z","title":"Toward Super-polynomial Quantum Speedup of Equivariant Quantum Algorithms with SU($d$) Symmetry","summary":"We introduce a framework of the equivariant convolutional quantum algorithms which is tailored for a number of machine-learning tasks on physical systems with arbitrary SU$(d)$ symmetries. It allows us to enhance a natural model of quantum computation -- permutational quantum computing (PQC) -- and define a more powerful model: PQC+. While PQC was shown to be efficiently classically simulatable, we exhibit a problem which can be efficiently solved on PQC+ machine, whereas no classical polynomial time algorithm is known; thus providing evidence against PQC+ being classically simulatable. We further discuss practical quantum machine learning algorithms which can be carried out in the paradigm of PQC+.","authors":["Han Zheng","Zimu Li","Sergii Strelchuk","Risi Kondor","Junyu Liu"],"pdf_url":"","comment":"Presented in TQC 2022"},{"id":"http://arxiv.org/abs/2505.10297v2","updated":"2025-11-21T14:13:48Z","published":"2025-05-15T13:44:32Z","title":"Defending the Edge: Representative-Attention Defense against Backdoor Attacks in Federated Learning","summary":"Federated learning (FL) remains highly vulnerable to adaptive backdoor attacks that preserve stealth by closely imitating benign update statistics. Existing defenses predominantly rely on anomaly detection in parameter or gradient space, overlooking behavioral constraints that backdoor attacks must satisfy to ensure reliable trigger activation. These anomaly-centric methods fail against adaptive attacks that normalize update magnitudes and mimic benign statistical patterns while preserving backdoor functionality, creating a fundamental detection gap. To address this limitation, this paper introduces FeRA (Federated Representative Attention) -- a novel attention-driven defense that shifts the detection paradigm from anomaly-centric to consistency-centric analysis. FeRA exploits the intrinsic need for backdoor persistence across training rounds, identifying malicious clients through suppressed representation-space variance, an orthogonal property to traditional magnitude-based statistics. The framework conducts multi-dimensional behavioral analysis combining spectral and spatial attention, directional alignment, mutual similarity, and norm inflation across two complementary detection mechanisms: consistency analysis and norm-inflation detection. Through this mechanism, FeRA isolates malicious clients that exhibit low-variance consistency or magnitude amplification. Extensive evaluation across six datasets, nine attacks, and three model architectures under both Independent and Identically Distributed (IID) and non-IID settings confirm FeRA achieves superior backdoor mitigation. Under different non-IID settings, FeRA achieved the lowest average Backdoor Accuracy (BA), about 1.67% while maintaining high clean accuracy compared to other state-of-the-art defenses. The code is available at https://github.com/Peatech/FeRA_defense.git.","authors":["Chibueze Peace Obioma","Youcheng Sun","Mustafa A. Mustafa"],"pdf_url":"","comment":"Submitted to IEEE EURO S&P 2026"},{"id":"http://arxiv.org/abs/2503.01361v3","updated":"2025-11-21T14:07:21Z","published":"2025-03-03T09:55:10Z","title":"Statistical physics analysis of graph neural networks: Approaching optimality in the contextual stochastic block model","summary":"Graph neural networks (GNNs) are designed to process data associated with graphs. They are finding an increasing range of applications; however, as with other modern machine learning techniques, their theoretical understanding is limited. GNNs can encounter difficulties in gathering information from nodes that are far apart by iterated aggregation steps. This situation is partly caused by so-called oversmoothing; and overcoming it is one of the practically motivated challenges. We consider the situation where information is aggregated by multiple steps of convolution, leading to graph convolutional networks (GCNs). We analyze the generalization performance of a basic GCN, trained for node classification on data generated by the contextual stochastic block model. We predict its asymptotic performance by deriving the free energy of the problem, using the replica method, in the high-dimensional limit. Calling depth the number of convolutional steps, we show the importance of going to large depth to approach the Bayes-optimality. We detail how the architecture of the GCN has to scale with the depth to avoid oversmoothing. The resulting large depth limit can be close to the Bayes-optimality and leads to a continuous GCN. Technically, we tackle this continuous limit via an approach that resembles dynamical mean-field theory (DMFT) with constraints at the initial and final times. An expansion around large regularization allows us to solve the corresponding equations for the performance of the deep GCN. This promising tool may contribute to the analysis of further deep neural networks.","authors":["O. Duranthon","L. Zdeborová"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17258v1","updated":"2025-11-21T14:03:28Z","published":"2025-11-21T14:03:28Z","title":"Enforcing governing equation constraints in neural PDE solvers via training-free projections","summary":"Neural PDE solvers used for scientific simulation often violate governing equation constraints. While linear constraints can be projected cheaply, many constraints are nonlinear, complicating projection onto the feasible set. Dynamical PDEs are especially difficult because constraints induce long-range dependencies in time. In this work, we evaluate two training-free, post hoc projections of approximate solutions: a nonlinear optimization-based projection, and a local linearization-based projection using Jacobian-vector and vector-Jacobian products. We analyze constraints across representative PDEs and find that both projections substantially reduce violations and improve accuracy over physics-informed baselines.","authors":["Omer Rochman","Gilles Louppe"],"pdf_url":"","comment":"Machine Learning and the Physical Sciences, Neurips 2025, San Diego"},{"id":"http://arxiv.org/abs/2502.15769v2","updated":"2025-11-21T14:01:48Z","published":"2025-02-15T10:47:49Z","title":"Asymptotic evaluation of the information processing capacity in reservoir computing","summary":"Reservoir computing (RC) is becoming increasingly important because of its short training time. The squared error normalized by the target output is called the information processing capacity (IPC) and is used to evaluate the performance of an RC system. Since RC aims to learn the relationship between input and output time series, we should evaluate the IPC for infinitely long data rather than the IPC for finite-length data. However, a method for estimating it has not been established. We evaluated the IPC for infinitely long data using the asymptotic expansion of the IPC and weighted least-squares fitting. Then, we showed the validity of our method by numerical simulations. This work makes the performance evaluation of RC more evident.","authors":["Yohei Saito"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17249v1","updated":"2025-11-21T13:50:54Z","published":"2025-11-21T13:50:54Z","title":"FlexiFlow: decomposable flow matching for generation of flexible molecular ensemble","summary":"Sampling useful three-dimensional molecular structures along with their most favorable conformations is a key challenge in drug discovery. Current state-of-the-art 3D de-novo design flow matching or diffusion-based models are limited to generating a single conformation. However, the conformational landscape of a molecule determines its observable properties and how tightly it is able to bind to a given protein target. By generating a representative set of low-energy conformers, we can more directly assess these properties and potentially improve the ability to generate molecules with desired thermodynamic observables. Towards this aim, we propose FlexiFlow, a novel architecture that extends flow-matching models, allowing for the joint sampling of molecules along with multiple conformations while preserving both equivariance and permutation invariance. We demonstrate the effectiveness of our approach on the QM9 and GEOM Drugs datasets, achieving state-of-the-art results in molecular generation tasks. Our results show that FlexiFlow can generate valid, unstrained, unique, and novel molecules with high fidelity to the training data distribution, while also capturing the conformational diversity of molecules. Moreover, we show that our model can generate conformational ensembles that provide similar coverage to state-of-the-art physics-based methods at a fraction of the inference time. Finally, FlexiFlow can be successfully transferred to the protein-conditioned ligand generation task, even when the dataset contains only static pockets without accompanying conformations.","authors":["Riccardo Tedoldi","Ola Engkvist","Patrick Bryant","Hossein Azizpour","Jon Paul Janet","Alessandro Tibo"],"pdf_url":"","comment":"Preprint. Code to be released upon full publication"},{"id":"http://arxiv.org/abs/2508.13663v2","updated":"2025-11-21T13:46:26Z","published":"2025-08-19T09:09:07Z","title":"Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints","summary":"Methods for query answering over incomplete knowledge graphs retrieve entities that are \\emph{likely} to be answers, which is particularly useful when such answers cannot be reached by direct graph traversal due to missing edges. However, existing approaches have focused on queries formalized using first-order-logic. In practice, many real-world queries involve constraints that are inherently vague or context-dependent, such as preferences for attributes or related categories. Addressing this gap, we introduce the problem of query answering with soft constraints. We formalize the problem and introduce two efficient methods designed to adjust query answer scores by incorporating soft constraints without disrupting the original answers to a query. These methods are lightweight, requiring tuning only two parameters or a small neural network trained to capture soft constraints while maintaining the original ranking structure. To evaluate the task, we extend existing QA benchmarks by generating datasets with soft constraints. Our experiments demonstrate that our methods can capture soft constraints while maintaining robust query answering performance and adding very little overhead.","authors":["Daniel Daza","Alberto Bernardi","Luca Costabello","Christophe Gueret","Masoud Mansoury","Michael Cochez","Martijn Schut"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.19588v2","updated":"2025-11-21T13:43:43Z","published":"2025-09-23T21:24:35Z","title":"Discovery of Sustainable Refrigerants through Physics-Informed RL Fine-Tuning of Sequence Models","summary":"Most refrigerants currently used in air-conditioning systems, such as hydrofluorocarbons, are potent greenhouse gases and are being phased down. Large-scale molecular screening has been applied to the search for alternatives, but in practice only about 300 refrigerants are known, and only a few additional candidates have been suggested without experimental validation. This scarcity of reliable data limits the effectiveness of purely data-driven methods. We present Refgen, a generative pipeline that integrates machine learning with physics-grounded inductive biases. Alongside fine-tuning for valid molecular generation, Refgen incorporates predictive models for critical properties, equations of state, thermochemical polynomials, and full vapor compression cycle simulations. These models enable reinforcement learning fine-tuning under thermodynamic constraints, enforcing consistency and guiding discovery toward molecules that balance efficiency, safety, and environmental impact. By embedding physics into the learning process, Refgen leverages scarce data effectively and enables de novo refrigerant discovery beyond the known set of compounds.","authors":["Adrien Goldszal","Diego Calanzone","Vincent Taboga","Pierre-Luc Bacon"],"pdf_url":"","comment":"Accepted to 1st SIMBIOCHEM Workshop at EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.17242v1","updated":"2025-11-21T13:41:47Z","published":"2025-11-21T13:41:47Z","title":"Equivariant-Aware Structured Pruning for Efficient Edge Deployment: A Comprehensive Framework with Adaptive Fine-Tuning","summary":"This paper presents a novel framework combining group equivariant convolutional neural networks (G-CNNs) with equivariant-aware structured pruning to produce compact, transformation-invariant models for resource-constrained environments. Equivariance to rotations is achieved through the C4 cyclic group via the e2cnn library,enabling consistent performance under geometric transformations while reducing computational overhead.\n  Our approach introduces structured pruning that preserves equivariant properties by analyzing e2cnn layer structure and applying neuron-level pruning to fully connected components. To mitigate accuracy degradation, we implement adaptive fine-tuning that automatically triggers when accuracy drop exceeds 2%, using early stopping and learning rate scheduling for efficient recovery. The framework includes dynamic INT8 quantization and a comprehensive pipeline encompassing training, knowledge distillation, structured pruning, fine-tuning, and quantization.\n  We evaluate our method on satellite imagery (EuroSAT) and standard benchmarks (CIFAR-10, Rotated MNIST) demonstrating effectiveness across diverse domains. Experimental results show 29.3% parameter reduction with significant accuracy recovery, demonstrating that structured pruning of equivariant networks achieves substantial compression while maintaining geometric robustness. Our pipeline provides a reproducible framework for optimizing equivariant models, bridging the gap between group-theoretic network design and practical deployment constraints, with particular relevance to satellite imagery analysis and geometric vision tasks.","authors":["Mohammed Alnemari"],"pdf_url":"","comment":"8 pages, 5 tables, 1 figure. Accepted at IEEE EdgeCom 2025 (11th IEEE International Conference on Edge Computing and Scalable Cloud)"},{"id":"http://arxiv.org/abs/2511.17240v1","updated":"2025-11-21T13:34:29Z","published":"2025-11-21T13:34:29Z","title":"Fast Decoding for Non-Adaptive Learning of Erdős--Rényi Random Graphs","summary":"We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with \\(n\\) nodes and \\(k\\) edges is hard in the non-adaptive setting, requiring \\(Ω\\big(\\min\\{k^2\\log n,\\,n^2\\}\\big)\\) tests even when a small error probability is allowed. We focus on learning Erdős--Rényi (ER) graphs \\(G\\sim\\ER(n,q)\\) in the non-adaptive setting, where the expected number of edges is \\(\\bar{k}=q\\binom{n}{2}\\), and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests \\(O(\\bar{k}\\log n)\\) but incurs \\(Ω(n^2)\\) decoding time, whereas their proposed sublinear-time algorithm incurs an extra \\((\\log \\bar{k})(\\log n)\\) factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using \\(O(\\bar{k}\\log n)\\) tests while attaining decoding time \\(O(\\bar{k}^{1+δ}\\log n)\\) for any fixed \\(δ>0\\).","authors":["Hoang Ta","Jonathan Scarlett"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.10273v2","updated":"2025-11-21T13:26:59Z","published":"2025-09-12T14:13:31Z","title":"A neural recommender system leveraging transfer learning for property prediction of ionic liquids","summary":"Ionic liquids (ILs) have emerged as versatile replacements for traditional solvents because their physicochemical properties can be precisely tailored to various applications. However, accurately predicting key thermophysical properties remains challenging due to the vast chemical design space and the limited availability of experimental data. In this study, we present a data-driven transfer learning framework combined with a neural recommender system (NRS) to enable reliable property prediction for ILs using sparse experimental datasets. The approach involves a two-stage process: first, pre-training NRS models on COSMO-RS-based simulated data at fixed temperature and pressure, and second, fine-tuning simple feedforward neural networks with experimental data at varying temperatures and pressures. In this work, five essential IL properties are considered: density, viscosity, surface tension, heat capacity, and melting point. We find that the framework supports both within-property and cross-property knowledge transfer. Notably, pre-trained models for density, viscosity, and heat capacity are used to fine-tune models for all five target properties, achieving improved performance by a substantial margin for four of them. The model exhibits robust extrapolation to previously unseen ILs. Moreover, the final trained models enable property prediction for over 700,000 IL combinations, offering a scalable solution for IL screening in process design. This work highlights the effectiveness of combining simulated data and transfer learning to overcome sparsity in the experimental data.","authors":["Sahil Sethi","Kai Sundmacher","Caroline Ganzer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17229v1","updated":"2025-11-21T13:15:25Z","published":"2025-11-21T13:15:25Z","title":"Generating transition states of chemical reactions via distance-geometry-based flow matching","summary":"Transition states (TSs) are crucial for understanding reaction mechanisms, yet their exploration is limited by the complexity of experimental and computational approaches. Here we propose TS-DFM, a flow matching framework that predicts TSs from reactants and products. By operating in molecular distance geometry space, TS-DFM explicitly captures the dynamic changes of interatomic distances in chemical reactions. A network structure named TSDVNet is designed to learn the velocity field for generating TS geometries accurately. On the benchmark dataset Transition1X, TS-DFM outperforms the previous state-of-the-art method React-OT by 30\\% in structural accuracy. These predicted TSs provide high-quality initial structures, accelerating the convergence of CI-NEB optimization. Additionally, TS-DFM can identify alternative reaction paths. In our experiments, even a more favorable TS with lower energy barrier is discovered. Further tests on RGD1 dataset confirm its strong generalization ability on unseen molecules and reaction types, highlighting its potential for facilitating reaction exploration.","authors":["Yufei Luo","Xiang Gu","Jian Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17228v1","updated":"2025-11-21T13:14:40Z","published":"2025-11-21T13:14:40Z","title":"Intrinsic preservation of plasticity in continual quantum learning","summary":"Artificial intelligence in dynamic, real-world environments requires the capacity for continual learning. However, standard deep learning suffers from a fundamental issue: loss of plasticity, in which networks gradually lose their ability to learn from new data. Here we show that quantum learning models naturally overcome this limitation, preserving plasticity over long timescales. We demonstrate this advantage systematically across a broad spectrum of tasks from multiple learning paradigms, including supervised learning and reinforcement learning, and diverse data modalities, from classical high-dimensional images to quantum-native datasets. Although classical models exhibit performance degradation correlated with unbounded weight and gradient growth, quantum neural networks maintain consistent learning capabilities regardless of the data or task. We identify the origin of the advantage as the intrinsic physical constraints of quantum models. Unlike classical networks where unbounded weight growth leads to landscape ruggedness or saturation, the unitary constraints confine the optimization to a compact manifold. Our results suggest that the utility of quantum computing in machine learning extends beyond potential speedups, offering a robust pathway for building adaptive artificial intelligence and lifelong learners.","authors":["Yu-Qin Chen","Shi-Xin Zhang"],"pdf_url":"","comment":"11 pages, 5 figures and supplementary information"},{"id":"http://arxiv.org/abs/2505.20714v2","updated":"2025-11-21T13:07:32Z","published":"2025-05-27T04:48:26Z","title":"Wideband RF Radiance Field Modeling Using Frequency-embedded 3D Gaussian Splatting","summary":"Indoor environments typically contain diverse RF signals distributed across multiple frequency bands, including NB-IoT, Wi-Fi, and millimeter-wave. Consequently, wideband RF modeling is essential for practical applications such as joint deployment of heterogeneous RF systems, cross-band communication, and distributed RF sensing. Although 3D Gaussian Splatting (3DGS) techniques effectively reconstruct RF radiance fields at a single frequency, they cannot model fields at arbitrary or unknown frequencies across a wide range. In this paper, we present a novel 3DGS algorithm for unified wideband RF radiance field modeling. RF wave propagation depends on signal frequency and the 3D spatial environment, including geometry and material electromagnetic (EM) properties. To address these factors, we introduce a frequency-embedded EM feature network that utilizes 3D Gaussian spheres at each spatial location to learn the relationship between frequency and transmission characteristics, such as attenuation and radiance intensity. With a dataset containing sparse frequency samples in a specific 3D environment, our model can efficiently reconstruct RF radiance fields at arbitrary and unseen frequencies. To assess our approach, we introduce a large-scale power angular spectrum (PAS) dataset with 50,000 samples spanning 1 to 94 GHz across six indoor environments. Experimental results show that the proposed model trained on multiple frequencies achieves a Structural Similarity Index Measure (SSIM) of 0.922 for PAS reconstruction, surpassing state-of-the-art single-frequency 3DGS models with SSIM of 0.863.","authors":["Zechen Li","Lanqing Yang","Yiheng Bian","Hao Pan","Yongjian Fu","Yezhou Wang","Zhuxi Chen","Yi-Chao Chen","Guangtao Xue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17220v1","updated":"2025-11-21T13:01:28Z","published":"2025-11-21T13:01:28Z","title":"Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs","summary":"This study presents PARROT (Persuasion and Agreement Robustness Rating of Output Truth), a robustness focused framework designed to measure the degradation in accuracy that occurs under social pressure exerted on users through authority and persuasion in large language models (LLMs) the phenomenon of sycophancy (excessive conformity). PARROT (i) isolates causal effects by comparing the neutral version of the same question with an authoritatively false version using a double-blind evaluation, (ii) quantifies confidence shifts toward the correct and imposed false responses using log-likelihood-based calibration tracking, and (iii) systematically classifies failure modes (e.g., robust correct, sycophantic agreement, reinforced error, stubborn error, self-correction, etc.) using an eight-state behavioral taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice questions across 13 domains and domain-specific authority templates. Findings show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet 4.5) exhibit low \"follow rates\" ($\\leq 11\\%$, GPT-5: 4\\%) and minimal accuracy loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\\%, Qwen 2.5-1.5B: 94\\%). The danger is not limited to response changes; weak models reduce confidence in the correct response while increasing confidence in the imposed incorrect response. While international law and global knowledge at the domain level exhibit high fragility, elementary mathematics is relatively resilient. Consequently, we argue that the goal of \"resistance to overfitting pressure\" should be addressed as a primary objective alongside accuracy, harm avoidance, and privacy for safe deployment in the real world.","authors":["Yusuf Çelebi","Mahmoud El Hussieni","Özay Ezerceli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17219v1","updated":"2025-11-21T13:01:23Z","published":"2025-11-21T13:01:23Z","title":"DelTriC: A Novel Clustering Method with Accurate Outlier","summary":"The paper introduces DelTriC (Delaunay Triangulation Clustering), a clustering algorithm which integrates PCA/UMAP-based projection, Delaunay triangulation, and a novel back-projection mechanism to form clusters in the original high-dimensional space. DelTriC decouples neighborhood construction from decision-making by first triangulating in a low-dimensional proxy to index local adjacency, and then back-projecting to the original space to perform robust edge pruning, merging, and anomaly detection. DelTriC can outperform traditional methods such as k-means, DBSCAN, and HDBSCAN in many scenarios; it is both scalable and accurate, and it also significantly improves outlier detection.","authors":["Tomas Javurek","Michal Gregor","Sebastian Kula","Marian Simko"],"pdf_url":"","comment":"10 pages, submitted to AISTATS"},{"id":"http://arxiv.org/abs/2409.14980v2","updated":"2025-11-21T12:57:11Z","published":"2024-09-23T12:57:42Z","title":"(De)-regularized Maximum Mean Discrepancy Gradient Flow","summary":"We introduce a (de)-regularization of the Maximum Mean Discrepancy (DrMMD) and its Wasserstein gradient flow. Existing gradient flows that transport samples from source distribution to target distribution with only target samples, either lack tractable numerical implementation ($f$-divergence flows) or require strong assumptions, and modifications such as noise injection, to ensure convergence (Maximum Mean Discrepancy flows). In contrast, DrMMD flow can simultaneously (i) guarantee near-global convergence for a broad class of targets in both continuous and discrete time, and (ii) be implemented in closed form using only samples. The former is achieved by leveraging the connection between the DrMMD and the $χ^2$-divergence, while the latter comes by treating DrMMD as MMD with a de-regularized kernel. Our numerical scheme uses an adaptive de-regularization schedule throughout the flow to optimally trade off between discretization errors and deviations from the $χ^2$ regime. The potential application of the DrMMD flow is demonstrated across several numerical experiments, including a large-scale setting of training student/teacher networks.","authors":["Zonghao Chen","Aratrika Mustafi","Pierre Glaser","Anna Korba","Arthur Gretton","Bharath K. Sriperumbudur"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23366v2","updated":"2025-11-21T12:53:21Z","published":"2025-09-27T15:24:17Z","title":"Splines-Based Feature Importance in Kolmogorov-Arnold Networks: A Framework for Supervised Tabular Data Dimensionality Reduction","summary":"Feature selection is a key step in many tabular prediction problems, where multiple candidate variables may be redundant, noisy, or weakly informative. We investigate feature selection based on Kolmogorov-Arnold Networks (KANs), which parameterize feature transformations with splines and expose per-feature importance scores in a natural way. From this idea we derive four KAN-based selection criteria (coefficient norms, gradient-based saliency, and knockout scores) and compare them with standard methods such as LASSO, Random Forest feature importance, Mutual Information, and SVM-RFE on a suite of real and synthetic classification and regression datasets. Using average F1 and $R^2$ scores across three feature-retention levels (20%, 40%, 60%), we find that KAN-based selectors are generally competitive with, and sometimes superior to, classical baselines. In classification, KAN criteria often match or exceed existing methods on multi-class tasks by removing redundant features and capturing nonlinear interactions. In regression, KAN-based scores provide robust performance on noisy and heterogeneous datasets, closely tracking strong ensemble predictors; we also observe characteristic failure modes, such as overly aggressive pruning with an $\\ell_1$ criterion. Stability and redundancy analyses further show that KAN-based selectors yield reproducible feature subsets across folds while avoiding unnecessary correlation inflation, ensuring reliable and non-redundant variable selection. Overall, our findings demonstrate that KAN-based feature selection provides a powerful and interpretable alternative to traditional methods, capable of uncovering nonlinear and multivariate feature relevance beyond sparsity or impurity-based measures.","authors":["Ange-Clément Akazan","Verlon Roel Mbingui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.05650v5","updated":"2025-11-21T12:45:04Z","published":"2024-07-08T06:22:10Z","title":"The Cooperative Network Architecture: Learning Structured Networks as Representation of Sensory Patterns","summary":"We introduce the Cooperative Network Architecture (CNA), a model that represents sensory signals using structured, recurrently connected networks of neurons, termed \"nets.\" Nets are dynamically assembled from overlapping net fragments, which are learned based on statistical regularities in sensory input. This architecture offers robustness to noise, deformation, and generalization to out-of-distribution data, addressing challenges in current vision systems from a novel perspective. We demonstrate that net fragments can be learned without supervision and flexibly recombined to encode novel patterns, enabling figure completion and resilience to noise. Our findings establish CNA as a promising paradigm for developing neural representations that integrate local feature processing with global structure formation, providing a foundation for future research on invariant object recognition.","authors":["Pascal J. Sager","Jan M. Deriu","Benjamin F. Grewe","Thilo Stadelmann","Christoph von der Malsburg"],"pdf_url":"","comment":"Accepted at Neural Computation"},{"id":"http://arxiv.org/abs/2511.00423v2","updated":"2025-11-21T12:39:02Z","published":"2025-11-01T06:33:04Z","title":"Bootstrap Off-policy with World Model","summary":"Online planning has proven effective in reinforcement learning (RL) for improving sample efficiency and final performance. However, using planning for environment interaction inevitably introduces a divergence between the collected data and the policy's actual behaviors, degrading both model learning and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy with WOrld Model), a framework that tightly integrates planning and off-policy learning through a bootstrap loop: the policy initializes the planner, and the planner refines actions to bootstrap the policy through behavior alignment. This loop is supported by a jointly learned world model, which enables the planner to simulate future trajectories and provides value targets to facilitate policy improvement. The core of BOOM is a likelihood-free alignment loss that bootstraps the policy using the planner's non-parametric action distribution, combined with a soft value-weighted mechanism that prioritizes high-return behaviors and mitigates variability in the planner's action quality within the replay buffer. Experiments on the high-dimensional DeepMind Control Suite and Humanoid-Bench show that BOOM achieves state-of-the-art results in both training stability and final performance. The code is accessible at https://github.com/molumitu/BOOM_MBRL.","authors":["Guojian Zhan","Likun Wang","Xiangteng Zhang","Jiaxin Gao","Masayoshi Tomizuka","Shengbo Eben Li"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2507.06819v3","updated":"2025-11-21T12:33:38Z","published":"2025-07-09T13:08:21Z","title":"Comprehensive Evaluation of Prototype Neural Networks","summary":"Prototype models are an important method for explainable artificial intelligence (XAI) and interpretable machine learning. In this paper, we perform an in-depth analysis of a set of prominent prototype models including ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive set of metrics. In addition to applying standard metrics from literature, we propose several new metrics to further complement the analysis of model interpretability. In our experimentation, we apply the set of prototype models on a diverse set of datasets including fine-grained classification, Non-IID settings and multi-label classification to further contrast the performance. Furthermore, we also provide our code as an open-source library (https://github.com/uos-sis/quanproto), which facilitates simple application of the metrics itself, as well as extensibility -- providing the option for easily adding new metrics and models.","authors":["Philipp Schlinge","Steffen Meinert","Martin Atzmueller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17200v1","updated":"2025-11-21T12:26:33Z","published":"2025-11-21T12:26:33Z","title":"Reconstruction of Surface EMG Signal using IMU data for Upper Limb Actions","summary":"Surface Electromyography (sEMG) provides vital insights into muscle function, but it can be noisy and challenging to acquire. Inertial Measurement Units (IMUs) provide a robust and wearable alternative to motion capture systems. This paper investigates the synthesis of normalized sEMG signals from 6-axis IMU data using a deep learning approach. We collected simultaneous sEMG and IMU data sampled at 1~KHz for various arm movements. A Sliding-Window-Wave-Net model, based on dilated causal convolutions, was trained to map the IMU data to the sEMG signal. The results show that the model successfully predicts the timing and general shape of muscle activations. Although peak amplitudes were often underestimated, the high temporal fidelity demonstrates the feasibility of using this method for muscle intent detection in applications such as prosthetics and rehabilitation biofeedback.","authors":["Shubhranil Basak","Mada Hemanth","Madhav Rao"],"pdf_url":"","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2506.02392v3","updated":"2025-11-21T12:16:15Z","published":"2025-06-03T03:15:22Z","title":"Improving Generalization of Neural Combinatorial Optimization for Vehicle Routing Problems via Test-Time Projection Learning","summary":"Neural Combinatorial Optimization (NCO) has emerged as a promising learning-based paradigm for addressing Vehicle Routing Problems (VRPs) by minimizing the need for extensive manual engineering. While existing NCO methods, trained on small-scale instances (e.g., 100 nodes), have demonstrated considerable success on problems of similar scale, their performance significantly degrades when applied to large-scale scenarios. This degradation arises from the distributional shift between training and testing data, rendering policies learned on small instances ineffective for larger problems. To overcome this limitation, we introduce a novel learning framework driven by Large Language Models (LLMs). This framework learns a projection between the training and testing distributions, which is then deployed to enhance the scalability of the NCO model. Notably, unlike prevailing techniques that necessitate joint training with the neural network, our approach operates exclusively during the inference phase, obviating the need for model retraining. Extensive experiments demonstrate that our method enables a backbone model (trained on 100-node instances) to achieve superior performance on large-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) of up to 100K nodes from diverse distributions.","authors":["Yuanyao Chen","Rongsheng Chen","Fu Luo","Zhenkun Wang"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2505.24627"},{"id":"http://arxiv.org/abs/2511.13049v2","updated":"2025-11-21T12:07:39Z","published":"2025-11-17T06:53:50Z","title":"Generalization Bounds for Semi-supervised Matrix Completion with Distributional Side Information","summary":"We study a matrix completion problem where both the ground truth $R$ matrix and the unknown sampling distribution $P$ over observed entries are low-rank matrices, and \\textit{share a common subspace}. We assume that a large amount $M$ of \\textit{unlabeled} data drawn from the sampling distribution $P$ is available, together with a small amount $N$ of labeled data drawn from the same distribution and noisy estimates of the corresponding ground truth entries. This setting is inspired by recommender systems scenarios where the unlabeled data corresponds to `implicit feedback' (consisting in interactions such as purchase, click, etc. ) and the labeled data corresponds to the `explicit feedback', consisting of interactions where the user has given an explicit rating to the item. Leveraging powerful results from the theory of low-rank subspace recovery, together with classic generalization bounds for matrix completion models, we show error bounds consisting of a sum of two error terms scaling as $\\widetilde{O}\\left(\\sqrt{\\frac{nd}{M}}\\right)$ and $\\widetilde{O}\\left(\\sqrt{\\frac{dr}{N}}\\right)$ respectively, where $d$ is the rank of $P$ and $r$ is the rank of $M$. In synthetic experiments, we confirm that the true generalization error naturally splits into independent error terms corresponding to the estimations of $P$ and and the ground truth matrix $\\ground$ respectively. In real-life experiments on Douban and MovieLens with most explicit ratings removed, we demonstrate that the method can outperform baselines relying only on the explicit ratings, demonstrating that our assumptions provide a valid toy theoretical setting to study the interaction between explicit and implicit feedbacks in recommender systems.","authors":["Antoine Ledent","Mun Chong Soo","Nong Minh Hieu"],"pdf_url":"","comment":"Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2511.17181v1","updated":"2025-11-21T12:04:00Z","published":"2025-11-21T12:04:00Z","title":"Investigating self-supervised representations for audio-visual deepfake detection","summary":"Self-supervised representations excel at many vision and speech tasks, but their potential for audio-visual deepfake detection remains underexplored. Unlike prior work that uses these features in isolation or buried within complex architectures, we systematically evaluate them across modalities (audio, video, multimodal) and domains (lip movements, generic visual content). We assess three key dimensions: detection effectiveness, interpretability of encoded information, and cross-modal complementarity. We find that most self-supervised features capture deepfake-relevant information, and that this information is complementary. Moreover, models primarily attend to semantically meaningful regions rather than spurious artifacts. Yet none generalize reliably across datasets. This generalization failure likely stems from dataset characteristics, not from the features themselves latching onto superficial patterns. These results expose both the promise and fundamental challenges of self-supervised representations for deepfake detection: while they learn meaningful patterns, achieving robust cross-domain performance remains elusive.","authors":["Dragos-Alexandru Boldisor","Stefan Smeu","Dan Oneata","Elisabeta Oneata"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17176v1","updated":"2025-11-21T11:54:22Z","published":"2025-11-21T11:54:22Z","title":"On the Predictive Skill of Artificial Intelligence-based Weather Models for Extreme Events using Uncertainty Quantification","summary":"Accurate prediction of extreme weather events remains a major challenge for artificial intelligence based weather prediction systems. While deterministic models such as FuXi, GraphCast, and SFNO have achieved competitive forecast skill relative to numerical weather prediction, their ability to represent uncertainty and capture extremes is still limited. This study investigates how state of the art deterministic artificial intelligence based models respond to initial-condition perturbations and evaluates the resulting ensembles in forecasting extremes. Using three perturbation strategies (Gaussian noise, Hemispheric Centered Bred Vectors, and Huge Ensembles), we generate 50 member ensembles for two major events in August 2022: the Pakistan floods and the China heatwave. Ensemble skill is assessed against ERA5 and compared with IFS ENS and the probabilistic AIFSENS model using deterministic and probabilistic metrics. Results show that flow dependent perturbations produce the most realistic ensemble spread and highest probabilistic skill, narrowing but not closing the performance gap with numerical weather prediction ensembles. Across variables, artificial intelligence based weather models capture temperature extremes more effectively than precipitation. These findings demonstrate that input perturbations can extend deterministic models toward probabilistic forecasting, paving the way for approaches that combine flow dependent perturbations with generative or latent-space uncertainty modeling for reliable artificial intelligence-driven early warning systems.","authors":["Rodrigo Almeida","Noelia Otero","Miguel-Ángel Fernández-Torres","Jackie Ma"],"pdf_url":"","comment":"24 pages, 12 figures"},{"id":"http://arxiv.org/abs/2511.07318v2","updated":"2025-11-21T11:45:34Z","published":"2025-11-10T17:19:27Z","title":"When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs","summary":"Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.","authors":["Shaowen Wang","Yiqi Dong","Ruinian Chang","Tansheng Zhu","Yuebo Sun","Kaifeng Lyu","Jian Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17171v1","updated":"2025-11-21T11:45:22Z","published":"2025-11-21T11:45:22Z","title":"FireScope: Wildfire Risk Prediction with a Chain-of-Thought Oracle","summary":"Predicting wildfire risk is a reasoning-intensive spatial problem that requires the integration of visual, climatic, and geographic factors to infer continuous risk maps. Existing methods lack the causal reasoning and multimodal understanding required for reliable generalization. We introduce $\\textbf{FireScope-Bench}$, a large-scale dataset and benchmark that couples Sentinel-2 imagery and climate data with expert-defined risk rasters across the USA, and real wildfire events in Europe for cross-continental evaluation. Building on this dataset, we propose $\\textbf{FireScope}$, a VLM-based reasoning-to-generation framework that learns from both reinforcement learning and visual supervision to predict risk rasters with complementary reasoning traces. When trained in the USA and tested in Europe, $\\textbf{FireScope}$ achieves substantial performance gains, while expert feedback and automated analysis confirm that its reasoning traces are faithful and semantically meaningful. Our findings demonstrate that reasoning can ground raster prediction models, improving both generalization and interpretability. To our knowledge, this is the first framework to (1) demonstrate that language-based reasoning can improve generalization in visual generation, (2) propose a high-resolution wildfire risk model that can be applied across continents, and (3) enable systematic studies of robust cross-continental generalization for multimodal fire risk models. We believe that $\\textbf{FireScope-Bench}$ has the potential to serve as a foundation for advancing reasoning-driven, interpretable and generalizable spatial modeling. Data and source code will be made publicly available.","authors":["Mario Markov","Stefan Maria Ailuro","Luc Van Gool","Konrad Schindler","Danda Pani Paudel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.16991v3","updated":"2025-11-21T11:33:42Z","published":"2025-03-21T09:55:43Z","title":"TRACE: Time SeRies PArameter EffiCient FinE-tuning","summary":"We propose an efficient fine-tuning method for time series foundation models, termed TRACE: Time Series Parameter Efficient Fine-tuning. While pretrained time series foundation models are gaining popularity, they face the following challenges: (1) Unlike natural language tasks, time series data vary in frequency, channel numbers, historical/prediction lengths. For long-term forecasting tasks in particular, tailored fine-tuning can significantly enhance performance.(2) Existing parameter-efficient tuning methods like LoRA remain applicable but require adaptation to temporal characteristics.\n  To address these challenges, our TRACE framework introduces two key innovations: (1) Gated DSIC (Gated Dynamic Simulation Importance Calculation), an unbiased LoRA module importance selection mechanism that ensures conditional parameter consistency before and after masking. Experiments demonstrate that Gated DSIC outperforms common fine-tuning. (2) Reconstructed prediction heads for long-term forecasting tasks, which achieve comparable or superior performance to linear probing heads while drastically reducing parameter counts.\n  Extensive experiments on long-/short-term forecasting, anomaly detection and natural language tasks across diverse datasets, coupled with ablation studies, validate the effectiveness of our method.","authors":["Yuze Li","Wei Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17165v1","updated":"2025-11-21T11:32:28Z","published":"2025-11-21T11:32:28Z","title":"MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward","summary":"Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.","authors":["Kesheng Chen","Wenjian Luo","Bang Zhang","Zeping Yin","Zipeng Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01588v2","updated":"2025-11-21T11:16:04Z","published":"2025-11-03T13:57:08Z","title":"Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization","summary":"Embedding models are a cornerstone of modern AI. Driven by Multimodal Large Language Models (MLLMs), they have made great progress in architecture and data curation, while the holistic paradigm is still limited to SSC, i.e., single input, singular embedding, contrastive supervision, which collapses rich, multifaceted inputs into monolithic embeddings and fails to fully exploit MLLM capabilities. In this paper, we tailor one Parallel Decoupling Framework (PDF) for multimodal embedding learning, by utilizing the proprietary steerability of MLLMs, i.e., their ability to flexibly generate quite differentiated response under explicit instructions. Concretely, PDF conditions a shared MLLM backbone on distinct, learnable prefixes to roll out multiple parallel paths for one input, then relies on these paths to obtain parallel embeddings. To promote full parallel diversity, we employ Mutual Information Minimization (MIM) as an explicit constraint, coupled with per-path contrastive supervision to maintain semantic alignment. Such dual-objectives force PDF to yield robust semantic coverage and a generalizable embedding space. Ultimately, the remarkable embedding space are accessible at inference via one single forward pass, incurring negligible computational overhead. We instantiate PDF on multiple MLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains are consistently achieved across various resolutions and model sizes, e.g., boosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9% (7B), while the VLM2Vec-Qwen2VL models by +4.2% (2B) and +3.1% (7B). In terms of efficiency, our 2B model surpasses its baseline by +2.6% using only half the computational budget.","authors":["Zhicheng Wang","Chen Ju","Xu Chen","Shuai Xiao","Jinsong Lan","Xiaoyong Zhu","Ying Chen","Zhiguo Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08274v5","updated":"2025-11-21T11:10:04Z","published":"2025-06-09T22:32:51Z","title":"The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks","summary":"This research addresses the critical lack of comprehensive studies on feature scaling by systematically evaluating 12 scaling techniques - including several less common transformations - across 14 different Machine Learning algorithms and 16 datasets for classification and regression tasks. We meticulously analyzed impacts on predictive performance (using metrics such as accuracy, MAE, MSE, and $R^2$) and computational costs (training time, inference time, and memory usage). Key findings reveal that while ensemble methods (such as Random Forest and gradient boosting models like XGBoost, CatBoost and LightGBM) demonstrate robust performance largely independent of scaling, other widely used models such as Logistic Regression, SVMs, TabNet, and MLPs show significant performance variations highly dependent on the chosen scaler. This extensive empirical analysis, with all source code, experimental results, and model parameters made publicly available to ensure complete transparency and reproducibility, offers model-specific crucial guidance to practitioners on the need for an optimal selection of feature scaling techniques.","authors":["João Manoel Herrera Pinheiro","Suzana Vilas Boas de Oliveira","Thiago Henrique Segreto Silva","Pedro Antonio Rabelo Saraiva","Enzo Ferreira de Souza","Ricardo V. Godoy","Leonardo André Ambrosio","Marcelo Becker"],"pdf_url":"","comment":"36 pages"},{"id":"http://arxiv.org/abs/2502.01588v3","updated":"2025-11-21T11:07:39Z","published":"2025-02-03T18:20:29Z","title":"A Differentiable Alignment Framework for Sequence-to-Sequence Modeling via Optimal Transport","summary":"Accurate sequence-to-sequence (seq2seq) alignment is critical for applications like medical speech analysis and language learning tools relying on automatic speech recognition (ASR). State-of-the-art end-to-end (E2E) ASR systems, such as the Connectionist Temporal Classification (CTC) and transducer-based models, suffer from peaky behavior and alignment inaccuracies. In this paper, we propose a novel differentiable alignment framework based on one-dimensional optimal transport, enabling the model to learn a single alignment and perform ASR in an E2E manner. We introduce a pseudo-metric, called Sequence Optimal Transport Distance (SOTD), over the sequence space and discuss its theoretical properties. Based on the SOTD, we propose Optimal Temporal Transport Classification (OTTC) loss for ASR and contrast its behavior with CTC. Experimental results on the TIMIT, AMI, and LibriSpeech datasets show that our method considerably improves alignment performance compared to CTC and the more recently proposed Consistency-Regularized CTC, though with a trade-off in ASR performance. We believe this work opens new avenues for seq2seq alignment research, providing a solid foundation for further exploration and development within the community. Our code is publicly available at: https://github.com/idiap/OTTC","authors":["Yacouba Kaloga","Shashi Kumar","Petr Motlicek","Ina Kodrasi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16258v2","updated":"2025-11-21T11:03:29Z","published":"2025-11-20T11:37:25Z","title":"GeoPTH: A Lightweight Approach to Category-Based Trajectory Retrieval via Geometric Prototype Trajectory Hashing","summary":"Trajectory similarity retrieval is an important part of spatiotemporal data mining, however, existing methods have the following limitations: traditional metrics are computationally expensive, while learning-based methods suffer from substantial training costs and potential instability. This paper addresses these problems by proposing Geometric Prototype Trajectory Hashing (GeoPTH), a novel, lightweight, and non-learning framework for efficient category-based trajectory retrieval. GeoPTH constructs data-dependent hash functions by using representative trajectory prototypes, i.e., small point sets preserving geometric characteristics, as anchors. The hashing process is efficient, which involves mapping a new trajectory to its closest prototype via a robust, Hausdorff metric. Extensive experiments show that GeoPTH's retrieval accuracy is highly competitive with both traditional metrics and state-of-the-art learning methods, and it significantly outperforms binary codes generated through simple binarization of the learned embeddings. Critically, GeoPTH consistently outperforms all competitors in terms of efficiency. Our work demonstrates that a lightweight, prototype-centric approach offers a practical and powerful alternative, achieving an exceptional retrieval performance and computational efficiency.","authors":["Yang Xu","Zuliang Yang","Kai Ming Ting"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17134v1","updated":"2025-11-21T10:53:19Z","published":"2025-11-21T10:53:19Z","title":"Four decades of circumpolar super-resolved satellite land surface temperature data","summary":"Land surface temperature (LST) is an essential climate variable (ECV) crucial for understanding land-atmosphere energy exchange and monitoring climate change, especially in the rapidly warming Arctic. Long-term satellite-based LST records, such as those derived from the Advanced Very High Resolution Radiometer (AVHRR), are essential for detecting climate trends. However, the coarse spatial resolution of AVHRR's global area coverage (GAC) data limit their utility for analyzing fine-scale permafrost dynamics and other surface processes in the Arctic. This paper presents a new 42 years pan-Arctic LST dataset, downscaled from AVHRR GAC to 1 km with a super-resolution algorithm based on a deep anisotropic diffusion model. The model is trained on MODIS LST data, using coarsened inputs and native-resolution outputs, guided by high-resolution land cover, digital elevation, and vegetation height maps. The resulting dataset provides twice-daily, 1 km LST observations for the entire pan-Arctic region over four decades. This enhanced dataset enables improved modelling of permafrost, reconstruction of near-surface air temperature, and assessment of surface mass balance of the Greenland Ice Sheet. Additionally, it supports climate monitoring efforts in the pre-MODIS era and offers a framework adaptable to future satellite missions for thermal infrared observation and climate data record continuity.","authors":["Sonia Dupuis","Nando Metzger","Konrad Schindler","Frank Göttsche","Stefan Wunderle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.14899v2","updated":"2025-11-21T10:45:21Z","published":"2025-06-17T18:13:09Z","title":"Optimal Convergence Rates of Deep Neural Network Classifiers","summary":"In this paper, we study the binary classification problem on $[0,1]^d$ under the Tsybakov noise condition (with exponent $s \\in [0,\\infty]$) and the compositional assumption. This assumption requires the conditional class probability function of the data distribution to be the composition of $q+1$ vector-valued multivariate functions, where each component function is either a maximum value function or a Hölder-$β$ smooth function that depends only on $d_*$ of its input variables. Notably, $d_*$ can be significantly smaller than the input dimension $d$. We prove that, under these conditions, the optimal convergence rate for the excess 0-1 risk of classifiers is $\\left( \\frac{1}{n} \\right)^{\\frac{β\\cdot(1\\wedgeβ)^q}{{\\frac{d_*}{s+1}+(1+\\frac{1}{s+1})\\cdotβ\\cdot(1\\wedgeβ)^q}}}$, which is independent of the input dimension $d$. Additionally, we demonstrate that ReLU deep neural networks (DNNs) trained with hinge loss can achieve this optimal convergence rate up to a logarithmic factor. This result provides theoretical justification for the excellent performance of ReLU DNNs in practical classification tasks, particularly in high-dimensional settings. The generalized approach is of independent interest.","authors":["Zihan Zhang","Lei Shi","Ding-Xuan Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17126v1","updated":"2025-11-21T10:41:54Z","published":"2025-11-21T10:41:54Z","title":"OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation","summary":"Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2.","authors":["Qi Jiang","Xiaolong Qian","Yao Gao","Lei Sun","Kailun Yang","Zhonghua Yi","Wenyong Li","Ming-Hsuan Yang","Luc Van Gool","Kaiwei Wang"],"pdf_url":"","comment":"The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2"},{"id":"http://arxiv.org/abs/2511.17123v1","updated":"2025-11-21T10:37:07Z","published":"2025-11-21T10:37:07Z","title":"Layer-wise Weight Selection for Power-Efficient Neural Network Acceleration","summary":"Systolic array accelerators execute CNNs with energy dominated by the switching activity of multiply accumulate (MAC) units. Although prior work exploits weight dependent MAC power for compression, existing methods often use global activation models, coarse energy proxies, or layer-agnostic policies, which limits their effectiveness on real hardware. We propose an energy aware, layer-wise compression framework that explicitly leverages MAC and layer level energy characteristics. First, we build a layer-aware MAC energy model that combines per-layer activation statistics with an MSB-Hamming distance grouping of 22-bit partial sum transitions, and integrate it with a tile-level systolic mapping to estimate convolution-layer energy. On top of this model, we introduce an energy accuracy co-optimized weight selection algorithm within quantization aware training and an energy-prioritized layer-wise schedule that compresses high energy layers more aggressively under a global accuracy constraint. Experiments on different CNN models demonstrate up to 58.6\\% energy reduction with 2-3\\% accuracy drop, outperforming a state-of-the-art power-aware baseline.","authors":["Jiaxun Fang","Li Zhang","Shaoyi Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05050v2","updated":"2025-11-21T10:33:32Z","published":"2025-11-07T07:44:06Z","title":"Estimating Bidirectional Causal Effects with Large Scale Online Kernel Learning","summary":"In this study, a scalable online kernel learning framework is proposed for estimating bidirectional causal effects in systems characterized by mutual dependence and heteroskedasticity. Traditional causal inference often focuses on unidirectional effects, overlooking the common bidirectional relationships in real-world phenomena. Building on heteroskedasticity-based identification, the proposed method integrates a quasi-maximum likelihood estimator for simultaneous equation models with large scale online kernel learning. It employs random Fourier feature approximations to flexibly model nonlinear conditional means and variances, while an adaptive online gradient descent algorithm ensures computational efficiency for streaming and high-dimensional data. Results from extensive simulations demonstrate that the proposed method achieves superior accuracy and stability than single equation and polynomial approximation baselines, exhibiting lower bias and root mean squared error across various data-generating processes. These results confirm that the proposed approach effectively captures complex bidirectional causal effects with near-linear computational scaling. By combining econometric identification with modern machine learning techniques, the proposed framework offers a practical, scalable, and theoretically grounded solution for large scale causal inference in natural/social science, policy making, business, and industrial applications.","authors":["Masahiro Tanaka"],"pdf_url":"","comment":"Accepted for publication in Proceedings of the 2025 International Conference on Data Science and Intelligent Systems (DSIS 2025)"},{"id":"http://arxiv.org/abs/2509.23629v2","updated":"2025-11-21T10:27:21Z","published":"2025-09-28T04:10:37Z","title":"How LLMs Learn to Reason: A Complex Network Perspective","summary":"Training large language models with Reinforcement Learning with Verifiable Rewards (RLVR) exhibits a set of distinctive and puzzling behaviors that remain poorly understood, including a two-stage learning curve, a V-shaped response-length trajectory, and a pronounced vulnerability to catastrophic forgetting. In this work, we propose that these behaviors are emergent collective phenomena governed not by neural implementation details, but by the topological evolution of the latent reasoning graph in semantic space. By demonstrating a dynamical isomorphism between a 1.5B-parameter LLM and a minimal Concept Network Model (CoNet), we trace the causal source to the self-organization of a sparse concept web pinned to an average degree of two. This geometric perspective provides a unified physical explanation for the observed anomalies: the V-shaped trajectory tracks the evolution from parallel local skill optimization to global network integration; catastrophic forgetting stems from the topological disconnection of critical ``trunk'' edges; and policy collapse arises from the accumulation of sequential transitions at the web's leaf nodes, where broad exploration abruptly freezes into rigid, high-reward trajectories. Identifying a ``maximally frustrated state'' at the transition between learning stages, we propose Annealed-RLVR, a principled algorithm that injects a targeted SFT ``heating'' step to resolve this topological bottleneck. Experiments confirm that this theory-driven intervention outperforms standard RLVR on both in-distribution and out-of-distribution benchmarks (including Minerva and AIME). By recasting RLVR from black-box optimization into a predictable process of structural self-organization, our work provides a new physical intuition for engineering the emergent reasoning capabilities of future AI systems.","authors":["Sihan Hu","Xiansheng Cai","Yuan Huang","Zhiyuan Yao","Linfeng Zhang","Pan Zhang","Youjin Deng","Kun Chen"],"pdf_url":"","comment":"24 pages, 11 figures, 1 table, under review as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2511.17113v1","updated":"2025-11-21T10:22:00Z","published":"2025-11-21T10:22:00Z","title":"AutoGraphAD: A novel approach using Variational Graph Autoencoders for anomalous network flow detection","summary":"Network Intrusion Detection Systems (NIDS) are essential tools for detecting network attacks and intrusions. While extensive research has explored the use of supervised Machine Learning for attack detection and characterisation, these methods require accurately labelled datasets, which are very costly to obtain. Moreover, existing public datasets have limited and/or outdated attacks, and many of them suffer from mislabelled data. To reduce the reliance on labelled data, we propose AutoGraphAD, a novel unsupervised anomaly detection approach based on a Heterogeneous Variational Graph Autoencoder. AutoGraphAD operates on heterogeneous graphs, made from connection and IP nodes that capture network activity within a time window. The model is trained using unsupervised and contrastive learning, without relying on any labelled data. The reconstruction, structural loss, and KL divergence are then weighted and combined in an anomaly score that is then used for anomaly detection. Overall, AutoGraphAD yields the same, and in some cases better, results than previous unsupervised approaches, such as Anomal-E, but without requiring costly downstream anomaly detectors. As a result, AutoGraphAD achieves around 1.18 orders of magnitude faster training and 1.03 orders of magnitude faster inference, which represents a significant advantage for operational deployment.","authors":["Georgios Anyfantis","Pere Barlet-Ros"],"pdf_url":"","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.17112v1","updated":"2025-11-21T10:21:39Z","published":"2025-11-21T10:21:39Z","title":"Dissecting Quantum Reinforcement Learning: A Systematic Evaluation of Key Components","summary":"Parameterised quantum circuit (PQC) based Quantum Reinforcement Learning (QRL) has emerged as a promising paradigm at the intersection of quantum computing and reinforcement learning (RL). By design, PQCs create hybrid quantum-classical models, but their practical applicability remains uncertain due to training instabilities, barren plateaus (BPs), and the difficulty of isolating the contribution of individual pipeline components. In this work, we dissect PQC based QRL architectures through a systematic experimental evaluation of three aspects recurrently identified as critical: (i) data embedding strategies, with Data Reuploading (DR) as an advanced approach; (ii) ansatz design, particularly the role of entanglement; and (iii) post-processing blocks after quantum measurement, with a focus on the underexplored Output Reuse (OR) technique. Using a unified PPO-CartPole framework, we perform controlled comparisons between hybrid and classical agents under identical conditions. Our results show that OR, though purely classical, exhibits distinct behaviour in hybrid pipelines, that DR improves trainability and stability, and that stronger entanglement can degrade optimisation, offsetting classical gains. Together, these findings provide controlled empirical evidence of the interplay between quantum and classical contributions, and establish a reproducible framework for systematic benchmarking and component-wise analysis in QRL.","authors":["Javier Lazaro","Juan-Ignacio Vazquez","Pablo Garcia-Bringas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17100v1","updated":"2025-11-21T09:58:25Z","published":"2025-11-21T09:58:25Z","title":"Geometric-Disentangelment Unlearning","summary":"Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients (\"retain-invariant\"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.","authors":["Duo Zhou","Yuji Zhang","Tianxin Wei","Ruizhong Qiu","Ke Yang","Xiao Lin","Cheng Qian","Jingrui He","Hanghang Tong","Heng Ji","Huan Zhang"],"pdf_url":"","comment":"27 Pages"},{"id":"http://arxiv.org/abs/2511.17085v1","updated":"2025-11-21T09:40:52Z","published":"2025-11-21T09:40:52Z","title":"Why Do Language Model Agents Whistleblow?","summary":"The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways. Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user. We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge. We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior. Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates. Additionally, we verify the robustness of our dataset by testing for model evaluation awareness, and find that both black-box methods and probes on model activations show lower evaluation awareness in our settings than in comparable previous work.","authors":["Kushal Agrawal","Frank Xiao","Guido Bergman","Asa Cooper Stickland"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.16846v3","updated":"2025-11-21T09:37:07Z","published":"2025-06-20T08:51:33Z","title":"Soft decision trees for survival analysis","summary":"Decision trees are popular in survival analysis for their interpretability and ability to model complex relationships. Survival trees, which predict the timing of singular events using censored historical data, are typically built through heuristic approaches. Recently, there has been growing interest in globally optimized trees, where the overall tree is trained by minimizing the error function over all its parameters. We propose a new soft survival tree model (SST), with a soft splitting rule at each branch node, trained via a nonlinear optimization formulation amenable to decomposition. Since SSTs provide for every input vector a specific survival function associated to a single leaf node, they satisfy the conditional computation property and inherit the related benefits. SST and the training formulation combine flexibility with interpretability: any smooth survival function (parametric, semiparametric, or nonparametric) estimated through maximum likelihood can be used, and each leaf node of an SST yields a cluster of distinct survival functions which are associated to the data points routed to it. Numerical experiments on 15 well-known datasets show that SSTs, with parametric and spline-based semiparametric survival functions, trained using an adaptation of the node-based decomposition algorithm proposed by Consolo et al. (2024) for soft regression trees, outperform three benchmark survival trees in terms of four widely-used discrimination and calibration measures. SSTs can also be extended to consider group fairness.","authors":["Antonio Consolo","Edoardo Amaldi","Emilio Carrizosa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.05826v2","updated":"2025-11-21T09:36:19Z","published":"2025-09-06T20:41:55Z","title":"Performance of Conformal Prediction in Capturing Aleatoric Uncertainty","summary":"Conformal prediction is a model-agnostic approach to generating prediction sets that cover the true class with a high probability. Although its prediction set size is expected to capture aleatoric uncertainty, there is a lack of evidence regarding its effectiveness. The literature presents that prediction set size can upper-bound aleatoric uncertainty or that prediction sets are larger for difficult instances and smaller for easy ones, but a validation of this attribute of conformal predictors is missing. This work investigates how effectively conformal predictors quantify aleatoric uncertainty, specifically the inherent ambiguity in datasets caused by overlapping classes. We perform this by measuring the correlation between prediction set sizes and the number of distinct labels assigned by human annotators per instance. We further assess the similarity between prediction sets and human-provided annotations. We use three conformal prediction approaches to generate prediction sets for eight deep learning models trained on four datasets. The datasets contain annotations from multiple human annotators (ranging from five to fifty participants) per instance, enabling the identification of class overlap. We show that the vast majority of the conformal prediction outputs show a very weak to weak correlation with human annotations, with only a few showing moderate correlation. These findings underscore the necessity of critically reassessing the prediction sets generated using conformal predictors. While they can provide a higher coverage of the true classes, their capability in capturing aleatoric uncertainty and generating sets that align with human annotations remains limited.","authors":["Misgina Tsighe Hagos","Claes Lundström"],"pdf_url":"","comment":"Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2026"},{"id":"http://arxiv.org/abs/2511.17080v1","updated":"2025-11-21T09:35:07Z","published":"2025-11-21T09:35:07Z","title":"An Efficient Computational Framework for Discrete Fuzzy Numbers Based on Total Orders","summary":"Discrete fuzzy numbers, and in particular those defined over a finite chain $L_n = \\{0, \\ldots, n\\}$, have been effectively employed to represent linguistic information within the framework of fuzzy systems. Research on total (admissible) orderings of such types of fuzzy subsets, and specifically those belonging to the set $\\mathcal{D}_1^{L_n\\rightarrow Y_m}$ consisting of discrete fuzzy numbers $A$ whose support is a closed subinterval of the finite chain $L_n = \\{0, 1, \\ldots, n\\}$ and whose membership values $A(x)$, for $x \\in L_n$, belong to the set $Y_m = \\{ 0 = y_1 < y_2 < \\cdots < y_{m-1} < y_m = 1 \\}$, has facilitated the development of new methods for constructing logical connectives, based on a bijective function, called $\\textit{pos function}$, that determines the position of each $A \\in \\mathcal{D}_1^{L_n\\rightarrow Y_m}$. For this reason, in this work we revisit the problem by introducing algorithms that exploit the combinatorial structure of total (admissible) orders to compute the $\\textit{pos}$ function and its inverse with exactness. The proposed approach achieves a complexity of $\\mathcal{O}(n^{2} m \\log n)$, which is quadratic in the size of the underlying chain ($n$) and linear in the number of membership levels ($m$). The key point is that the dominant factor is $m$, ensuring scalability with respect to the granularity of membership values. The results demonstrate that this formulation substantially reduces computational cost and enables the efficient implementation of algebraic operations -- such as aggregation and implication -- on the set of discrete fuzzy numbers.","authors":["Arnau Mir","Alejandro Mus","Juan Vicente Riera"],"pdf_url":"","comment":"19 pages, 2 figures. Submitted to Computational and Applied Mathematics (Springer)"},{"id":"http://arxiv.org/abs/2506.00133v2","updated":"2025-11-21T09:32:43Z","published":"2025-05-30T18:11:31Z","title":"A Reinforcement Learning-Based Telematic Routing Protocol for the Internet of Underwater Things","summary":"The Internet of Underwater Things (IoUT) has a lot of problems, like low bandwidth, high latency, mobility, and not enough energy. Routing protocols that were made for land-based networks, like RPL, don't work well in these underwater settings. This paper talks about RL-RPL-UA, a new routing protocol that uses reinforcement learning to make things work better in underwater situations. Each node has a small RL agent that picks the best parent node depending on local data such the link quality, buffer level, packet delivery ratio, and remaining energy. RL-RPL-UA works with all standard RPL messages and adds a dynamic objective function to help people make decisions in real time. Aqua-Sim simulations demonstrate that RL-RPL-UA boosts packet delivery by up to 9.2%, uses 14.8% less energy per packet, and adds 80 seconds to the network's lifetime compared to previous approaches. These results show that RL-RPL-UA is a potential and energy-efficient way to route data in underwater networks.","authors":["Mohammadhossein Homaei","Mehran Tarif","Agustin Di Bartolo","Victor Gonzalez Morales","Mar Avila Vegas"],"pdf_url":"","comment":"8 Pages, 10 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2511.17078v1","updated":"2025-11-21T09:31:42Z","published":"2025-11-21T09:31:42Z","title":"Hash Collisions in Molecular Fingerprints: Effects on Property Prediction and Bayesian Optimization","summary":"Molecular fingerprinting methods use hash functions to create fixed-length vector representations of molecules. However, hash collisions cause distinct substructures to be represented with the same feature, leading to overestimates in molecular similarity calculations. We investigate whether using exact fingerprints improves accuracy compared to standard compressed fingerprints in molecular property prediction and Bayesian optimization where the underlying predictive model is a Gaussian process. We find that using exact fingerprints yields a small yet consistent improvement in predictive accuracy on five molecular property prediction benchmarks from the DOCKSTRING dataset. However, these gains did not translate to significant improvements in Bayesian optimization performance.","authors":["Walter Virany","Austin Tripp"],"pdf_url":"","comment":"NeurIPS 2025 AI4Science workshop. Code: https://github.com/wvirany/molcollisions Openreview: https://openreview.net/forum?id=POgOHi8a7t"},{"id":"http://arxiv.org/abs/2310.06746v3","updated":"2025-11-21T09:30:05Z","published":"2023-10-10T16:19:20Z","title":"A New Causal Rule Learning Approach to Interpretable Estimation of Heterogeneous Treatment Effect","summary":"Interpretability plays a crucial role in the application of statistical learning to estimate heterogeneous treatment effects (HTE) in complex diseases. In this study, we leverage a rule-based workflow, namely causal rule learning (CRL), to estimate and improve our understanding of HTE for atrial septal defect, addressing an overlooked question in the previous literature: what if an individual simultaneously belongs to multiple groups with different average treatment effects? The CRL process consists of three steps: rule discovery, which generates a set of causal rules with corresponding subgroup average treatment effects; rule selection, which identifies a subset of these rules to deconstruct individual-level treatment effects as a linear combination of subgroup-level effects; and rule analysis, which presents a detailed procedure for further analyzing each selected rule from multiple perspectives to identify the most promising rules for validation. Extensive simulation studies and real-world data analysis demonstrate that CRL outperforms other methods in providing interpretable estimates of HTE, especially when dealing with complex ground truth and sufficient sample sizes.","authors":["Ying Wu","Hanzhong Liu","Kai Ren","Shujie Ma","Xiangyu Chang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.20973v2","updated":"2025-11-21T09:12:45Z","published":"2025-07-28T16:36:13Z","title":"Model-Agnostic Gender Bias Control for Text-to-Image Generation via Sparse Autoencoder","summary":"Text-to-image (T2I) diffusion models often exhibit gender bias, particularly by generating stereotypical associations between professions and gendered subjects. This paper presents SAE Debias, a lightweight and model-agnostic framework for mitigating such bias in T2I generation. Unlike prior approaches that rely on CLIP-based filtering or prompt engineering, which often require model-specific adjustments and offer limited control, SAE Debias operates directly within the feature space without retraining or architectural modifications. By leveraging a k-sparse autoencoder pre-trained on a gender bias dataset, the method identifies gender-relevant directions within the sparse latent space, capturing professional stereotypes. Specifically, a biased direction per profession is constructed from sparse latents and suppressed during inference to steer generations toward more gender-balanced outputs. Trained only once, the sparse autoencoder provides a reusable debiasing direction, offering effective control and interpretable insight into biased subspaces. Extensive evaluations across multiple T2I models, including Stable Diffusion 1.4, 1.5, 2.1, and SDXL, demonstrate that SAE Debias substantially reduces gender bias while preserving generation quality. To the best of our knowledge, this is the first work to apply sparse autoencoders for identifying and intervening in gender bias within T2I models. These findings contribute toward building socially responsible generative AI, providing an interpretable and model-agnostic tool to support fairness in text-to-image generation.","authors":["Chao Wu","Zhenyi Wang","Kangxian Xie","Naresh Kumar Devulapally","Vishnu Suresh Lokhande","Mingchen Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.11078v2","updated":"2025-11-21T09:05:05Z","published":"2024-09-17T11:10:59Z","title":"MonoKAN: Certified Monotonic Kolmogorov-Arnold Network","summary":"Artificial Neural Networks (ANNs) have significantly advanced various fields by effectively recognizing patterns and solving complex problems. Despite these advancements, their interpretability remains a critical challenge, especially in applications where transparency and accountability are essential. To address this, explainable AI (XAI) has made progress in demystifying ANNs, yet interpretability alone is often insufficient. In certain applications, model predictions must align with expert-imposed requirements, sometimes exemplified by partial monotonicity constraints. While monotonic approaches are found in the literature for traditional Multi-layer Perceptrons (MLPs), they still face difficulties in achieving both interpretability and certified partial monotonicity. Recently, the Kolmogorov-Arnold Network (KAN) architecture, based on learnable activation functions parametrized as splines, has been proposed as a more interpretable alternative to MLPs. Building on this, we introduce a novel ANN architecture called MonoKAN, which is based on the KAN architecture and achieves certified partial monotonicity while enhancing interpretability. To achieve this, we employ cubic Hermite splines, which guarantee monotonicity through a set of straightforward conditions. Additionally, by using positive weights in the linear combinations of these splines, we ensure that the network preserves the monotonic relationships between input and output. Our experiments demonstrate that MonoKAN not only enhances interpretability but also improves predictive performance across the majority of benchmarks, outperforming state-of-the-art monotonic MLP approaches.","authors":["Alejandro Polo-Molina","David Alfaya","Jose Portela"],"pdf_url":"","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.17040v1","updated":"2025-11-21T08:31:43Z","published":"2025-11-21T08:31:43Z","title":"Step-E: A Differentiable Data Cleaning Framework for Robust Learning with Noisy Labels","summary":"Training data collected in the wild often contain noisy labels and outliers that substantially degrade the performance and reliability of deep neural networks. While data cleaning is commonly applied as a separate preprocessing stage, such two-stage pipelines neither fully exploit feedback from the downstream model nor adapt to unknown noise patterns. We propose Step-E, a simple framework that integrates sample selection and model learning into a single optimization process. At each epoch, Step-E ranks samples by loss and gradually increases the fraction of high-loss examples that are excluded from gradient updates after a brief warm-up stage, yielding an online curriculum that focuses on easy and consistent examples and eventually ignores persistent outliers. On CIFAR-100N, Step-E improves the test accuracy of a ResNet-18 model from 43.3% (+/- 0.7%) to 50.4% (+/- 0.9%), clearly outperforming loss truncation, self-paced learning, and one-shot filtering while approaching the clean-label oracle at 60.5% (+/- 0.2%). On CIFAR-10N (aggre), Step-E also improves over the noisy baseline (85.3% vs. 83.9%) and nearly matches the clean-label oracle (85.9%), with only moderate training-time overhead.","authors":["Wenzhang Du"],"pdf_url":"","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.17031v1","updated":"2025-11-21T08:12:47Z","published":"2025-11-21T08:12:47Z","title":"Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation","summary":"The rapidly growing computational demands of diffusion models for image generation have raised significant concerns about energy consumption and environmental impact. While existing approaches to energy optimization focus on architectural improvements or hardware acceleration, there is a lack of principled methods to predict energy consumption across different model configurations and hardware setups. We propose an adaptation of Kaplan scaling laws to predict GPU energy consumption for diffusion models based on computational complexity (FLOPs). Our approach decomposes diffusion model inference into text encoding, iterative denoising, and decoding components, with the hypothesis that denoising operations dominate energy consumption due to their repeated execution across multiple inference steps. We conduct comprehensive experiments across four state-of-the-art diffusion models (Stable Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures (NVIDIA A100, A4000, A6000), spanning various inference configurations including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts (10-50), and classifier-free guidance settings. Our energy scaling law achieves high predictive accuracy within individual architectures (R-squared > 0.9) and exhibits strong cross-architecture generalization, maintaining high rank correlations across models and enabling reliable energy estimation for unseen model-hardware combinations. These results validate the compute-bound nature of diffusion inference and provide a foundation for sustainable AI deployment planning and carbon footprint estimation.","authors":["Aniketh Iyengar","Jiaqi Han","Boris Ruf","Vincent Grari","Marcin Detyniecki","Stefano Ermon"],"pdf_url":"","comment":"Accepted at EurIPS 2025 workshop \"Rethinking AI: Efficiency, Frugality, and Sustainability\""},{"id":"http://arxiv.org/abs/2505.01094v2","updated":"2025-11-21T08:00:14Z","published":"2025-05-02T08:14:01Z","title":"Multi-Objective Reinforcement Learning for Water Management","summary":"Many real-world problems (e.g., resource management, autonomous driving, drug discovery) require optimizing multiple, conflicting objectives. Multi-objective reinforcement learning (MORL) extends classic reinforcement learning to handle multiple objectives simultaneously, yielding a set of policies that capture various trade-offs. However, the MORL field lacks complex, realistic environments and benchmarks. We introduce a water resource (Nile river basin) management case study and model it as a MORL environment. We then benchmark existing MORL algorithms on this task. Our results show that specialized water management methods outperform state-of-the-art MORL approaches, underscoring the scalability challenges MORL algorithms face in real-world scenarios.","authors":["Zuzanna Osika","Roxana Rădulescu","Jazmin Zatarain Salazar","Frans Oliehoek","Pradeep K. Murukannaiah"],"pdf_url":"","comment":"Accepted to AAMAS 2025"},{"id":"http://arxiv.org/abs/2511.00794v2","updated":"2025-11-21T07:44:25Z","published":"2025-11-02T04:16:47Z","title":"Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration","summary":"Reinforcement learning with verifiable rewards (RLVR) has improved the reasoning ability of large language models, yet training remains costly because many rollouts contribute little to optimization, considering the amount of computation required. This study investigates how simply leveraging intrinsic data properties, almost free benefit during training, can improve data efficiency for RLVR. We propose PREPO with two complementary components. First, we adopt prompt perplexity as an indicator of model adaptability in learning, enabling the model to progress from well-understood contexts to more challenging ones. Second, we amplify the discrepancy among the rollouts by differentiating their relative entropy, and prioritize sequences that exhibit a higher degree of exploration. Together, these mechanisms reduce rollout demand while preserving competitive performance. On the Qwen and Llama models, PREPO achieves effective results on mathematical reasoning benchmarks with up to 3 times fewer rollouts than the baselines. Beyond empirical gains, we provide theoretical and in-depth analyses explaining the underlying rationale of our method to improve the data efficiency of RLVR.","authors":["Yan Sun","Jia Guo","Stanley Kok","Zihao Wang","Zujie Wen","Zhiqiang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17008v1","updated":"2025-11-21T07:26:40Z","published":"2025-11-21T07:26:40Z","title":"Mask the Redundancy: Evolving Masking Representation Learning for Multivariate Time-Series Clustering","summary":"Multivariate Time-Series (MTS) clustering discovers intrinsic grouping patterns of temporal data samples. Although time-series provide rich discriminative information, they also contain substantial redundancy, such as steady-state machine operation records and zero-output periods of solar power generation. Such redundancy diminishes the attention given to discriminative timestamps in representation learning, thus leading to performance bottlenecks in MTS clustering. Masking has been widely adopted to enhance the MTS representation, where temporal reconstruction tasks are designed to capture critical information from MTS. However, most existing masking strategies appear to be standalone preprocessing steps, isolated from the learning process, which hinders dynamic adaptation to the importance of clustering-critical timestamps. Accordingly, this paper proposes the Evolving-masked MTS Clustering (EMTC) method, with its model architecture composed of Importance-aware Variate-wise Masking (IVM) and Multi-Endogenous Views (MEV) representation learning modules. IVM adaptively guides the model in learning more discriminative representations for clustering, while the MEV-based reconstruction and contrastive learning pathways enhance the generalization. That is, the MEV reconstruction facilitates multi-perspective complementary to prevent the masking from premature convergence, and the clustering-guided contrastive learning facilitates the joint optimization of representation and clustering. Extensive experiments on 15 real benchmark datasets demonstrate the superiority of EMTC in comparison with eight SOTA methods, where the EMTC achieves an average improvement of 4.85% over the strongest baselines.","authors":["Zexi Tan","Xiaopeng Luo","Yunlin Liu","Yiqun Zhang"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2511.17007v1","updated":"2025-11-21T07:25:49Z","published":"2025-11-21T07:25:49Z","title":"Generative MIMO Beam Map Construction for Location Recovery and Beam Tracking","summary":"Machine learning (ML) has greatly advanced data-driven channel modeling and resource optimization in wireless communication systems. However, most existing ML-based methods rely on large, accurately labeled datasets with location information, which are often difficult and costly to obtain. This paper proposes a generative framework to recover location labels directly from sequences of sparse channel state information (CSI) measurements, without explicit location labels for radio map construction. Instead of directly storing raw CSI, we learn a compact low-dimensional radio map embedding and leverage a generative model to reconstruct the high-dimensional CSI. Specifically, to address the uncertainty of sparse CSI, a dual-scale feature extraction scheme is designed to enhance feature representation by jointly exploiting correlations from angular space and across neighboring samples. We develop a hybrid recurrent-convolutional encoder to learn mobility patterns, which combines a truncation strategy and multi-scale convolutions in the recurrent neural network (RNN) to ensure feature robustness against short-term fluctuations. Unlike conventional Gaussian priors in latent space, we embed a learnable radio map to capture the location information by encoding high-level positional features from CSI measurements. Finally, a diffusion-based generative decoder reconstructs the full CSI with high fidelity by conditioning on the positional features in the radio map. Numerical experiments demonstrate that the proposed model can improve localization accuracy by over 30% and achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with model-based Kalman filter approaches.","authors":["Wangqian Chen","Junting Chen","Shuguang Cui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.01218v3","updated":"2025-11-21T07:10:33Z","published":"2025-05-02T12:13:23Z","title":"Quantitative Attractor Analysis of High-Capacity Kernel Logistic Regression Hopfield Networks","summary":"Kernel-based learning methods such as Kernel Logistic Regression (KLR) can dramatically increase the storage capacity of Hopfield networks, but the principles governing their performance and stability remain largely uncharacterized. This paper presents a comprehensive quantitative analysis of the attractor landscape in KLR-trained networks to establish a solid foundation for their design and application. Through extensive, statistically validated simulations, we address critical questions of generality, scalability, and robustness. Our comparative analysis reveals that KLR and Kernel Ridge Regression (KRR) exhibit similarly high storage capacities and clean attractor landscapes, suggesting this is a general property of kernel regression methods, though KRR is computationally much faster. We uncover a non-trivial, scale-dependent scaling law for the kernel width ($γ$), demonstrating that optimal capacity requires $γ$ to be scaled such that $γ\\times N$ increases with network size $N$. This implies that larger networks necessitate more localized kernels -- where each pattern's influence is more spatially confined -- to manage inter-pattern interference. Under this optimized scaling, we provide definitive evidence that the storage capacity scales linearly with network size ($P \\propto N$). Furthermore, our sensitivity analysis shows that performance is remarkably robust to the choice of the regularization parameter $λ$. Collectively, these findings provide a clear set of empirical principles for designing high-capacity, robust associative memories and clarify the mechanisms that enable kernel methods to overcome the classical limitations of Hopfield-type models.","authors":["Akira Tamamori"],"pdf_url":"","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.16992v1","updated":"2025-11-21T06:59:28Z","published":"2025-11-21T06:59:28Z","title":"FIRM: Federated In-client Regularized Multi-objective Alignment for Large Language Models","summary":"Aligning Large Language Models (LLMs) with human values often involves balancing multiple, conflicting objectives such as helpfulness and harmlessness. Training these models is computationally intensive, and centralizing the process raises significant data privacy concerns. Federated Learning (FL) offers a compelling alternative, but existing Federated Multi-Objective Optimization (FMOO) methods face severe communication bottlenecks as their reliance on transmitting multiple gradients to a server is unscalable for large models. We introduce FIRM (Federated In-client Regularized Multi-objective alignment), a novel algorithm that achieves both client disagreement drift mitigation and communication efficiency. In FIRM, each client locally solves a regularized multi-objective optimization problem. By directly mitigating client disagreement drift through in-client regularization, our method eliminates the need for the multi-gradient transmissions common in prior works. Consequently, clients need only to transmit a single set of adapted parameters, maintaining high communication efficiency. We prove that our algorithm converges to Pareto-stationary points and, to our knowledge, provide the first finite-time convergence guarantees for this federated multi-objective alignment setting. Empirically, we show that FIRM leads to smoother training dynamics, reduced client disagreement drift, and improved reward trade-offs compared to baselines. We further propose a method to incorporate a preference over the objectives and report empirical Pareto plots, demonstrating that FIRM can smoothly adapt trade-offs between objectives in response to specified preferences.","authors":[" Fatemeh"," Nourzad","Amirhossein Roknilamouki","Eylem Ekici"," Jia"," Liu","Ness B. Shroff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16982v1","updated":"2025-11-21T06:29:52Z","published":"2025-11-21T06:29:52Z","title":"A Diversity-optimized Deep Ensemble Approach for Accurate Plant Leaf Disease Detection","summary":"Plant diseases pose a significant threat to global agriculture, causing over $220 billion in annual economic losses and jeopardizing food security. The timely and accurate detection of these diseases from plant leaf images is critical to mitigating their adverse effects. Deep neural network Ensembles (Deep Ensembles) have emerged as a powerful approach to enhancing prediction accuracy by leveraging the strengths of diverse Deep Neural Networks (DNNs). However, selecting high-performing ensemble member models is challenging due to the inherent difficulty in measuring ensemble diversity. In this paper, we introduce the Synergistic Diversity (SQ) framework to enhance plant disease detection accuracy. First, we conduct a comprehensive analysis of the limitations of existing ensemble diversity metrics (denoted as Q metrics), which often fail to identify optimal ensemble teams. Second, we present the SQ metric, a novel measure that captures the synergy between ensemble members and consistently aligns with ensemble accuracy. Third, we validate our SQ approach through extensive experiments on a plant leaf image dataset, which demonstrates that our SQ metric substantially improves ensemble selection and enhances detection accuracy. Our findings pave the way for a more reliable and efficient image-based plant disease detection.","authors":["Sai Nath Chowdary Medikonduru","Hongpeng Jin","Yanzhao Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16976v1","updated":"2025-11-21T06:14:41Z","published":"2025-11-21T06:14:41Z","title":"Gradient flow for deep equilibrium single-index models","summary":"Deep equilibrium models (DEQs) have recently emerged as a powerful paradigm for training infinitely deep weight-tied neural networks that achieve state of the art performance across many modern machine learning tasks. Despite their practical success, theoretically understanding the gradient descent dynamics for training DEQs remains an area of active research. In this work, we rigorously study the gradient descent dynamics for DEQs in the simple setting of linear models and single-index models, filling several gaps in the literature. We prove a conservation law for linear DEQs which implies that the parameters remain trapped on spheres during training and use this property to show that gradient flow remains well-conditioned for all time. We then prove linear convergence of gradient descent to a global minimizer for linear DEQs and deep equilibrium single-index models under appropriate initialization and with a sufficiently small step size. Finally, we validate our theoretical findings through experiments.","authors":["Sanjit Dandapanthula","Aaditya Ramdas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16972v1","updated":"2025-11-21T06:01:28Z","published":"2025-11-21T06:01:28Z","title":"ToC: Tree-of-Claims Search with Multi-Agent Language Models","summary":"Optimizing patent claims is a critical yet challenging task, demanding careful balance between maximizing novelty and preserving legal scope. Manual claim drafting is labor-intensive, costly, and inherently inconsistent, while conventional Large Language Models (LLMs) often lack the structured, iterative reasoning essential for precise claim refinement. To address these challenges, we introduce Tree of Claims (ToC), an innovative framework that redefines claim editing as a guided search problem. ToC synergistically integrates Monte Carlo Tree Search (MCTS) with a collaborative multi-agent system, comprising an LLM-based EditorAgent that proposes contextually grounded edits, and an ExaminerAgent that mimics patent examiner critiques through structured, chain-of-thought analyses of novelty and prior art disclosure. Driven by a carefully designed multi-objective reward function, ToC jointly optimizes novelty, scope retention, and semantic coherence. Experimental evaluation on a benchmark of 1145 claims demonstrates that ToC significantly outperforms standard LLMs in zero-shot and few-shot scenarios, achieving an average composite score improvement of 8\\%, and up to 9\\% in certain cases. Extensive experiments, including detailed ablation studies, validate ToC's efficacy in generating superior, legally robust claim revisions. Overall, ToC establishes a transparent, controllable, and interpretable methodology that effectively bridges advanced LLM reasoning capabilities with strategic MCTS planning for structured patent claim optimization.The source code is available at https://github.com/ysy2003/ToC.","authors":["Shuyang Yu","Jianan Liang","Hui Hu"],"pdf_url":"","comment":"Accepted by AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2503.15013v4","updated":"2025-11-21T05:50:11Z","published":"2025-03-19T09:10:43Z","title":"Ambient Noise Full Waveform Inversion with Neural Operators","summary":"Numerical simulations of seismic wave propagation are crucial for investigating velocity structures and improving seismic hazard assessment. However, standard methods such as finite difference or finite element are computationally expensive. Recent studies have shown that a new class of machine learning models, called neural operators, can solve the elastodynamic wave equation orders of magnitude faster than conventional methods. Full waveform inversion is a prime beneficiary of the accelerated simulations. Neural operators, as end-to-end differentiable operators, combined with automatic differentiation, provide an alternative approach to the adjoint-state method. State-of-the-art optimization techniques built into PyTorch provide neural operators with greater flexibility to improve the optimization dynamics of full waveform inversion, thereby mitigating cycle-skipping problems. In this study, we demonstrate the first application of neural operators for full waveform inversion on a real seismic dataset, which consists of several nodal transects collected across the San Gabriel, Chino, and San Bernardino basins in the Los Angeles metropolitan area.","authors":["Caifeng Zou","Zachary E. Ross","Robert W. Clayton","Fan-Chi Lin","Kamyar Azizzadenesheli"],"pdf_url":"","comment":"Align with the published version"},{"id":"http://arxiv.org/abs/2511.16965v1","updated":"2025-11-21T05:38:15Z","published":"2025-11-21T05:38:15Z","title":"Real-Time Cooked Food Image Synthesis and Visual Cooking Progress Monitoring on Edge Devices","summary":"Synthesizing realistic cooked food images from raw inputs on edge devices is a challenging generative task, requiring models to capture complex changes in texture, color and structure during cooking. Existing image-to-image generation methods often produce unrealistic results or are too resource-intensive for edge deployment. We introduce the first oven-based cooking-progression dataset with chef-annotated doneness levels and propose an edge-efficient recipe and cooking state guided generator that synthesizes realistic food images conditioned on raw food image. This formulation enables user-preferred visual targets rather than fixed presets. To ensure temporal consistency and culinary plausibility, we introduce a domain-specific \\textit{Culinary Image Similarity (CIS)} metric, which serves both as a training loss and a progress-monitoring signal. Our model outperforms existing baselines with significant reductions in FID scores (30\\% improvement on our dataset; 60\\% on public datasets)","authors":["Jigyasa Gupta","Soumya Goyal","Anil Kumar","Ishan Jindal"],"pdf_url":"","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2311.02733v2","updated":"2025-11-21T05:23:01Z","published":"2023-11-05T18:35:03Z","title":"AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Deepfake Detection of Frontal Face Videos","summary":"Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multimodal models that can exploit both pieces of information simultaneously. However, previous methods mainly adopt unimodal video forensics and use supervised pre-training for forgery detection. This study proposes a new method based on a multimodal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multimodal video forgery detection. We use the transformer-based SSL pre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multi-scale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.","authors":["Sahibzada Adil Shahzad","Ammarah Hashmi","Yan-Tsung Peng","Yu Tsao","Hsin-Min Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16955v1","updated":"2025-11-21T05:02:47Z","published":"2025-11-21T05:02:47Z","title":"Neighbor GRPO: Contrastive ODE Policy Optimization Aligns Flow Models","summary":"Group Relative Policy Optimization (GRPO) has shown promise in aligning image and video generative models with human preferences. However, applying it to modern flow matching models is challenging because of its deterministic sampling paradigm. Current methods address this issue by converting Ordinary Differential Equations (ODEs) to Stochastic Differential Equations (SDEs), which introduce stochasticity. However, this SDE-based GRPO suffers from issues of inefficient credit assignment and incompatibility with high-order solvers for fewer-step sampling. In this paper, we first reinterpret existing SDE-based GRPO methods from a distance optimization perspective, revealing their underlying mechanism as a form of contrastive learning. Based on this insight, we propose Neighbor GRPO, a novel alignment algorithm that completely bypasses the need for SDEs. Neighbor GRPO generates a diverse set of candidate trajectories by perturbing the initial noise conditions of the ODE and optimizes the model using a softmax distance-based surrogate leaping policy. We establish a theoretical connection between this distance-based objective and policy gradient optimization, rigorously integrating our approach into the GRPO framework. Our method fully preserves the advantages of deterministic ODE sampling, including efficiency and compatibility with high-order solvers. We further introduce symmetric anchor sampling for computational efficiency and group-wise quasi-norm reweighting to address reward flattening. Extensive experiments demonstrate that Neighbor GRPO significantly outperforms SDE-based counterparts in terms of training cost, convergence speed, and generation quality.","authors":["Dailan He","Guanlin Feng","Xingtong Ge","Yazhe Niu","Yi Zhang","Bingqi Ma","Guanglu Song","Yu Liu","Hongsheng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.07772v2","updated":"2025-11-21T04:57:07Z","published":"2025-11-11T02:45:48Z","title":"SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought","summary":"As Large Language Models (LLMs) evolve into personal assistants with access to sensitive user data, they face a critical privacy challenge: while prior work has addressed output-level privacy, recent findings reveal that LLMs often leak private information through their internal reasoning processes, violating contextual privacy expectations. These leaky thoughts occur when models inadvertently expose sensitive details in their reasoning traces, even when final outputs appear safe. The challenge lies in preventing such leakage without compromising the model's reasoning capabilities, requiring a delicate balance between privacy and utility. We introduce Steering Activations towards Leakage-free Thinking (SALT), a lightweight test-time intervention that mitigates privacy leakage in model's Chain of Thought (CoT) by injecting targeted steering vectors into hidden state. We identify the high-leakage layers responsible for this behavior. Through experiments across multiple LLMs, we demonstrate that SALT achieves reductions including $18.2\\%$ reduction in CPL on QwQ-32B, $17.9\\%$ reduction in CPL on Llama-3.1-8B, and $31.2\\%$ reduction in CPL on Deepseek in contextual privacy leakage dataset AirGapAgent-R while maintaining comparable task performance and utility. Our work establishes SALT as a practical approach for test-time privacy protection in reasoning-capable language models, offering a path toward safer deployment of LLM-based personal agents.","authors":["Shourya Batra","Pierce Tillman","Samarth Gaggar","Shashank Kesineni","Kevin Zhu","Sunishchal Dev","Ashwinee Panda","Vasu Sharma","Maheep Chaudhary"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.13597v3","updated":"2025-11-21T04:30:39Z","published":"2024-10-17T14:30:27Z","title":"Text-guided multi-property molecular optimization with a diffusion language model","summary":"Molecular optimization (MO) is a crucial stage in drug discovery in which task-oriented generated molecules are optimized to meet practical industrial requirements. Existing mainstream MO approaches primarily utilize external property predictors to guide iterative property optimization. However, learning all molecular samples in the vast chemical space is unrealistic for predictors. As a result, errors and noise are inevitably introduced during property prediction due to the nature of approximation. This leads to discrepancy accumulation, generalization reduction and suboptimal molecular candidates. In this paper, we propose a text-guided multi-property molecular optimization method utilizing transformer-based diffusion language model (TransDLM). TransDLM leverages standardized chemical nomenclature as semantic representations of molecules and implicitly embeds property requirements into textual descriptions, thereby mitigating error propagation during diffusion process. By fusing physically and chemically detailed textual semantics with specialized molecular representations, TransDLM effectively integrates diverse information sources to guide precise optimization, which enhances the model's ability to balance structural retention and property enhancement. Additionally, the success of a case study further demonstrates TransDLM's ability to solve practical problems. Experimentally, our approach surpasses state-of-the-art methods in maintaining molecular structural similarity and enhancing chemical properties on the benchmark dataset.","authors":["Yida Xiong","Kun Li","Jiameng Chen","Hongzhi Zhang","Di Lin","Yan Che","Wenbin Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16933v1","updated":"2025-11-21T03:57:52Z","published":"2025-11-21T03:57:52Z","title":"A novel approach to classification of ECG arrhythmia types with latent ODEs","summary":"12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health.","authors":["Angelina Yan","Matt L. Sampson","Peter Melchior"],"pdf_url":"","comment":"Accepted into NeurIPS 2025 Learning from Time Series for Health workshop"},{"id":"http://arxiv.org/abs/2511.16929v1","updated":"2025-11-21T03:43:37Z","published":"2025-11-21T03:43:37Z","title":"CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection","summary":"Detecting trajectory anomalies is a vital task in modern Intelligent Transportation Systems (ITS), enabling the identification of unsafe, inefficient, or irregular travel behaviours. While deep learning has emerged as the dominant approach, several key challenges remain unresolved. First, sub-trajectory anomaly detection, capable of pinpointing the precise segments where anomalies occur, remains underexplored compared to whole-trajectory analysis. Second, many existing methods depend on carefully tuned thresholds, limiting their adaptability in real-world applications. Moreover, the irregular sampling of trajectory data and the presence of noise in training sets further degrade model performance, making it difficult to learn reliable representations of normal routes. To address these challenges, we propose a contrastive reinforcement learning framework for online trajectory anomaly detection, CroTad. Our method is threshold-free and robust to noisy, irregularly sampled data. By incorporating contrastive learning, CroTad learns to extract diverse normal travel patterns for different itineraries and effectively distinguish anomalous behaviours at both sub-trajectory and point levels. The detection module leverages deep reinforcement learning to perform online, real-time anomaly scoring, enabling timely and fine-grained identification of abnormal segments. Extensive experiments on two real-world datasets demonstrate the effectiveness and robustness of our framework across various evaluation scenarios.","authors":["Rui Xue","Dan He","Fengmei Jin","Chen Zhang","Xiaofang Zhou"],"pdf_url":"","comment":"18 pages, 4 figures, will be submitted to VLDBJ"},{"id":"http://arxiv.org/abs/2511.16923v1","updated":"2025-11-21T03:23:47Z","published":"2025-11-21T03:23:47Z","title":"A Hybrid Computational Intelligence Framework for scRNA-seq Imputation: Integrating scRecover and Random Forests","summary":"Single-cell RNA sequencing (scRNA-seq) enables transcriptomic profiling at cellular resolution but suffers from pervasive dropout events that obscure biological signals. We present SCR-MF, a modular two-stage workflow that combines principled dropout detection using scRecover with robust non-parametric imputation via missForest. Across public and simulated datasets, SCR-MF achieves robust and interpretable performance comparable to or exceeding existing imputation methods in most cases, while preserving biological fidelity and transparency. Runtime analysis demonstrates that SCR-MF provides a competitive balance between accuracy and computational efficiency, making it suitable for mid-scale single-cell datasets.","authors":["Ali Anaissi","Deshao Liu","Yuanzhe Jia","Weidong Huang","Widad Alyassine","Junaid Akram"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16912v1","updated":"2025-11-21T02:51:15Z","published":"2025-11-21T02:51:15Z","title":"PepEVOLVE: Position-Aware Dynamic Peptide Optimization via Group-Relative Advantage","summary":"Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists to pre-specify mutable positions for optimization, choices that are not always known a priori, and rely on static pretraining and optimization algorithms that limit the model's ability to generalize and effectively optimize peptide sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that learns both where to edit and how to dynamically optimize peptides for multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic masking and CHUCKLES shifting to improve generalization, (ii) uses a context-free multi-armed bandit router that discovers high-reward residues, and (iii) couples a novel evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates. During in silico evaluations, the router policy reliably learns and concentrates probability on chemically meaningful sites that influence the peptide's properties. On a therapeutically motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under the task of optimizing permeability and lipophilicity with structural constraints. Overall, PepEVOLVE offers a practical, reproducible path to peptide lead optimization when optimal edit sites are unknown, enabling more efficient exploration and improving design quality across multiple objectives.","authors":["Trieu Nguyen","Hao-Wei Pang","Shasha Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16905v1","updated":"2025-11-21T02:37:30Z","published":"2025-11-21T02:37:30Z","title":"Predicting Talent Breakout Rate using Twitter and TV data","summary":"Early detection of rising talents is of paramount importance in the field of advertising. In this paper, we define a concept of talent breakout and propose a method to detect Japanese talents before their rise to stardom. The main focus of the study is to determine the effectiveness of combining Twitter and TV data on predicting time-dependent changes in social data. Although traditional time-series models are known to be robust in many applications, the success of neural network models in various fields (e.g.\\ Natural Language Processing, Computer Vision, Reinforcement Learning) continues to spark an interest in the time-series community to apply new techniques in practice. Therefore, in order to find the best modeling approach, we have experimented with traditional, neural network and ensemble learning methods. We observe that ensemble learning methods outperform traditional and neural network models based on standard regression metrics. However, by utilizing the concept of talent breakout, we are able to assess the true forecasting ability of the models, where neural networks outperform traditional and ensemble learning methods in terms of precision and recall.","authors":["Bilguun Batsaikhan","Hiroyuki Fukuda"],"pdf_url":"","comment":"4 pages. Presented at the 34th Annual Conference of the Japanese Society for Artificial Intelligence (JSAI 2020), paper ID 1K3-ES-2-02"},{"id":"http://arxiv.org/abs/2511.12797v2","updated":"2025-11-21T02:11:05Z","published":"2025-11-16T21:56:39Z","title":"Genomic Next-Token Predictors are In-Context Learners","summary":"In-context learning (ICL) -- the capacity of a model to infer and apply abstract patterns from examples provided within its input -- has been extensively studied in large language models trained for next-token prediction on human text. In fact, prior work often attributes this emergent behavior to distinctive statistical properties in human language. This raises a fundamental question: can ICL arise organically in other sequence domains purely through large-scale predictive training?\n  To explore this, we turn to genomic sequences, an alternative symbolic domain rich in statistical structure. Specifically, we study the Evo2 genomic model, trained predominantly on next-nucleotide (A/T/C/G) prediction, at a scale comparable to mid-sized LLMs. We develop a controlled experimental framework comprising symbolic reasoning tasks instantiated in both linguistic and genomic forms, enabling direct comparison of ICL across genomic and linguistic models. Our results show that genomic models, like their linguistic counterparts, exhibit log-linear gains in pattern induction as the number of in-context demonstrations increases. To the best of our knowledge, this is the first evidence of organically emergent ICL in genomic sequences, supporting the hypothesis that ICL arises as a consequence of large-scale predictive modeling over rich data. These findings extend emergent meta-learning beyond language, pointing toward a unified, modality-agnostic view of in-context learning.","authors":["Nathan Breslow","Aayush Mishra","Mahler Revsine","Michael C. Schatz","Anqi Liu","Daniel Khashabi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16886v1","updated":"2025-11-21T01:54:23Z","published":"2025-11-21T01:54:23Z","title":"Deep Improvement Supervision","summary":"Recently, it was shown that small, looped architectures, such as Tiny Recursive Models (TRMs), can outperform Large Language Models (LLMs) on complex reasoning tasks, including the Abstraction and Reasoning Corpus (ARC). In this work, we investigate a core question: how can we further improve the efficiency of these methods with minimal changes? To address this, we frame the latent reasoning of TRMs as a form of classifier-free guidance and implicit policy improvement algorithm. Building on these insights, we propose a novel training scheme that provides a target for each loop during training. We demonstrate that our approach significantly enhances training efficiency. Our method reduces the total number of forward passes by 18x and eliminates halting mechanisms, while maintaining quality comparable to standard TRMs. Notably, we achieve 24% accuracy on ARC-1 with only 0.8M parameters, outperforming most LLMs.","authors":["Arip Asadulaev","Rayan Banerjee","Fakhri Karray","Martin Takac"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.13614v2","updated":"2025-11-21T01:42:26Z","published":"2025-05-19T18:01:08Z","title":"Deterministic Bounds and Random Estimates of Metric Tensors on Neuromanifolds","summary":"The high dimensional parameter space of modern deep neural networks -- the neuromanifold -- is endowed with a unique metric tensor defined by the Fisher information, estimating which is crucial for both theory and practical methods in deep learning. To analyze this tensor for classification networks, we return to a low dimensional space of probability distributions -- the core space -- and carefully analyze the spectrum of its Riemannian metric. We extend our discoveries there into deterministic bounds of the metric tensor on the neuromanifold. We introduce an unbiased random estimate of the metric tensor and its bounds based on Hutchinson's trace estimator. It can be evaluated efficiently through a single backward pass, with a standard deviation bounded by the true value up to scaling.","authors":["Ke Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06609v2","updated":"2025-11-21T01:36:16Z","published":"2025-11-10T01:40:35Z","title":"A Weak Penalty Neural ODE for Learning Chaotic Dynamics from Noisy Time Series","summary":"Accurate forecasting of complex high-dimensional dynamical systems from observational data is essential for several applications across science and engineering. A key challenge, however, is that real-world measurements are often corrupted by noise, which severely degrades the performance of data-driven models. Particularly, in chaotic dynamical systems, where small errors amplify rapidly, it is challenging to identify a data-driven model from noisy data that achieves short-term accuracy while preserving long-term invariant properties. In this paper, we propose the use of the weak formulation as a complementary approach to the classical strong formulation of data-driven time-series forecasting models. Specifically, we focus on the neural ordinary differential equation (NODE) architecture. Unlike the standard strong formulation, which relies on the discretization of the NODE followed by optimization, the weak formulation constrains the model using a set of integrated residuals over temporal subdomains. While such a formulation yields an effective NODE model, we discover that the performance of a NODE can be further enhanced by employing this weak formulation as a penalty alongside the classical strong formulation-based learning. Through numerical demonstrations, we illustrate that our proposed training strategy, which we coined as the Weak-Penalty NODE (WP-NODE), achieves state-of-the-art forecasting accuracy and exceptional robustness across benchmark chaotic dynamical systems and real-world climate dataset.","authors":["Xuyang Li","John Harlim","Dibyajyoti Chakraborty","Romit Maulik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16883v1","updated":"2025-11-21T01:19:34Z","published":"2025-11-21T01:19:34Z","title":"PersonalizedRouter: Personalized LLM Routing via Graph-based User Preference Modeling","summary":"The growing number of Large Language Models (LLMs) with diverse capabilities and response styles provides users with a wider range of choices, which presents challenges in selecting appropriate LLMs, as user preferences vary in terms of performance, cost, and response style. Current LLM selection methods typically optimize for a single fixed objective, such as performance, cost, or a trade-off between them, and fail to learn individual user preferences from interaction data. To address these limitations, we propose PersonalizedRouter, a graph-based framework that models diverse user profiles and performs personalized LLM selection by leveraging interaction data that includes task context, queries, candidate LLMs, and user decisions. To capture contextual information between user queries and optimal LLMs, PersonalizedRouter converts the interaction data into a heterogeneous graph, where the relationships between different types of nodes are represented by edges. To evaluate adaptability across users, we design two strategies: the multi-cost-efficiency simulation strategy and the LLM-as-a-Judge strategy. In addition, we construct PersonaRoute-Bench, a large-scale benchmark with 1,000 simulated users and 10 LLMs. Experimental results show that PersonalizedRouter significantly outperforms existing LLM selection methods and surpasses the strongest methods by a large margin of 15.38% and 9.83% under two simulation strategies. On the PersonaRoute-Bench with 1,000 users, it further surpasses the best methods by 16.19% and 59.69% while maintaining higher efficiency. Moreover, PersonalizedRouter demonstrates strong few-shot generalization, achieving 64.81% and 85.80% of the fully trained model's performance when adapting to new users and new LLMs.","authors":["Zhongjie Dai","Tao Feng","Jiaxuan You"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.10518v2","updated":"2025-11-21T00:59:21Z","published":"2025-09-03T16:54:45Z","title":"Holographic Knowledge Manifolds: A Novel Pipeline for Continual Learning Without Catastrophic Forgetting in Large Language Models","summary":"We introduce the Holographic Knowledge Manifold (HKM), a four-phase pipeline that achieves zero catastrophic forgetting in AI knowledge representation while maintaining minimal memory growth and high efficiency. Leveraging fractal quantization, probabilistic entanglement, and dynamic diffraction chipping, HKM compresses knowledge substrates by 3x with 67% storage savings, integrates holographically at 100%, and supports over 1,020 updates with 1% growth per increment. In experiments on combined WikiText and FB15k datasets (scaled to 2,997 nodes), we demonstrate industry-leading performance: 0% forgetting (infinite improvement over GEM baselines), 3x compression, and 53% training time reduction on consumer GPU hardware. Hypothetical cost analyses project $92.4M savings over 5 years at petabyte scale, with 21.2% energy reduction and 33% lower carbon footprint. This work hypothesizes a paradigm shift for public large language models (LLMs), enabling \"eternal\" adaptation without retraining. Future extensions to multimodal fusion and quantum hardware could further democratize scalable AI, potentially reducing fine-tuning costs by 60-80% for models like Llama-3 or Grok-4. Code, datasets, and full results are publicly available for reproducibility.","authors":["Justin Arndt"],"pdf_url":"","comment":"This paper includes significant errors discovered post publication by the author"},{"id":"http://arxiv.org/abs/2507.01598v4","updated":"2025-11-21T00:56:01Z","published":"2025-07-02T11:03:13Z","title":"Convergence Bound and Critical Batch Size of Muon Optimizer","summary":"Muon, a recently proposed optimizer that leverages the inherent matrix structure of neural network parameters, has demonstrated strong empirical performance, indicating its potential as a successor to standard optimizers such as AdamW. This paper presents theoretical analysis to support its practical success. We provide convergence proofs for Muon across four practical settings, systematically examining its behavior with and without the inclusion of Nesterov momentum and weight decay. Our analysis covers the standard configuration using both, thereby elucidating its real-world performance. We then demonstrate that the addition of weight decay yields strictly tighter theoretical bounds and clarify the interplay between the weight decay coefficient and the learning rate. Finally, we derive the critical batch size for Muon that minimizes the computational cost of training. Our analysis identifies the hyperparameters governing this value, and our experiments validate the corresponding theoretical findings across workloads including image classification and language modeling task.","authors":["Naoki Sato","Hiroki Naganuma","Hideaki Iiduka"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16871v1","updated":"2025-11-21T00:43:14Z","published":"2025-11-21T00:43:14Z","title":"Topologic Attention Networks: Attending to Direct and Indirect Neighbors through Gaussian Belief Propagation","summary":"Graph Neural Networks rely on local message passing, which limits their ability to model long-range dependencies in graphs. Existing approaches extend this range through continuous-time dynamics or dense self-attention, but both suffer from high computational cost and limited scalability. We propose Topologic Attention Networks, a new framework that applies topologic attention, a probabilistic mechanism that learns how information should flow through both direct and indirect connections in a graph. Unlike conventional attention that depends on explicit pairwise interactions, topologic attention emerges from the learned information propagation of the graph, enabling unified reasoning over local and global relationships. This method achieves provides state-of-the-art performance across all measured baseline models. Our implementation is available at https://github.com/Marshall-Rosenhoover/Topologic-Attention-Networks.","authors":["Marshall Rosenhoover","Huaming Zhang"],"pdf_url":"","comment":"15 pages, 13 Figures"},{"id":"http://arxiv.org/abs/2511.16870v1","updated":"2025-11-21T00:37:04Z","published":"2025-11-21T00:37:04Z","title":"Align & Invert: Solving Inverse Problems with Diffusion and Flow-based Models via Representational Alignment","summary":"Enforcing alignment between the internal representations of diffusion or flow-based generative models and those of pretrained self-supervised encoders has recently been shown to provide a powerful inductive bias, improving both convergence and sample quality. In this work, we extend this idea to inverse problems, where pretrained generative models are employed as priors. We propose applying representation alignment (REPA) between diffusion or flow-based models and a pretrained self-supervised visual encoder, such as DINOv2, to guide the reconstruction process at inference time. Although ground-truth signals are unavailable in inverse problems, we show that aligning model representations with approximate target features can substantially enhance reconstruction fidelity and perceptual realism. We provide theoretical results showing (a) the relation between the REPA regularization and a divergence measure in the DINOv2 embedding space, and (b) how REPA updates steer the model's internal representations toward those of the clean image. These results offer insights into the role of REPA in improving perceptual fidelity. Finally, we demonstrate the generality of our approach by integrating it into multiple state-of-the-art inverse problem solvers. Extensive experiments on super-resolution, box inpainting, Gaussian deblurring, and motion deblurring confirm that our method consistently improves reconstruction quality across tasks, while also providing substantial efficiency gains by reducing the number of required discretization steps without compromising the performance of the underlying solver.","authors":["Loukas Sfountouris","Giannis Daras","Paris Giampouras"],"pdf_url":"","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2511.15846v2","updated":"2025-11-21T18:53:03Z","published":"2025-11-19T20:10:39Z","title":"The Loss of Control Playbook: Degrees, Dynamics, and Preparedness","summary":"This research report addresses the absence of an actionable definition for Loss of Control (LoC) in AI systems by developing a novel taxonomy and preparedness framework. Despite increasing policy and research attention, existing LoC definitions vary significantly in scope and timeline, hindering effective LoC assessment and mitigation. To address this issue, we draw from an extensive literature review and propose a graded LoC taxonomy, based on the metrics of severity and persistence, that distinguishes between Deviation, Bounded LoC, and Strict LoC. We model pathways toward a societal state of vulnerability in which sufficiently advanced AI systems have acquired or could acquire the means to cause Bounded or Strict LoC once a catalyst, either misalignment or pure malfunction, materializes. We argue that this state becomes increasingly likely over time, absent strategic intervention, and propose a strategy to avoid reaching a state of vulnerability. Rather than focusing solely on intervening on AI capabilities and propensities potentially relevant for LoC or on preventing potential catalysts, we introduce a complementary framework that emphasizes three extrinsic factors: Deployment context, Affordances, and Permissions (the DAP framework). Compared to work on intrinsic factors and catalysts, this framework has the unfair advantage of being actionable today. Finally, we put forward a plan to maintain preparedness and prevent the occurrence of LoC outcomes should a state of societal vulnerability be reached, focusing on governance measures (threat modeling, deployment policies, emergency response) and technical controls (pre-deployment testing, control measures, monitoring) that could maintain a condition of perennial suspension.","authors":["Charlotte Stix","Annika Hallensleben","Alejandro Ortega","Matteo Pistillo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15675v2","updated":"2025-11-21T18:28:30Z","published":"2025-11-19T18:18:53Z","title":"MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features","summary":"Depression is a prevalent global mental health disorder, characterised by persistent low mood and anhedonia. However, it remains underdiagnosed because current diagnostic methods depend heavily on subjective clinical assessments. To enable objective detection, we introduce a gold standard dataset of 103 clinically assessed participants collected through a tripartite data approach which uniquely integrated eye tracking data with audio and video to give a comprehensive representation of depressive symptoms. Eye tracking data quantifies the attentional bias towards negative stimuli that is frequently observed in depressed groups. Audio and video data capture the affective flattening and psychomotor retardation characteristic of depression. Statistical validation confirmed their significant discriminative power in distinguishing depressed from non depressed groups. We address a critical limitation of existing graph-based models that focus on low-frequency information and propose a Multi-Frequency Graph Convolutional Network (MF-GCN). This framework consists of a novel Multi-Frequency Filter Bank Module (MFFBM), which can leverage both low and high frequency signals. Extensive evaluation against traditional machine learning algorithms and deep learning frameworks demonstrates that MF-GCN consistently outperforms baselines. In binary classification, the model achieved a sensitivity of 0.96 and F2 score of 0.94. For the 3 class classification task, the proposed method achieved a sensitivity of 0.79 and specificity of 0.87 and siginificantly suprassed other models. To validate generalizability, the model was also evaluated on the Chinese Multimodal Depression Corpus (CMDC) dataset and achieved a sensitivity of 0.95 and F2 score of 0.96. These results confirm that our trimodal, multi frequency framework effectively captures cross modal interaction for accurate depression detection.","authors":["Sejuti Rahman","Swakshar Deb","MD. Sameer Iqbal Chowdhury","MD. Jubair Ahmed Sourov","Mohammad Shamsuddin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17477v1","updated":"2025-11-21T18:25:46Z","published":"2025-11-21T18:25:46Z","title":"Enhancing Quranic Learning: A Multimodal Deep Learning Approach for Arabic Phoneme Recognition","summary":"Recent advances in multimodal deep learning have greatly enhanced the capability of systems for speech analysis and pronunciation assessment. Accurate pronunciation detection remains a key challenge in Arabic, particularly in the context of Quranic recitation, where subtle phonetic differences can alter meaning. Addressing this challenge, the present study proposes a transformer-based multimodal framework for Arabic phoneme mispronunciation detection that combines acoustic and textual representations to achieve higher precision and robustness. The framework integrates UniSpeech-derived acoustic embeddings with BERT-based textual embeddings extracted from Whisper transcriptions, creating a unified representation that captures both phonetic detail and linguistic context. To determine the most effective integration strategy, early, intermediate, and late fusion methods were implemented and evaluated on two datasets containing 29 Arabic phonemes, including eight hafiz sounds, articulated by 11 native speakers. Additional speech samples collected from publicly available YouTube recordings were incorporated to enhance data diversity and generalization. Model performance was assessed using standard evaluation metrics: accuracy, precision, recall, and F1-score, allowing a detailed comparison of the fusion strategies. Experimental findings show that the UniSpeech-BERT multimodal configuration provides strong results and that fusion-based transformer architectures are effective for phoneme-level mispronunciation detection. The study contributes to the development of intelligent, speaker-independent, and multimodal Computer-Aided Language Learning (CALL) systems, offering a practical step toward technology-supported Quranic pronunciation training and broader speech-based educational applications.","authors":["Ayhan Kucukmanisa","Derya Gelmez","Sukru Selim Calik","Zeynep Hilal Kilimci"],"pdf_url":"","comment":"11 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.17473v1","updated":"2025-11-21T18:23:04Z","published":"2025-11-21T18:23:04Z","title":"Masked-and-Reordered Self-Supervision for Reinforcement Learning from Verifiable Rewards","summary":"Test-time scaling has been shown to substantially improve large language models' (LLMs) mathematical reasoning. However, for a large portion of mathematical corpora, especially theorem proving, RLVR's scalability is limited: intermediate reasoning is crucial, while final answers are difficult to directly and reliably verify. Meanwhile, token-level SFT often degenerates into rote memorization rather than inducing longer chains of thought. Inspired by BERT's self-supervised tasks, we propose MR-RLVR (Masked-and-Reordered RLVR), which constructs process-level self-supervised rewards via \"masked-then-fill\" and \"step reordering\" to extract learnable signals from intermediate reasoning. Our training pipeline comprises two stages: we first perform self-supervised training on sampled mathematical calculation and proof data; we then conduct RLVR fine-tuning on mathematical calculation datasets where only outcomes are verifiable. We implement MR-RLVR on Qwen2.5-3B and DeepSeek-R1-Distill-Qwen-1.5B, and evaluate on AIME24, AIME25, AMC23, and MATH500. Under a fixed sampling and decoding budget, MR-RLVR achieves average relative gains over the original RLVR of +9.86% Pass@1, +5.27% Pass@5, and +4.00% Pass@8. These results indicate that incorporating process-aware self-supervised signals can effectively enhance RLVR's scalability and performance in only outcome-verifiable settings.","authors":["Zhen Wang","Zhifeng Gao","Guolin Ke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.21651v2","updated":"2025-11-21T18:22:41Z","published":"2025-09-25T22:09:17Z","title":"Can AI Perceive Physical Danger and Intervene?","summary":"When AI interacts with the physical world -- as a robot or an assistive agent -- new safety challenges emerge beyond those of purely ``digital AI\". In such interactions, the potential for physical harm is direct and immediate. How well do state-of-the-art foundation models understand common-sense facts about physical safety, e.g. that a box may be too heavy to lift, or that a hot cup of coffee should not be handed to a child? In this paper, our contributions are three-fold: first, we develop a highly scalable approach to continuous physical safety benchmarking of Embodied AI systems, grounded in real-world injury narratives and operational safety constraints. To probe multi-modal safety understanding, we turn these narratives and constraints into photorealistic images and videos capturing transitions from safe to unsafe states, using advanced generative models. Secondly, we comprehensively analyze the ability of major foundation models to perceive risks, reason about safety, and trigger interventions; this yields multi-faceted insights into their deployment readiness for safety-critical agentic applications. Finally, we develop a post-training paradigm to teach models to explicitly reason about embodiment-specific safety constraints provided through system instructions. The resulting models generate thinking traces that make safety reasoning interpretable and transparent, achieving state of the art performance in constraint satisfaction evaluations. The benchmark is released at https://asimov-benchmark.github.io/v2","authors":["Abhishek Jindal","Dmitry Kalashnikov","R. Alex Hofer","Oscar Chang","Divya Garikapati","Anirudha Majumdar","Pierre Sermanet","Vikas Sindhwani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17467v1","updated":"2025-11-21T18:15:47Z","published":"2025-11-21T18:15:47Z","title":"PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM","summary":"We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's \"persona\" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F","authors":["Siqi Liang","Yudi Zhang","Yue Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.10577v2","updated":"2025-11-21T18:14:10Z","published":"2025-09-11T18:08:32Z","title":"The Coding Limits of Robust Watermarking for Generative Models","summary":"We ask a basic question about cryptographic watermarking for generative models: to what extent can a watermark remain reliable when an adversary is allowed to corrupt the encoded signal? To study this question, we introduce a minimal coding abstraction that we call a zero-bit tamper-detection code. This is a secret-key procedure that samples a pseudorandom codeword and, given a candidate word, decides whether it should be treated as unmarked content or as the result of tampering with a valid codeword. It captures the two core requirements of robust watermarking: soundness and tamper detection.\n  Within this abstraction we prove a sharp unconditional limit on robustness to independent symbol corruption. For an alphabet of size $q$, there is a critical corruption rate of $1 - 1/q$ such that no scheme with soundness, even relaxed to allow a fixed constant false positive probability on random content, can reliably detect tampering once an adversary can change more than this fraction of symbols. In particular, in the binary case no cryptographic watermark can remain robust if more than half of the encoded bits are modified. We also show that this threshold is tight by giving simple information-theoretic constructions that achieve soundness and tamper detection for all strictly smaller corruption rates.\n  We then test experimentally whether this limit appears in practice by looking at the recent watermarking for images of Gunn, Zhao, and Song (ICLR 2025). We show that a simple crop and resize operation reliably flipped about half of the latent signs and consistently prevented belief-propagation decoding from recovering the codeword, erasing the watermark while leaving the image visually intact.","authors":["Danilo Francati","Yevin Nikhel Goonatilake","Shubham Pawar","Daniele Venturi","Giuseppe Ateniese"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17461v1","updated":"2025-11-21T18:03:48Z","published":"2025-11-21T18:03:48Z","title":"SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception","summary":"Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.","authors":["Jiaxi Liu","Chengyuan Ma","Hang Zhou","Weizhe Tang","Shixiao Liang","Haoyang Ding","Xiaopeng Li","Bin Ran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17450v1","updated":"2025-11-21T17:48:02Z","published":"2025-11-21T17:48:02Z","title":"Planning with Sketch-Guided Verification for Physics-Aware Video Generation","summary":"Recent video generation approaches increasingly rely on planning intermediate control signals such as object trajectories to improve temporal coherence and motion fidelity. However, these methods mostly employ single-shot plans that are typically limited to simple motions, or iterative refinement which requires multiple calls to the video generator, incuring high computational cost. To overcome these limitations, we propose SketchVerify, a training-free, sketch-verification-based planning framework that improves motion planning quality with more dynamically coherent trajectories (i.e., physically plausible and instruction-consistent motions) prior to full video generation by introducing a test-time sampling and verification loop. Given a prompt and a reference image, our method predicts multiple candidate motion plans and ranks them using a vision-language verifier that jointly evaluates semantic alignment with the instruction and physical plausibility. To efficiently score candidate motion plans, we render each trajectory as a lightweight video sketch by compositing objects over a static background, which bypasses the need for expensive, repeated diffusion-based synthesis while achieving comparable performance. We iteratively refine the motion plan until a satisfactory one is identified, which is then passed to the trajectory-conditioned generator for final synthesis. Experiments on WorldModelBench and PhyWorldBench demonstrate that our method significantly improves motion quality, physical realism, and long-term consistency compared to competitive baselines while being substantially more efficient. Our ablation study further shows that scaling up the number of trajectory candidates consistently enhances overall performance.","authors":["Yidong Huang","Zun Wang","Han Lin","Dong-Ki Kim","Shayegan Omidshafiei","Jaehong Yoon","Yue Zhang","Mohit Bansal"],"pdf_url":"","comment":"website: https://sketchverify.github.io/"},{"id":"http://arxiv.org/abs/2511.17443v1","updated":"2025-11-21T17:42:09Z","published":"2025-11-21T17:42:09Z","title":"GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity","summary":"Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing AI-based systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.","authors":["Joana Rovira Martins","Pedro Martins","Ana Boavida"],"pdf_url":"","comment":"20 pages, 16 figures"},{"id":"http://arxiv.org/abs/2406.03283v2","updated":"2025-11-21T17:41:45Z","published":"2024-06-05T13:56:42Z","title":"CATCODER: Repository-Level Code Generation with Relevant Code and Type Context","summary":"Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, repository-level code generation presents unique challenges, particularly due to the need to utilize information spread across multiple files within a repository. Specifically, successful generation depends on a solid grasp of both general, context-agnostic knowledge and specific, context-dependent knowledge. While LLMs are widely used for the context-agnostic aspect, existing retrieval-based approaches sometimes fall short as they are limited in obtaining a broader and deeper repository context. In this paper, we present CatCoder, a novel code generation framework designed for statically typed programming languages. CatCoder enhances repository-level code generation by integrating relevant code and type context. Specifically, it leverages static analyzers to extract type dependencies and merges this information with retrieved code to create comprehensive prompts for LLMs. To evaluate the effectiveness of CatCoder, we adapt and construct benchmarks that include 199 Java tasks and 90 Rust tasks. The results show that CatCoder outperforms the RepoCoder baseline by up to 14.44% and 17.35%, in terms of compile@k and pass@k scores. In addition, the generalizability of CatCoder is assessed using various LLMs, including both code-specialized models and general-purpose models. Our findings indicate consistent performance improvements across all models, which underlines the practicality of CatCoder. Furthermore, we evaluate the time consumption of CatCoder in a large open source repository, and the results demonstrate the scalability of CatCoder.","authors":["Zhiyuan Pan","Xing Hu","Xin Xia","Xiaohu Yang"],"pdf_url":"","comment":"Revised and extended version; To be published in ACM Transactions on Software Engineering and Methodology"},{"id":"http://arxiv.org/abs/2511.17442v1","updated":"2025-11-21T17:41:26Z","published":"2025-11-21T17:41:26Z","title":"REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing","summary":"Foundation Models (FMs) are increasingly used in remote sensing (RS) for tasks such as environmental monitoring, disaster assessment, and land-use mapping. These models include unimodal vision encoders trained on a single data modality and multimodal architectures trained on combinations of SAR, multispectral, hyperspectral, and image-text data. They support diverse RS tasks including semantic segmentation, image classification, change detection, and visual question answering. However, selecting an appropriate remote sensing foundation model (RSFM) remains difficult due to scattered documentation, heterogeneous formats, and varied deployment constraints. We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms. Built on RS-FMD, we present REMSA, the first LLM-based agent for automated RSFM selection from natural language queries. REMSA interprets user requirements, resolves missing constraints, ranks candidate models using in-context learning, and provides transparent justifications. We also propose a benchmark of 75 expert-verified RS query scenarios, producing 900 configurations under an expert-centered evaluation protocol. REMSA outperforms several baselines, including naive agents, dense retrieval, and unstructured RAG-based LLMs. It operates entirely on publicly available metadata and does not access private or sensitive data.","authors":["Binger Chen","Tacettin Emre Bök","Behnood Rasti","Volker Markl","Begüm Demir"],"pdf_url":"","comment":"Code and data available at https://github.com/be-chen/REMSA"},{"id":"http://arxiv.org/abs/2511.17439v1","updated":"2025-11-21T17:36:12Z","published":"2025-11-21T17:36:12Z","title":"InTAct: Interval-based Task Activation Consolidation for Continual Learning","summary":"Continual learning aims to enable neural networks to acquire new knowledge without forgetting previously learned information. While recent prompt-based methods perform strongly in class-incremental settings, they remain vulnerable under domain shifts, where the input distribution changes but the label space remains fixed. This exposes a persistent problem known as representation drift. Shared representations evolve in ways that overwrite previously useful features and cause forgetting even when prompts isolate task-specific parameters. To address this issue, we introduce InTAct, a method that preserves functional behavior in shared layers without freezing parameters or storing past data. InTAct captures the characteristic activation ranges associated with previously learned tasks and constrains updates to ensure the network remains consistent within these regions, while still allowing for flexible adaptation elsewhere. In doing so, InTAct stabilizes the functional role of important neurons rather than directly restricting parameter values. The approach is architecture-agnostic and integrates seamlessly into existing prompt-based continual learning frameworks. By regulating representation changes where past knowledge is encoded, InTAct achieves a principled balance between stability and plasticity. Across diverse domain-incremental benchmarks, including DomainNet and ImageNet-R, InTAct consistently reduces representation drift and improves performance, increasing Average Accuracy by up to 8 percentage points over state-of-the-art baselines.","authors":["Patryk Krukowski","Jan Miksa","Piotr Helm","Jacek Tabor","Paweł Wawrzyński","Przemysław Spurek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17432v1","updated":"2025-11-21T17:30:18Z","published":"2025-11-21T17:30:18Z","title":"SMILE: A Composite Lexical-Semantic Metric for Question-Answering Evaluation","summary":"Traditional evaluation metrics for textual and visual question answering, like ROUGE, METEOR, and Exact Match (EM), focus heavily on n-gram based lexical similarity, often missing the deeper semantic understanding needed for accurate assessment. While measures like BERTScore and MoverScore leverage contextual embeddings to address this limitation, they lack flexibility in balancing sentence-level and keyword-level semantics and ignore lexical similarity, which remains important. Large Language Model (LLM) based evaluators, though powerful, come with drawbacks like high costs, bias, inconsistency, and hallucinations. To address these issues, we introduce SMILE: Semantic Metric Integrating Lexical Exactness, a novel approach that combines sentence-level semantic understanding with keyword-level semantic understanding and easy keyword matching. This composite method balances lexical precision and semantic relevance, offering a comprehensive evaluation. Extensive benchmarks across text, image, and video QA tasks show SMILE is highly correlated with human judgments and computationally lightweight, bridging the gap between lexical and semantic evaluation.","authors":["Shrikant Kendre","Austin Xu","Honglu Zhou","Michael Ryoo","Shafiq Joty","Juan Carlos Niebles"],"pdf_url":"","comment":"23 pages, 6 tables, 9 figures"},{"id":"http://arxiv.org/abs/2511.13646v2","updated":"2025-11-21T17:22:32Z","published":"2025-11-17T17:58:18Z","title":"Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?","summary":"Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that LIVE-SWE-AGENT can achieve an impressive solve rate of 77.4% without test-time scaling, outperforming all existing software agents, including the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%.","authors":["Chunqiu Steven Xia","Zhe Wang","Yan Yang","Yuxiang Wei","Lingming Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17421v1","updated":"2025-11-21T17:18:35Z","published":"2025-11-21T17:18:35Z","title":"Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers","summary":"Deep learning models are prone to learning shortcut solutions to problems using spuriously correlated yet irrelevant features of their training data. In high-risk applications such as medical image analysis, this phenomenon may prevent models from using clinically meaningful features when making predictions, potentially leading to poor robustness and harm to patients. We demonstrate that different types of shortcuts (those that are diffuse and spread throughout the image, as well as those that are localized to specific areas) manifest distinctly across network layers and can, therefore, be more effectively targeted through mitigation strategies that target the intermediate layers. We propose a novel knowledge distillation framework that leverages a teacher network fine-tuned on a small subset of task-relevant data to mitigate shortcut learning in a student network trained on a large dataset corrupted with a bias feature. Through extensive experiments on CheXpert, ISIC 2017, and SimBA datasets using various architectures (ResNet-18, AlexNet, DenseNet-121, and 3D CNNs), we demonstrate consistent improvements over traditional Empirical Risk Minimization, augmentation-based bias-mitigation, and group-based bias-mitigation approaches. In many cases, we achieve comparable performance with a baseline model trained on bias-free data, even on out-of-distribution test data. Our results demonstrate the practical applicability of our approach to real-world medical imaging scenarios where bias annotations are limited and shortcut features are difficult to identify a priori.","authors":["Christopher Boland","Sotirios Tsaftaris","Sonia Dahdouh"],"pdf_url":"","comment":"Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:020"},{"id":"http://arxiv.org/abs/2511.17419v1","updated":"2025-11-21T17:17:51Z","published":"2025-11-21T17:17:51Z","title":"DS-Span: Single-Phase Discriminative Subgraph Mining for Efficient Graph Embeddings","summary":"Graph representation learning seeks to transform complex, high-dimensional graph structures into compact vector spaces that preserve both topology and semantics. Among the various strategies, subgraph-based methods provide an interpretable bridge between symbolic pattern discovery and continuous embedding learning. Yet, existing frequent or discriminative subgraph mining approaches often suffer from redundant multi-phase pipelines, high computational cost, and weak coupling between mined structures and their discriminative relevance. We propose DS-Span, a single-phase discriminative subgraph mining framework that unifies pattern growth, pruning, and supervision-driven scoring within one traversal of the search space. DS-Span introduces a coverage-capped eligibility mechanism that dynamically limits exploration once a graph is sufficiently represented, and an information-gain-guided selection that promotes subgraphs with strong class-separating ability while minimizing redundancy. The resulting subgraph set serves as an efficient, interpretable basis for downstream graph embedding and classification. Extensive experiments across benchmarks demonstrate that DS-Span generates more compact and discriminative subgraph features than prior multi-stage methods, achieving higher or comparable accuracy with significantly reduced runtime. These results highlight the potential of unified, single-phase discriminative mining as a foundation for scalable and interpretable graph representation learning.","authors":["Yeamin Kaiser","Muhammed Tasnim Bin Anwar","Bholanath Das","Chowdhury Farhan Ahmed","Md. Tanvir Alam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17408v1","updated":"2025-11-21T17:08:48Z","published":"2025-11-21T17:08:48Z","title":"That's not natural: The Impact of Off-Policy Training Data on Probe Performance","summary":"Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.","authors":["Nathalie Kirch","Samuel Dower","Adrians Skapars","Ekdeep Singh Lubana","Dmitrii Krasheninnikov"],"pdf_url":"","comment":"10 pages, EurIPS 2025 Workshop on Private AI Governance"},{"id":"http://arxiv.org/abs/2511.17405v1","updated":"2025-11-21T17:06:37Z","published":"2025-11-21T17:06:37Z","title":"Beyond Multiple Choice: A Hybrid Framework for Unifying Robust Evaluation and Verifiable Reasoning Training","summary":"Multiple-choice question answering (MCQA) has been a popular format for evaluating and reinforcement fine-tuning (RFT) of modern multimodal language models. Its constrained output format allows for simplified, deterministic automatic verification. However, we find that the options may leak exploitable signals, which makes the accuracy metrics unreliable for indicating real capabilities and encourages explicit or implicit answer guessing behaviors during RFT. We propose ReVeL (Rewrite and Verify by LLM), a framework that rewrites multiple-choice questions into open-form questions while keeping answers verifiable whenever possible. The framework categorizes questions according to different answer types, apply different rewriting and verification schemes, respectively. When applied for RFT, we converted 20k MCQA examples and use GRPO to finetune Qwen2.5-VL models. Models trained on ReVeL-OpenQA match MCQA accuracy on multiple-choice benchmarks and improve OpenQA accuracy by about six percentage points, indicating better data efficiency and more robust reward signals than MCQA-based training. When used for evaluation, ReVeL also reveals up to 20 percentage points of score inflation in MCQA benchmarks (relative to OpenQA), improves judging accuracy, and reduces both cost and latency. We will release code and data publicly.","authors":["Yesheng Liu","Hao Li","Haiyu Xu","Baoqi Pei","Jiahao Wang","Mingxuan Zhao","Jingshu Zheng","Zheqi He","JG Yao","Bowen Qin","Xi Yang","Jiajun Zhang"],"pdf_url":"","comment":"Project url: https://flageval-baai.github.io/ReVeL/"},{"id":"http://arxiv.org/abs/2511.17400v1","updated":"2025-11-21T17:00:02Z","published":"2025-11-21T17:00:02Z","title":"Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?","summary":"Vision Transformers ($\\text{ViTs}$) have become the backbone of vision foundation models, yet their optimization for multi-channel domains - such as cell painting or satellite imagery - remains underexplored. A key challenge in these domains is capturing interactions between channels, as each channel carries different information. While existing works have shown efficacy by treating each channel independently during tokenization, this approach naturally introduces a major computational bottleneck in the attention block - channel-wise comparisons leads to a quadratic growth in attention, resulting in excessive $\\text{FLOPs}$ and high training cost. In this work, we shift focus from efficacy to the overlooked efficiency challenge in cross-channel attention and ask: \"Is it necessary to model all channel interactions?\". Inspired by the philosophy of Sparse Mixture-of-Experts ($\\text{MoE}$), we propose MoE-ViT, a Mixture-of-Experts architecture for multi-channel images in $\\text{ViTs}$, which treats each channel as an expert and employs a lightweight router to select only the most relevant experts per patch for attention. Proof-of-concept experiments on real-world datasets - JUMP-CP and So2Sat - demonstrate that $\\text{MoE-ViT}$ achieves substantial efficiency gains without sacrificing, and in some cases enhancing, performance, making it a practical and attractive backbone for multi-channel imaging.","authors":["Sukwon Yun","Heming Yao","Burkhard Hoeckendorf","David Richmond","Aviv Regev","Russell Littman"],"pdf_url":"","comment":"This has been accepted at the NeurIPS AI4Science Workshop 2025"},{"id":"http://arxiv.org/abs/2506.08255v3","updated":"2025-11-21T16:58:45Z","published":"2025-06-09T21:43:56Z","title":"SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense","summary":"Continual learning under adversarial conditions remains an open problem, as existing methods often compromise either robustness, scalability, or both. We propose a novel framework that integrates Interval Bound Propagation (IBP) with a hypernetwork-based architecture to enable certifiably robust continual learning across sequential tasks. Our method, SHIELD, generates task-specific model parameters via a shared hypernetwork conditioned solely on compact task embeddings, eliminating the need for replay buffers or full model copies and enabling efficient over time. To further enhance robustness, we introduce Interval MixUp, a novel training strategy that blends virtual examples represented as $\\ell_{\\infty}$ balls centered around MixUp points. Leveraging interval arithmetic, this technique guarantees certified robustness while mitigating the wrapping effect, resulting in smoother decision boundaries. We evaluate SHIELD under strong white-box adversarial attacks, including PGD and AutoAttack, across multiple benchmarks. It consistently outperforms existing robust continual learning methods, achieving state-of-the-art average accuracy while maintaining both scalability and certification. These results represent a significant step toward practical and theoretically grounded continual learning in adversarial settings.","authors":["Patryk Krukowski","Łukasz Gorczyca","Piotr Helm","Kamil Książek","Przemysław Spurek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02969v2","updated":"2025-11-21T16:56:52Z","published":"2025-11-04T20:22:58Z","title":"Value of Information-Enhanced Exploration in Bootstrapped DQN","summary":"Efficient exploration in deep reinforcement learning remains a fundamental challenge, especially in environments characterized by high-dimensional states and sparse rewards. Traditional exploration strategies that rely on random local policy noise, such as $ε$-greedy and Boltzmann exploration methods, often struggle to efficiently balance exploration and exploitation. In this paper, we integrate the notion of (expected) value of information (EVOI) within the well-known Bootstrapped DQN algorithmic framework, to enhance the algorithm's deep exploration ability. Specifically, we develop two novel algorithms that incorporate the expected gain from learning the value of information into Bootstrapped DQN. Our methods use value of information estimates to measure the discrepancies of opinions among distinct network heads, and drive exploration towards areas with the most potential. We evaluate our algorithms with respect to performance and their ability to exploit inherent uncertainty arising from random network initialization. Our experiments in complex, sparse-reward Atari games demonstrate increased performance, all the while making better use of uncertainty, and, importantly, without introducing extra hyperparameters.","authors":["Stergios Plataniotis","Charilaos Akasiadis","Georgios Chalkiadakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17393v1","updated":"2025-11-21T16:53:08Z","published":"2025-11-21T16:53:08Z","title":"Designing and Generating Diverse, Equitable Face Image Datasets for Face Verification Tasks","summary":"Face verification is a significant component of identity authentication in various applications including online banking and secure access to personal devices. The majority of the existing face image datasets often suffer from notable biases related to race, gender, and other demographic characteristics, limiting the effectiveness and fairness of face verification systems. In response to these challenges, we propose a comprehensive methodology that integrates advanced generative models to create varied and diverse high-quality synthetic face images. This methodology emphasizes the representation of a diverse range of facial traits, ensuring adherence to characteristics permissible in identity card photographs. Furthermore, we introduce the Diverse and Inclusive Faces for Verification (DIF-V) dataset, comprising 27,780 images of 926 unique identities, designed as a benchmark for future research in face verification. Our analysis reveals that existing verification models exhibit biases toward certain genders and races, and notably, applying identity style modifications negatively impacts model performance. By tackling the inherent inequities in existing datasets, this work not only enriches the discussion on diversity and ethics in artificial intelligence but also lays the foundation for developing more inclusive and reliable face verification technologies","authors":["Georgia Baltsou","Ioannis Sarridis","Christos Koutlis","Symeon Papadopoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.18777v3","updated":"2025-11-21T16:41:05Z","published":"2025-04-26T03:09:54Z","title":"Evaluating AI-Driven Automated Map Digitization in QGIS","summary":"Map digitization is an important process that converts maps into digital formats that can be used for further analysis. This process typically requires a deep human involvement because of the need for interpretation and decision-making when translating complex features. With the advancement of artificial intelligence, there is an alternative to conducting map digitization with the help of machine learning techniques. Deepness, or Deep Neural Remote Sensing, is an advanced AI-driven tool designed and integrated as a plugin in QGIS application. This research focuses on assessing the effectiveness of Deepness in automated digitization. This study analyses AI-generated digitization results from Google Earth imagery and compares them with digitized outputs from OpenStreetMap (OSM) to evaluate performance.","authors":["Diana Febrita"],"pdf_url":"","comment":"Presented at the 2025 Indiana Geographic Information Council (IGIC) Conference"},{"id":"http://arxiv.org/abs/2511.17372v1","updated":"2025-11-21T16:37:18Z","published":"2025-11-21T16:37:18Z","title":"Quantum Masked Autoencoders for Vision Learning","summary":"Classical autoencoders are widely used to learn features of input data. To improve the feature learning, classical masked autoencoders extend classical autoencoders to learn the features of the original input sample in the presence of masked-out data. While quantum autoencoders exist, there is no design and implementation of quantum masked autoencoders that can leverage the benefits of quantum computing and quantum autoencoders. In this paper, we propose quantum masked autoencoders (QMAEs) that can effectively learn missing features of a data sample within quantum states instead of classical embeddings. We showcase that our QMAE architecture can learn the masked features of an image and can reconstruct the masked input image with improved visual fidelity in MNIST images. Experimental evaluation highlights that QMAE can significantly outperform (12.86% on average) in classification accuracy compared to state-of-the-art quantum autoencoders in the presence of masks.","authors":["Emma Andrews","Prabhat Mishra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.10998v3","updated":"2025-11-21T16:31:02Z","published":"2025-07-15T05:34:44Z","title":"Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data","summary":"Adversarial attacks on tabular data present unique challenges due to the heterogeneous nature of mixed categorical and numerical features. Unlike images where pixel perturbations maintain visual similarity, tabular data lacks intuitive similarity metrics, making it difficult to define imperceptible modifications. Additionally, traditional gradient-based methods prioritise $\\ell_p$-norm constraints, often producing adversarial examples that deviate from the original data distributions. To address this, we propose a latent-space perturbation framework using a mixed-input Variational Autoencoder (VAE) to generate statistically consistent adversarial examples. The proposed VAE integrates categorical embeddings and numerical features into a unified latent manifold, enabling perturbations that preserve statistical consistency. We introduce In-Distribution Success Rate (IDSR) to jointly evaluate attack effectiveness and distributional alignment. Evaluation across six publicly available datasets and three model architectures demonstrates that our method achieves substantially lower outlier rates and more consistent performance compared to traditional input-space attacks and other VAE-based methods adapted from image domain approaches, achieving substantially lower outlier rates and higher IDSR across six datasets and three model architectures. Our comprehensive analyses of hyperparameter sensitivity, sparsity control, and generative architecture demonstrate that the effectiveness of VAE-based attacks depends strongly on reconstruction quality and the availability of sufficient training data. When these conditions are met, the proposed framework achieves superior practical utility and stability compared with input-space methods. This work underscores the importance of maintaining on-manifold perturbations for generating realistic and robust adversarial examples in tabular domains.","authors":["Zhipeng He","Alexander Stevens","Chun Ouyang","Johannes De Smedt","Alistair Barros","Catarina Moreira"],"pdf_url":"","comment":"Final Version"},{"id":"http://arxiv.org/abs/2511.17332v1","updated":"2025-11-21T15:54:44Z","published":"2025-11-21T15:54:44Z","title":"Agentifying Agentic AI","summary":"Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.","authors":["Virginia Dignum","Frank Dignum"],"pdf_url":"","comment":"10 pages; 1 figure"},{"id":"http://arxiv.org/abs/2505.11289v2","updated":"2025-11-21T15:53:08Z","published":"2025-05-16T14:24:03Z","title":"Meta-World+: An Improved, Standardized, RL Benchmark","summary":"Meta-World is widely used for evaluating multi-task and meta-reinforcement learning agents, which are challenged to master diverse skills simultaneously. Since its introduction however, there have been numerous undocumented changes which inhibit a fair comparison of algorithms. This work strives to disambiguate these results from the literature, while also leveraging the past versions of Meta-World to provide insights into multi-task and meta-reinforcement learning benchmark design. Through this process we release a new open-source version of Meta-World (https://github.com/Farama-Foundation/Metaworld/) that has full reproducibility of past results, is more technically ergonomic, and gives users more control over the tasks that are included in a task set.","authors":["Reginald McLean","Evangelos Chatzaroulas","Luc McCutcheon","Frank Röder","Tianhe Yu","Zhanpeng He","K. R. Zentner","Ryan Julian","J K Terry","Isaac Woungang","Nariman Farsad","Pablo Samuel Castro"],"pdf_url":"","comment":"Accepted at NeurIPs 2025, Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2511.17331v1","updated":"2025-11-21T15:52:44Z","published":"2025-11-21T15:52:44Z","title":"AI Workers, Geopolitics, and Algorithmic Collective Action","summary":"According to the theory of International Political Economy (IPE), states are often incentivized to rely on rather than constrain powerful corporations. For this reason, IPE provides a useful lens to explain why efforts to govern Artificial Intelligence (AI) at the international and national levels have thus far been developed, applied, and enforced unevenly. Building on recent work that explores how AI companies engage in geopolitics, this position paper argues that some AI workers can be considered actors of geopolitics. It makes the timely case that governance alone cannot ensure responsible, ethical, or robust AI development and use, and greater attention should be paid to bottom-up interventions at the site of AI development. AI workers themselves should be situated as individual agents of change, especially when considering their potential to foster Algorithmic Collective Action (ACA). Drawing on methods of Participatory Design (PD), this paper proposes engaging AI workers as sources of knowledge, relative power, and intentionality to encourage more responsible and just AI development and create the conditions that can facilitate ACA.","authors":["Sydney Reis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17323v1","updated":"2025-11-21T15:43:27Z","published":"2025-11-21T15:43:27Z","title":"MusicAIR: A Multimodal AI Music Generation Framework Powered by an Algorithm-Driven Core","summary":"Recent advances in generative AI have made music generation a prominent research focus. However, many neural-based models rely on large datasets, raising concerns about copyright infringement and high-performance costs. In contrast, we propose MusicAIR, an innovative multimodal AI music generation framework powered by a novel algorithm-driven symbolic music core, effectively mitigating copyright infringement risks. The music core algorithms connect critical lyrical and rhythmic information to automatically derive musical features, creating a complete, coherent melodic score solely from the lyrics. The MusicAIR framework facilitates music generation from lyrics, text, and images. The generated score adheres to established principles of music theory, lyrical structure, and rhythmic conventions. We developed Generate AI Music (GenAIM), a web tool using MusicAIR for lyric-to-song, text-to-music, and image-to-music generation. In our experiments, we evaluated AI-generated music scores produced by the system using both standard music metrics and innovative analysis that compares these compositions with original works. The system achieves an average key confidence of 85%, outperforming human composers at 79%, and aligns closely with established music theory standards, demonstrating its ability to generate diverse, human-like compositions. As a co-pilot tool, GenAIM can serve as a reliable music composition assistant and a possible educational composition tutor while simultaneously lowering the entry barrier for all aspiring musicians, which is innovative and significantly contributes to AI for music generation.","authors":["Callie C. Liao","Duoduo Liao","Ellie L. Zhang"],"pdf_url":"","comment":"Accepted by IEEE Big Data 2025"},{"id":"http://arxiv.org/abs/2511.17318v1","updated":"2025-11-21T15:36:41Z","published":"2025-11-21T15:36:41Z","title":"FORWARD: Dataset of a forwarder operating in rough terrain","summary":"We present FORWARD, a high-resolution multimodal dataset of a cut-to-length forwarder operating in rough terrain on two harvest sites in the middle part of Sweden. The forwarder is a large Komatsu model equipped with a variety of sensors, including RTK-GNSS, 360-camera, operator vibration sensors, internal CAN-bus signal recording, and multiple IMUs. The data includes event time logs recorded in 5 Hz with e.g., driving speed, fuel consumption, vehicle position with centimeter accuracy, and crane use while the vehicle operates in forest areas laser-scanned with very high-resolution, $\\sim$1500 points per square meter. Production log files (StanForD standard) with time-stamped machine events, extensive video material, and terrain data in various formats are included as well. About 18 hours of regular wood extraction work during three days is annotated from 360-video material into individual work elements and included in the dataset. We also include scenario specifications of conducted experiments on forest roads and in terrain. Scenarios include repeatedly driving the same routes with and without steel tracks, different load weight, and different target driving speeds. The dataset is intended for developing models and algorithms for trafficability, perception, and autonomous control of forest machines using artificial intelligence, simulation, and experiments on physical testbeds. In part, we focus on forwarders traversing terrain, avoiding obstacles, and loading or unloading logs, with consideration for efficiency, fuel consumption, safety, and environmental impact. Other benefits of the open dataset include the ability to explore auto-generation and calibration of forestry machine simulators and automation scenario descriptions using the data recorded in the field.","authors":["Mikael Lundbäck","Erik Wallin","Carola Häggström","Mattias Nyström","Andreas Grönlund","Mats Richardson","Petrus Jönsson","William Arnvik","Lucas Hedström","Arvid Fälldin","Martin Servin"],"pdf_url":"","comment":"25 pages, 22 figures"},{"id":"http://arxiv.org/abs/2507.04224v3","updated":"2025-11-21T15:33:14Z","published":"2025-07-06T03:28:24Z","title":"Fairness Evaluation of Large Language Models in Academic Library Reference Services","summary":"As libraries explore large language models (LLMs) for use in virtual reference services, a key question arises: Can LLMs serve all users equitably, regardless of demographics or social status? While they offer great potential for scalable support, LLMs may also reproduce societal biases embedded in their training data, risking the integrity of libraries' commitment to equitable service. To address this concern, we evaluate whether LLMs differentiate responses across user identities by prompting six state-of-the-art LLMs to assist patrons differing in sex, race/ethnicity, and institutional role. We find no evidence of differentiation by race or ethnicity, and only minor evidence of stereotypical bias against women in one model. LLMs demonstrate nuanced accommodation of institutional roles through the use of linguistic choices related to formality, politeness, and domain-specific vocabularies, reflecting professional norms rather than discriminatory treatment. These findings suggest that current LLMs show a promising degree of readiness to support equitable and contextually appropriate communication in academic library reference services.","authors":["Haining Wang","Jason Clark","Yueru Yan","Star Bradley","Ruiyang Chen","Yiqiong Zhang","Hengyi Fu","Zuoyu Tian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.22397v5","updated":"2025-11-21T15:31:44Z","published":"2025-06-27T17:10:43Z","title":"HazeMatching: Dehazing Light Microscopy Images with Guided Conditional Flow Matching","summary":"Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 11 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.","authors":["Anirban Ray"," Ashesh","Florian Jug"],"pdf_url":"","comment":"4 figures, 8 pages + refs, 45 pages total (including supplement), 28 supplementary figures"},{"id":"http://arxiv.org/abs/2511.16544v2","updated":"2025-11-21T15:29:43Z","published":"2025-11-20T16:59:20Z","title":"WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue","summary":"As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA through DSPy to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.","authors":["Zachary Ellis","Jared Joselowitz","Yash Deo","Yajie He","Anna Kalygina","Aisling Higham","Mana Rahimzadeh","Yan Jia","Ibrahim Habli","Ernest Lim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17309v1","updated":"2025-11-21T15:25:47Z","published":"2025-11-21T15:25:47Z","title":"MuM: Multi-View Masked Image Modeling for 3D Vision","summary":"Self-supervised learning on images seeks to extract meaningful visual representations from unlabeled data. When scaled to large datasets, this paradigm has achieved state-of-the-art performance and the resulting trained models such as DINOv3 have seen widespread adoption. However, most prior efforts are optimized for semantic understanding rather than geometric reasoning. One important exception is Cross-View Completion, CroCo, which is a form of masked autoencoding (MAE) tailored for 3D understanding. In this work, we continue on the path proposed by CroCo and focus on learning features tailored for 3D vision. In a nutshell, we extend MAE to arbitrarily many views of the same scene. By uniformly masking all views and employing a lightweight decoder with inter-frame attention, our approach is inherently simpler and more scalable than CroCo. We evaluate the resulting model, MuM, extensively on downstream tasks including feedforward reconstruction, dense image matching and relative pose estimation, finding that it outperforms the state-of-the-art visual encoders DINOv3 and CroCo v2.","authors":["David Nordström","Johan Edstedt","Fredrik Kahl","Georg Bökman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26601v2","updated":"2025-11-21T15:25:30Z","published":"2025-10-30T15:29:20Z","title":"ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching","summary":"Computational Super-Resolution (CSR) in fluorescence microscopy has, despite being an ill-posed problem, a long history. At its very core, CSR is about finding a prior that can be used to extrapolate frequencies in a micrograph that have never been imaged by the image-generating microscope. It stands to reason that, with the advent of better data-driven machine learning techniques, stronger prior can be learned and hence CSR can lead to better results. Here, we present ResMatching, a novel CSR method that uses guided conditional flow matching to learn such improved data-priors. We evaluate ResMatching on 4 diverse biological structures from the BioSR dataset and compare its results against 7 baselines. ResMatching consistently achieves competitive results, demonstrating in all cases the best trade-off between data fidelity and perceptual realism. We observe that CSR using ResMatching is particularly effective in cases where a strong prior is hard to learn, e.g. when the given low-resolution images contain a lot of noise. Additionally, we show that ResMatching can be used to sample from an implicitly learned posterior distribution and that this distribution is calibrated for all tested use-cases, enabling our method to deliver a pixel-wise data-uncertainty term that can guide future users to reject uncertain predictions.","authors":["Anirban Ray","Vera Galinova","Florian Jug"],"pdf_url":"","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.17301v1","updated":"2025-11-21T15:14:32Z","published":"2025-11-21T15:14:32Z","title":"Large Language Models for Sentiment Analysis to Detect Social Challenges: A Use Case with South African Languages","summary":"Sentiment analysis can aid in understanding people's opinions and emotions on social issues. In multilingual communities sentiment analysis systems can be used to quickly identify social challenges in social media posts, enabling government departments to detect and address these issues more precisely and effectively. Recently, large-language models (LLMs) have become available to the wide public and initial analyses have shown that they exhibit magnificent zero-shot sentiment analysis abilities in English. However, there is no work that has investigated to leverage LLMs for sentiment analysis on social media posts in South African languages and detect social challenges. Consequently, in this work, we analyse the zero-shot performance of the state-of-the-art LLMs GPT-3.5, GPT-4, LlaMa 2, PaLM 2, and Dolly 2 to investigate the sentiment polarities of the 10 most emerging topics in English, Sepedi and Setswana social media posts that fall within the jurisdictional areas of 10 South African government departments. Our results demonstrate that there are big differences between the various LLMs, topics, and languages. In addition, we show that a fusion of the outcomes of different LLMs provides large gains in sentiment classification performance with sentiment classification errors below 1%. Consequently, it is now feasible to provide systems that generate reliable information about sentiment analysis to detect social challenges and draw conclusions about possible needs for actions on specific topics and within different language groups.","authors":["Koena Ronny Mabokela","Tim Schlippe","Matthias Wölfel"],"pdf_url":"","comment":"Published in the Proceedings of The Southern African Conference on AI Research (SACAIR 2024), Bloemfontein, South Africa, 2-6 December 2024. ISBN: 978-0-7961-6069-0"},{"id":"http://arxiv.org/abs/2511.15738v2","updated":"2025-11-21T15:10:10Z","published":"2025-11-18T14:07:57Z","title":"Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and Turn","summary":"Reasoning reinforcement learning (RL) has recently revealed a new scaling effect: test-time scaling. Thinking models such as R1 and o1 improve their reasoning accuracy at test time as the length of the reasoning context increases. However, compared with training-time scaling, test-time scaling is fundamentally limited by the limited context length of base models, which remains orders of magnitude smaller than the amount of tokens consumed during training. We revisit test-time enhancement techniques through the lens of scaling effect and introduce a unified framework of multi-dimensional test-time scaling to extend the capacity of test-time reasoning. Beyond conventional context-length scaling, we consider two additional dimensions: batch scaling, where accuracy improves with parallel sampling, and turn scaling, where iterative self-refinement enhances reasoning quality. Building on this perspective, we propose 3D test-time scaling, which integrates context, batch, and turn scaling. We show that: (1) each dimension demonstrates a test-time scaling effect, but with a bounded capacity; (2) combining all three dimensions substantially improves the reasoning performance of challenging testbeds, including IOI, IMO, and CPHO, and further benefits from human preference feedback; and (3) the human-in-the-loop framework naturally extends to a more open-ended domain, i.e., embodied learning, which enables the design of humanoid control behaviors.","authors":["Chao Yu","Qixin Tan","Jiaxuan Gao","Shi Yu","Hong Lu","Xinting Yang","Zelai Xu","Yu Wang","Yi Wu","Eugene Vinitsky"],"pdf_url":"","comment":"44 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.01183v3","updated":"2025-11-21T15:08:01Z","published":"2024-06-03T10:39:12Z","title":"Estimating Global Input Relevance and Enforcing Sparse Representations with a Scalable Spectral Neural Network Approach","summary":"In machine learning practice it is often useful to identify relevant input features. Isolating key input elements, ranked according their respective degree of relevance, can help to elaborate on the process of decision making. Here, we propose a novel method to estimate the relative importance of the input components for a Deep Neural Network. This is achieved by leveraging on a spectral re-parametrization of the optimization process. Eigenvalues associated to input nodes provide in fact a robust proxy to gauge the relevance of the supplied entry features. Notably, the spectral features ranking is performed automatically, as a byproduct of the network training, with no additional processing to be carried out. Moreover, by leveraging on the regularization of the eigenvalues, it is possible to enforce solutions making use of a minimum subset of the input components, increasing the explainability of the model and providing sparse input representations. The technique is compared to the most common methods in the literature and is successfully challenged against both synthetic and real data.","authors":["Lorenzo Chicchi","Lorenzo Buffoni","Diego Febbe","Lorenzo Giambagli","Raffaele Marino","Duccio Fanelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.04736v2","updated":"2025-11-21T15:00:06Z","published":"2025-05-07T18:48:23Z","title":"The promise and limits of LLMs in constructing proofs and hints for logic problems in intelligent tutoring systems","summary":"Intelligent tutoring systems have demonstrated effectiveness in teaching formal propositional logic proofs, but their reliance on template-based explanations limits their ability to provide personalized student feedback. While large language models (LLMs) offer promising capabilities for dynamic feedback generation, they risk producing hallucinations or pedagogically unsound explanations. We evaluated the stepwise accuracy of LLMs in constructing multi-step symbolic logic proofs, comparing six prompting techniques across four state-of-the-art LLMs on 358 propositional logic problems. Results show that DeepSeek-V3 achieved superior performance up to 86.7% accuracy on stepwise proof construction and excelled particularly in simpler rules. We further used the best-performing LLM to generate explanatory hints for 1,050 unique student problem-solving states from a logic ITS and evaluated them on 4 criteria with both an LLM grader and human expert ratings on a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate and rated highly by human evaluators on consistency and clarity, but did not perform as well explaining why the hint was provided or its larger context. Our results demonstrate that LLMs may be used to augment tutoring systems with logic tutoring hints, but require additional modifications to ensure accuracy and pedagogical appropriateness.","authors":["Sutapa Dey Tithi","Arun Kumar Ramesh","Clara DiMarco","Xiaoyi Tian","Nazia Alam","Kimia Fazeli","Tiffany Barnes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17282v1","updated":"2025-11-21T14:40:50Z","published":"2025-11-21T14:40:50Z","title":"Where Culture Fades: Revealing the Cultural Gap in Text-to-Image Generation","summary":"Multilingual text-to-image (T2I) models have advanced rapidly in terms of visual realism and semantic alignment, and are now widely utilized. Yet outputs vary across cultural contexts: because language carries cultural connotations, images synthesized from multilingual prompts should preserve cross-lingual cultural consistency. We conduct a comprehensive analysis showing that current T2I models often produce culturally neutral or English-biased results under multilingual prompts. Analyses of two representative models indicate that the issue stems not from missing cultural knowledge but from insufficient activation of culture-related representations. We propose a probing method that localizes culture-sensitive signals to a small set of neurons in a few fixed layers. Guided by this finding, we introduce two complementary alignment strategies: (1) inference-time cultural activation that amplifies the identified neurons without backbone fine-tuned; and (2) layer-targeted cultural enhancement that updates only culturally relevant layers. Experiments on our CultureBench demonstrate consistent improvements over strong baselines in cultural consistency while preserving fidelity and diversity.","authors":["Chuancheng Shi","Shangze Li","Shiming Guo","Simiao Xie","Wenhua Wu","Jingtong Dou","Chao Wu","Canran Xiao","Cong Wang","Zifeng Cheng","Fei Shen","Tat-Seng Chua"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.14001v4","updated":"2025-11-21T14:33:03Z","published":"2025-09-17T14:13:20Z","title":"MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment","summary":"Personalized object detection aims to adapt a general-purpose detector to recognize user-specific instances from only a few examples. Lightweight models often struggle in this setting due to their weak semantic priors, while large vision-language models (VLMs) offer strong object-level understanding but are too computationally demanding for real-time or on-device applications. We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment), a distillation framework that transfers multimodal region-level knowledge from a frozen VLM teacher into a lightweight vision-only detector. MOCHA extracts fused visual and textual teacher's embeddings and uses them to guide student training through a dual-objective loss that enforces accurate local alignment and global relational consistency across regions. This process enables efficient transfer of semantics without the need for teacher modifications or textual input at inference. MOCHA consistently outperforms prior baselines across four personalized detection benchmarks under strict few-shot regimes, yielding a +10.1 average improvement, with minimal inference cost.","authors":["Elena Camuffo","Francesco Barbato","Mete Ozay","Simone Milani","Umberto Michieli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01109v2","updated":"2025-11-21T14:32:46Z","published":"2025-08-01T23:07:16Z","title":"Platonic Representations for Poverty Mapping: Unified Vision-Language Codes or Agent-Induced Novelty?","summary":"We investigate whether socio-economic indicators like household wealth leave recoverable imprints in satellite imagery (capturing physical features) and Internet-sourced text (reflecting historical/economic narratives). Using Demographic and Health Survey (DHS) data from African neighborhoods, we pair Landsat images with LLM-generated textual descriptions conditioned on location/year and text retrieved by an AI search agent from web sources. We develop a multimodal framework predicting household wealth (International Wealth Index) through five pipelines: (i) vision model on satellite images, (ii) LLM using only location/year, (iii) AI agent searching/synthesizing web text, (iv) joint image-text encoder, (v) ensemble of all signals. Our framework yields three contributions. First, fusing vision and agent/LLM text outperforms vision-only baselines in wealth prediction (e.g., R-squared of 0.77 vs. 0.63 on out-of-sample splits), with LLM-internal knowledge proving more effective than agent-retrieved text, improving robustness to out-of-country and out-of-time generalization. Second, we find partial representational convergence: fused embeddings from vision/language modalities correlate moderately (median cosine similarity of 0.60 after alignment), suggesting a shared latent code of material well-being while retaining complementary details, consistent with the Platonic Representation Hypothesis. Although LLM-only text outperforms agent-retrieved data, challenging our Agent-Induced Novelty Hypothesis, modest gains from combining agent data in some splits weakly support the notion that agent-gathered information introduces unique representational structures not fully captured by static LLM knowledge. Third, we release a large-scale multimodal dataset comprising more than 60,000 DHS clusters linked to satellite images, LLM-generated descriptions, and agent-retrieved texts.","authors":["Satiyabooshan Murugaboopathy","Connor T. Jerzak","Adel Daoud"],"pdf_url":"","comment":"7 figures"},{"id":"http://arxiv.org/abs/2511.14567v3","updated":"2025-11-21T14:31:55Z","published":"2025-11-18T15:09:12Z","title":"SweeperBot: Making 3D Browsing Accessible through View Analysis and Visual Question Answering","summary":"Accessing 3D models remains challenging for Screen Reader (SR) users. While some existing 3D viewers allow creators to provide alternative text, they often lack sufficient detail about the 3D models. Grounded on a formative study, this paper introduces SweeperBot, a system that enables SR users to leverage visual question answering to explore and compare 3D models. SweeperBot answers SR users' visual questions by combining an optimal view selection technique with the strength of generative- and recognition-based foundation models. An expert review with 10 Blind and Low-Vision (BLV) users with SR experience demonstrated the feasibility of using SweeperBot to assist BLV users in exploring and comparing 3D models. The quality of the descriptions generated by SweeperBot was validated by a second survey study with 30 sighted participants.","authors":["Chen Chen","Cuong Nguyen","Alexa Siu","Dingzeyu Li","Nadir Weibel"],"pdf_url":"","comment":"28 pages, 16 figures, this is an original manuscript of an article published by Taylor & Francis in the International Journal of Human-Computer Interaction (IJHCI), available online: https://doi.org/10.1080/10447318.2025.2594750"},{"id":"http://arxiv.org/abs/2511.17276v1","updated":"2025-11-21T14:31:39Z","published":"2025-11-21T14:31:39Z","title":"Leveraging CVAE for Joint Configuration Estimation of Multifingered Grippers from Point Cloud Data","summary":"This paper presents an efficient approach for determining the joint configuration of a multifingered gripper solely from the point cloud data of its poly-articulated chain, as generated by visual sensors, simulations or even generative neural networks. Well-known inverse kinematics (IK) techniques can provide mathematically exact solutions (when they exist) for joint configuration determination based solely on the fingertip pose, but often require post-hoc decision-making by considering the positions of all intermediate phalanges in the gripper's fingers, or rely on algorithms to numerically approximate solutions for more complex kinematics. In contrast, our method leverages machine learning to implicitly overcome these challenges. This is achieved through a Conditional Variational Auto-Encoder (CVAE), which takes point cloud data of key structural elements as input and reconstructs the corresponding joint configurations. We validate our approach on the MultiDex grasping dataset using the Allegro Hand, operating within 0.05 milliseconds and achieving accuracy comparable to state-of-the-art methods. This highlights the effectiveness of our pipeline for joint configuration estimation within the broader context of AI-driven techniques for grasp planning.","authors":["Julien Merand","Boris Meden","Mathieu Grossard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13302v2","updated":"2025-11-21T14:29:26Z","published":"2025-10-15T08:43:24Z","title":"LLM one-shot style transfer for Authorship Attribution and Verification","summary":"Computational stylometry analyzes writing style through quantitative patterns in text, supporting applications from forensic tasks such as identity linking and plagiarism detection to literary attribution in the humanities. Supervised and contrastive approaches rely on data with spurious correlations and often confuse style with topic. Despite their natural use in AI-generated text detection, the CLM pre-training of modern LLMs has been scarcely leveraged for general authorship problems. We propose a novel unsupervised approach based on this extensive pre-training and the in-context learning capabilities of LLMs, employing the log-probabilities of an LLM to measure style transferability from one text to another. Our method significantly outperforms LLM prompting approaches of comparable scale and achieves higher accuracy than contrastively trained baselines when controlling for topical correlations. Moreover, performance scales fairly consistently with the size of the base model and, in the case of authorship verification, with an additional mechanism that increases test-time computation; enabling flexible trade-offs between computational cost and accuracy.","authors":["Pablo Miralles-González","Javier Huertas-Tato","Alejandro Martín","David Camacho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17269v1","updated":"2025-11-21T14:16:27Z","published":"2025-11-21T14:16:27Z","title":"Range-Edit: Semantic Mask Guided Outdoor LiDAR Scene Editing","summary":"Training autonomous driving and navigation systems requires large and diverse point cloud datasets that capture complex edge case scenarios from various dynamic urban settings. Acquiring such diverse scenarios from real-world point cloud data, especially for critical edge cases, is challenging, which restricts system generalization and robustness. Current methods rely on simulating point cloud data within handcrafted 3D virtual environments, which is time-consuming, computationally expensive, and often fails to fully capture the complexity of real-world scenes. To address some of these issues, this research proposes a novel approach that addresses the problem discussed by editing real-world LiDAR scans using semantic mask-based guidance to generate novel synthetic LiDAR point clouds. We incorporate range image projection and semantic mask conditioning to achieve diffusion-based generation. Point clouds are transformed to 2D range view images, which are used as an intermediate representation to enable semantic editing using convex hull-based semantic masks. These masks guide the generation process by providing information on the dimensions, orientations, and locations of objects in the real environment, ensuring geometric consistency and realism. This approach demonstrates high-quality LiDAR point cloud generation, capable of producing complex edge cases and dynamic scenes, as validated on the KITTI-360 dataset. This offers a cost-effective and scalable solution for generating diverse LiDAR data, a step toward improving the robustness of autonomous driving systems.","authors":["Suchetan G. Uppur","Hemant Kumar","Vaibhav Kumar"],"pdf_url":"","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2207.07250v3","updated":"2025-11-21T14:16:08Z","published":"2022-07-15T01:41:53Z","title":"Toward Super-polynomial Quantum Speedup of Equivariant Quantum Algorithms with SU($d$) Symmetry","summary":"We introduce a framework of the equivariant convolutional quantum algorithms which is tailored for a number of machine-learning tasks on physical systems with arbitrary SU$(d)$ symmetries. It allows us to enhance a natural model of quantum computation -- permutational quantum computing (PQC) -- and define a more powerful model: PQC+. While PQC was shown to be efficiently classically simulatable, we exhibit a problem which can be efficiently solved on PQC+ machine, whereas no classical polynomial time algorithm is known; thus providing evidence against PQC+ being classically simulatable. We further discuss practical quantum machine learning algorithms which can be carried out in the paradigm of PQC+.","authors":["Han Zheng","Zimu Li","Sergii Strelchuk","Risi Kondor","Junyu Liu"],"pdf_url":"","comment":"Presented in TQC 2022"},{"id":"http://arxiv.org/abs/2505.10297v2","updated":"2025-11-21T14:13:48Z","published":"2025-05-15T13:44:32Z","title":"Defending the Edge: Representative-Attention Defense against Backdoor Attacks in Federated Learning","summary":"Federated learning (FL) remains highly vulnerable to adaptive backdoor attacks that preserve stealth by closely imitating benign update statistics. Existing defenses predominantly rely on anomaly detection in parameter or gradient space, overlooking behavioral constraints that backdoor attacks must satisfy to ensure reliable trigger activation. These anomaly-centric methods fail against adaptive attacks that normalize update magnitudes and mimic benign statistical patterns while preserving backdoor functionality, creating a fundamental detection gap. To address this limitation, this paper introduces FeRA (Federated Representative Attention) -- a novel attention-driven defense that shifts the detection paradigm from anomaly-centric to consistency-centric analysis. FeRA exploits the intrinsic need for backdoor persistence across training rounds, identifying malicious clients through suppressed representation-space variance, an orthogonal property to traditional magnitude-based statistics. The framework conducts multi-dimensional behavioral analysis combining spectral and spatial attention, directional alignment, mutual similarity, and norm inflation across two complementary detection mechanisms: consistency analysis and norm-inflation detection. Through this mechanism, FeRA isolates malicious clients that exhibit low-variance consistency or magnitude amplification. Extensive evaluation across six datasets, nine attacks, and three model architectures under both Independent and Identically Distributed (IID) and non-IID settings confirm FeRA achieves superior backdoor mitigation. Under different non-IID settings, FeRA achieved the lowest average Backdoor Accuracy (BA), about 1.67% while maintaining high clean accuracy compared to other state-of-the-art defenses. The code is available at https://github.com/Peatech/FeRA_defense.git.","authors":["Chibueze Peace Obioma","Youcheng Sun","Mustafa A. Mustafa"],"pdf_url":"","comment":"Submitted to IEEE EURO S&P 2026"},{"id":"http://arxiv.org/abs/2511.17265v1","updated":"2025-11-21T14:13:16Z","published":"2025-11-21T14:13:16Z","title":"DISCA: A Digital In-memory Stochastic Computing Architecture Using A Compressed Bent-Pyramid Format","summary":"Nowadays, we are witnessing an Artificial Intelligence revolution that dominates the technology landscape in various application domains, such as healthcare, robotics, automotive, security, and defense. Massive-scale AI models, which mimic the human brain's functionality, typically feature millions and even billions of parameters through data-intensive matrix multiplication tasks. While conventional Von-Neumann architectures struggle with the memory wall and the end of Moore's Law, these AI applications are migrating rapidly towards the edge, such as in robotics and unmanned aerial vehicles for surveillance, thereby adding more constraints to the hardware budget of AI architectures at the edge. Although in-memory computing has been proposed as a promising solution for the memory wall, both analog and digital in-memory computing architectures suffer from substantial degradation of the proposed benefits due to various design limitations. We propose a new digital in-memory stochastic computing architecture, DISCA, utilizing a compressed version of the quasi-stochastic Bent-Pyramid data format. DISCA inherits the same computational simplicity of analog computing, while preserving the same scalability, productivity, and reliability of digital systems. Post-layout modeling results of DISCA show an energy efficiency of 3.59 TOPS/W per bit at 500 MHz using a commercial 180nm CMOS technology. Therefore, DISCA significantly improves the energy efficiency for matrix multiplication workloads by orders of magnitude if scaled and compared to its counterpart architectures.","authors":["Shady Agwa","Yikang Shen","Shiwei Wang","Themis Prodromakis"],"pdf_url":"","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.17254v1","updated":"2025-11-21T13:57:38Z","published":"2025-11-21T13:57:38Z","title":"Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats","summary":"Despite their impressive performance across a wide range of tasks, Large Vision-Language Models (LVLMs) remain prone to hallucination. In this study, we propose a comprehensive intervention framework aligned with the transformer's causal architecture in LVLMs, integrating the effects of different intervention paths on hallucination. We find that hallucinations in LVLMs do not arise from a single causal path, but rather from the interplay among image-to-input-text, image-to-output-text, and text-to-text pathways. For the first time, we also find that LVLMs rely on different pathways depending on the question-answer alignment format. Building on these insights, we propose simple yet effective methods to identify and intervene on critical hallucination heads within each pathway, tailored to discriminative and generative formats. Experiments across multiple benchmarks demonstrate that our approach consistently reduces hallucinations across diverse alignment types.","authors":["Jiaye Qian","Ge Zheng","Yuchen Zhu","Sibei Yang"],"pdf_url":"","comment":"Accepted to NeurIPS 2025, Project Page: https://github.com/SooLab/AllPath"},{"id":"http://arxiv.org/abs/2508.13663v2","updated":"2025-11-21T13:46:26Z","published":"2025-08-19T09:09:07Z","title":"Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints","summary":"Methods for query answering over incomplete knowledge graphs retrieve entities that are \\emph{likely} to be answers, which is particularly useful when such answers cannot be reached by direct graph traversal due to missing edges. However, existing approaches have focused on queries formalized using first-order-logic. In practice, many real-world queries involve constraints that are inherently vague or context-dependent, such as preferences for attributes or related categories. Addressing this gap, we introduce the problem of query answering with soft constraints. We formalize the problem and introduce two efficient methods designed to adjust query answer scores by incorporating soft constraints without disrupting the original answers to a query. These methods are lightweight, requiring tuning only two parameters or a small neural network trained to capture soft constraints while maintaining the original ranking structure. To evaluate the task, we extend existing QA benchmarks by generating datasets with soft constraints. Our experiments demonstrate that our methods can capture soft constraints while maintaining robust query answering performance and adding very little overhead.","authors":["Daniel Daza","Alberto Bernardi","Luca Costabello","Christophe Gueret","Masoud Mansoury","Michael Cochez","Martijn Schut"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17238v1","updated":"2025-11-21T13:32:56Z","published":"2025-11-21T13:32:56Z","title":"Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables","summary":"The impressive performance of VLMs is largely measured on benchmarks that fail to capture the complexities of real-world scenarios. Existing datasets for tabular QA, such as WikiTableQuestions and FinQA, are overwhelmingly monolingual (English) and present tables in a digitally perfect, clean format. This creates a significant gap between research and practice. To address this, we present \\textbf{MirageTVQA}, a new benchmark designed to evaluate VLMs on these exact dimensions. Featuring nearly 60,000 QA pairs across 24 languages, MirageTVQA challenges models with tables that are not only multilingual but also visually imperfect, incorporating realistic noise to mimic scanned documents. Our evaluation of the leading VLMs reveals two primary failure points: a severe degradation in performance (over 35\\% drop for the best models) when faced with visual noise and a consistent English-first bias where reasoning abilities fail to transfer to other languages. MirageTVQA provides a benchmark for measuring and driving progress towards more robust VLM models for table reasoning. The dataset and the code are available at: https://github.com/anshulsc/MirageTVQA.","authors":["Anshul Singh","Rohan Chaudhary","Gagneet Singh","Abhay Kumary"],"pdf_url":"","comment":"Accepted as Spotligh Talk at EurIPS 2025 Workshop on AI For Tabular Data"},{"id":"http://arxiv.org/abs/2409.11393v3","updated":"2025-11-21T13:25:25Z","published":"2024-09-17T17:54:17Z","title":"LLM-Agent-UMF: LLM-based Agent Unified Modeling Framework for Seamless Design of Multi Active/Passive Core-Agent Architectures","summary":"In an era where vast amounts of data are collected and processed from diverse sources, there is a growing demand for sophisticated AI systems capable of intelligently fusing and analyzing this information. To address these challenges, researchers have turned towards integrating tools into LLM-powered agents to enhance the overall information fusion process. However, the conjunction of these technologies and the proposed enhancements in several state-of-the-art works followed a non-unified software architecture, resulting in a lack of modularity and terminological inconsistencies among researchers. To address these issues, we propose a novel LLM-based Agent Unified Modeling Framework (LLM-Agent-UMF) that establishes a clear foundation for agent development from both functional and software architectural perspectives, developed and evaluated using the Architecture Tradeoff and Risk Analysis Framework (ATRAF). Our framework clearly distinguishes between the different components of an LLM-based agent, setting LLMs and tools apart from a new element, the core-agent, which plays the role of central coordinator. This pivotal entity comprises five modules: planning, memory, profile, action, and security -- the latter often neglected in previous works. By classifying core-agents into passive and active types based on their authoritative natures, we propose various multi-core agent architectures that combine unique characteristics of distinctive agents to tackle complex tasks more efficiently. We evaluate our framework by applying it to thirteen state-of-the-art agents, thereby demonstrating its alignment with their functionalities and clarifying overlooked architectural aspects. Moreover, we thoroughly assess five architecture variants of our framework by designing new agent architectures that combine characteristics of state-of-the-art agents to address specific goals. ...","authors":["Amine Ben Hassouna","Hana Chaari","Ines Belhaj"],"pdf_url":"","comment":"39 pages, 19 figures, 3 tables. Published in Information Fusion, Volume 127, March 2026, 103865. Part of the special issue \"Data Fusion Approaches in Data-Centric AI for Developing Trustworthy AI Systems\""},{"id":"http://arxiv.org/abs/2511.17233v1","updated":"2025-11-21T13:21:20Z","published":"2025-11-21T13:21:20Z","title":"Algorithmic design and implementation considerations of deep MPC","summary":"Deep Model Predictive Control (Deep MPC) is an evolving field that integrates model predictive control and deep learning. This manuscript is focused on a particular approach, which employs deep neural network in the loop with MPC. This class of approaches distributes control authority between a neural network and an MPC controller, in such a way that the neural network learns the model uncertainties while the MPC handles constraints. The approach is appealing because training data collected while the system is in operation can be used to fine-tune the neural network, and MPC prevents unsafe behavior during those learning transients. This manuscript explains implementation challenges of Deep MPC, algorithmic way to distribute control authority and argues that a poor choice in distributing control authority may lead to poor performance. A reason of poor performance is explained through a numerical experiment on a four-wheeled skid-steer dynamics.","authors":["Prabhat K. Mishra","Mateus V. Gasparino","Girish Chowdhary"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04652v4","updated":"2025-11-21T13:14:11Z","published":"2025-08-06T17:18:25Z","title":"LLM Collaboration With Multi-Agent Reinforcement Learning","summary":"A large amount of work has been done in Multi-Agent Systems (MAS) for modeling and solving problems with multiple interacting agents. However, most LLMs are pretrained independently and not specifically optimized for coordination. Existing LLM fine-tuning frameworks rely on individual rewards, which require complex reward designs for each agent to encourage collaboration. To address these challenges, we model LLM collaboration as a cooperative Multi-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent, multi-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO), to solve it, building on current RL approaches for LLMs as well as MARL techniques. Our experiments on LLM writing and coding collaboration demonstrate that fine-tuning MAS with MAGRPO enables agents to generate high-quality responses efficiently through effective cooperation. Our approach opens the door to using other MARL methods for LLMs and highlights the associated challenges.\n  Our code is available at https://github.com/OpenMLRL/CoMLRL.","authors":["Shuo Liu","Tianle Chen","Zeyu Liang","Xueguang Lyu","Christopher Amato"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17225v1","updated":"2025-11-21T13:12:13Z","published":"2025-11-21T13:12:13Z","title":"TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making","summary":"In daily life, people often move through spaces to find objects that meet their needs, posing a key challenge in embodied AI. Traditional Demand-Driven Navigation (DDN) handles one need at a time but does not reflect the complexity of real-world tasks involving multiple needs and personal choices. To bridge this gap, we introduce Task-Preferenced Multi-Demand-Driven Navigation (TP-MDDN), a new benchmark for long-horizon navigation involving multiple sub-demands with explicit task preferences. To solve TP-MDDN, we propose AWMSystem, an autonomous decision-making system composed of three key modules: BreakLLM (instruction decomposition), LocateLLM (goal selection), and StatusMLLM (task monitoring). For spatial memory, we design MASMap, which combines 3D point cloud accumulation with 2D semantic mapping for accurate and efficient environmental understanding. Our Dual-Tempo action generation framework integrates zero-shot planning with policy-based fine control, and is further supported by an Adaptive Error Corrector that handles failure cases in real time. Experiments demonstrate that our approach outperforms state-of-the-art baselines in both perception accuracy and navigation robustness.","authors":["Shanshan Li","Da Huang","Yu He","Yanwei Fu","Yu-Gang Jiang","Xiangyang Xue"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2505.20714v2","updated":"2025-11-21T13:07:32Z","published":"2025-05-27T04:48:26Z","title":"Wideband RF Radiance Field Modeling Using Frequency-embedded 3D Gaussian Splatting","summary":"Indoor environments typically contain diverse RF signals distributed across multiple frequency bands, including NB-IoT, Wi-Fi, and millimeter-wave. Consequently, wideband RF modeling is essential for practical applications such as joint deployment of heterogeneous RF systems, cross-band communication, and distributed RF sensing. Although 3D Gaussian Splatting (3DGS) techniques effectively reconstruct RF radiance fields at a single frequency, they cannot model fields at arbitrary or unknown frequencies across a wide range. In this paper, we present a novel 3DGS algorithm for unified wideband RF radiance field modeling. RF wave propagation depends on signal frequency and the 3D spatial environment, including geometry and material electromagnetic (EM) properties. To address these factors, we introduce a frequency-embedded EM feature network that utilizes 3D Gaussian spheres at each spatial location to learn the relationship between frequency and transmission characteristics, such as attenuation and radiance intensity. With a dataset containing sparse frequency samples in a specific 3D environment, our model can efficiently reconstruct RF radiance fields at arbitrary and unseen frequencies. To assess our approach, we introduce a large-scale power angular spectrum (PAS) dataset with 50,000 samples spanning 1 to 94 GHz across six indoor environments. Experimental results show that the proposed model trained on multiple frequencies achieves a Structural Similarity Index Measure (SSIM) of 0.922 for PAS reconstruction, surpassing state-of-the-art single-frequency 3DGS models with SSIM of 0.863.","authors":["Zechen Li","Lanqing Yang","Yiheng Bian","Hao Pan","Yongjian Fu","Yezhou Wang","Zhuxi Chen","Yi-Chao Chen","Guangtao Xue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17220v1","updated":"2025-11-21T13:01:28Z","published":"2025-11-21T13:01:28Z","title":"Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs","summary":"This study presents PARROT (Persuasion and Agreement Robustness Rating of Output Truth), a robustness focused framework designed to measure the degradation in accuracy that occurs under social pressure exerted on users through authority and persuasion in large language models (LLMs) the phenomenon of sycophancy (excessive conformity). PARROT (i) isolates causal effects by comparing the neutral version of the same question with an authoritatively false version using a double-blind evaluation, (ii) quantifies confidence shifts toward the correct and imposed false responses using log-likelihood-based calibration tracking, and (iii) systematically classifies failure modes (e.g., robust correct, sycophantic agreement, reinforced error, stubborn error, self-correction, etc.) using an eight-state behavioral taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice questions across 13 domains and domain-specific authority templates. Findings show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet 4.5) exhibit low \"follow rates\" ($\\leq 11\\%$, GPT-5: 4\\%) and minimal accuracy loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\\%, Qwen 2.5-1.5B: 94\\%). The danger is not limited to response changes; weak models reduce confidence in the correct response while increasing confidence in the imposed incorrect response. While international law and global knowledge at the domain level exhibit high fragility, elementary mathematics is relatively resilient. Consequently, we argue that the goal of \"resistance to overfitting pressure\" should be addressed as a primary objective alongside accuracy, harm avoidance, and privacy for safe deployment in the real world.","authors":["Yusuf Çelebi","Mahmoud El Hussieni","Özay Ezerceli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.09878v4","updated":"2025-11-21T12:54:49Z","published":"2025-03-12T22:18:29Z","title":"CleverDistiller: Simple and Spatially Consistent Cross-modal Distillation","summary":"Vision foundation models (VFMs) such as DINO have led to a paradigm shift in 2D camera-based perception towards extracting generalized features to support many downstream tasks. Recent works introduce self-supervised cross-modal knowledge distillation (KD) as a way to transfer these powerful generalization capabilities into 3D LiDAR-based models. However, they either rely on highly complex distillation losses, pseudo-semantic maps, or limit KD to features useful for semantic segmentation only. In this work, we propose CleverDistiller, a self-supervised, cross-modal 2D-to-3D KD framework introducing a set of simple yet effective design choices: Unlike contrastive approaches relying on complex loss design choices, our method employs a direct feature similarity loss in combination with a multi layer perceptron (MLP) projection head to allow the 3D network to learn complex semantic dependencies throughout the projection. Crucially, our approach does not depend on pseudo-semantic maps, allowing for direct knowledge transfer from a VFM without explicit semantic supervision. Additionally, we introduce the auxiliary self-supervised spatial task of occupancy prediction to enhance the semantic knowledge, obtained from a VFM through KD, with 3D spatial reasoning capabilities. Experiments on standard autonomous driving benchmarks for 2D-to-3D KD demonstrate that CleverDistiller achieves state-of-the-art performance in both semantic segmentation and 3D object detection (3DOD) by up to 10% mIoU, especially when fine tuning on really low data amounts, showing the effectiveness of our simple yet powerful KD strategy","authors":["Hariprasath Govindarajan","Maciej K. Wozniak","Marvin Klingner","Camille Maurice","B Ravi Kiran","Senthil Yogamani"],"pdf_url":"","comment":"Accepted to BMVC 2025"},{"id":"http://arxiv.org/abs/2407.05650v5","updated":"2025-11-21T12:45:04Z","published":"2024-07-08T06:22:10Z","title":"The Cooperative Network Architecture: Learning Structured Networks as Representation of Sensory Patterns","summary":"We introduce the Cooperative Network Architecture (CNA), a model that represents sensory signals using structured, recurrently connected networks of neurons, termed \"nets.\" Nets are dynamically assembled from overlapping net fragments, which are learned based on statistical regularities in sensory input. This architecture offers robustness to noise, deformation, and generalization to out-of-distribution data, addressing challenges in current vision systems from a novel perspective. We demonstrate that net fragments can be learned without supervision and flexibly recombined to encode novel patterns, enabling figure completion and resilience to noise. Our findings establish CNA as a promising paradigm for developing neural representations that integrate local feature processing with global structure formation, providing a foundation for future research on invariant object recognition.","authors":["Pascal J. Sager","Jan M. Deriu","Benjamin F. Grewe","Thilo Stadelmann","Christoph von der Malsburg"],"pdf_url":"","comment":"Accepted at Neural Computation"},{"id":"http://arxiv.org/abs/2511.00423v2","updated":"2025-11-21T12:39:02Z","published":"2025-11-01T06:33:04Z","title":"Bootstrap Off-policy with World Model","summary":"Online planning has proven effective in reinforcement learning (RL) for improving sample efficiency and final performance. However, using planning for environment interaction inevitably introduces a divergence between the collected data and the policy's actual behaviors, degrading both model learning and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy with WOrld Model), a framework that tightly integrates planning and off-policy learning through a bootstrap loop: the policy initializes the planner, and the planner refines actions to bootstrap the policy through behavior alignment. This loop is supported by a jointly learned world model, which enables the planner to simulate future trajectories and provides value targets to facilitate policy improvement. The core of BOOM is a likelihood-free alignment loss that bootstraps the policy using the planner's non-parametric action distribution, combined with a soft value-weighted mechanism that prioritizes high-return behaviors and mitigates variability in the planner's action quality within the replay buffer. Experiments on the high-dimensional DeepMind Control Suite and Humanoid-Bench show that BOOM achieves state-of-the-art results in both training stability and final performance. The code is accessible at https://github.com/molumitu/BOOM_MBRL.","authors":["Guojian Zhan","Likun Wang","Xiangteng Zhang","Jiaxin Gao","Masayoshi Tomizuka","Shengbo Eben Li"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2508.06869v3","updated":"2025-11-21T12:37:49Z","published":"2025-08-09T07:38:48Z","title":"VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding","summary":"Multimodal large language models (MLLMs) demonstrate exceptional performance in vision-language tasks, yet their processing of long videos is constrained by input context length and high computational costs. Sparse frame sampling thus becomes a necessary preprocessing step, with sampled frame quality directly impacting downstream performance. Existing keyframe search algorithms achieve a balance between efficiency and sampled frame quality but heavily rely on the visual modality alone. This makes them difficult to adapt to text-related tasks and often leads to retrieval results deviating from core semantic content. To address this, we propose the VISUAL-SUBTITLE INTEGRATION (VSI), a multimodal keyframe retrieval framework. It employs a dual-branch collaborative retrieval approach combining Video Search and Subtitle Match to fuse complementary visual and textual information for precise localization. Experiments on LongVideoBench and VideoMME demonstrate that VSI achieves state-of-the-art accuracy in keyframe retrieval while delivering breakthrough performance in text-related tasks and exhibiting strong generalization across other tasks.","authors":["Jianxiang He","Meisheng Hong","Jungang Li","Ziyang Chen","Weiyu Guo","Xuming Hu","Hui Xiong"],"pdf_url":"","comment":"9 pages,3 figures"},{"id":"http://arxiv.org/abs/2507.06819v3","updated":"2025-11-21T12:33:38Z","published":"2025-07-09T13:08:21Z","title":"Comprehensive Evaluation of Prototype Neural Networks","summary":"Prototype models are an important method for explainable artificial intelligence (XAI) and interpretable machine learning. In this paper, we perform an in-depth analysis of a set of prominent prototype models including ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive set of metrics. In addition to applying standard metrics from literature, we propose several new metrics to further complement the analysis of model interpretability. In our experimentation, we apply the set of prototype models on a diverse set of datasets including fine-grained classification, Non-IID settings and multi-label classification to further contrast the performance. Furthermore, we also provide our code as an open-source library (https://github.com/uos-sis/quanproto), which facilitates simple application of the metrics itself, as well as extensibility -- providing the option for easily adding new metrics and models.","authors":["Philipp Schlinge","Steffen Meinert","Martin Atzmueller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17198v1","updated":"2025-11-21T12:25:47Z","published":"2025-11-21T12:25:47Z","title":"Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism","summary":"LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.","authors":["Kaiyu Li","Jiayu Wang","Zhi Wang","Hui Qiao","Weizhan Zhang","Deyu Meng","Xiangyong Cao"],"pdf_url":"","comment":"Page: https://earth-insights.github.io/EarthAgent"},{"id":"http://arxiv.org/abs/2506.08708v2","updated":"2025-11-21T12:13:42Z","published":"2025-06-10T11:46:06Z","title":"PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly","summary":"While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.","authors":["Liang Ma","Jiajun Wen","Min Lin","Rongtao Xu","Xiwen Liang","Bingqian Lin","Jun Ma","Yongxin Wang","Ziming Wei","Haokun Lin","Mingfei Han","Meng Cao","Bokui Chen","Ivan Laptev","Xiaodan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17184v1","updated":"2025-11-21T12:05:31Z","published":"2025-11-21T12:05:31Z","title":"Attention-Guided Feature Fusion (AGFF) Model for Integrating Statistical and Semantic Features in News Text Classification","summary":"News text classification is a crucial task in natural language processing, essential for organizing and filtering the massive volume of digital content. Traditional methods typically rely on statistical features like term frequencies or TF-IDF values, which are effective at capturing word-level importance but often fail to reflect contextual meaning. In contrast, modern deep learning approaches utilize semantic features to understand word usage within context, yet they may overlook simple, high-impact statistical indicators. This paper introduces an Attention-Guided Feature Fusion (AGFF) model that combines statistical and semantic features in a unified framework. The model applies an attention-based mechanism to dynamically determine the relative importance of each feature type, enabling more informed classification decisions. Through evaluation on benchmark news datasets, the AGFF model demonstrates superior performance compared to both traditional statistical models and purely semantic deep learning models. The results confirm that strategic integration of diverse feature types can significantly enhance classification accuracy. Additionally, ablation studies validate the contribution of each component in the fusion process. The findings highlight the model's ability to balance and exploit the complementary strengths of statistical and semantic representations, making it a practical and effective solution for real-world news classification tasks.","authors":["Mohammad Zare"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.09110v3","updated":"2025-11-21T12:01:11Z","published":"2025-10-10T08:04:30Z","title":"Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding","summary":"Visual grouping -- operationalized through tasks such as instance segmentation, visual grounding, and object detection -- enables applications ranging from robotic perception to photo editing. These fundamental problems in computer vision are powered by large-scale, painstakingly annotated datasets. Despite their impact, these datasets are costly to build, biased in coverage, and difficult to scale. Synthetic datasets offer a promising alternative but struggle with flexibility, accuracy, and compositional diversity.\n  We introduce Synthetic Object Compositions (SOC), an accurate and scalable data synthesis pipeline via a novel object-centric composition strategy. It composes high-quality synthetic object segments into new images using 3D geometric layout augmentation and camera configuration augmentation with generative harmonization and mask-area-weighted blending, yielding accurate and diverse masks, boxes, and referring expressions.\n  Models trained on just 100K of our synthetic images outperform those trained on larger real datasets (GRIT 20M, V3Det 200K) and synthetic pipelines (Copy-Paste, X-Paste, SynGround, SegGen) by +24-36% -- achieving +10.9 AP on LVIS and +8.4 NAcc on gRefCOCO. Beyond the general open-vocabulary setup, SOC also enables controllable dataset construction for different use cases and boosts performance in both low-data and closed-vocabulary scenarios.\n  Augmenting LVIS and COCO with synthetic object segments delivers strong performance across different real-data scales and yields even greater improvements under extremely limited real-data conditions, including +6.59 AP on a 1% COCO data setup. Furthermore, this controllability enables targeted data generation for intra-class referring, a diagnostic grounding task we propose that requires fine-grained attribute discrimination.","authors":["Weikai Huang","Jieyu Zhang","Taoyang Jia","Chenhao Zheng","Ziqi Gao","Jae Sung Park","Winson Han","Ranjay Krishna"],"pdf_url":"","comment":"Project website: https://github.com/weikaih04/Synthetic-Detection-Segmentation-Grounding-Data"},{"id":"http://arxiv.org/abs/2511.16449v2","updated":"2025-11-21T11:57:47Z","published":"2025-11-20T15:16:09Z","title":"VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference","summary":"Vision-Language-Action (VLA) models have shown great promise for embodied AI, yet the heavy computational cost of processing continuous visual streams severely limits their real-time deployment. Token pruning (keeping salient visual tokens and dropping redundant ones) has emerged as an effective approach for accelerating Vision-Language Models (VLMs), offering a solution for efficient VLA. However, these VLM-specific token pruning methods select tokens based solely on semantic salience metrics (e.g., prefill attention), while overlooking the VLA's intrinsic dual-system nature of high-level semantic understanding and low-level action execution. Consequently, these methods bias token retention toward semantic cues, discard critical information for action generation, and significantly degrade VLA performance. To bridge this gap, we propose VLA-Pruner, a versatile plug-and-play VLA-specific token prune method that aligns with the dual-system nature of VLA models and exploits the temporal continuity in robot manipulation. Specifically, VLA-Pruner adopts a dual-level importance criterion for visual token retention: vision-language prefill attention for semantic-level relevance and action decode attention, estimated via temporal smoothing, for action-level importance. Based on this criterion, VLA-Pruner proposes a novel dual-level token selection strategy that adaptively preserves a compact, informative set of visual tokens for both semantic understanding and action execution under given compute budget. Experiments show that VLA-Pruner achieves state-of-the-art performance across multiple VLA architectures and diverse robotic tasks.","authors":["Ziyan Liu","Yeqiu Chen","Hongyi Cai","Tao Lin","Shuo Yang","Zheng Liu","Bo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12233v2","updated":"2025-11-21T11:52:36Z","published":"2025-11-15T14:21:16Z","title":"Model Inversion Attack Against Deep Hashing","summary":"Deep hashing improves retrieval efficiency through compact binary codes, yet it introduces severe and often overlooked privacy risks. The ability to reconstruct original training data from hash codes could lead to serious threats such as biometric forgery and privacy breaches. However, model inversion attacks specifically targeting deep hashing models remain unexplored, leaving their security implications unexamined. This research gap stems from the inaccessibility of genuine training hash codes and the highly discrete Hamming space, which prevents existing methods from adapting to deep hashing. To address these challenges, we propose DHMI, the first diffusion-based model inversion framework designed for deep hashing. DHMI first clusters an auxiliary dataset to derive semantic hash centers as surrogate anchors. It then introduces a surrogate-guided denoising optimization method that leverages a novel attack metric (fusing classification consistency and hash proximity) to dynamically select candidate samples. A cluster of surrogate models guides the refinement of these candidates, ensuring the generation of high-fidelity and semantically consistent images. Experiments on multiple datasets demonstrate that DHMI successfully reconstructs high-resolution, high-quality images even under the most challenging black-box setting, where no training hash codes are available. Our method outperforms the existing state-of-the-art model inversion attacks in black-box scenarios, confirming both its practical efficacy and the critical privacy risks inherent in deep hashing systems.","authors":["Dongdong Zhao","Qiben Xu","Ranxin Fang","Baogang Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.07318v2","updated":"2025-11-21T11:45:34Z","published":"2025-11-10T17:19:27Z","title":"When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs","summary":"Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.","authors":["Shaowen Wang","Yiqi Dong","Ruinian Chang","Tansheng Zhu","Yuebo Sun","Kaifeng Lyu","Jian Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17170v1","updated":"2025-11-21T11:42:49Z","published":"2025-11-21T11:42:49Z","title":"Hallucinate Less by Thinking More: Aspect-Based Causal Abstention for Large Language Models","summary":"Large Language Models (LLMs) often produce fluent but factually incorrect responses, a phenomenon known as hallucination. Abstention, where the model chooses not to answer and instead outputs phrases such as \"I don't know\", is a common safeguard. However, existing abstention methods typically rely on post-generation signals, such as generation variations or feedback, which limits their ability to prevent unreliable responses in advance. In this paper, we introduce Aspect-Based Causal Abstention (ABCA), a new framework that enables early abstention by analysing the internal diversity of LLM knowledge through causal inference. This diversity reflects the multifaceted nature of parametric knowledge acquired from various sources, representing diverse aspects such as disciplines, legal contexts, or temporal frames. ABCA estimates causal effects conditioned on these aspects to assess the reliability of knowledge relevant to a given query. Based on these estimates, we enable two types of abstention: Type-1, where aspect effects are inconsistent (knowledge conflict), and Type-2, where aspect effects consistently support abstention (knowledge insufficiency). Experiments on standard benchmarks demonstrate that ABCA improves abstention reliability, achieves state-of-the-art performance, and enhances the interpretability of abstention decisions.","authors":["Vy Nguyen","Ziqi Xu","Jeffrey Chan","Estrid He","Feng Xia","Xiuzhen Zhang"],"pdf_url":"","comment":"Accepted to AAAI 2026 (Main Technical Track)"},{"id":"http://arxiv.org/abs/2511.17165v1","updated":"2025-11-21T11:32:28Z","published":"2025-11-21T11:32:28Z","title":"MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward","summary":"Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.","authors":["Kesheng Chen","Wenjian Luo","Bang Zhang","Zeping Yin","Zipeng Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17162v1","updated":"2025-11-21T11:30:17Z","published":"2025-11-21T11:30:17Z","title":"The Belief-Desire-Intention Ontology for modelling mental reality and agency","summary":"The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.","authors":["Sara Zuppiroli","Carmelo Fabio Longo","Anna Sofia Lippolis","Rocco Paolillo","Lorenzo Giammei","Miguel Ceriani","Francesco Poggi","Antonio Zinilli","Andrea Giovanni Nuzzolese"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17161v1","updated":"2025-11-21T11:28:11Z","published":"2025-11-21T11:28:11Z","title":"The PLLuM Instruction Corpus","summary":"This paper describes the instruction dataset used to fine-tune a set of transformer-based large language models (LLMs) developed in the PLLuM (Polish Large Language Model) project. We present a functional typology of the organic, converted, and synthetic instructions used in PLLuM and share some observations about the implications of using human-authored versus synthetic instruction datasets in the linguistic adaptation of base LLMs. Additionally, we release the first representative subset of the PLLuM instruction corpus (PLLuMIC), which we believe to be useful in guiding and planning the development of similar datasets for other LLMs.","authors":["Piotr Pęzik","Filip Żarnecki","Konrad Kaczyński","Anna Cichosz","Zuzanna Deckert","Monika Garnys","Izabela Grabarczyk","Wojciech Janowski","Sylwia Karasińska","Aleksandra Kujawiak","Piotr Misztela","Maria Szymańska","Karolina Walkusz","Igor Siek","Maciej Chrabąszcz","Anna Kołos","Agnieszka Karlińska","Karolina Seweryn","Aleksandra Krasnodębska","Paula Betscher","Zofia Cieślińska","Katarzyna Kowol","Artur Wilczek","Maciej Trzciński","Katarzyna Dziewulska","Roman Roszko","Tomasz Bernaś","Jurgita Vaičenonienė","Danuta Roszko","Paweł Levchuk","Paweł Kowalski","Irena Prawdzic-Jankowska","Marek Kozłowski","Sławomir Dadas","Rafał Poświata","Alina Wróblewska","Katarzyna Krasnowska-Kieraś","Maciej Ogrodniczuk","Michał Rudolf","Piotr Rybak","Karolina Saputa","Joanna Wołoszyn","Marcin Oleksy","Bartłomiej Koptyra","Teddy Ferdinan","Stanisław Woźniak","Maciej Piasecki","Paweł Walkowiak","Konrad Wojtasik","Arkadiusz Janz","Przemysław Kazienko","Julia Moska","Jan Kocoń"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17147v1","updated":"2025-11-21T11:11:04Z","published":"2025-11-21T11:11:04Z","title":"A lightweight detector for real-time detection of remote sensing images","summary":"Remote sensing imagery is widely used across various fields, yet real-time detection remains challenging due to the prevalence of small objects and the need to balance accuracy with efficiency. To address this, we propose DMG-YOLO, a lightweight real-time detector tailored for small object detection in remote sensing images. Specifically, we design a Dual-branch Feature Extraction (DFE) module in the backbone, which partitions feature maps into two parallel branches: one extracts local features via depthwise separable convolutions, and the other captures global context using a vision transformer with a gating mechanism. Additionally, a Multi-scale Feature Fusion (MFF) module with dilated convolutions enhances multi-scale integration while preserving fine details. In the neck, we introduce the Global and Local Aggregate Feature Pyramid Network (GLAFPN) to further boost small object detection through global-local feature fusion. Extensive experiments on the VisDrone2019 and NWPU VHR-10 datasets show that DMG-YOLO achieves competitive performance in terms of mAP, model size, and other key metrics.","authors":["Qianyi Wang","Guoqiang Ren"],"pdf_url":"","comment":"none"},{"id":"http://arxiv.org/abs/2504.21719v2","updated":"2025-11-21T11:04:47Z","published":"2025-04-30T15:05:20Z","title":"Sionna RT: Technical Report","summary":"Sionna is an open-source, GPU-accelerated library that, as of version 0.14, incorporates a ray tracer, Sionna RT, for simulating radio wave propagation. A unique feature of Sionna RT is differentiability, enabling the calculation of gradients for the channel impulse responses (CIRs), radio maps, and other related metrics with respect to system and environmental parameters, such as material properties, antenna patterns, and array geometries. The release of Sionna 1.0 provides a complete overhaul of the ray tracer, significantly improving its speed, memory efficiency, and extensibility. This document details the algorithms employed by Sionna RT to simulate radio wave propagation efficiently, while also addressing their current limitations. Given that the computation of CIRs and radio maps requires distinct algorithms, these are detailed in separate sections. For CIRs, Sionna RT integrates shooting and bouncing of rays (SBR) with the image method and uses a hashing-based mechanism to efficiently eliminate duplicate paths. Radio maps are computed using a purely SBR-based approach.","authors":["Fayçal Aït Aoudia","Jakob Hoydis","Merlin Nimier-David","Baptiste Nicolet","Sebastian Cammerer","Alexander Keller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17136v1","updated":"2025-11-21T10:57:11Z","published":"2025-11-21T10:57:11Z","title":"Device-Guided Music Transfer","summary":"Device-guided music transfer adapts playback across unseen devices for users who lack them. Existing methods mainly focus on modifying the timbre, rhythm, harmony, or instrumentation to mimic genres or artists, overlooking the diverse hardware properties of the playback device (i.e., speaker). Therefore, we propose DeMT, which processes a speaker's frequency response curve as a line graph using a vision-language model to extract device embeddings. These embeddings then condition a hybrid transformer via feature-wise linear modulation. Fine-tuned on a self-collected dataset, DeMT enables effective speaker-style transfer and robust few-shot adaptation for unseen devices, supporting applications like device-style augmentation and quality enhancement.","authors":["Manh Pham Hung","Changshuo Hu","Ting Dang","Dong Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17131v1","updated":"2025-11-21T10:47:22Z","published":"2025-11-21T10:47:22Z","title":"UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability","summary":"While current Computer Use Agent (CUA) benchmarks measure task completion effectively, they provide limited assessment of enterprise deployment readiness, emphasizing functional correctness over the operational reliability required for production systems. We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs. Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks), with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state. Evaluation of five state-of-the-art models reveals a sharp capability cliff rather than gradual performance degradation. Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%. Human evaluators with no prior application experience achieve only 61.2% on complex tasks despite near-perfect performance on simple tasks, establishing realistic performance ceilings. This discontinuous performance pattern -- where agents achieve 68-87% of human performance on simple tasks but only 15-32% on complex workflows -- indicates fundamental architectural limitations in memory management, hierarchical planning, and state coordination rather than incremental capability gaps addressable through better training or prompting. UI-CUBE functions as an enterprise-readiness diagnostic, revealing that while current CUAs can manipulate individual interface elements, they cannot yet function as reliable workflow automation tools. These findings provide architectural insights essential for developing production-ready CUAs capable of managing complex, multi-step enterprise processes.","authors":["Horia Cristescu","Charles Park","Trong Canh Nguyen","Sergiu Talmacel","Alexandru-Gabriel Ilie","Stefan Adam"],"pdf_url":"","comment":"18 pages, 8 figures, 5 tables. Benchmark comprising 226 tasks across two difficulty tiers. Code and benchmark available at https://github.com/UiPath/uipath_enterprise_benchmark"},{"id":"http://arxiv.org/abs/2511.17129v1","updated":"2025-11-21T10:45:44Z","published":"2025-11-21T10:45:44Z","title":"Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation","summary":"Text representation plays a critical role in tasks like clustering, retrieval, and other downstream applications. With the emergence of large language models (LLMs), there is increasing interest in harnessing their capabilities for this purpose. However, most of the LLMs are inherently causal and optimized for next-token prediction, making them suboptimal for producing holistic representations. To address this, recent studies introduced pretext tasks to adapt LLMs for text representation. Most of these tasks, however, rely on token-level prediction objectives, such as the masked next-token prediction (MNTP) used in LLM2Vec. In this work, we explore the untapped potential of context compression as a pretext task for unsupervised adaptation of LLMs. During compression pre-training, the model learns to generate compact memory tokens, which substitute the whole context for downstream sequence prediction. Experiments demonstrate that a well-designed compression objective can significantly enhance LLM-based text representations, outperforming models trained with token-level pretext tasks. Further improvements through contrastive learning produce a strong representation model (LLM2Comp) that outperforms contemporary LLM-based text encoders on a wide range of tasks while being more sample-efficient, requiring significantly less training data.","authors":["Yeqin Zhang","Yizheng Zhao","Chen Hu","Binxing Jiao","Daxin Jiang","Ruihang Miao","Cam-Tu Nguyen"],"pdf_url":"","comment":"Accepted by AAAI'26"},{"id":"http://arxiv.org/abs/2511.17127v1","updated":"2025-11-21T10:44:02Z","published":"2025-11-21T10:44:02Z","title":"Training Foundation Models on a Full-Stack AMD Platform: Compute, Networking, and System Design","summary":"We report on the first large-scale mixture-of-experts (MoE) pretraining study on pure AMD hardware, utilizing both MI300X GPUs with Pollara interconnect. We distill practical guidance for both systems and model design. On the systems side, we deliver a comprehensive cluster and networking characterization: microbenchmarks for all core collectives (all-reduce, reduce-scatter, all-gather, broadcast) across message sizes and GPU counts on Pollara. To our knowledge, this is the first at this scale. We further provide MI300X microbenchmarks on kernel sizing and memory bandwidth to inform model design. On the modeling side, we introduce and apply MI300X-aware transformer sizing rules for attention and MLP blocks and justify MoE widths that jointly optimize training throughput and inference latency. We describe our training stack in depth, including often-ignored utilities such as fault-tolerance and checkpoint-reshaping, as well as detailed information on our training recipe. We also provide a preview of our model architecture and base model - ZAYA1 (760M active, 8.3B total parameters MoE) - which will be further improved upon in forthcoming papers. ZAYA1-base achieves performance comparable to leading base models such as Qwen3-4B and Gemma3-12B at its scale and larger, and outperforms models including Llama-3-8B and OLMoE across reasoning, mathematics, and coding benchmarks. Together, these results demonstrate that the AMD hardware, network, and software stack are mature and optimized enough for competitive large-scale pretraining.","authors":["Quentin Anthony","Yury Tokpanov","Skyler Szot","Srivatsan Rajagopal","Praneeth Medepalli","Rishi Iyer","Vasu Shyam","Anna Golubeva","Ansh Chaurasia","Xiao Yang","Tomas Figliolia","Robert Washbourne","Drew Thorstensen","Amartey Pearson","Zack Grossbart","Jason van Patten","Emad Barsoum","Zhenyu Gu","Yao Fu","Beren Millidge"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23629v2","updated":"2025-11-21T10:27:21Z","published":"2025-09-28T04:10:37Z","title":"How LLMs Learn to Reason: A Complex Network Perspective","summary":"Training large language models with Reinforcement Learning with Verifiable Rewards (RLVR) exhibits a set of distinctive and puzzling behaviors that remain poorly understood, including a two-stage learning curve, a V-shaped response-length trajectory, and a pronounced vulnerability to catastrophic forgetting. In this work, we propose that these behaviors are emergent collective phenomena governed not by neural implementation details, but by the topological evolution of the latent reasoning graph in semantic space. By demonstrating a dynamical isomorphism between a 1.5B-parameter LLM and a minimal Concept Network Model (CoNet), we trace the causal source to the self-organization of a sparse concept web pinned to an average degree of two. This geometric perspective provides a unified physical explanation for the observed anomalies: the V-shaped trajectory tracks the evolution from parallel local skill optimization to global network integration; catastrophic forgetting stems from the topological disconnection of critical ``trunk'' edges; and policy collapse arises from the accumulation of sequential transitions at the web's leaf nodes, where broad exploration abruptly freezes into rigid, high-reward trajectories. Identifying a ``maximally frustrated state'' at the transition between learning stages, we propose Annealed-RLVR, a principled algorithm that injects a targeted SFT ``heating'' step to resolve this topological bottleneck. Experiments confirm that this theory-driven intervention outperforms standard RLVR on both in-distribution and out-of-distribution benchmarks (including Minerva and AIME). By recasting RLVR from black-box optimization into a predictable process of structural self-organization, our work provides a new physical intuition for engineering the emergent reasoning capabilities of future AI systems.","authors":["Sihan Hu","Xiansheng Cai","Yuan Huang","Zhiyuan Yao","Linfeng Zhang","Pan Zhang","Youjin Deng","Kun Chen"],"pdf_url":"","comment":"24 pages, 11 figures, 1 table, under review as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2511.17113v1","updated":"2025-11-21T10:22:00Z","published":"2025-11-21T10:22:00Z","title":"AutoGraphAD: A novel approach using Variational Graph Autoencoders for anomalous network flow detection","summary":"Network Intrusion Detection Systems (NIDS) are essential tools for detecting network attacks and intrusions. While extensive research has explored the use of supervised Machine Learning for attack detection and characterisation, these methods require accurately labelled datasets, which are very costly to obtain. Moreover, existing public datasets have limited and/or outdated attacks, and many of them suffer from mislabelled data. To reduce the reliance on labelled data, we propose AutoGraphAD, a novel unsupervised anomaly detection approach based on a Heterogeneous Variational Graph Autoencoder. AutoGraphAD operates on heterogeneous graphs, made from connection and IP nodes that capture network activity within a time window. The model is trained using unsupervised and contrastive learning, without relying on any labelled data. The reconstruction, structural loss, and KL divergence are then weighted and combined in an anomaly score that is then used for anomaly detection. Overall, AutoGraphAD yields the same, and in some cases better, results than previous unsupervised approaches, such as Anomal-E, but without requiring costly downstream anomaly detectors. As a result, AutoGraphAD achieves around 1.18 orders of magnitude faster training and 1.03 orders of magnitude faster inference, which represents a significant advantage for operational deployment.","authors":["Georgios Anyfantis","Pere Barlet-Ros"],"pdf_url":"","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2306.08543v5","updated":"2025-11-21T10:20:53Z","published":"2023-06-14T14:44:03Z","title":"MiniLLM: Knowledge Distillation of Large Language Models","summary":"Knowledge Distillation (KD) is a promising technique for reducing the high computational demand of large language models (LLMs). However, previous KD methods are primarily applied to white-box classification models or training small models to imitate black-box model APIs like ChatGPT. How to effectively distill the knowledge of white-box LLMs into small models is still under-explored, which becomes more important with the prosperity of open-source LLMs. In this work, we propose a KD approach that distills LLMs into smaller language models. We first replace the forward Kullback-Leibler divergence (KLD) objective in the standard KD approaches with reverse KLD, which is more suitable for KD on generative language models, to prevent the student model from overestimating the low-probability regions of the teacher distribution. Then, we derive an effective on-policy optimization approach to learn this objective. The student models are named MiniLLM. Extensive experiments in the instruction-following setting show that MiniLLM generates more precise responses with higher overall quality, lower exposure bias, better calibration, and higher long-text generation performance than the baselines. Our method is scalable for different model families with 120M to 13B parameters. Our code, data, and model checkpoints can be found in https://github.com/microsoft/LMOps/tree/main/minillm.","authors":["Yuxian Gu","Li Dong","Furu Wei","Minlie Huang"],"pdf_url":"","comment":"Published as a conference paper in ICLR 2024"},{"id":"http://arxiv.org/abs/2511.17100v1","updated":"2025-11-21T09:58:25Z","published":"2025-11-21T09:58:25Z","title":"Geometric-Disentangelment Unlearning","summary":"Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients (\"retain-invariant\"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.","authors":["Duo Zhou","Yuji Zhang","Tianxin Wei","Ruizhong Qiu","Ke Yang","Xiao Lin","Cheng Qian","Jingrui He","Hanghang Tong","Heng Ji","Huan Zhang"],"pdf_url":"","comment":"27 Pages"},{"id":"http://arxiv.org/abs/2503.01424v4","updated":"2025-11-21T09:49:56Z","published":"2025-03-03T11:27:13Z","title":"From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems","summary":"Research is a fundamental process driving the advancement of human civilization, yet it demands substantial time and effort from researchers. In recent years, the rapid development of artificial intelligence (AI) technologies has inspired researchers to explore how AI can accelerate and enhance research. To monitor relevant advancements, this paper presents a systematic review of the progress in this domain. Specifically, we organize the relevant studies into three main categories: hypothesis formulation, hypothesis validation, and manuscript publication. Hypothesis formulation involves knowledge synthesis and hypothesis generation. Hypothesis validation includes the verification of scientific claims, theorem proving, and experiment validation. Manuscript publication encompasses manuscript writing and the peer review process. Furthermore, we identify and discuss the current challenges faced in these areas, as well as potential future directions for research. Finally, we also offer a comprehensive overview of existing benchmarks and tools across various domains that support the integration of AI into the research process. We hope this paper serves as an introduction for beginners and fosters future research. Resources have been made publicly available at https://github.com/zkzhou126/AI-for-Research.","authors":["Zekun Zhou","Xiaocheng Feng","Lei Huang","Xiachong Feng","Ziyun Song","Ruihan Chen","Liang Zhao","Weitao Ma","Yuxuan Gu","Baoxin Wang","Dayong Wu","Guoping Hu","Ting Liu","Bing Qin"],"pdf_url":"","comment":"Accepted to EMNLP 2025"},{"id":"http://arxiv.org/abs/2511.12135v2","updated":"2025-11-21T09:48:05Z","published":"2025-11-15T09:55:55Z","title":"RTMol: Rethinking Molecule-text Alignment in a Round-trip View","summary":"Aligning molecular sequence representations (e.g., SMILES notations) with textual descriptions is critical for applications spanning drug discovery, materials design, and automated chemical literature analysis. Existing methodologies typically treat molecular captioning (molecule-to-text) and text-based molecular design (text-to-molecule) as separate tasks, relying on supervised fine-tuning or contrastive learning pipelines. These approaches face three key limitations: (i) conventional metrics like BLEU prioritize linguistic fluency over chemical accuracy, (ii) training datasets frequently contain chemically ambiguous narratives with incomplete specifications, and (iii) independent optimization of generation directions leads to bidirectional inconsistency. To address these issues, we propose RTMol, a bidirectional alignment framework that unifies molecular captioning and text-to-SMILES generation through self-supervised round-trip learning. The framework introduces novel round-trip evaluation metrics and enables unsupervised training for molecular captioning without requiring paired molecule-text corpora. Experiments demonstrate that RTMol enhances bidirectional alignment performance by up to 47% across various LLMs, establishing an effective paradigm for joint molecule-text understanding and generation.","authors":["Letian Chen","Runhan Shi","Gufeng Yu","Yang Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17089v1","updated":"2025-11-21T09:45:17Z","published":"2025-11-21T09:45:17Z","title":"Spanning Tree Autoregressive Visual Generation","summary":"We present Spanning Tree Autoregressive (STAR) modeling, which can incorporate prior knowledge of images, such as center bias and locality, to maintain sampling performance while also providing sufficiently flexible sequence orders to accommodate image editing at inference. Approaches that expose randomly permuted sequence orders to conventional autoregressive (AR) models in visual generation for bidirectional context either suffer from a decline in performance or compromise the flexibility in sequence order choice at inference. Instead, STAR utilizes traversal orders of uniform spanning trees sampled in a lattice defined by the positions of image patches. Traversal orders are obtained through breadth-first search, allowing us to efficiently construct a spanning tree whose traversal order ensures that the connected partial observation of the image appears as a prefix in the sequence through rejection sampling. Through the tailored yet structured randomized strategy compared to random permutation, STAR preserves the capability of postfix completion while maintaining sampling performance without any significant changes to the model architecture widely adopted in the language AR modeling.","authors":["Sangkyu Lee","Changho Lee","Janghoon Han","Hosung Song","Tackgeun You","Hwasup Lim","Stanley Jungkyu Choi","Honglak Lee","Youngjae Yu"],"pdf_url":"","comment":"Preprint; Under review"},{"id":"http://arxiv.org/abs/2511.17085v1","updated":"2025-11-21T09:40:52Z","published":"2025-11-21T09:40:52Z","title":"Why Do Language Model Agents Whistleblow?","summary":"The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways. Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user. We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge. We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior. Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates. Additionally, we verify the robustness of our dataset by testing for model evaluation awareness, and find that both black-box methods and probes on model activations show lower evaluation awareness in our settings than in comparable previous work.","authors":["Kushal Agrawal","Frank Xiao","Guido Bergman","Asa Cooper Stickland"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.00133v2","updated":"2025-11-21T09:32:43Z","published":"2025-05-30T18:11:31Z","title":"A Reinforcement Learning-Based Telematic Routing Protocol for the Internet of Underwater Things","summary":"The Internet of Underwater Things (IoUT) has a lot of problems, like low bandwidth, high latency, mobility, and not enough energy. Routing protocols that were made for land-based networks, like RPL, don't work well in these underwater settings. This paper talks about RL-RPL-UA, a new routing protocol that uses reinforcement learning to make things work better in underwater situations. Each node has a small RL agent that picks the best parent node depending on local data such the link quality, buffer level, packet delivery ratio, and remaining energy. RL-RPL-UA works with all standard RPL messages and adds a dynamic objective function to help people make decisions in real time. Aqua-Sim simulations demonstrate that RL-RPL-UA boosts packet delivery by up to 9.2%, uses 14.8% less energy per packet, and adds 80 seconds to the network's lifetime compared to previous approaches. These results show that RL-RPL-UA is a potential and energy-efficient way to route data in underwater networks.","authors":["Mohammadhossein Homaei","Mehran Tarif","Agustin Di Bartolo","Victor Gonzalez Morales","Mar Avila Vegas"],"pdf_url":"","comment":"8 Pages, 10 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2503.12972v3","updated":"2025-11-21T09:26:05Z","published":"2025-03-17T09:31:14Z","title":"Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning","summary":"Multimodal reasoning in Large Language Models (LLMs) struggles with incomplete knowledge and hallucination artifacts, challenges that textual Knowledge Graphs (KGs) only partially mitigate due to their modality isolation. While Multimodal Knowledge Graphs (MMKGs) promise enhanced cross-modal understanding, their practical construction is impeded by semantic narrowness of manual text annotations and inherent noise in visual-semantic entity linkages. In this paper, we propose Vision-align-to-Language integrated Knowledge Graph (VaLiK), a novel approach for constructing MMKGs that enhances LLMs reasoning through cross-modal information supplementation. Specifically, we cascade pre-trained Vision-Language Models (VLMs) to align image features with text, transforming them into descriptions that encapsulate image-specific information. Furthermore, we developed a cross-modal similarity verification mechanism to quantify semantic consistency, effectively filtering out noise introduced during feature alignment. Even without manually annotated image captions, the refined descriptions alone suffice to construct the MMKG. Compared to conventional MMKGs construction paradigms, our approach achieves substantial storage efficiency gains while maintaining direct entity-to-image linkage capability. Experimental results on multimodal reasoning tasks demonstrate that LLMs augmented with VaLiK outperform previous state-of-the-art models. Our code is published at https://github.com/Wings-Of-Disaster/VaLiK.","authors":["Junming Liu","Siyuan Meng","Yanting Gao","Song Mao","Pinlong Cai","Guohang Yan","Yirong Chen","Zilin Bian","Ding Wang","Botian Shi"],"pdf_url":"","comment":"14 pages, 7 figures, 6 tables; Accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2510.17108v3","updated":"2025-11-21T09:22:40Z","published":"2025-10-20T02:50:03Z","title":"Structured Debate Improves Corporate Credit Reasoning in Financial AI","summary":"Despite advances in financial AI, the automation of evidence-based reasoning remains unresolved in corporate credit assessment, where qualitative non-financial indicators exert decisive influence on loan repayment outcomes yet resist formalization. Existing approaches focus predominantly on numerical prediction and provide limited support for the interpretive judgments required in professional loan evaluation. This study develops and evaluates two operational large language model (LLM)-based systems designed to generate structured reasoning from non-financial evidence. The first is a non-adversarial single-agent system (NAS) that produces bidirectional analysis through a single-pass reasoning pipeline. The second is a debate-based multi-agent system (KPD-MADS) that operationalizes adversarial verification through a ten-step structured interaction protocol grounded in Karl Popper's critical dialogue framework. Both systems were applied to three real corporate cases and evaluated by experienced credit risk professionals. Compared to manual expert reporting, both systems achieved substantial productivity gains (NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The KPD-MADS demonstrated superior reasoning quality, receiving higher median ratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs. 3.0), and usability (62.5 vs. 52.5). These findings show that structured multi-agent interaction can enhance reasoning rigor and interpretability in financial AI, advancing scalable and defensible automation in corporate credit assessment.","authors":["Yoonjin Lee","Munhee Kim","Hanbi Choi","Juhyeon Park","Seungho Lyoo","Woojin Park"],"pdf_url":"","comment":"18 pages, 4 figures, 2 algorithms, 2 tables, 4 appendices"},{"id":"http://arxiv.org/abs/2511.17068v1","updated":"2025-11-21T09:18:35Z","published":"2025-11-21T09:18:35Z","title":"ReBrain: Brain MRI Reconstruction from Sparse CT Slice via Retrieval-Augmented Diffusion","summary":"Magnetic Resonance Imaging (MRI) plays a crucial role in brain disease diagnosis, but it is not always feasible for certain patients due to physical or clinical constraints. Recent studies attempt to synthesize MRI from Computed Tomography (CT) scans; however, low-dose protocols often result in highly sparse CT volumes with poor through-plane resolution, making accurate reconstruction of the full brain MRI volume particularly challenging. To address this, we propose ReBrain, a retrieval-augmented diffusion framework for brain MRI reconstruction. Given any 3D CT scan with limited slices, we first employ a Brownian Bridge Diffusion Model (BBDM) to synthesize MRI slices along the 2D dimension. Simultaneously, we retrieve structurally and pathologically similar CT slices from a comprehensive prior database via a fine-tuned retrieval model. These retrieved slices are used as references, incorporated through a ControlNet branch to guide the generation of intermediate MRI slices and ensure structural continuity. We further account for rare retrieval failures when the database lacks suitable references and apply spherical linear interpolation to provide supplementary guidance. Extensive experiments on SynthRAD2023 and BraTS demonstrate that ReBrain achieves state-of-the-art performance in cross-modal reconstruction under sparse conditions.","authors":["Junming Liu","Yifei Sun","Weihua Cheng","Yujin Kang","Yirong Chen","Ding Wang","Guosun Zeng"],"pdf_url":"","comment":"16 pages, 12 figures, 7 tables; Accepted by WACV 2026"},{"id":"http://arxiv.org/abs/2504.08016v2","updated":"2025-11-21T09:07:03Z","published":"2025-04-10T15:36:30Z","title":"Emergence of psychopathological computations in large language models","summary":"Can large language models (LLMs) instantiate computations of psychopathology? An effective approach to the question hinges on addressing two factors. First, for conceptual validity, we require a general and computational account of psychopathology that is applicable to computational entities without biological embodiment or subjective experience. Second, psychopathological computations, derived from the adapted theory, need to be empirically identified within the LLM's internal processing. Thus, we establish a computational-theoretical framework to provide an account of psychopathology applicable to LLMs. Based on the framework, we conduct experiments demonstrating two key claims: first, that the computational structure of psychopathology exists in LLMs; and second, that executing this computational structure results in psychopathological functions. We further observe that as LLM size increases, the computational structure of psychopathology becomes denser and that the functions become more effective. Taken together, the empirical results corroborate our hypothesis that network-theoretic computations of psychopathology have already emerged in LLMs. This suggests that certain LLM behaviors mirroring psychopathology may not be a superficial mimicry but a feature of their internal processing. Our work shows the promise of developing a new powerful in silico model of psychopathology and also alludes to the possibility of safety threat from the AI systems with psychopathological behaviors in the near future.","authors":["Soo Yong Lee","Hyunjin Hwang","Taekwan Kim","Yuyeong Kim","Kyuri Park","Jaemin Yoo","Denny Borsboom","Kijung Shin"],"pdf_url":"","comment":"pre-print"},{"id":"http://arxiv.org/abs/2409.11078v2","updated":"2025-11-21T09:05:05Z","published":"2024-09-17T11:10:59Z","title":"MonoKAN: Certified Monotonic Kolmogorov-Arnold Network","summary":"Artificial Neural Networks (ANNs) have significantly advanced various fields by effectively recognizing patterns and solving complex problems. Despite these advancements, their interpretability remains a critical challenge, especially in applications where transparency and accountability are essential. To address this, explainable AI (XAI) has made progress in demystifying ANNs, yet interpretability alone is often insufficient. In certain applications, model predictions must align with expert-imposed requirements, sometimes exemplified by partial monotonicity constraints. While monotonic approaches are found in the literature for traditional Multi-layer Perceptrons (MLPs), they still face difficulties in achieving both interpretability and certified partial monotonicity. Recently, the Kolmogorov-Arnold Network (KAN) architecture, based on learnable activation functions parametrized as splines, has been proposed as a more interpretable alternative to MLPs. Building on this, we introduce a novel ANN architecture called MonoKAN, which is based on the KAN architecture and achieves certified partial monotonicity while enhancing interpretability. To achieve this, we employ cubic Hermite splines, which guarantee monotonicity through a set of straightforward conditions. Additionally, by using positive weights in the linear combinations of these splines, we ensure that the network preserves the monotonic relationships between input and output. Our experiments demonstrate that MonoKAN not only enhances interpretability but also improves predictive performance across the majority of benchmarks, outperforming state-of-the-art monotonic MLP approaches.","authors":["Alejandro Polo-Molina","David Alfaya","Jose Portela"],"pdf_url":"","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.17056v1","updated":"2025-11-21T08:59:42Z","published":"2025-11-21T08:59:42Z","title":"Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks","summary":"Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.","authors":["Paloma Rabaey","Adrick Tench","Stefan Heytens","Thomas Demeester"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17053v1","updated":"2025-11-21T08:54:49Z","published":"2025-11-21T08:54:49Z","title":"OmniPT: Unleashing the Potential of Large Vision Language Models for Pedestrian Tracking and Understanding","summary":"LVLMs have been shown to perform excellently in image-level tasks such as VQA and caption. However, in many instance-level tasks, such as visual grounding and object detection, LVLMs still show performance gaps compared to previous expert models. Meanwhile, although pedestrian tracking is a classical task, there have been a number of new topics in combining object tracking and natural language, such as Referring MOT, Cross-view Referring MOT, and Semantic MOT. These tasks emphasize that models should understand the tracked object at an advanced semantic level, which is exactly where LVLMs excel. In this paper, we propose a new unified Pedestrian Tracking framework, namely OmniPT, which can track, track based on reference and generate semantic understanding of tracked objects interactively. We address two issues: how to model the tracking task into a task that foundation models can perform, and how to make the model output formatted answers. To this end, we implement a training phase consisting of RL-Mid Training-SFT-RL. Based on the pre-trained weights of the LVLM, we first perform a simple RL phase to enable the model to output fixed and supervisable bounding box format. Subsequently, we conduct a mid-training phase using a large number of pedestrian-related datasets. Finally, we perform supervised fine-tuning on several pedestrian tracking datasets, and then carry out another RL phase to improve the model's tracking performance and enhance its ability to follow instructions. We conduct experiments on tracking benchmarks and the experimental results demonstrate that the proposed method can perform better than the previous methods.","authors":["Teng Fu","Mengyang Zhao","Ke Niu","Kaixin Peng","Bin Li"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.17045v1","updated":"2025-11-21T08:44:33Z","published":"2025-11-21T08:44:33Z","title":"RacketVision: A Multiple Racket Sports Benchmark for Unified Ball and Racket Analysis","summary":"We introduce RacketVision, a novel dataset and benchmark for advancing computer vision in sports analytics, covering table tennis, tennis, and badminton. The dataset is the first to provide large-scale, fine-grained annotations for racket pose alongside traditional ball positions, enabling research into complex human-object interactions. It is designed to tackle three interconnected tasks: fine-grained ball tracking, articulated racket pose estimation, and predictive ball trajectory forecasting. Our evaluation of established baselines reveals a critical insight for multi-modal fusion: while naively concatenating racket pose features degrades performance, a CrossAttention mechanism is essential to unlock their value, leading to trajectory prediction results that surpass strong unimodal baselines. RacketVision provides a versatile resource and a strong starting point for future research in dynamic object tracking, conditional motion forecasting, and multimodal analysis in sports. Project page at https://github.com/OrcustD/RacketVision","authors":["Linfeng Dong","Yuchen Yang","Hao Wu","Wei Wang","Yuenan HouZhihang Zhong","Xiao Sun"],"pdf_url":"","comment":"Accepted to AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2511.16541v2","updated":"2025-11-21T08:44:06Z","published":"2025-11-20T16:53:24Z","title":"Supervised Contrastive Learning for Few-Shot AI-Generated Image Detection and Attribution","summary":"The rapid advancement of generative artificial intelligence has enabled the creation of synthetic images that are increasingly indistinguishable from authentic content, posing significant challenges for digital media integrity. This problem is compounded by the accelerated release cycle of novel generative models, which renders traditional detection approaches (reliant on periodic retraining) computationally infeasible and operationally impractical.\n  This work proposes a novel two-stage detection framework designed to address the generalization challenge inherent in synthetic image detection. The first stage employs a vision deep learning model trained via supervised contrastive learning to extract discriminative embeddings from input imagery. Critically, this model was trained on a strategically partitioned subset of available generators, with specific architectures withheld from training to rigorously ablate cross-generator generalization capabilities. The second stage utilizes a k-nearest neighbors (k-NN) classifier operating on the learned embedding space, trained in a few-shot learning paradigm incorporating limited samples from previously unseen test generators.\n  With merely 150 images per class in the few-shot learning regime, which are easily obtainable from current generation models, the proposed framework achieves an average detection accuracy of 91.3%, representing a 5.2 percentage point improvement over existing approaches . For the source attribution task, the proposed approach obtains improvements of of 14.70% and 4.27% in AUC and OSCR respectively on an open set classification context, marking a significant advancement toward robust, scalable forensic attribution systems capable of adapting to the evolving generative AI landscape without requiring exhaustive retraining protocols.","authors":["Jaime Álvarez Urueña","David Camacho","Javier Huertas Tato"],"pdf_url":"","comment":"17 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2511.17043v1","updated":"2025-11-21T08:42:20Z","published":"2025-11-21T08:42:20Z","title":"MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays","summary":"Chest radiography remains one of the most widely used imaging modalities for thoracic diagnosis, yet increasing imaging volumes and radiologist workload continue to challenge timely interpretation. In this work, we investigate the use of MedImageInsight, a medical imaging foundational model, for automated binary classification of chest X-rays into Normal and Abnormal categories. Two approaches were evaluated: (1) fine-tuning MedImageInsight for end-to-end classification, and (2) employing the model as a feature extractor for a transfer learning pipeline using traditional machine learning classifiers. Experiments were conducted using a combination of the ChestX-ray14 dataset and real-world clinical data sourced from partner hospitals. The fine-tuned classifier achieved the highest performance, with an ROC-AUC of 0.888 and superior calibration compared to the transfer learning models, demonstrating performance comparable to established architectures such as CheXNet. These results highlight the effectiveness of foundational medical imaging models in reducing task-specific training requirements while maintaining diagnostic reliability. The system is designed for integration into web-based and hospital PACS workflows to support triage and reduce radiologist burden. Future work will extend the model to multi-label pathology classification to provide preliminary diagnostic interpretation in clinical environments.","authors":["Rama Krishna Boya","Mohan Kireeti Magalanadu","Azaruddin Palavalli","Rupa Ganesh Tekuri","Amrit Pattanayak","Prasanthi Enuga","Vignesh Esakki Muthu","Vivek Aditya Boya"],"pdf_url":"","comment":"9 pages, 5 figures and 3 tables"},{"id":"http://arxiv.org/abs/2511.17041v1","updated":"2025-11-21T08:37:39Z","published":"2025-11-21T08:37:39Z","title":"CLLMRec: LLM-powered Cognitive-Aware Concept Recommendation via Semantic Alignment and Prerequisite Knowledge Distillation","summary":"The growth of Massive Open Online Courses (MOOCs) presents significant challenges for personalized learning, where concept recommendation is crucial. Existing approaches typically rely on heterogeneous information networks or knowledge graphs to capture conceptual relationships, combined with knowledge tracing models to assess learners' cognitive states. However, these methods face significant limitations due to their dependence on high-quality structured knowledge graphs, which are often scarce in real-world educational scenarios. To address this fundamental challenge, this paper proposes CLLMRec, a novel framework that leverages Large Language Models through two synergistic technical pillars: Semantic Alignment and Prerequisite Knowledge Distillation. The Semantic Alignment component constructs a unified representation space by encoding unstructured textual descriptions of learners and concepts. The Prerequisite Knowledge Distillation paradigm employs a teacher-student architecture, where a large teacher LLM (implemented as the Prior Knowledge Aware Component) extracts conceptual prerequisite relationships from its internalized world knowledge and distills them into soft labels to train an efficient student ranker. Building upon these foundations, our framework incorporates a fine-ranking mechanism that explicitly models learners' real-time cognitive states through deep knowledge tracing, ensuring recommendations are both structurally sound and cognitively appropriate. Extensive experiments on two real-world MOOC datasets demonstrate that CLLMRec significantly outperforms existing baseline methods across multiple evaluation metrics, validating its effectiveness in generating truly cognitive-aware and personalized concept recommendations without relying on explicit structural priors.","authors":["Xiangrui Xiong","Yichuan Lu","Zifei Pan","Chang Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17038v1","updated":"2025-11-21T08:28:36Z","published":"2025-11-21T08:28:36Z","title":"DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing","summary":"From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \\textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \\textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.","authors":["Hao Chen","Renzheng Zhang","Scott S. Howard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.01094v2","updated":"2025-11-21T08:00:14Z","published":"2025-05-02T08:14:01Z","title":"Multi-Objective Reinforcement Learning for Water Management","summary":"Many real-world problems (e.g., resource management, autonomous driving, drug discovery) require optimizing multiple, conflicting objectives. Multi-objective reinforcement learning (MORL) extends classic reinforcement learning to handle multiple objectives simultaneously, yielding a set of policies that capture various trade-offs. However, the MORL field lacks complex, realistic environments and benchmarks. We introduce a water resource (Nile river basin) management case study and model it as a MORL environment. We then benchmark existing MORL algorithms on this task. Our results show that specialized water management methods outperform state-of-the-art MORL approaches, underscoring the scalability challenges MORL algorithms face in real-world scenarios.","authors":["Zuzanna Osika","Roxana Rădulescu","Jazmin Zatarain Salazar","Frans Oliehoek","Pradeep K. Murukannaiah"],"pdf_url":"","comment":"Accepted to AAMAS 2025"},{"id":"http://arxiv.org/abs/2511.00794v2","updated":"2025-11-21T07:44:25Z","published":"2025-11-02T04:16:47Z","title":"Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration","summary":"Reinforcement learning with verifiable rewards (RLVR) has improved the reasoning ability of large language models, yet training remains costly because many rollouts contribute little to optimization, considering the amount of computation required. This study investigates how simply leveraging intrinsic data properties, almost free benefit during training, can improve data efficiency for RLVR. We propose PREPO with two complementary components. First, we adopt prompt perplexity as an indicator of model adaptability in learning, enabling the model to progress from well-understood contexts to more challenging ones. Second, we amplify the discrepancy among the rollouts by differentiating their relative entropy, and prioritize sequences that exhibit a higher degree of exploration. Together, these mechanisms reduce rollout demand while preserving competitive performance. On the Qwen and Llama models, PREPO achieves effective results on mathematical reasoning benchmarks with up to 3 times fewer rollouts than the baselines. Beyond empirical gains, we provide theoretical and in-depth analyses explaining the underlying rationale of our method to improve the data efficiency of RLVR.","authors":["Yan Sun","Jia Guo","Stanley Kok","Zihao Wang","Zujie Wen","Zhiqiang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10135v2","updated":"2025-11-21T07:42:59Z","published":"2025-10-11T09:36:20Z","title":"CharCom: Composable Identity Control for Multi-Character Story Illustration","summary":"Ensuring character identity consistency across varying prompts remains a fundamental limitation in diffusion-based text-to-image generation. We propose CharCom, a modular and parameter-efficient framework that achieves character-consistent story illustration through composable LoRA adapters, enabling efficient per-character customization without retraining the base model. Built on a frozen diffusion backbone, CharCom dynamically composes adapters at inference using prompt-aware control. Experiments on multi-scene narratives demonstrate that CharCom significantly enhances character fidelity, semantic alignment, and temporal coherence. It remains robust in crowded scenes and enables scalable multi-character generation with minimal overhead, making it well-suited for real-world applications such as story illustration and animation.","authors":["Zhongsheng Wang","Ming Lin","Zhedong Lin","Yaser Shakib","Qian Liu","Jiamou Liu"],"pdf_url":"","comment":"Accepted by ACM MMAsia 2025"},{"id":"http://arxiv.org/abs/2510.20333v2","updated":"2025-11-21T07:38:12Z","published":"2025-10-23T08:33:24Z","title":"GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?","summary":"Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.","authors":["Chiyu Chen","Xinhao Song","Yunkai Chai","Yang Yao","Haodong Zhao","Lijun Li","Jie Li","Yan Teng","Gongshen Liu","Yingchun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16193v2","updated":"2025-11-21T07:34:03Z","published":"2025-11-20T10:00:03Z","title":"Fast LLM Post-training via Decoupled and Best-of-N Speculation","summary":"Rollout dominates the training time in large language model (LLM) post-training, where the trained model is used to generate tokens given a batch of prompts. SpecActor achieves fast rollout with speculative decoding that deploys a fast path (e.g., a smaller model) to accelerate the unparallelizable generation, while the correctness is guaranteed by fast parallel verification of the outputs with the original model. SpecActor addresses two foundational challenges in speculative rollout by (1) a \\emph{dynamic decoupled speculation} execution method that maximizes the GPU computational efficiency to realize speedup for large-batch execution -- a configuration common in training but unfriendly to speculative execution and (2) a \\emph{dynamic Best-of-N speculation} method that selects and combines different drafting methods according to the rollout progress. It substantially improves the speculation accuracy even when the best drafting method is unknown a priori, meanwhile without requiring adding extra computation resources. {\\sys} is {1.7}\\,$\\times$ faster than veRL in end-to-end training, and is {1.3--1.5}\\,$\\times$ faster compared to baselines with speculative decoding.","authors":["Rongxin Cheng","Kai Zhou","Xingda Wei","Siyuan Liu","Mingcong Han","Mingjing Ai","Yeju Zhou","Baoquan Zhong","Wencong Xiao","Rong Chen","Haibo Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17014v1","updated":"2025-11-21T07:32:05Z","published":"2025-11-21T07:32:05Z","title":"Parameter-Free Neural Lens Blur Rendering for High-Fidelity Composites","summary":"Consistent and natural camera lens blur is important for seamlessly blending 3D virtual objects into photographed real-scenes. Since lens blur typically varies with scene depth, the placement of virtual objects and their corresponding blur levels significantly affect the visual fidelity of mixed reality compositions. Existing pipelines often rely on camera parameters (e.g., focal length, focus distance, aperture size) and scene depth to compute the circle of confusion (CoC) for realistic lens blur rendering. However, such information is often unavailable to ordinary users, limiting the accessibility and generalizability of these methods. In this work, we propose a novel compositing approach that directly estimates the CoC map from RGB images, bypassing the need for scene depth or camera metadata. The CoC values for virtual objects are inferred through a linear relationship between its signed CoC map and depth, and realistic lens blur is rendered using a neural reblurring network. Our method provides flexible and practical solution for real-world applications. Experimental results demonstrate that our method achieves high-fidelity compositing with realistic defocus effects, outperforming state-of-the-art techniques in both qualitative and quantitative evaluations.","authors":["Lingyan Ruan","Bin Chen","Taehyun Rhee"],"pdf_url":"","comment":"Accepted by ISMAR 2025 with oral presentation. 10 pages, 11 figures"},{"id":"http://arxiv.org/abs/2511.17012v1","updated":"2025-11-21T07:30:20Z","published":"2025-11-21T07:30:20Z","title":"Supervised Fine Tuning of Large Language Models for Domain Specific Knowledge Graph Construction:A Case Study on Hunan's Historical Celebrities","summary":"Large language models and knowledge graphs offer strong potential for advancing research on historical culture by supporting the extraction, analysis, and interpretation of cultural heritage. Using Hunan's modern historical celebrities shaped by Huxiang culture as a case study, pre-trained large models can help researchers efficiently extract key information, including biographical attributes, life events, and social relationships, from textual sources and construct structured knowledge graphs. However, systematic data resources for Hunan's historical celebrities remain limited, and general-purpose models often underperform in domain knowledge extraction and structured output generation in such low-resource settings. To address these issues, this study proposes a supervised fine-tuning approach for enhancing domain-specific information extraction. First, we design a fine-grained, schema-guided instruction template tailored to the Hunan historical celebrities domain and build an instruction-tuning dataset to mitigate the lack of domain-specific training corpora. Second, we apply parameter-efficient instruction fine-tuning to four publicly available large language models - Qwen2.5-7B, Qwen3-8B, DeepSeek-R1-Distill-Qwen-7B, and Llama-3.1-8B-Instruct - and develop evaluation criteria for assessing their extraction performance. Experimental results show that all models exhibit substantial performance gains after fine-tuning. Among them, Qwen3-8B achieves the strongest results, reaching a score of 89.3866 with 100 samples and 50 training iterations. This study provides new insights into fine-tuning vertical large language models for regional historical and cultural domains and highlights their potential for cost-effective applications in cultural heritage knowledge extraction and knowledge graph construction.","authors":["Junjie Hao","Chun Wang","Ying Qiao","Qiuyue Zuo","Qiya Song","Hua Ma","Xieping Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17006v1","updated":"2025-11-21T07:18:55Z","published":"2025-11-21T07:18:55Z","title":"Budget-Aware Tool-Use Enables Effective Agent Scaling","summary":"Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack \"budget awareness\" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to \"dig deeper\" on a promising lead or \"pivot\" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.","authors":["Tengxiao Liu","Zifeng Wang","Jin Miao","I-Hung Hsu","Jun Yan","Jiefeng Chen","Rujun Han","Fangyuan Xu","Yanfei Chen","Ke Jiang","Samira Daruki","Yi Liang","William Yang Wang","Tomas Pfister","Chen-Yu Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17005v1","updated":"2025-11-21T07:18:37Z","published":"2025-11-21T07:18:37Z","title":"FLUID: Training-Free Face De-identification via Latent Identity Substitution","summary":"We present FLUID (Face de-identification in the Latent space via Utility-preserving Identity Displacement), a training-free framework that directly substitutes identity in the latent space of pretrained diffusion models. Inspired by substitution mechanisms in chemistry, we reinterpret identity editing as semantic displacement in the latent h-space of a pretrained unconditional diffusion model. Our framework discovers identity-editing directions through optimization guided by novel reagent losses, which supervise for attribute preservation and identity suppression. We further propose both linear and geodesic (tangent-based) editing schemes to effectively navigate the latent manifold. Experimental results on CelebA-HQ and FFHQ demonstrate that FLUID achieves a superior trade-off between identity suppression and attribute preservation, outperforming state-of-the-art de-identification methods in both qualitative and quantitative metrics.","authors":["Jinhyeong Park","Shaheryar Muhammad","Seangmin Lee","Jong Taek Lee","Soon Ki Jung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16600v2","updated":"2025-11-21T07:08:45Z","published":"2025-11-20T17:55:21Z","title":"You Only Forward Once: An Efficient Compositional Judging Paradigm","summary":"Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis -- where subsequent judgments are conditioned on previous ones -- and further benefits from post-hoc CoT.","authors":["Tianlong Zhang","Hongwei Xue","Shilin Yan","Di Wu","Chen Xu","Yunyun Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16997v1","updated":"2025-11-21T07:05:26Z","published":"2025-11-21T07:05:26Z","title":"MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists","summary":"The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.","authors":["Qingbin Zeng","Bingbing Fan","Zhiyu Chen","Sijian Ren","Zhilun Zhou","Xuhua Zhang","Yuanyi Zhen","Fengli Xu","Yong Li","Tie-Yan Liu"],"pdf_url":"","comment":"26 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.16979v1","updated":"2025-11-21T06:19:19Z","published":"2025-11-21T06:19:19Z","title":"The Finer the Better: Towards Granular-aware Open-set Domain Generalization","summary":"Open-Set Domain Generalization (OSDG) tackles the realistic scenario where deployed models encounter both domain shifts and novel object categories. Despite impressive progress with vision-language models like CLIP, existing methods still fall into the dilemma between structural risk of known-classes and open-space risk from unknown-classes, and easily suffers from over-confidence, especially when distinguishing ``hard unknowns\" that share fine-grained visual similarities with known classes. To this end, we propose a Semantic-enhanced CLIP (SeeCLIP) framework that explicitly addresses this dilemma through fine-grained semantic enhancement. In SeeCLIP, we propose a semantic-aware prompt enhancement module to decompose images into discriminative semantic tokens, enabling nuanced vision-language alignment beyond coarse category labels. To position unknown prompts effectively, we introduce duplex contrastive learning with complementary objectives, that is, repulsion to maintain separability from known classes, and cohesion to preserve semantic proximity. Further, our semantic-guided diffusion module synthesizes pseudo-unknowns by perturbing extracted semantic tokens, generating challenging samples that are visually similar to known classes yet exhibit key local differences. These hard negatives force the model to learn finer decision boundaries. Extensive experiments across five benchmarks demonstrate consistent improvements of 3% accuracy and 5% H-score over state-of-the-art methods.","authors":["Yunyun Wang","Zheng Duan","Xinyue Liao","Ke-Jia Chen","Songcan Chen"],"pdf_url":"","comment":"9 pages,3 figures,aaai2026"},{"id":"http://arxiv.org/abs/2511.15974v2","updated":"2025-11-21T06:00:04Z","published":"2025-11-20T02:04:46Z","title":"KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy","summary":"Clinical antimicrobial therapy requires the dynamic integration of pathogen profiles,host factors, pharmacological properties of antimicrobials,and the severity of infection. This complexity imposes fundamental limitations on the applicability of Large Language Models (LLMs) in high-stakes clinical decision-making including knowledge gaps, data privacy concerns, high deployment costs, and limited reasoning capabilities. To address these challenges, we propose KRAL (Knowledge and Reasoning Augmented Learning), a low-cost, scalable, privacy-preserving paradigm that leverages teacher-model reasoning to automatically distill knowledge and reasoning trajectories via answer-to-question reverse generation, employs heuristic learning for semi-supervised data augmentation (reducing manual annotation requirements by approximately 80%), and utilizes agentic reinforcement learning to jointly enhance medical knowledge and reasoning while optimizing computational and memory efficiency. A hierarchical evaluation employing diverse teacher-model proxies reduces assessment costs, while modular interface design facilitates seamless system updates. Experimental results demonstrate that KRAL significantly outperforms traditional Retrieval-Augmented Generation (RAG) and Supervised Fine-Tuning (SFT) methods. It improves knowledge question-answering capability (Accuracy@1 on the external open-source benchmark MEDQA increased by 1.8% vs. SFT and 3.6% vs. RAG) and reasoning capability (Pass@1 on the external benchmark PUMCH Antimicrobial increased by 27% vs. SFT and 27.2% vs. RAG), achieved at about 20% of SFT's long-term training costs. This establishes KRAL as an effective solution for enhancing local LLMs' clinical diagnostic capabilities, enabling low-cost, high-safety deployment in complex medical decision support.","authors":["Zhe Li","Yehan Qiu","Yujie Chen","Xiang Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10599v3","updated":"2025-11-21T05:56:07Z","published":"2025-08-14T12:40:19Z","title":"MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models","summary":"Activation steering offers a promising approach to controlling the behavior of Large Language Models by directly manipulating their internal activations. However, most existing methods struggle to jointly steer multiple attributes, often resulting in interference and undesirable trade-offs. To address this challenge, we propose Multi-Subspace Representation Steering (MSRS), a novel framework for effective multi-attribute steering via subspace representation fine-tuning. MSRS reduces inter-attribute interference by allocating orthogonal subspaces to each attribute, isolating their influence within the model's representation space. MSRS also incorporates a hybrid subspace composition strategy: it combines attribute-specific subspaces for unique steering directions with a shared subspace for common steering directions. A dynamic weighting function learns to efficiently integrate these components for precise control. During inference, MSRS introduces a token-level steering mechanism that dynamically identifies and intervenes on the most semantically relevant tokens, enabling fine-grained behavioral modulation. Experimental results show that MSRS significantly reduces attribute conflicts, surpasses existing methods across a range of attributes, and generalizes effectively to diverse downstream tasks.","authors":["Xinyan Jiang","Lin Zhang","Jiayi Zhang","Qingsong Yang","Guimin Hu","Di Wang","Lijie Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.12194v2","updated":"2025-11-21T05:43:16Z","published":"2025-10-14T06:40:11Z","title":"ResearStudio: A Human-Intervenable Framework for Building Controllable Deep-Research Agents","summary":"Current deep-research agents run in a ''fire-and-forget'' mode: once started, they give users no way to fix errors or add expert knowledge during execution. We present ResearStudio, the first open-source framework that places real-time human control at its core. The system follows a Collaborative Workshop design. A hierarchical Planner-Executor writes every step to a live ''plan-as-document,'' a fast communication layer streams each action, file change, and tool call to a web interface. At any moment, the user can pause the run, edit the plan or code, run custom commands, and resume -- switching smoothly between AI-led, human-assisted and human-led, AI-assisted modes. In fully autonomous mode, ResearStudio achieves state-of-the-art results on the GAIA benchmark, surpassing systems like OpenAI's DeepResearch and Manus. These results show that strong automated performance and fine-grained human control can coexist. The full code, protocol, and evaluation scripts are available at https://github.com/ResearAI/ResearStudio. We will continue to update the repository to encourage further work on safe and controllable research agents. Our live demo is publicly accessible at http://ai-researcher.net:3000/. We support the development of DeepScientist, which can be accessed at https://github.com/ResearAI/DeepScientist.","authors":["Linyi Yang","Yixuan Weng"],"pdf_url":"","comment":"EMNLP 2025 Demo, Oral"},{"id":"http://arxiv.org/abs/2511.16964v1","updated":"2025-11-21T05:37:38Z","published":"2025-11-21T05:37:38Z","title":"Optimizing PyTorch Inference with LLM-Based Multi-Agent Systems","summary":"Maximizing performance on available GPU hardware is an ongoing challenge for modern AI inference systems. Traditional approaches include writing custom GPU kernels and using specialized model compilers to tune high-level code for specific GPU targets. Recent work shows that LLM-based multi-agent systems can effectively perform such tuning, often outperforming existing compilers and eliminating the need for manual kernel development. However, the dynamics of multi-agent systems for this task remain unexplored. In this work, we present a logical framework for comparing multi-agent PyTorch optimization systems. Our evaluation shows that exploit-heavy strategies perform best when paired with error-fixing agents, and that performance correlates with the granularity of optimization steps. The best implementation achieves an average 2.88x speedup on an H100 GPU across diverse tasks in KernelBench, a benchmark suite covering a range of machine learning architectures in PyTorch.","authors":["Kirill Nagaitsev","Luka Grbcic","Samuel Williams","Costin Iancu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16961v1","updated":"2025-11-21T05:25:23Z","published":"2025-11-21T05:25:23Z","title":"Comparing verbal, visual and combined explanations for Bayesian Network inferences","summary":"Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of BNs. To address this problem, we have designed verbal and visual extensions to the standard BN UI, which can guide users through common inference patterns.\n  We conducted a user study to compare our verbal, visual and combined UI extensions, and a baseline UI. Our main findings are: (1) users did better with all three types of extensions than with the baseline UI for questions about the impact of an observation, the paths that enable this impact, and the way in which an observation influences the impact of other observations; and (2) using verbal and visual modalities together is better than using either modality alone for some of these question types.","authors":["Erik P. Nyberg","Steven Mascaro","Ingrid Zukerman","Michael Wybrow","Duc-Minh Vo","Ann Nicholson"],"pdf_url":"","comment":"26 pages total, 12 pages main, 14 pages for 5 appendices"},{"id":"http://arxiv.org/abs/2311.02733v2","updated":"2025-11-21T05:23:01Z","published":"2023-11-05T18:35:03Z","title":"AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Deepfake Detection of Frontal Face Videos","summary":"Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multimodal models that can exploit both pieces of information simultaneously. However, previous methods mainly adopt unimodal video forensics and use supervised pre-training for forgery detection. This study proposes a new method based on a multimodal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multimodal video forgery detection. We use the transformer-based SSL pre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multi-scale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.","authors":["Sahibzada Adil Shahzad","Ammarah Hashmi","Yan-Tsung Peng","Yu Tsao","Hsin-Min Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.22300v2","updated":"2025-11-21T05:17:51Z","published":"2025-10-25T14:00:26Z","title":"T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense on Text-to-Image Model","summary":"Using risky text prompts, such as pornography and violent prompts, to test the safety of text-to-image (T2I) models is a critical task. However, existing risky prompt datasets are limited in three key areas: 1) limited risky categories, 2) coarse-grained annotation, and 3) low effectiveness. To address these limitations, we introduce T2I-RiskyPrompt, a comprehensive benchmark designed for evaluating safety-related tasks in T2I models. Specifically, we first develop a hierarchical risk taxonomy, which consists of 6 primary categories and 14 fine-grained subcategories. Building upon this taxonomy, we construct a pipeline to collect and annotate risky prompts. Finally, we obtain 6,432 effective risky prompts, where each prompt is annotated with both hierarchical category labels and detailed risk reasons. Moreover, to facilitate the evaluation, we propose a reason-driven risky image detection method that explicitly aligns the MLLM with safety annotations. Based on T2I-RiskyPrompt, we conduct a comprehensive evaluation of eight T2I models, nine defense methods, five safety filters, and five attack strategies, offering nine key insights into the strengths and limitations of T2I model safety. Finally, we discuss potential applications of T2I-RiskyPrompt across various research fields. The dataset and code are provided in https://github.com/datar001/T2I-RiskyPrompt.","authors":["Chenyu Zhang","Tairen Zhang","Lanjun Wang","Ruidong Chen","Wenhui Li","Anan Liu"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.07772v2","updated":"2025-11-21T04:57:07Z","published":"2025-11-11T02:45:48Z","title":"SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought","summary":"As Large Language Models (LLMs) evolve into personal assistants with access to sensitive user data, they face a critical privacy challenge: while prior work has addressed output-level privacy, recent findings reveal that LLMs often leak private information through their internal reasoning processes, violating contextual privacy expectations. These leaky thoughts occur when models inadvertently expose sensitive details in their reasoning traces, even when final outputs appear safe. The challenge lies in preventing such leakage without compromising the model's reasoning capabilities, requiring a delicate balance between privacy and utility. We introduce Steering Activations towards Leakage-free Thinking (SALT), a lightweight test-time intervention that mitigates privacy leakage in model's Chain of Thought (CoT) by injecting targeted steering vectors into hidden state. We identify the high-leakage layers responsible for this behavior. Through experiments across multiple LLMs, we demonstrate that SALT achieves reductions including $18.2\\%$ reduction in CPL on QwQ-32B, $17.9\\%$ reduction in CPL on Llama-3.1-8B, and $31.2\\%$ reduction in CPL on Deepseek in contextual privacy leakage dataset AirGapAgent-R while maintaining comparable task performance and utility. Our work establishes SALT as a practical approach for test-time privacy protection in reasoning-capable language models, offering a path toward safer deployment of LLM-based personal agents.","authors":["Shourya Batra","Pierce Tillman","Samarth Gaggar","Shashank Kesineni","Kevin Zhu","Sunishchal Dev","Ashwinee Panda","Vasu Sharma","Maheep Chaudhary"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.17987v3","updated":"2025-11-21T04:55:46Z","published":"2025-03-23T08:40:39Z","title":"Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning","summary":"Text-to-Image(T2I) models typically deploy safety filters to prevent the generation of sensitive images. Unfortunately, recent jailbreaking attack methods manually design instructions for the LLM to generate adversarial prompts, which effectively bypass safety filters while producing sensitive images, exposing safety vulnerabilities of T2I models. However, due to the LLM's limited understanding of the T2I model and its safety filters, existing methods require numerous queries to achieve a successful attack, limiting their practical applicability. To address this issue, we propose Reason2Attack(R2A), which aims to enhance the LLM's reasoning capabilities in generating adversarial prompts by incorporating the jailbreaking attack into the post-training process of the LLM. Specifically, we first propose a CoT example synthesis pipeline based on Frame Semantics, which generates adversarial prompts by identifying related terms and corresponding context illustrations. Using CoT examples generated by the pipeline, we fine-tune the LLM to understand the reasoning path and format the output structure. Subsequently, we incorporate the jailbreaking attack task into the reinforcement learning process of the LLM and design an attack process reward that considers prompt length, prompt stealthiness, and prompt effectiveness, aiming to further enhance reasoning accuracy. Extensive experiments on various T2I models show that R2A achieves a better attack success ratio while requiring fewer queries than baselines. Moreover, our adversarial prompts demonstrate strong attack transferability across both open-source and commercial T2I models.","authors":["Chenyu Zhang","Lanjun Wang","Yiwen Ma","Wenhui Li","An-An Liu"],"pdf_url":"","comment":"Noted that This paper includes model-generated content that may contain offensive or distressing material"},{"id":"http://arxiv.org/abs/2511.16943v1","updated":"2025-11-21T04:39:32Z","published":"2025-11-21T04:39:32Z","title":"RASTP: Representation-Aware Semantic Token Pruning for Generative Recommendation with Semantic Identifiers","summary":"Generative recommendation systems typically leverage Semantic Identifiers (SIDs), which represent each item as a sequence of tokens that encode semantic information. However, representing item ID with multiple SIDs significantly increases input sequence length, which is a major determinant of computational complexity and memory consumption. While existing efforts primarily focus on optimizing attention computation and KV cache, we propose RASTP (Representation-Aware Semantic Token Pruning), which directly prunes less informative tokens in the input sequence. Specifically, RASTP evaluates token importance by combining semantic saliency, measured via representation magnitude, and attention centrality, derived from cumulative attention weights. Since RASTP dynamically prunes low-information or irrelevant semantic tokens, experiments on three real-world Amazon datasets show that RASTP reduces training time by 26.7\\%, while maintaining or slightly improving recommendation performance. The code has been open-sourced at https://github.com/Yuzt-zju/RASTP.","authors":["Tianyu Zhan","Kairui Fu","Zheqi Lv","Shengyu Zhang"],"pdf_url":"","comment":"4 pages"},{"id":"http://arxiv.org/abs/2410.13597v3","updated":"2025-11-21T04:30:39Z","published":"2024-10-17T14:30:27Z","title":"Text-guided multi-property molecular optimization with a diffusion language model","summary":"Molecular optimization (MO) is a crucial stage in drug discovery in which task-oriented generated molecules are optimized to meet practical industrial requirements. Existing mainstream MO approaches primarily utilize external property predictors to guide iterative property optimization. However, learning all molecular samples in the vast chemical space is unrealistic for predictors. As a result, errors and noise are inevitably introduced during property prediction due to the nature of approximation. This leads to discrepancy accumulation, generalization reduction and suboptimal molecular candidates. In this paper, we propose a text-guided multi-property molecular optimization method utilizing transformer-based diffusion language model (TransDLM). TransDLM leverages standardized chemical nomenclature as semantic representations of molecules and implicitly embeds property requirements into textual descriptions, thereby mitigating error propagation during diffusion process. By fusing physically and chemically detailed textual semantics with specialized molecular representations, TransDLM effectively integrates diverse information sources to guide precise optimization, which enhances the model's ability to balance structural retention and property enhancement. Additionally, the success of a case study further demonstrates TransDLM's ability to solve practical problems. Experimentally, our approach surpasses state-of-the-art methods in maintaining molecular structural similarity and enhancing chemical properties on the benchmark dataset.","authors":["Yida Xiong","Kun Li","Jiameng Chen","Hongzhi Zhang","Di Lin","Yan Che","Wenbin Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.18694v2","updated":"2025-11-21T04:30:13Z","published":"2025-08-26T05:39:47Z","title":"AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot","summary":"Advances in AI and Robotics have accelerated significant initiatives in agriculture, particularly in the areas of robot navigation and 3D digital twin creation. A significant bottleneck impeding this progress is the critical lack of \"in-the-wild\" datasets that capture the full complexities of real farmland, including non-rigid motion from wind, drastic illumination variance, and morphological changes resulting from growth. This data gap fundamentally limits research on robust AI models for autonomous field navigation and scene-level dynamic 3D reconstruction. In this paper, we present AgriChrono, a modular robotic data collection platform and multi-modal dataset designed to capture these dynamic farmland conditions. Our platform integrates multiple sensors, enabling remote, time-synchronized acquisition of RGB, Depth, LiDAR, IMU, and Pose data for efficient and repeatable long-term data collection in real-world agricultural environments. We successfully collected 18TB of data over one month, documenting the entire growth cycle of Canola under diverse illumination conditions. We benchmark state-of-the-art 3D reconstruction methods on AgriChrono, revealing the profound challenge of reconstructing high-fidelity, dynamic non-rigid scenes in such farmland settings. This benchmark validates AgriChrono as a critical asset for advancing model generalization, and its public release is expected to significantly accelerate research and development in precision agriculture. The code and dataset are publicly available at: https://github.com/StructuresComp/agri-chrono","authors":["Jaehwan Jeong","Tuan-Anh Vu","Mohammad Jony","Shahab Ahmad","Md. Mukhlesur Rahman","Sangpil Kim","M. Khalid Jawed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16937v1","updated":"2025-11-21T04:23:04Z","published":"2025-11-21T04:23:04Z","title":"OmniGround: A Comprehensive Spatio-Temporal Grounding Benchmark for Real-World Complex Scenarios","summary":"Spatio-Temporal Video Grounding (STVG) aims to localize target objects in videos based on natural language descriptions. Despite recent advances in Multimodal Large Language Models, a significant gap remains between current models and real-world demands involving diverse objects and complex queries. We attribute this to limited benchmark scope, causing models to exhibit category bias, oversimplified reasoning, and poor linguistic robustness. To address these limitations, we introduce OmniGround, a comprehensive benchmark with 3,475 videos spanning 81 categories and complex real-world queries. We propose the Forward-Backward-Refinement annotation pipeline that combines multi-directional tracking with intelligent error correction for high-quality labels. We further introduce DeepSTG, a systematic evaluation framework quantifying dataset quality across four complementary dimensions beyond superficial statistics. Evaluations reveal performance average drop of 10.4% on complex real-world scenes, particularly with small/occluded objects and intricate spatial relations. Motivated by these, we propose PG-TAF, a training-free two-stage framework decomposing STVG into high-level temporal grounding and fine-grained spatio-temporal propagation. Experiments demonstrate PG-TAF achieves 25.6% and 35.6% improvements in m\\_tIoU and m\\_vIoU on OmniGround with consistent gains across four benchmarks.","authors":["Hong Gao","Jingyu Wu","Xiangkai Xu","Kangni Xie","Yunchen Zhang","Bin Zhong","Xurui Gao","Min-Ling Zhang"],"pdf_url":"","comment":"20 pages"},{"id":"http://arxiv.org/abs/2511.16202v2","updated":"2025-11-21T03:50:21Z","published":"2025-11-20T10:12:34Z","title":"Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning","summary":"We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.","authors":["Pei Yang","Ke Zhang","Ji Wang","Xiao Chen","Yuxin Tang","Eric Yang","Lynn Ai","Bill Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16916v1","updated":"2025-11-21T02:58:04Z","published":"2025-11-21T02:58:04Z","title":"Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving","summary":"In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.","authors":["Ye Han","Lijun Zhang","Dejian Meng","Zhuang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16912v1","updated":"2025-11-21T02:51:15Z","published":"2025-11-21T02:51:15Z","title":"PepEVOLVE: Position-Aware Dynamic Peptide Optimization via Group-Relative Advantage","summary":"Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists to pre-specify mutable positions for optimization, choices that are not always known a priori, and rely on static pretraining and optimization algorithms that limit the model's ability to generalize and effectively optimize peptide sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that learns both where to edit and how to dynamically optimize peptides for multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic masking and CHUCKLES shifting to improve generalization, (ii) uses a context-free multi-armed bandit router that discovers high-reward residues, and (iii) couples a novel evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates. During in silico evaluations, the router policy reliably learns and concentrates probability on chemically meaningful sites that influence the peptide's properties. On a therapeutically motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under the task of optimizing permeability and lipophilicity with structural constraints. Overall, PepEVOLVE offers a practical, reproducible path to peptide lead optimization when optimal edit sites are unknown, enabling more efficient exploration and improving design quality across multiple objectives.","authors":["Trieu Nguyen","Hao-Wei Pang","Shasha Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12797v2","updated":"2025-11-21T02:11:05Z","published":"2025-11-16T21:56:39Z","title":"Genomic Next-Token Predictors are In-Context Learners","summary":"In-context learning (ICL) -- the capacity of a model to infer and apply abstract patterns from examples provided within its input -- has been extensively studied in large language models trained for next-token prediction on human text. In fact, prior work often attributes this emergent behavior to distinctive statistical properties in human language. This raises a fundamental question: can ICL arise organically in other sequence domains purely through large-scale predictive training?\n  To explore this, we turn to genomic sequences, an alternative symbolic domain rich in statistical structure. Specifically, we study the Evo2 genomic model, trained predominantly on next-nucleotide (A/T/C/G) prediction, at a scale comparable to mid-sized LLMs. We develop a controlled experimental framework comprising symbolic reasoning tasks instantiated in both linguistic and genomic forms, enabling direct comparison of ICL across genomic and linguistic models. Our results show that genomic models, like their linguistic counterparts, exhibit log-linear gains in pattern induction as the number of in-context demonstrations increases. To the best of our knowledge, this is the first evidence of organically emergent ICL in genomic sequences, supporting the hypothesis that ICL arises as a consequence of large-scale predictive modeling over rich data. These findings extend emergent meta-learning beyond language, pointing toward a unified, modality-agnostic view of in-context learning.","authors":["Nathan Breslow","Aayush Mishra","Mahler Revsine","Michael C. Schatz","Anqi Liu","Daniel Khashabi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13827v2","updated":"2025-11-21T02:06:39Z","published":"2025-10-10T03:07:55Z","title":"Bridging the Semantic Gap: Contrastive Rewards for Multilingual Text-to-SQL with GRPO","summary":"Current Text-to-SQL methods are evaluated and only focused on executable queries, overlooking the semantic alignment challenge -- both in terms of the semantic meaning of the query and the correctness of the execution results. Even execution accuracy itself shows significant drops when moving from English to other languages, with an average decline of 6 percentage points across non-English languages. We address these challenges by presenting a new framework that combines Group Relative Policy Optimization (GRPO) within a multilingual contrastive reward signal to enhance both task efficiency and semantic accuracy in Text-to-SQL systems in cross-lingual scenarios. Our method teaches models to obtain better correspondence between SQL generation and user intent by combining a reward signal based on semantic similarity. On the seven-language MultiSpider dataset, fine-tuning the LLaMA-3-3B model with GRPO improved the execution accuracy up to 87.4 percent (+26 pp over zero-shot) and semantic accuracy up to 52.29 percent (+32.86 pp). Adding our contrastive reward signal in the GRPO framework further improved the average semantic accuracy to 59.14 percent (+6.85 pp, up to +10 pp for Vietnamese). Our experiments showcase that a smaller, parameter-efficient 3B LLaMA model fine-tuned with our contrastive reward signal outperforms a much larger zero-shot 8B LLaMA model, with an uplift of 7.43 pp in execution accuracy (from 81.43 percent on the 8B model to 88.86 percent on the 3B model), and nearly matches its semantic accuracy (59.14 percent vs. 68.57 percent) -- all using just 3,000 reinforcement learning training examples. These results demonstrate how we can improve the performance of Text-to-SQL systems with contrastive rewards for directed semantic alignment, without requiring large-scale training datasets.","authors":["Ashish Kattamuri","Ishita Prasad","Meetu Malhotra","Arpita Vats","Rahul Raja","Albert Lie"],"pdf_url":"","comment":"20th International Workshop on Semantic and Social Media Adaptation & Personalization"},{"id":"http://arxiv.org/abs/2511.16886v1","updated":"2025-11-21T01:54:23Z","published":"2025-11-21T01:54:23Z","title":"Deep Improvement Supervision","summary":"Recently, it was shown that small, looped architectures, such as Tiny Recursive Models (TRMs), can outperform Large Language Models (LLMs) on complex reasoning tasks, including the Abstraction and Reasoning Corpus (ARC). In this work, we investigate a core question: how can we further improve the efficiency of these methods with minimal changes? To address this, we frame the latent reasoning of TRMs as a form of classifier-free guidance and implicit policy improvement algorithm. Building on these insights, we propose a novel training scheme that provides a target for each loop during training. We demonstrate that our approach significantly enhances training efficiency. Our method reduces the total number of forward passes by 18x and eliminates halting mechanisms, while maintaining quality comparable to standard TRMs. Notably, we achieve 24% accuracy on ARC-1 with only 0.8M parameters, outperforming most LLMs.","authors":["Arip Asadulaev","Rayan Banerjee","Fakhri Karray","Martin Takac"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.25522v3","updated":"2025-11-21T01:54:14Z","published":"2025-10-29T13:46:19Z","title":"Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography","summary":"Segmentation of liver structures in multi-phase contrast-enhanced computed tomography (CECT) plays a crucial role in computer-aided diagnosis and treatment planning for liver diseases, including tumor detection. In this study, we investigate the performance of UNet-based architectures for liver tumor segmentation, starting from the original UNet and extending to UNet3+ with various backbone networks. We evaluate ResNet, Transformer-based, and State-space (Mamba) backbones, all initialized with pretrained weights. Surprisingly, despite the advances in modern architecture, ResNet-based models consistently outperform Transformer- and Mamba-based alternatives across multiple evaluation metrics. To further improve segmentation quality, we introduce attention mechanisms into the backbone and observe that incorporating the Convolutional Block Attention Module (CBAM) yields the best performance. ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a Dice score of 0.755 and IoU of 0.662, but also achieved the most precise boundary delineation, evidenced by the lowest HD95 distance of 77.911. The model's superiority was further cemented by its leading overall accuracy of 0.925 and specificity of 0.926, showcasing its robust capability in accurately identifying both lesion and healthy tissue. To further enhance interpretability, Grad-CAM visualizations were employed to highlight the region's most influential predictions, providing insights into its decision-making process. These findings demonstrate that classical ResNet architecture, when combined with modern attention modules, remain highly competitive for medical image segmentation tasks, offering a promising direction for liver tumor detection in clinical practice.","authors":["Doan-Van-Anh Ly","Thi-Thu-Hien Pham","Thanh-Hai Le"],"pdf_url":"","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.16884v1","updated":"2025-11-21T01:34:28Z","published":"2025-11-21T01:34:28Z","title":"Generative AI in Sociological Research: State of the Discipline","summary":"Generative artificial intelligence (GenAI) has garnered considerable attention for its potential utility in research and scholarship, even among those who typically do not rely on computational tools. Early commentators, however, have also articulated concerns about how GenAI usage comes with enormous environmental costs, serious social risks, and a tendency to produce low-quality content. In the midst of both excitement and skepticism, it is crucial to take stock of how GenAI is actually being used. Our study focuses on sociological research as our site, and here we present findings from a survey of 433 authors of articles published in 50 sociology journals in the last five years. The survey provides an overview of the state of the discipline with regard to the use of GenAI by providing answers to fundamental questions: how (much) do scholars use the technology for their research; what are their reasons for using it; and how concerned, trustful, and optimistic are they about the technology? Of the approximately one third ofrespondents who self-report using GenAI at least weekly, the primary uses are for writing assistance and comparatively less so in planning, data collection, or data analysis. In both use and attitudes, there are surprisingly few differences between self-identified computational and non-computational researchers. Generally, respondents are very concerned about the social and environmental consequences of GenAI. Trust in GenAI outputs is low, regardless of expertise or frequency of use. While optimism that GenAI will improve is high, scholars are divided on whether GenAI will have a positive impact on the field.","authors":["AJ Alvero","Dustin S. Stoltz","Oscar Stuhler","Marshall Taylor"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12188v3","updated":"2025-11-21T00:44:24Z","published":"2025-05-18T01:31:42Z","title":"LLM-DSE: Searching Accelerator Parameters with LLM Agents","summary":"Even though high-level synthesis (HLS) tools mitigate the challenges of programming domain-specific accelerators (DSAs) by raising the abstraction level, optimizing hardware directive parameters remains a significant hurdle. Existing heuristic and learning-based methods struggle with adaptability and sample efficiency. We present LLM-DSE, a multi-agent framework designed specifically for optimizing HLS directives. Combining LLM with design space exploration (DSE), our explorer coordinates four agents: Router, Specialists, Arbitrator, and Critic. These multi-agent components interact with various tools to accelerate the optimization process. LLM-DSE leverages essential domain knowledge to identify efficient parameter combinations while maintaining adaptability through verbal learning from online interactions. Evaluations on the HLSyn dataset demonstrate that LLM-DSE achieves substantial $2.55\\times$ performance gains over state-of-the-art methods, uncovering novel designs while reducing runtime. Ablation studies validate the effectiveness and necessity of the proposed agent interactions. Our code is open-sourced here: https://github.com/Nozidoali/LLM-DSE.","authors":["Hanyu Wang","Xinrui Wu","Zijian Ding","Su Zheng","Chengyue Wang","Neha Prakriya","Tony Nowatzki","Yizhou Sun","Jason Cong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.09613v2","updated":"2025-11-21T00:40:57Z","published":"2024-11-14T17:33:36Z","title":"Task-Aligned Tool Recommendation for Large Language Models","summary":"By augmenting Large Language Models (LLMs) with external tools, their capacity to solve complex problems has been significantly enhanced. However, despite ongoing advancements in the parsing capabilities of LLMs, incorporating all available tools simultaneously in the prompt remains impractical due to the vast number of external tools. Consequently, it is essential to provide LLMs with a precise set of tools tailored to the specific task, considering both quantity and quality. Current tool retrieval methods primarily focus on refining the ranking list of tools and directly packaging a fixed number of top-ranked tools as the tool set. However, these approaches often fail to equip LLMs with the optimal set of tools prior to execution, since the optimal number of tools for different tasks could be different, resulting in inefficiencies such as redundant or unsuitable tools, which impede immediate access to the most relevant tools. This paper addresses the challenge of recommending precise toolsets for LLMs. We introduce the problem of tool recommendation, define its scope, and propose a novel Precision-driven Tool Recommendation (PTR) approach. PTR captures an initial, concise set of tools by leveraging historical tool bundle usage and dynamically adjusts the tool set by performing tool matching, culminating in a multi-view-based tool addition. Additionally, we present a new dataset, RecTools, and a metric, TRACC, designed to evaluate the effectiveness of tool recommendation for LLMs. We further validate our design choices through comprehensive experiments, demonstrating promising accuracy across two open benchmarks and our RecTools dataset.","authors":["Hang Gao","Yongfeng Zhang"],"pdf_url":"","comment":"IJCNLP-AACL 2025 Main"}]},"2025-11-24T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2511.19433v1","updated":"2025-11-24T18:59:51Z","published":"2025-11-24T18:59:51Z","title":"Mixture of Horizons in Action Chunking","summary":"Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\\textbf{action chunk length}$ used during training, termed $\\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $π_0$, $π_{0.5}$, and one-step regression policy $π_{\\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $π_{0.5}$ with MoH reaches a new state-of-the-art with 99$\\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons","authors":["Dong Jing","Gang Wang","Jiaqi Liu","Weiliang Tang","Zelong Sun","Yunchao Yao","Zhenyu Wei","Yunhui Liu","Zhiwu Lu","Mingyu Ding"],"pdf_url":"","comment":"15 pages, 14 figures"},{"id":"http://arxiv.org/abs/2501.10100v4","updated":"2025-11-24T18:17:51Z","published":"2025-01-17T10:39:09Z","title":"Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics","summary":"Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19377v1","updated":"2025-11-24T18:17:28Z","published":"2025-11-24T18:17:28Z","title":"Deployment Dynamics and Optimization of Novel Space Antenna Deployable Mechanism","summary":"Given the increasing need for large aperture antennas in space missions, the difficulty of fitting such structures into small launch vehicles has prompted the design of deployable antenna systems. The thesis introduces a new Triple Scissors Deployable Truss Mechanism (TSDTM) for space antenna missions. The new mechanism is to be stowed during launch and efficiently deploy in orbit, offering maximum aperture size while taking up minimal launch volume. The thesis covers the entire design process from geometric modeling, kinematic analysis with screw theory and Newtonian approaches, dynamic analysis by eigenvalue and simulation methods, and verification with SolidWorks. In addition, optimization routines were coded based on Support Vector Machines for material choice in LEO environments and machine learning method for geometric setup. The TSDTM presented has enhanced structural dynamics with good comparison between simulation and analytical predictions. The structure optimized proved highly accurate, with a deviation of just 1.94% between machine learning-predicted and simulated natural frequencies, demonstrating the potential of incorporating AI-based methods in space structural design.","authors":["Mamoon Aamir","Mariyam Sattar","Naveed Ur Rehman Junejo","Aqsa Zafar Abbasi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19355v1","updated":"2025-11-24T17:55:46Z","published":"2025-11-24T17:55:46Z","title":"Leveraging LLMs for reward function design in reinforcement learning control tasks","summary":"The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.","authors":["Franklin Cardenoso","Wouter Caarls"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.02595v2","updated":"2025-11-24T17:18:18Z","published":"2024-10-03T15:37:11Z","title":"Extremum Seeking Controlled Wiggling for Tactile Insertion","summary":"When humans perform complex insertion tasks such as pushing a cup into a cupboard, routing a cable, or putting a key in a lock, they wiggle the object and adapt the process through tactile feedback. A similar robotic approach has not been developed. We study an extremum seeking control law that wiggles end effector pose to maximize insertion depth while minimizing strain measured by a GelSight Mini sensor. Evaluation is conducted on four keys featuring complex geometry and five assembly tasks featuring basic geometry.\n  On keys, the algorithm achieves 71% success rate over 120 trials with 6-DOF perturbations, 84% over 240 trials with 1-DOF perturbations, and 75% over 40 trials initialized with vision. It significantly outperforms a baseline optimizer, CMA-ES, that replaces wiggling with random sampling. When tested on a state-of-the-art assembly benchmark featuring basic geometry, it achieves 98% over 50 vision-initialized trials. The benchmark's most similar baseline, which was trained on the objects, achieved 86%. These results, realized without contact modeling or learning, show that closed loop wiggling based on tactile feedback is a robust paradigm for robotic insertion.","authors":["Levi Burner","Pavan Mantripragada","Gabriele M. Caddeo","Lorenzo Natale","Cornelia Fermüller","Yiannis Aloimonos"],"pdf_url":"","comment":"8 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.19315v1","updated":"2025-11-24T17:09:50Z","published":"2025-11-24T17:09:50Z","title":"Rethinking Intermediate Representation for VLM-based Robot Manipulation","summary":"Vision-Language Model (VLM) is an important component to enable robust robot manipulation. Yet, using it to translate human instructions into an action-resolvable intermediate representation often needs a tradeoff between VLM-comprehensibility and generalizability. Inspired by context-free grammar, we design the Semantic Assembly representation named SEAM, by decomposing the intermediate representation into vocabulary and grammar. Doing so leads us to a concise vocabulary of semantically-rich operations and a VLM-friendly grammar for handling diverse unseen tasks. In addition, we design a new open-vocabulary segmentation paradigm with a retrieval-augmented few-shot learning strategy to localize fine-grained object parts for manipulation, effectively with the shortest inference time over all state-of-the-art parallel works. Also, we formulate new metrics for action-generalizability and VLM-comprehensibility, demonstrating the compelling performance of SEAM over mainstream representations on both aspects. Extensive real-world experiments further manifest its SOTA performance under varying settings and tasks.","authors":["Weiliang Tang","Jialin Gao","Jia-Hui Pan","Gang Wang","Li Erran Li","Yunhui Liu","Mingyu Ding","Pheng-Ann Heng","Chi-Wing Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.16621v2","updated":"2025-11-24T17:08:56Z","published":"2025-07-22T14:15:28Z","title":"A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System","summary":"Extrinsic Calibration represents the cornerstone of autonomous driving. Its accuracy plays a crucial role in the perception pipeline, as any errors can have implications for the safety of the vehicle. Modern sensor systems collect different types of data from the environment, making it harder to align the data. To this end, we propose a target-based extrinsic calibration system tailored for a multi-LiDAR and multi-camera sensor suite. This system enables cross-calibration between LiDARs and cameras with limited prior knowledge using a custom ChArUco board and a tailored nonlinear optimization method. We test the system with real-world data gathered in a warehouse. Results demonstrated the effectiveness of the proposed method, highlighting the feasibility of a unique pipeline tailored for various types of sensors.","authors":["Lorenzo Gentilini","Pierpaolo Serio","Valentina Donzella","Lorenzo Pollini"],"pdf_url":"","comment":"RiTA 2025 Accepted, 13 Pages, 6 Figures and 2 Tables"},{"id":"http://arxiv.org/abs/2511.19236v1","updated":"2025-11-24T15:48:59Z","published":"2025-11-24T15:48:59Z","title":"SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control","summary":"Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.","authors":["Yuxuan Wang","Haobin Jiang","Shiqing Yao","Ziluo Ding","Zongqing Lu"],"pdf_url":"","comment":"23 pages, 8 figures, 11 tables"},{"id":"http://arxiv.org/abs/2511.19211v1","updated":"2025-11-24T15:19:47Z","published":"2025-11-24T15:19:47Z","title":"Soft pneumatic grippers: Topology optimization, 3D-printing and experimental validation","summary":"This paper presents a systematic topology optimization framework for designing a soft pneumatic gripper (SPG), explicitly considering the design-dependent nature of the actuating load. The load is modeled using Darcy's law with an added drainage term. A 2D soft arm unit is optimized by formulating it as a compliant mechanism design problem using the robust formulation. The problem is posed as a min-max optimization, where the output deformations of blueprint and eroded designs are considered. A volume constraint is imposed on the blueprint part, while a strain-energy constraint is enforced on the eroded part. The MMA is employed to solve the optimization problem and obtain the optimized soft unit. Finite element analysis with the Ogden material model confirms that the optimized 2D unit outperforms a conventional rectangular design under pneumatic loading. The optimized 2D unit is extruded to obtain a 3D module, and ten such units are assembled to create a soft arm. Deformation profiles of the optimized arm are analysed under different pressure loads. Four arms are 3D-printed and integrated with a supporting structure to realize the proposed SPG. The gripping performance of the SPG is demonstrated on objects with different weights, sizes, stiffness, and shapes.","authors":["Prabhat Kumar","Chandra Prakash","Josh Pinskier","David Howard","Matthijs Langelaar"],"pdf_url":"","comment":"9 Figures"},{"id":"http://arxiv.org/abs/2511.19204v1","updated":"2025-11-24T15:15:01Z","published":"2025-11-24T15:15:01Z","title":"Reference-Free Sampling-Based Model Predictive Control","summary":"We present a sampling-based model predictive control (MPC) framework that enables emergent locomotion without relying on handcrafted gait patterns or predefined contact sequences. Our method discovers diverse motion patterns, ranging from trotting to galloping, robust standing policies, jumping, and handstand balancing, purely through the optimization of high-level objectives. Building on model predictive path integral (MPPI), we propose a dual-space spline parameterization that operates on position and velocity control points. Our approach enables contact-making and contact-breaking strategies that adapt automatically to task requirements, requiring only a limited number of sampled trajectories. This sample efficiency allows us to achieve real-time control on standard CPU hardware, eliminating the need for GPU acceleration typically required by other state-of-the-art MPPI methods. We validate our approach on the Go2 quadrupedal robot, demonstrating various emergent gaits and basic jumping capabilities. In simulation, we further showcase more complex behaviors, such as backflips, dynamic handstand balancing and locomotion on a Humanoid, all without requiring reference tracking or offline pre-training.","authors":["Fabian Schramm","Pierre Fabre","Nicolas Perrin-Gilbert","Justin Carpentier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19201v1","updated":"2025-11-24T15:09:41Z","published":"2025-11-24T15:09:41Z","title":"Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap","summary":"Untethered magnetic manipulation of biomedical millirobots has a high potential for minimally invasive surgical applications. However, it is still challenging to exert high actuation forces on the small robots over a large distance. Permanent magnets offer stronger magnetic torques and forces than electromagnetic coils, however, feedback control is more difficult. As proven by Earnshaw's theorem, it is not possible to achieve a stable magnetic trap in 3D by static permanent magnets. Here, we report a stable 2D magnetic force trap by an array of permanent magnets to control a millirobot. The trap is located in an open space with a tunable distance to the magnet array in the range of 20 - 120mm, which is relevant to human anatomical scales. The design is achieved by a novel GPU-accelerated optimization algorithm that uses mean squared error (MSE) and Adam optimizer to efficiently compute the optimal angles for any number of magnets in the array. The algorithm is verified using numerical simulation and physical experiments with an array of two magnets. A millirobot is successfully trapped and controlled to follow a complex trajectory. The algorithm demonstrates high scalability by optimizing the angles for 100 magnets in under three seconds. Moreover, the optimization workflow can be adapted to optimize a permanent magnet array to achieve the desired force vector fields.","authors":["Ann-Sophia Müller","Moonkwang Jeong","Jiyuan Tian","Meng Zhang","Tian Qiu"],"pdf_url":"","comment":"6 pages, 6 figures, IEEE International Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2511.19198v1","updated":"2025-11-24T15:07:45Z","published":"2025-11-24T15:07:45Z","title":"Three-Dimensional Anatomical Data Generation Based on Artificial Neural Networks","summary":"Surgical planning and training based on machine learning requires a large amount of 3D anatomical models reconstructed from medical imaging, which is currently one of the major bottlenecks. Obtaining these data from real patients and during surgery is very demanding, if even possible, due to legal, ethical, and technical challenges. It is especially difficult for soft tissue organs with poor imaging contrast, such as the prostate. To overcome these challenges, we present a novel workflow for automated 3D anatomical data generation using data obtained from physical organ models. We additionally use a 3D Generative Adversarial Network (GAN) to obtain a manifold of 3D models useful for other downstream machine learning tasks that rely on 3D data. We demonstrate our workflow using an artificial prostate model made of biomimetic hydrogels with imaging contrast in multiple zones. This is used to physically simulate endoscopic surgery. For evaluation and 3D data generation, we place it into a customized ultrasound scanner that records the prostate before and after the procedure. A neural network is trained to segment the recorded ultrasound images, which outperforms conventional, non-learning-based computer vision techniques in terms of intersection over union (IoU). Based on the segmentations, a 3D mesh model is reconstructed, and performance feedback is provided.","authors":["Ann-Sophia Müller","Moonkwang Jeong","Meng Zhang","Jiyuan Tian","Arkadiusz Miernik","Stefanie Speidel","Tian Qiu"],"pdf_url":"","comment":"6 pages, 4 figures, 1 table, IEEE International Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2511.19165v1","updated":"2025-11-24T14:28:49Z","published":"2025-11-24T14:28:49Z","title":"First-order Sobolev Reinforcement Learning","summary":"We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also their derivatives with respect to states and actions. By differentiating the Bellman backup through differentiable dynamics, we obtain analytically consistent gradient targets. Incorporating these into the critic objective using a Sobolev-type loss encourages the critic to align with both the value and local geometry of the target function. This first-order TD matching principle can be seamlessly integrated into existing algorithms, such as Q-learning or actor-critic methods (e.g., DDPG, SAC), potentially leading to faster critic convergence and more stable policy gradients without altering their overall structure.","authors":["Fabian Schramm","Nicolas Perrin-Gilbert","Justin Carpentier"],"pdf_url":"","comment":"Workshop paper at Differentiable Systems and Scientific Machine Learning, EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.19135v1","updated":"2025-11-24T13:59:31Z","published":"2025-11-24T13:59:31Z","title":"Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts","summary":"Multi-rotor UAVs face limited flight time due to battery constraints. Autonomous docking on blimps with onboard battery recharging and data offloading offers a promising solution for extended UAV missions. However, the vulnerability of blimps to wind gusts causes trajectory deviations, requiring precise, obstacle-aware docking strategies. To this end, this work introduces two key novelties: (i) a temporal convolutional network that predicts blimp responses to wind gusts, enabling rapid gust detection and estimation of points where the wind gust effect has subsided; (ii) a model predictive controller (MPC) that leverages these predictions to compute collision-free trajectories for docking, enabled by a novel obstacle avoidance method for close-range manoeuvres near the blimp. Simulation results show our method outperforms a baseline constant-velocity model of the blimp significantly across different scenarios. We further validate the approach in real-world experiments, demonstrating the first autonomous multi-rotor docking control strategy on blimps shown outside simulation. Source code is available here https://github.com/robot-perception-group/multi_rotor_airship_docking.","authors":["Pascal Goldschmid","Aamir Ahmad"],"pdf_url":"","comment":"13 pages, 8 figures, 8 tables"},{"id":"http://arxiv.org/abs/2511.19094v1","updated":"2025-11-24T13:33:23Z","published":"2025-11-24T13:33:23Z","title":"Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework","summary":"Over the last years collaborative robots have gained great success in manufacturing applications where human and robot work together in close proximity. However, current ISO/TS-15066-compliant implementations often limit the efficiency of collaborative tasks due to conservative speed restrictions. For this reason, this paper introduces a deep-learning-based human-robot-safety framework (HRSF) that aims at a dynamical adaptation of robot velocities depending on the separation distance between human and robot while respecting maximum biomechanical force and pressure limits. The applicability of the framework was investigated for four different deep learning approaches that can be used for human body extraction: human body recognition, human body segmentation, human pose estimation, and human body part segmentation. Unlike conventional industrial safety systems, the proposed HRSF differentiates individual human body parts from other objects, enabling optimized robot process execution. Experiments demonstrated a quantitative reduction in cycle time of up to 15% compared to conventional safety technology.","authors":["David Bricher","Andreas Mueller"],"pdf_url":"","comment":"MDPI Sensors, published 22 November 2025"},{"id":"http://arxiv.org/abs/2511.19031v1","updated":"2025-11-24T12:05:13Z","published":"2025-11-24T12:05:13Z","title":"Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors","summary":"Monocular Simultaneous Localization and Mapping (SLAM) aims to estimate a robot's pose while simultaneously reconstructing an unknown 3D scene using a single camera. While existing monocular SLAM systems generate detailed 3D geometry through dense scene representations, they are computationally expensive due to the need for iterative optimization. To address this challenge, MASt3R-SLAM utilizes learned 3D reconstruction priors, enabling more efficient and accurate estimation of both 3D structures and camera poses. However, MASt3R-SLAM is limited to single-agent operation. In this paper, we extend MASt3R-SLAM to introduce the first multi-agent monocular dense SLAM system. Each agent performs local SLAM using a 3D reconstruction prior, and their individual maps are fused into a globally consistent map through a loop-closure-based map fusion mechanism. Our approach improves computational efficiency compared to state-of-the-art methods, while maintaining similar mapping accuracy when evaluated on real-world datasets.","authors":["Haihang Wu","Yuchen Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19011v1","updated":"2025-11-24T11:40:24Z","published":"2025-11-24T11:40:24Z","title":"End-to-end Autonomous Vehicle Following System using Monocular Fisheye Camera","summary":"The increase in vehicle ownership has led to increased traffic congestion, more accidents, and higher carbon emissions. Vehicle platooning is a promising solution to address these issues by improving road capacity and reducing fuel consumption. However, existing platooning systems face challenges such as reliance on lane markings and expensive high-precision sensors, which limits their general applicability. To address these issues, we propose a vehicle following framework that expands its capability from restricted scenarios to general scenario applications using only a camera. This is achieved through our newly proposed end-to-end method, which improves overall driving performance. The method incorporates a semantic mask to address causal confusion in multi-frame data fusion. Additionally, we introduce a dynamic sampling mechanism to precisely track the trajectories of preceding vehicles. Extensive closed-loop validation in real-world vehicle experiments demonstrates the system's ability to follow vehicles in various scenarios, outperforming traditional multi-stage algorithms. This makes it a promising solution for cost-effective autonomous vehicle platooning. A complete real-world vehicle experiment is available at https://youtu.be/zL1bcVb9kqQ.","authors":["Jiale Zhang","Yeqiang Qian","Tong Qin","Mingyang Jiang","Siyuan Chen","Ming Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.00416v3","updated":"2025-11-24T11:10:14Z","published":"2025-07-01T04:05:47Z","title":"Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding","summary":"Vision-Language-Action (VLA) models have emerged as a promising framework for enabling generalist robots capable of perceiving, reasoning, and acting in the real world. These models usually build upon pretrained Vision-Language Models (VLMs), which excel at semantic understanding due to large-scale image and text pretraining. However, existing VLMs typically lack precise spatial understanding capabilities, as they are primarily tuned on 2D image-text pairs without 3D supervision. To address this limitation, recent approaches have incorporated explicit 3D inputs such as point clouds or depth maps, but this necessitates additional depth sensors or pre-trained depth estimation models, which may yield defective results. In contrast, our work introduces a plug-and-play module that implicitly incorporates 3D geometry features into VLA models by leveraging an off-the-shelf visual geometry foundation model. This integration provides the model with depth-aware visual representations, improving its ability to understand the geometric structure of the scene and the spatial relationships among objects from RGB images alone. We evaluate our method on a set of spatially challenging tasks in both simulation and the real world. Extensive evaluations show that our method significantly improves the performance of state-of-the-art VLA models across diverse scenarios.","authors":["Tao Lin","Gen Li","Yilei Zhong","Yanwen Zou","Yuxin Du","Jiting Liu","Encheng Gu","Bo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.18662v2","updated":"2025-11-24T10:52:11Z","published":"2025-04-25T19:36:17Z","title":"M2R2: MultiModal Robotic Representation for Temporal Action Segmentation","summary":"Temporal action segmentation (TAS) has long been a key area of research in both robotics and computer vision. In robotics, algorithms have primarily focused on leveraging proprioceptive information to determine skill boundaries, with recent approaches in surgical robotics incorporating vision. In contrast, computer vision typically relies on exteroceptive sensors, such as cameras. Existing multimodal TAS models in robotics integrate feature fusion within the model, making it difficult to reuse learned features across different models. Meanwhile, pretrained vision-only feature extractors commonly used in computer vision struggle in scenarios with limited object visibility. In this work, we address these challenges by proposing M2R2, a multimodal feature extractor tailored for TAS, which combines information from both proprioceptive and exteroceptive sensors. We introduce a novel pretraining strategy that enables the reuse of learned features across multiple TAS models. Our method achieves state-of-the-art performance on the REASSEMBLE dataset, a challenging multimodal robotic assembly dataset, outperforming existing robotic action segmentation models by 46.6%. Additionally, we conduct an extensive ablation study to evaluate the contribution of different modalities in robotic TAS tasks.","authors":["Daniel Sliwowski","Dongheui Lee"],"pdf_url":"","comment":"8 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2511.18960v1","updated":"2025-11-24T10:22:28Z","published":"2025-11-24T10:22:28Z","title":"AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention","summary":"Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.","authors":["Lei Xiao","Jifeng Li","Juntao Gao","Feiyang Ye","Yan Jin","Jingjing Qian","Jing Zhang","Yong Wu","Xiaoyuan Yu"],"pdf_url":"","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.18950v1","updated":"2025-11-24T10:06:41Z","published":"2025-11-24T10:06:41Z","title":"Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation","summary":"Vision-Language-Action (VLA) models have emerged as a powerful paradigm in Embodied AI. However, the significant computational overhead of processing redundant visual tokens remains a critical bottleneck for real-time robotic deployment. While standard token pruning techniques can alleviate this, these task-agnostic methods struggle to preserve task-critical visual information. To address this challenge, simultaneously preserving both the holistic context and fine-grained details for precise action, we propose Compressor-VLA, a novel hybrid instruction-conditioned token compression framework designed for efficient, task-oriented compression of visual information in VLA models. The proposed Compressor-VLA framework consists of two token compression modules: a Semantic Task Compressor (STC) that distills holistic, task-relevant context, and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial details. This compression is dynamically modulated by the natural language instruction, allowing for the adaptive condensation of task-relevant visual information. Experimentally, extensive evaluations demonstrate that Compressor-VLA achieves a competitive success rate on the LIBERO benchmark while reducing FLOPs by 59% and the visual token count by over 3x compared to its baseline. The real-robot deployments on a dual-arm robot platform validate the model's sim-to-real transferability and practical applicability. Moreover, qualitative analyses reveal that our instruction guidance dynamically steers the model's perceptual focus toward task-relevant objects, thereby validating the effectiveness of our approach.","authors":["Juntao Gao","Feiyang Ye","Jing Zhang","Wenjing Qian"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.11043v2","updated":"2025-11-24T09:43:11Z","published":"2025-11-14T07:56:34Z","title":"Autonomous Vehicle Path Planning by Searching With Differentiable Simulation","summary":"Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.","authors":["Asen Nachkov","Jan-Nico Zaech","Danda Pani Paudel","Xi Wang","Luc Van Gool"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17373v2","updated":"2025-11-24T09:20:41Z","published":"2025-11-21T16:37:24Z","title":"Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data","summary":"Humanoid robots are envisioned to perform a wide range of tasks in human-centered environments, requiring controllers that combine agility with robust balance. Recent advances in locomotion and whole-body tracking have enabled impressive progress in either agile dynamic skills or stability-critical behaviors, but existing methods remain specialized, focusing on one capability while compromising the other. In this work, we introduce AMS (Agility Meets Stability), the first framework that unifies both dynamic motion tracking and extreme balance maintenance in a single policy. Our key insight is to leverage heterogeneous data sources: human motion capture datasets that provide rich, agile behaviors, and physically constrained synthetic balance motions that capture stability configurations. To reconcile the divergent optimization goals of agility and stability, we design a hybrid reward scheme that applies general tracking objectives across all data while injecting balance-specific priors only into synthetic motions. Further, an adaptive learning strategy with performance-driven sampling and motion-specific reward shaping enables efficient training across diverse motion distributions. We validate AMS extensively in simulation and on a real Unitree G1 humanoid. Experiments demonstrate that a single policy can execute agile skills such as dancing and running, while also performing zero-shot extreme balance motions like Ip Man's Squat, highlighting AMS as a versatile control paradigm for future humanoid applications.","authors":["Yixuan Pan","Ruoyi Qiao","Li Chen","Kashyap Chitta","Liang Pan","Haoguang Mai","Qingwen Bu","Hao Zhao","Cunyuan Zheng","Ping Luo","Hongyang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18910v1","updated":"2025-11-24T09:15:54Z","published":"2025-11-24T09:15:54Z","title":"An Efficient Closed-Form Solution to Full Visual-Inertial State Initialization","summary":"In this letter, we present a closed-form initialization method that recovers the full visual-inertial state without nonlinear optimization. Unlike previous approaches that rely on iterative solvers, our formulation yields analytical, easy-to-implement, and numerically stable solutions for reliable start-up. Our method builds on small-rotation and constant-velocity approximations, which keep the formulation compact while preserving the essential coupling between motion and inertial measurements. We further propose an observability-driven, two-stage initialization scheme that balances accuracy with initialization latency. Extensive experiments on the EuRoC dataset validate our assumptions: our method achieves 10-20% lower initialization error than optimization-based approaches, while using 4x shorter initialization windows and reducing computational cost by 5x.","authors":["Samuel Cerezo","Seong Hun Lee","Javier Civera"],"pdf_url":"","comment":"8 pages, 2 figures, 10 tables. Submitted to RA-L"},{"id":"http://arxiv.org/abs/2503.02916v2","updated":"2025-11-24T08:57:24Z","published":"2025-03-04T11:07:27Z","title":"Monocular Person Localization under Camera Ego-motion","summary":"Localizing a person from a moving monocular camera is critical for Human-Robot Interaction (HRI). To estimate the 3D human position from a 2D image, existing methods either depend on the geometric assumption of a fixed camera or use a position regression model trained on datasets containing little camera ego-motion. These methods are vulnerable to severe camera ego-motion, resulting in inaccurate person localization. We consider person localization as a part of a pose estimation problem. By representing a human with a four-point model, our method jointly estimates the 2D camera attitude and the person's 3D location through optimization. Evaluations on both public datasets and real robot experiments demonstrate our method outperforms baselines in person localization accuracy. Our method is further implemented into a person-following system and deployed on an agile quadruped robot.","authors":["Yu Zhan","Hanjing Ye","Hong Zhang"],"pdf_url":"","comment":"Accepted by IROS2025. Project page: https://medlartea.github.io/rpf-quadruped/"},{"id":"http://arxiv.org/abs/2511.18878v1","updated":"2025-11-24T08:33:47Z","published":"2025-11-24T08:33:47Z","title":"Accelerating Reinforcement Learning via Error-Related Human Brain Signals","summary":"In this work, we investigate how implicit neural feed back can accelerate reinforcement learning in complex robotic manipulation settings. While prior electroencephalogram (EEG) guided reinforcement learning studies have primarily focused on navigation or low-dimensional locomotion tasks, we aim to understand whether such neural evaluative signals can improve policy learning in high-dimensional manipulation tasks involving obstacles and precise end-effector control. We integrate error related potentials decoded from offline-trained EEG classifiers into reward shaping and systematically evaluate the impact of human-feedback weighting. Experiments on a 7-DoF manipulator in an obstacle-rich reaching environment show that neural feedback accelerates reinforcement learning and, depending on the human-feedback weighting, can yield task success rates that at times exceed those of sparse-reward baselines. Moreover, when applying the best-performing feedback weighting across all sub jects, we observe consistent acceleration of reinforcement learning relative to the sparse-reward setting. Furthermore, leave-one subject-out evaluations confirm that the proposed framework remains robust despite the intrinsic inter-individual variability in EEG decodability. Our findings demonstrate that EEG-based reinforcement learning can scale beyond locomotion tasks and provide a viable pathway for human-aligned manipulation skill acquisition.","authors":["Suzie Kim","Hye-Bin Shin","Hyo-Jeong Jang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18874v1","updated":"2025-11-24T08:28:42Z","published":"2025-11-24T08:28:42Z","title":"GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction","summary":"Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.","authors":["Yuzhi Chen","Yuanchang Xie","Lei Zhao","Pan Liu","Yajie Zou","Chen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2105.06896v3","updated":"2025-11-24T08:01:04Z","published":"2021-05-14T15:31:28Z","title":"Towards Sensor Data Abstraction of Autonomous Vehicle Perception Systems","summary":"Full-stack autonomous driving perception modules usually consist of data-driven models based on multiple sensor modalities. However, these models might be biased to the sensor setup used for data acquisition. This bias can seriously impair the perception models' transferability to new sensor setups, which continuously occur due to the market's competitive nature. We envision sensor data abstraction as an interface between sensor data and machine learning applications for highly automated vehicles (HAD).\n  For this purpose, we review the primary sensor modalities, camera, lidar, and radar, published in autonomous-driving related datasets, examine single sensor abstraction and abstraction of sensor setups, and identify critical paths towards an abstraction of sensor data from multiple perception configurations.","authors":["Hannes Reichert","Lukas Lang","Kevin Rösch","Daniel Bogdoll","Konrad Doll","Bernhard Sick","Hans-Christian Reuss","Christoph Stiller","J. Marius Zöllner"],"pdf_url":"","comment":"Hannes Reichert, Lukas Lang, Kevin Rösch and Daniel Bogdoll contributed equally. Accepted for publication at ISC2 2021"},{"id":"http://arxiv.org/abs/2109.09607v4","updated":"2025-11-24T07:58:18Z","published":"2021-09-20T15:04:55Z","title":"Description of Corner Cases in Automated Driving: Goals and Challenges","summary":"Scaling the distribution of automated vehicles requires handling various unexpected and possibly dangerous situations, termed corner cases (CC). Since many modules of automated driving systems are based on machine learning (ML), CC are an essential part of the data for their development. However, there is only a limited amount of CC data in large-scale data collections, which makes them challenging in the context of ML. With a better understanding of CC, offline applications, e.g., dataset analysis, and online methods, e.g., improved performance of automated driving systems, can be improved. While there are knowledge-based descriptions and taxonomies for CC, there is little research on machine-interpretable descriptions. In this extended abstract, we will give a brief overview of the challenges and goals of such a description.","authors":["Daniel Bogdoll","Jasmin Breitenstein","Florian Heidecker","Maarten Bieshaar","Bernhard Sick","Tim Fingscheidt","J. Marius Zöllner"],"pdf_url":"","comment":"Daniel Bogdoll, Jasmin Breitenstein and Florian Heidecker contributed equally. Accepted for publication at ICCV 2021 ERCVAD Workshop"},{"id":"http://arxiv.org/abs/2511.18857v1","updated":"2025-11-24T07:56:12Z","published":"2025-11-24T07:56:12Z","title":"AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion","summary":"Accurate proprioceptive odometry is fundamental for legged robot navigation in GPS-denied and visually degraded environments where conventional visual odometry systems fail. Current approaches face critical limitations: analytical filtering methods suffer from modeling uncertainties and cumulative drift, hybrid learning-filtering approaches remain constrained by their analytical components, while pure learning-based methods struggle with simulation-to-reality transfer and demand extensive real-world data collection. This paper introduces AutoOdom, a novel autoregressive proprioceptive odometry system that overcomes these challenges through an innovative two-stage training paradigm. Stage 1 employs large-scale simulation data to learn complex nonlinear dynamics and rapidly changing contact states inherent in legged locomotion, while Stage 2 introduces an autoregressive enhancement mechanism using limited real-world data to effectively bridge the sim-to-real gap. The key innovation lies in our autoregressive training approach, where the model learns from its own predictions to develop resilience against sensor noise and improve robustness in highly dynamic environments. Comprehensive experimental validation on the Booster T1 humanoid robot demonstrates that AutoOdom significantly outperforms state-of-the-art methods across all evaluation metrics, achieving 57.2% improvement in absolute trajectory error, 59.2% improvement in Umeyama-aligned error, and 36.2% improvement in relative pose error compared to the Legolas baseline. Extensive ablation studies provide critical insights into sensor modality selection and temporal modeling, revealing counterintuitive findings about IMU acceleration data and validating our systematic design choices for robust proprioceptive odometry in challenging locomotion scenarios.","authors":["Changsheng Luo","Yushi Wang","Wenhan Cai","Mingguo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2204.07974v2","updated":"2025-11-24T07:55:12Z","published":"2022-04-17T10:48:25Z","title":"Anomaly Detection in Autonomous Driving: A Survey","summary":"Nowadays, there are outstanding strides towards a future with autonomous vehicles on our roads. While the perception of autonomous vehicles performs well under closed-set conditions, they still struggle to handle the unexpected. This survey provides an extensive overview of anomaly detection techniques based on camera, lidar, radar, multimodal and abstract object level data. We provide a systematization including detection approach, corner case level, ability for an online application, and further attributes. We outline the state-of-the-art and point out current research gaps.","authors":["Daniel Bogdoll","Maximilian Nitsche","J. Marius Zöllner"],"pdf_url":"","comment":"Daniel Bogdoll and Maximilian Nitsche contributed equally. Accepted for publication at CVPR 2022 WAD workshop"},{"id":"http://arxiv.org/abs/2405.03411v3","updated":"2025-11-24T07:25:30Z","published":"2024-05-06T12:22:11Z","title":"Greedy Heuristics for Sampling-Based Motion Planning in High-Dimensional State Spaces","summary":"Informed sampling techniques accelerate the convergence of sampling-based motion planners by biasing sampling toward regions of the state space that are most likely to yield better solutions. However, when the current solution path contains redundant or tortuous segments, the resulting informed subset may remain unnecessarily large, slowing convergence. Our prior work addressed this issue by introducing the greedy informed set, which reduces the sampling region based on the maximum heuristic cost along the current solution path. In this article, we formally characterize the behavior of the greedy informed set within Rapidly-exploring Random Tree (RRT*)-like planners and analyze how greedy sampling affects exploration and asymptotic optimality. We then present Greedy RRT* (G-RRT*), a bi-directional anytime variant of RRT* that leverages the greedy informed set to focus sampling in the most promising regions of the search space. Experiments on abstract planning benchmarks, manipulation tasks from the MotionBenchMaker dataset, and a dual-arm Barrett WAM problem demonstrate that G-RRT* rapidly finds initial solutions and converges asymptotically to optimal paths, outperforming state-of-the-art sampling-based planners.","authors":["Phone Thiha Kyaw","Anh Vu Le","Rajesh Elara Mohan","Jonathan Kelly"],"pdf_url":"","comment":"Submitted to the Autonomous Robots journal"},{"id":"http://arxiv.org/abs/2511.18810v1","updated":"2025-11-24T06:30:04Z","published":"2025-11-24T06:30:04Z","title":"MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent","summary":"Recent Vision-Language-Action (VLA) models reformulate vision-language models by tuning them with millions of robotic demonstrations. While they perform well when fine-tuned for a single embodiment or task family, extending them to multi-skill settings remains challenging: directly merging VLA experts trained on different tasks results in near-zero success rates. This raises a fundamental question: what prevents VLAs from mastering multiple skills within one model? With an empirical decomposition of learnable parameters during VLA fine-tuning, we identify two key sources of non-mergeability: (1) Finetuning drives LoRA adapters in the VLM backbone toward divergent, task-specific directions beyond the capacity of existing merging methods to unify. (2) Action experts develop inter-block dependencies through self-attention feedback, causing task information to spread across layers and preventing modular recombination. To address these challenges, we present MergeVLA, a merging-oriented VLA architecture that preserves mergeability by design. MergeVLA introduces sparsely activated LoRA adapters via task masks to retain consistent parameters and reduce irreconcilable conflicts in the VLM. Its action expert replaces self-attention with cross-attention-only blocks to keep specialization localized and composable. When the task is unknown, it uses a test-time task router to adaptively select the appropriate task mask and expert head from the initial observation, enabling unsupervised task inference. Across LIBERO, LIBERO-Plus, RoboTwin, and multi-task experiments on the real SO101 robotic arm, MergeVLA achieves performance comparable to or even exceeding individually finetuned experts, demonstrating robust generalization across tasks, embodiments, and environments.","authors":["Yuxia Fu","Zhizhen Zhang","Yuqi Zhang","Zijian Wang","Zi Huang","Yadan Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.11094v4","updated":"2025-11-24T05:15:45Z","published":"2024-05-17T21:14:50Z","title":"Yummy Operations Robot Initiative: Autonomous Cooking System Utilizing a Modular Robotic Kitchen and a Dual-Arm Proprioceptive Manipulator","summary":"This paper presents Yummy Operations Robot Initiative (YORI), a proprioceptive dual-arm robotic system that demonstrates autonomous multi-dish cooking for scalable food service applications. YORI integrates a dual-arm manipulator equipped with proprioceptive actuators, custom-designed tools, appliances, and a structured kitchen environment to address the complexities of cooking tasks. The proprioceptive actuators enable fast, precise, force-controlled movements while mitigating the risks associated with cooking-related impacts. The system's modular kitchen design and flexible tool-changing mechanism support simultaneous multi-dish preparation through torque control and optimization-based motion planning and scheduling. A comprehensive scheduling framework with dynamic rescheduling ensures reliable adaptation to new orders and delays. The system was publicly validated through live demonstrations, reliably preparing steak-frites across multiple convention sessions. This paper details YORI's design and explores future directions in kitchen optimization, task planning, and food quality control, demonstrating its potential as a scalable robotic cooking solution. A system introduction and cooking videos are available online.","authors":["Donghun Noh","Hyunwoo Nam","Kyle Gillespie","Yeting Liu","Dennis Hong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17502v2","updated":"2025-11-24T04:49:33Z","published":"2025-11-21T18:59:32Z","title":"RynnVLA-002: A Unified Vision-Language-Action and World Model","summary":"We introduce RynnVLA-002, a unified Vision-Language-Action (VLA) and world model. The world model leverages action and visual inputs to predict future image states, learning the underlying physics of the environment to refine action generation. Conversely, the VLA model produces subsequent actions from image observations, enhancing visual understanding and supporting the world model's image generation. The unified framework of RynnVLA-002 enables joint learning of environmental dynamics and action planning. Our experiments show that RynnVLA-002 surpasses individual VLA and world models, demonstrating their mutual enhancement. We evaluate RynnVLA-002 in both simulation and real-world robot tasks. RynnVLA-002 achieves 97.4% success rate on the LIBERO simulation benchmark without pretraining, while in real-world LeRobot experiments, its integrated world model boosts the overall success rate by 50%.","authors":["Jun Cen","Siteng Huang","Yuqian Yuan","Kehan Li","Hangjie Yuan","Chaohui Yu","Yuming Jiang","Jiayan Guo","Xin Li","Hao Luo","Fan Wang","Deli Zhao","Hao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18756v1","updated":"2025-11-24T04:32:19Z","published":"2025-11-24T04:32:19Z","title":"SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map","summary":"Filter-based visual inertial navigation system (VINS) has attracted mobile-robot researchers for the good balance between accuracy and efficiency, but its limited mapping quality hampers long-term high-accuracy state estimation. To this end, we first propose a novel filter-based stereo VINS, differing from traditional simultaneous localization and mapping (SLAM) systems based on 3D map, which performs efficient loop closure constraints with implicit environmental map composed of keyframes and 2D keypoints. Secondly, we proposed a hybrid residual filter framework that combines landmark reprojection and ray constraints to construct a unified Jacobian matrix for measurement updates. Finally, considering the degraded environment, we incorporated the camera-IMU extrinsic parameters into visual description to achieve online calibration. Benchmark experiments demonstrate that the proposed SP-VINS achieves high computational efficiency while maintaining long-term high-accuracy localization performance, and is superior to existing state-of-the-art (SOTA) methods.","authors":["Xueyu Du","Lilian Zhang","Fuan Duan","Xincan Luo","Maosong Wang","Wenqi Wu"," JunMao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.11461v3","updated":"2025-11-24T04:15:39Z","published":"2025-02-17T05:37:07Z","title":"Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence","summary":"Achieving successful scan matching is essential for LiDAR odometry. However, in challenging environments with adverse weather conditions or repetitive geometric patterns, LiDAR odometry performance is degraded due to incorrect scan matching. Recently, the emergence of frequency-modulated continuous wave 4D LiDAR and 4D radar technologies has provided the potential to address these unfavorable conditions. The term 4D refers to point cloud data characterized by range, azimuth, and elevation along with Doppler velocity. Although 4D data is available, most scan matching methods for 4D LiDAR and 4D radar still establish correspondence by repeatedly identifying the closest points between consecutive scans, overlooking the Doppler information. This paper introduces, for the first time, a simple Doppler velocity-based correspondence -- Doppler Correspondence -- that is invariant to translation and small rotation of the sensor, with its geometric and kinematic foundations. Extensive experiments demonstrate that the proposed method enables the direct matching of consecutive point clouds without an iterative process, making it computationally efficient. Additionally, it provides a more robust correspondence estimation in environments with repetitive geometric patterns.The implementation of our proposed method is publicly available at https://github.com/Tars0523/Doppler Correspondence.","authors":["Jiwoo Kim","Geunsik Bae","Changseung Kim","Jinwoo Lee","Woojae Shin","Hyondong Oh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.20840v3","updated":"2025-11-24T03:42:01Z","published":"2025-08-28T14:31:48Z","title":"Learning Primitive Embodied World Models: Towards Scalable Robotic Learning","summary":"While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a \"GPT moment\" in the embodied domain. There is a naive observation: the diversity of embodied data far exceeds the relatively small space of possible primitive motions. Based on this insight, we propose a novel paradigm for world modeling--Primitive Embodied World Models (PEWM). By restricting video generation to fixed short horizons, our approach 1) enables fine-grained alignment between linguistic concepts and visual representations of robotic actions, 2) reduces learning complexity, 3) improves data efficiency in embodied data collection, and 4) decreases inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.","authors":["Qiao Sun","Liujia Yang","Wei Tang","Wei Huang","Kaixin Xu","Yongchao Chen","Mingyu Liu","Jiange Yang","Haoyi Zhu","Yating Wang","Tong He","Yilun Chen","Xili Dai","Nanyang Ye","Qinying Gu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06659v3","updated":"2025-11-24T03:32:51Z","published":"2025-06-07T04:39:06Z","title":"DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning","summary":"Autonomous vehicles must navigate safely in complex driving environments. Imitating a single expert trajectory, as in regression-based approaches, usually does not explicitly assess the safety of the predicted trajectory. Selection-based methods address this by generating and scoring multiple trajectory candidates and predicting the safety score for each. However, they face optimization challenges in precisely selecting the best option from thousands of candidates and distinguishing subtle but safety-critical differences, especially in rare and challenging scenarios. We propose DriveSuprim to overcome these challenges and advance the selection-based paradigm through a coarse-to-fine paradigm for progressive candidate filtering, a rotation-based augmentation method to improve robustness in out-of-distribution scenarios, and a self-distillation framework to stabilize training. DriveSuprim achieves state-of-the-art performance, reaching 93.5% PDMS in NAVSIM v1 and 87.1% EPDMS in NAVSIM v2 without extra data, with 83.02 Driving Score and 60.00 Success Rate on the Bench2Drive benchmark, demonstrating superior planning capabilities in various driving scenarios.","authors":["Wenhao Yao","Zhenxin Li","Shiyi Lan","Zi Wang","Xinglong Sun","Jose M. Alvarez","Zuxuan Wu"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2508.05186v4","updated":"2025-11-24T03:28:59Z","published":"2025-08-07T09:21:20Z","title":"Learning to See and Act: Task-Aware Virtual View Exploration for Robotic Manipulation","summary":"Recent vision-language-action (VLA) models for multi-task robotic manipulation commonly rely on static viewpoints and shared visual encoders, which limit 3D perception and cause task interference, hindering robustness and generalization. In this work, we propose Task-aware Virtual View Exploration (TVVE), a framework designed to overcome these challenges by integrating virtual view exploration with task-specific representation learning. TVVE employs an efficient exploration policy, accelerated by a novel pseudo-environment, to acquire informative views. Furthermore, we introduce a Task-aware Mixture-of-Experts (TaskMoE) visual encoder to disentangle features across different tasks, boosting both representation fidelity and task generalization. By learning to see the world in a task-aware way, TVVE generates more complete and discriminative visual representations, demonstrating significantly enhanced action prediction across a wide array of manipulation challenges. To further validate the robustness and generalization capability of TVVE under out-of-distribution (OOD) settings, we construct a challenging benchmark, RLBench-OG, covering various visual perturbations and camera pose variations. Extensive experiments on RLBench and RLBench-OG show that our TVVE achieves superior performance over state-of-the-art approaches. In real-robot experiments, TVVE demonstrates exceptional performance and generalizes robustly in multiple OOD settings, including visual disturbances and unseen instructions. Visual results and code are provided at: https://hcplab-sysu.github.io/TAVP.","authors":["Yongjie Bai","Zhouxia Wang","Yang Liu","Kaijun Luo","Yifan Wen","Mingtong Dai","Weixing Chen","Ziliang Chen","Lingbo Liu","Guanbin Li","Liang Lin"],"pdf_url":"","comment":"24 pages, 15 figures, project page: https://hcplab-sysu.github.io/TAVP"},{"id":"http://arxiv.org/abs/2511.18718v1","updated":"2025-11-24T03:18:55Z","published":"2025-11-24T03:18:55Z","title":"AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation","summary":"We introduce AIRHILT (Aviation Integrated Reasoning, Human-in-the-Loop Testbed), a modular and lightweight simulation environment designed to evaluate multimodal pilot and air traffic control (ATC) assistance systems for aviation conflict detection. Built on the open-source Godot engine, AIRHILT synchronizes pilot and ATC radio communications, visual scene understanding from camera streams, and ADS-B surveillance data within a unified, scalable platform. The environment supports pilot- and controller-in-the-loop interactions, providing a comprehensive scenario suite covering both terminal area and en route operational conflicts, including communication errors and procedural mistakes. AIRHILT offers standardized JSON-based interfaces that enable researchers to easily integrate, swap, and evaluate automatic speech recognition (ASR), visual detection, decision-making, and text-to-speech (TTS) models. We demonstrate AIRHILT through a reference pipeline incorporating fine-tuned Whisper ASR, YOLO-based visual detection, ADS-B-based conflict logic, and GPT-OSS-20B structured reasoning, and present preliminary results from representative runway-overlap scenarios, where the assistant achieves an average time-to-first-warning of approximately 7.7 s, with average ASR and vision latencies of approximately 5.9 s and 0.4 s, respectively. The AIRHILT environment and scenario suite are openly available, supporting reproducible research on multimodal situational awareness and conflict detection in aviation; code and scenarios are available at https://github.com/ogarib3/airhilt.","authors":["Omar Garib","Jayaprakash D. Kambhampaty","Olivia J. Pinon Fischer","Dimitri N. Mavris"],"pdf_url":"","comment":"9 pages, 4 figures, 1 table, 1 algorithm"},{"id":"http://arxiv.org/abs/2511.18712v1","updated":"2025-11-24T03:10:33Z","published":"2025-11-24T03:10:33Z","title":"Head Stabilization for Wheeled Bipedal Robots via Force-Estimation-Based Admittance Control","summary":"Wheeled bipedal robots are emerging as flexible platforms for field exploration. However, head instability induced by uneven terrain can degrade the accuracy of onboard sensors or damage fragile payloads. Existing research primarily focuses on stabilizing the mobile platform but overlooks active stabilization of the head in the world frame, resulting in vertical oscillations that undermine overall stability. To address this challenge, we developed a model-based ground force estimation method for our 6-degree-of-freedom wheeled bipedal robot. Leveraging these force estimates, we implemented an admittance control algorithm to enhance terrain adaptability. Simulation experiments validated the real-time performance of the force estimator and the robot's robustness when traversing uneven terrain.","authors":["Tianyu Wang","Chunxiang Yan","Xuanhong Liao","Tao Zhang","Ping Wang","Cong Wen","Dingchuan Liu","Haowen Yu","Ximin Lyu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18709v1","updated":"2025-11-24T03:06:55Z","published":"2025-11-24T03:06:55Z","title":"Autonomous Surface Selection For Manipulator-Based UV Disinfection In Hospitals Using Foundation Models","summary":"Ultraviolet (UV) germicidal radiation is an established non-contact method for surface disinfection in medical environments. Traditional approaches require substantial human intervention to define disinfection areas, complicating automation, while deep learning-based methods often need extensive fine-tuning and large datasets, which can be impractical for large-scale deployment. Additionally, these methods often do not address scene understanding for partial surface disinfection, which is crucial for avoiding unintended UV exposure. We propose a solution that leverages foundation models to simplify surface selection for manipulator-based UV disinfection, reducing human involvement and removing the need for model training. Additionally, we propose a VLM-assisted segmentation refinement to detect and exclude thin and small non-target objects, showing that this reduces mis-segmentation errors. Our approach achieves over 92\\% success rate in correctly segmenting target and non-target surfaces, and real-world experiments with a manipulator and simulated UV light demonstrate its practical potential for real-world applications.","authors":["Xueyan Oh","Jonathan Her","Zhixiang Ong","Brandon Koh","Yun Hann Tan","U-Xuan Tan"],"pdf_url":"","comment":"7 pages, 7 figures; This paper has been accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2511.18708v1","updated":"2025-11-24T03:02:39Z","published":"2025-11-24T03:02:39Z","title":"GVD-TG: Topological Graph based on Fast Hierarchical GVD Sampling for Robot Exploration","summary":"Topological maps are more suitable than metric maps for robotic exploration tasks. However, real-time updating of accurate and detail-rich environmental topological maps remains a challenge. This paper presents a topological map updating method based on the Generalized Voronoi Diagram (GVD). First, the newly observed areas are denoised to avoid low-efficiency GVD nodes misleading the topological structure. Subsequently, a multi-granularity hierarchical GVD generation method is designed to control the sampling granularity at both global and local levels. This not only ensures the accuracy of the topological structure but also enhances the ability to capture detail features, reduces the probability of path backtracking, and ensures no overlap between GVDs through the maintenance of a coverage map, thereby improving GVD utilization efficiency. Second, a node clustering method with connectivity constraints and a connectivity method based on a switching mechanism are designed to avoid the generation of unreachable nodes and erroneous nodes caused by obstacle attraction. A special cache structure is used to store all connectivity information, thereby improving exploration efficiency. Finally, to address the issue of frontiers misjudgment caused by obstacles within the scope of GVD units, a frontiers extraction method based on morphological dilation is designed to effectively ensure the reachability of frontiers. On this basis, a lightweight cost function is used to assess and switch to the next viewpoint in real time. This allows the robot to quickly adjust its strategy when signs of path backtracking appear, thereby escaping the predicament and increasing exploration flexibility. And the performance of system for exploration task is verified through comparative tests with SOTA methods.","authors":["Yanbin Li","Canran Xiao","Shenghai Yuan","Peilai Yu","Ziruo Li","Zhiguo Zhang","Wenzheng Chi","Wei Zhang"],"pdf_url":"","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.18703v1","updated":"2025-11-24T02:55:12Z","published":"2025-11-24T02:55:12Z","title":"Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication","summary":"This paper addresses the challenge of coordinating multi-robot systems under realistic communication delays using distributed optimization. We focus on consensus ADMM as a scalable framework for generating collision-free, dynamically feasible motion plans in both trajectory optimization and receding-horizon control settings. In practice, however, these algorithms are sensitive to penalty tuning or adaptation schemes (e.g. residual balancing and adaptive parameter heuristics) that do not explicitly consider delays. To address this, we introduce a Delay-Aware ADMM (DA-ADMM) variant that adapts penalty parameters based on real-time delay statistics, allowing agents to down-weight stale information and prioritize recent updates during consensus and dual updates. Through extensive simulations in 2D and 3D environments with double-integrator, Dubins-car, and drone dynamics, we show that DA-ADMM significantly improves robustness, success rate, and solution quality compared to fixed-parameter, residual-balancing, and fixed-constraint baselines. Our results highlight that performance degradation is not solely determined by delay length or frequency, but by the optimizer's ability to contextually reason over delayed information. The proposed DA-ADMM achieves consistently better coordination performance across a wide range of delay conditions, offering a principled and efficient mechanism for resilient multi-robot motion planning under imperfect communication.","authors":["Ardalan Tajbakhsh","Augustinos Saravanos","James Zhu","Evangelos A. Theodorou","Lorenz T. Biegler","Aaron M. Johnson"],"pdf_url":"","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.18702v1","updated":"2025-11-24T02:52:36Z","published":"2025-11-24T02:52:36Z","title":"CNN-Based Camera Pose Estimation and Localisation of Scan Images for Aircraft Visual Inspection","summary":"General Visual Inspection is a manual inspection process regularly used to detect and localise obvious damage on the exterior of commercial aircraft. There has been increasing demand to perform this process at the boarding gate to minimise the downtime of the aircraft and automating this process is desired to reduce the reliance on human labour. Automating this typically requires estimating a camera's pose with respect to the aircraft for initialisation but most existing localisation methods require infrastructure, which is very challenging in uncontrolled outdoor environments and within the limited turnover time (approximately 2 hours) on an airport tarmac. Additionally, many airlines and airports do not allow contact with the aircraft's surface or using UAVs for inspection between flights, and restrict access to commercial aircraft. Hence, this paper proposes an on-site method that is infrastructure-free and easy to deploy for estimating a pan-tilt-zoom camera's pose and localising scan images. This method initialises using the same pan-tilt-zoom camera used for the inspection task by utilising a Deep Convolutional Neural Network fine-tuned on only synthetic images to predict its own pose. We apply domain randomisation to generate the dataset for fine-tuning the network and modify its loss function by leveraging aircraft geometry to improve accuracy. We also propose a workflow for initialisation, scan path planning, and precise localisation of images captured from a pan-tilt-zoom camera. We evaluate and demonstrate our approach through experiments with real aircraft, achieving root-mean-square camera pose estimation errors of less than 0.24 m and 2 degrees for all real scenes.","authors":["Xueyan Oh","Leonard Loh","Shaohui Foong","Zhong Bao Andy Koh","Kow Leong Ng","Poh Kang Tan","Pei Lin Pearlin Toh","U-Xuan Tan"],"pdf_url":"","comment":"12 pages, 12 figures"},{"id":"http://arxiv.org/abs/2511.18694v1","updated":"2025-11-24T02:28:31Z","published":"2025-11-24T02:28:31Z","title":"Stable Multi-Drone GNSS Tracking System for Marine Robots","summary":"Accurate localization is essential for marine robotics, yet Global Navigation Satellite System (GNSS) signals are unreliable or unavailable even at a very short distance below the water surface. Traditional alternatives, such as inertial navigation, Doppler Velocity Loggers (DVL), SLAM, and acoustic methods, suffer from error accumulation, high computational demands, or infrastructure dependence. In this work, we present a scalable multi-drone GNSS-based tracking system for surface and near-surface marine robots. Our approach combines efficient visual detection, lightweight multi-object tracking, GNSS-based triangulation, and a confidence-weighted Extended Kalman Filter (EKF) to provide stable GNSS estimation in real time. We further introduce a cross-drone tracking ID alignment algorithm that enforces global consistency across views, enabling robust multi-robot tracking with redundant aerial coverage. We validate our system in diversified complex settings to show the scalability and robustness of the proposed algorithm.","authors":["Shuo Wen","Edwin Meriaux","Mariana Sosa Guzmán","Zhizun Wang","Junming Shi","Gregory Dudek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18685v1","updated":"2025-11-24T02:02:29Z","published":"2025-11-24T02:02:29Z","title":"Beyond Description: Cognitively Benchmarking Fine-Grained Action for Embodied Agents","summary":"Multimodal Large Language Models (MLLMs) show promising results as decision-making engines for embodied agents operating in complex, physical environments. However, existing benchmarks often prioritize high-level planning or spatial reasoning, leaving the fine-grained action intelligence required for embodied physical interaction underexplored. To address this gap, we introduce CFG-Bench, a new benchmark designed to systematically evaluate this crucial capability. CFG-Bench consists of 1,368 curated videos paired with 19,562 three-modalities question-answer pairs targeting four cognitive abilities: 1) Physical Interaction, 2) Temporal-Causal Relation, 3) Intentional Understanding, and 4) Evaluative Judgment. Together, these dimensions provide a systematic framework for assessing a model's ability to translate visual observations into actionable knowledge, moving beyond mere surface-level recognition. Our comprehensive evaluation on CFG-Bench reveals that leading MLLMs struggle to produce detailed instructions for physical interactions and exhibit profound limitations in the higher-order reasoning of intention and evaluation. Moreover, supervised fine-tuning (SFT) on our data demonstrates that teaching an MLLMs to articulate fine-grained actions directly translates to significant performance gains on established embodied benchmarks. Our analysis highlights these limitations and offers insights for developing more capable and grounded embodied agents.","authors":["Dayong Liu","Chao Xu","Weihong Chen","Suyu Zhang","Juncheng Wang","Jiankang Deng","Baigui Sun","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18683v1","updated":"2025-11-24T01:47:50Z","published":"2025-11-24T01:47:50Z","title":"Online Learning-Enhanced Lie Algebraic MPC for Robust Trajectory Tracking of Autonomous Surface Vehicles","summary":"Autonomous surface vehicles (ASVs) are easily influenced by environmental disturbances such as wind and waves, making accurate trajectory tracking a persistent challenge in dynamic marine conditions. In this paper, we propose an efficient controller for trajectory tracking of marine vehicles under unknown disturbances by combining a convex error-state MPC on the Lie group with an online learning module to compensate for these disturbances in real time. This design enables adaptive and robust control while maintaining computational efficiency. Extensive evaluations in numerical simulations, the Virtual RobotX (VRX) simulator, and real-world field experiments demonstrate that our method achieves superior tracking accuracy under various disturbance scenarios compared with existing approaches.","authors":["Yinan Dong","Ziyu Xu","Tsimafei Lazouski","Sangli Teng","Maani Ghaffari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.15350v2","updated":"2025-11-24T23:52:35Z","published":"2025-10-17T06:30:19Z","title":"Nauplius Optimisation for Autonomous Hydrodynamics","summary":"Autonomous Underwater vehicles must operate in strong currents, limited acoustic bandwidth, and persistent sensing requirements where conventional swarm optimisation methods are unreliable. This paper formulates an irreversible hydrodynamic deployment problem for Autonomous Underwater Vehicle (AUV) swarms and presents Nauplius Optimisation for Autonomous Hydrodynamics (NOAH), a novel nature-inspired swarm optimisation algorithm that combines current-aware drift, irreversible settlement in persistent sensing nodes, and colony- based communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH addresses the critical limitations of existing swarm algorithms by providing hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based communication capabilities essential for underwater exploration missions. The algorithm establishes a comprehensive foundation for scalable and energy-efficient underwater swarm robotics with validated performance analysis. Validation studies demonstrate an 86% success rate for permanent anchoring scenarios, providing a unified formulation for hydrodynamic constraints and irreversible settlement behaviours with an empirical study under flow.","authors":["Shyalan Ramesh","Scott Mann","Alex Stumpf"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.12842v2","updated":"2025-11-24T23:47:56Z","published":"2024-09-19T15:36:28Z","title":"Vision Language Models Can Parse Floor Plan Maps","summary":"Vision language models (VLMs) can simultaneously reason about images and texts to tackle many tasks, from visual question answering to image captioning. This paper focuses on map parsing, a novel task that is unexplored within the VLM context and particularly useful to mobile robots. Map parsing requires understanding not only the labels but also the geometric configurations of a map, i.e., what areas are like and how they are connected. To evaluate the performance of VLMs on map parsing, we prompt VLMs with floor plan maps to generate task plans for complex indoor navigation. Our results demonstrate the remarkable capability of VLMs in map parsing, with a success rate of 0.96 in tasks requiring a sequence of nine navigation actions, e.g., approaching and going through doors. Other than intuitive observations, e.g., VLMs do better in smaller maps and simpler navigation tasks, there was a very interesting observation that its performance drops in large open areas. We provide practical suggestions to address such challenges as validated by our experimental results. Webpage: https://sites.google.com/view/vlm-floorplan/","authors":["David DeFazio","Hrudayangam Mehta","Meng Wang","Ping Yang","Jeremy Blackburn","Shiqi Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19768v1","updated":"2025-11-24T22:50:50Z","published":"2025-11-24T22:50:50Z","title":"Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering","summary":"Large vision-language models (VLMs) have improved embodied question answering (EQA) agents by providing strong semantic priors for open-vocabulary reasoning. However, when used directly for step-level exploration, VLMs often exhibit frontier oscillations, unstable back-and-forth movements caused by overconfidence and miscalibration, leading to inefficient navigation and degraded answer quality. We propose Prune-Then-Plan, a simple and effective framework that stabilizes exploration through step-level calibration. Instead of trusting raw VLM scores, our method prunes implausible frontier choices using a Holm-Bonferroni inspired pruning procedure and then delegates final decisions to a coverage-based planner. This separation converts overconfident predictions into conservative, interpretable actions by relying on human-level judgments to calibrate the step-level behavior of VLMs. Integrated into the 3D-Mem EQA framework, our approach achieves relative improvements of up to 49% and 33% in visually grounded SPL and LLM-Match metrics respectively over baselines. Overall, our method achieves better scene coverage under equal exploration budgets on both OpenEQA and EXPRESS-Bench datasets.","authors":["Noah Frahm","Prakrut Patel","Yue Zhang","Shoubin Yu","Mohit Bansal","Roni Sengupta"],"pdf_url":"","comment":"webpage: https://noahfrahm.github.io/Prune-Then-Plan-project-page/"},{"id":"http://arxiv.org/abs/2511.19728v1","updated":"2025-11-24T21:45:01Z","published":"2025-11-24T21:45:01Z","title":"Maritime Small Object Detection from UAVs using Deep Learning with Altitude-Aware Dynamic Tiling","summary":"Unmanned Aerial Vehicles (UAVs) are crucial in Search and Rescue (SAR) missions due to their ability to monitor vast maritime areas. However, small objects often remain difficult to detect from high altitudes due to low object-to-background pixel ratios. We propose an altitude-aware dynamic tiling method that scales and adaptively subdivides the image into tiles for enhanced small object detection. By integrating altitude-dependent scaling with an adaptive tiling factor, we reduce unnecessary computation while maintaining detection performance. Tested on the SeaDronesSee dataset [1] with YOLOv5 [2] and Slicing Aided Hyper Inference (SAHI) framework [3], our approach improves Mean Average Precision (mAP) for small objects by 38% compared to a baseline and achieves more than double the inference speed compared to static tiling. This approach enables more efficient and accurate UAV-based SAR operations under diverse conditions.","authors":["Sakib Ahmed","Oscar Pizarro"],"pdf_url":"","comment":"This is the author's accepted version of an article that has been published by IEEE. The final published version is available at IEEE Xplore"},{"id":"http://arxiv.org/abs/2511.19709v1","updated":"2025-11-24T21:20:39Z","published":"2025-11-24T21:20:39Z","title":"Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation","summary":"Loco-manipulation demands coordinated whole-body motion to manipulate objects effectively while maintaining locomotion stability, presenting significant challenges for both planning and control. In this work, we propose a whole-body model predictive control (MPC) framework that directly optimizes joint torques through full-order inverse dynamics, enabling unified motion and force planning and execution within a single predictive layer. This approach allows emergent, physically consistent whole-body behaviors that account for the system's dynamics and physical constraints. We implement our MPC formulation using open software frameworks (Pinocchio and CasADi), along with the state-of-the-art interior-point solver Fatrop. In real-world experiments on a Unitree B2 quadruped equipped with a Unitree Z1 manipulator arm, our MPC formulation achieves real-time performance at 80 Hz. We demonstrate loco-manipulation tasks that demand fine control over the end-effector's position and force to perform real-world interactions like pulling heavy loads, pushing boxes, and wiping whiteboards.","authors":["Lukas Molnar","Jin Cheng","Gabriele Fadini","Dongho Kang","Fatemeh Zargarbashi","Stelian Coros"],"pdf_url":"","comment":"9 pages, 6 figures, to be published in IEEE Robotics and Automation Letters (Special Issue: Advancements in MPC and Learning Algorithms for Legged Robots)"},{"id":"http://arxiv.org/abs/2511.19691v1","updated":"2025-11-24T20:55:13Z","published":"2025-11-24T20:55:13Z","title":"Multi-Agent gatekeeper: Safe Flight Planning and Formation Control for Urban Air Mobility","summary":"We present Multi-Agent gatekeeper, a framework that provides provable safety guarantees for leader-follower formation control in cluttered 3D environments. Existing methods face a trad-off: online planners and controllers lack formal safety guarantees, while offline planners lack adaptability to changes in the number of agents or desired formation. To address this gap, we propose a hybrid architecture where a single leader tracks a pre-computed, safe trajectory, which serves as a shared trajectory backup set for all follower agents. Followers execute a nominal formation-keeping tracking controller, and are guaranteed to remain safe by always possessing a known-safe backup maneuver along the leader's path. We formally prove this method ensures collision avoidance with both static obstacles and other agents. The primary contributions are: (1) the multi-agent gatekeeper algorithm, which extends our single-agent gatekeeper framework to multi-agent systems; (2) the trajectory backup set for provably safe inter-agent coordination for leader-follower formation control; and (3) the first application of the gatekeeper framework in a 3D environment. We demonstrate our approach in a simulated 3D urban environment, where it achieved a 100% collision-avoidance success rate across 100 randomized trials, significantly outperforming baseline CBF and NMPC methods. Finally, we demonstrate the physical feasibility of the resulting trajectories on a team of quadcopters.","authors":["Thomas Marshall Vielmetti","Devansh R Agrawal","Dimitra Panagou"],"pdf_url":"","comment":"13 pages, 4 figures, to appear AIAA SciTech 2026"},{"id":"http://arxiv.org/abs/2511.19684v1","updated":"2025-11-24T20:45:17Z","published":"2025-11-24T20:45:17Z","title":"IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants","summary":"We introduce IndEgo, a multimodal egocentric and exocentric dataset addressing common industrial tasks, including assembly/disassembly, logistics and organisation, inspection and repair, woodworking, and others. The dataset contains 3,460 egocentric recordings (approximately 197 hours), along with 1,092 exocentric recordings (approximately 97 hours). A key focus of the dataset is collaborative work, where two workers jointly perform cognitively and physically intensive tasks. The egocentric recordings include rich multimodal data and added context via eye gaze, narration, sound, motion, and others. We provide detailed annotations (actions, summaries, mistake annotations, narrations), metadata, processed outputs (eye gaze, hand pose, semi-dense point cloud), and benchmarks on procedural and non-procedural task understanding, Mistake Detection, and reasoning-based Question Answering. Baseline evaluations for Mistake Detection, Question Answering and collaborative task understanding show that the dataset presents a challenge for the state-of-the-art multimodal models. Our dataset is available at: https://huggingface.co/datasets/FraunhoferIPK/IndEgo","authors":["Vivek Chavan","Yasmina Imgrund","Tung Dao","Sanwantri Bai","Bosong Wang","Ze Lu","Oliver Heimann","Jörg Krüger"],"pdf_url":"","comment":"Accepted to NeurIPS 2025 D&B Track. Project Page: https://indego-dataset.github.io/"},{"id":"http://arxiv.org/abs/2511.19675v1","updated":"2025-11-24T20:17:50Z","published":"2025-11-24T20:17:50Z","title":"Anytime-Feasible First-Order Optimization via Safe Sequential QCQP","summary":"This paper presents the Safe Sequential Quadratically Constrained Quadratic Programming (SS-QCQP) algorithm, a first-order method for smooth inequality-constrained nonconvex optimization that guarantees feasibility at every iteration. The method is derived from a continuous-time dynamical system whose vector field is obtained by solving a convex QCQP that enforces monotonic descent of the objective and forward invariance of the feasible set. The resulting continuous-time dynamics achieve an $O(1/t)$ convergence rate to first-order stationary points under standard constraint qualification conditions. We then propose a safeguarded Euler discretization with adaptive step-size selection that preserves this convergence rate while maintaining both descent and feasibility in discrete time. To enhance scalability, we develop an active-set variant (SS-QCQP-AS) that selectively enforces constraints near the boundary, substantially reducing computational cost without compromising theoretical guarantees. Numerical experiments on a multi-agent nonlinear optimal control problem demonstrate that SS-QCQP and SS-QCQP-AS maintain feasibility, exhibit the predicted convergence behavior, and deliver solution quality comparable to second-order solvers such as SQP and IPOPT.","authors":["Jiarui Wang","Mahyar Fazlyab"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19655v1","updated":"2025-11-24T19:43:03Z","published":"2025-11-24T19:43:03Z","title":"Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection","summary":"Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.","authors":["Shantanu Rahman","Nayeb Hasin","Mainul Islam"],"pdf_url":"","comment":"49 pages, 23 figures"},{"id":"http://arxiv.org/abs/2511.19653v1","updated":"2025-11-24T19:35:56Z","published":"2025-11-24T19:35:56Z","title":"Flow-Based Path Planning for Multiple Homogenous UAVs for Outdoor Formation-Flying","summary":"Collision-free path planning is the most crucial component in multi-UAV formation-flying (MFF). We use unlabeled homogenous quadcopters (UAVs) to demonstrate the use of a flow network to create complete (inter-UAV) collision-free paths. This procedure has three main parts: 1) Creating a flow network graph from physical GPS coordinates, 2) Finding a path of minimum cost (least distance) using any graph-based path-finding algorithm, and 3) Implementing the Ford-Fulkerson Method to find the paths with the maximum flow (no collision). Simulations of up to 64 UAVs were conducted for various formations, followed by a practical experiment with 3 quadcopters for testing physical plausibility and feasibility. The results of these tests show the efficacy of this method's ability to produce safe, collision-free paths.","authors":["Mahmud Suhaimi Ibrahim","Shantanu Rahman","Muhammad Samin Hasan","Minhaj Uddin Ahmad","Abdullah Abrar"],"pdf_url":"","comment":"9 pages, 15 figures, conference"},{"id":"http://arxiv.org/abs/2511.19651v1","updated":"2025-11-24T19:32:02Z","published":"2025-11-24T19:32:02Z","title":"Online Learning-Enhanced High Order Adaptive Safety Control","summary":"Control barrier functions (CBFs) are an effective model-based tool to formally certify the safety of a system. With the growing complexity of modern control problems, CBFs have received increasing attention in both optimization-based and learning-based control communities as a safety filter, owing to their provable guarantees. However, success in transferring these guarantees to real-world systems is critically tied to model accuracy. For example, payloads or wind disturbances can significantly influence the dynamics of an aerial vehicle and invalidate the safety guarantee. In this work, we propose an efficient yet flexible online learning-enhanced high-order adaptive control barrier function using Neural ODEs. Our approach improves the safety of a CBF-certified system on the fly, even under complex time-varying model perturbations. In particular, we deploy our hybrid adaptive CBF controller on a 38g nano quadrotor, keeping a safe distance from the obstacle, against 18km/h wind.","authors":["Lishuo Pan","Mattia Catellani","Thales C. Silva","Lorenzo Sabattini","Nora Ayanian"],"pdf_url":"","comment":"8 pages, 7 figures, submitted to RA-L"},{"id":"http://arxiv.org/abs/2511.19647v1","updated":"2025-11-24T19:23:04Z","published":"2025-11-24T19:23:04Z","title":"Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation","summary":"Foundation models (FM) have unlocked powerful zero-shot capabilities in vision and language, yet their reliance on internet pretraining data leaves them brittle in unstructured, real-world settings. The messy, real-world data encountered during deployment (e.g. occluded or multilingual text) remains massively underrepresented in existing corpora. Robots, as embodied agents, are uniquely positioned to close this gap: they can act in physical environments to collect large-scale, real-world data that enriches FM training with precisely the examples current models lack. We introduce the Robot-Powered Data Flywheel, a framework that transforms robots from FM consumers into data generators. By deploying robots equipped with FMs in the wild, we enable a virtuous cycle: robots perform useful tasks while collecting real-world data that improves both domain-specific adaptation and domain-adjacent generalization. We instantiate this framework with Scanford, a mobile manipulator deployed in the East Asia Library for 2 weeks. Scanford autonomously scans shelves, identifies books using a vision-language model (VLM), and leverages the library catalog to label images without human annotation. This deployment both aids librarians and produces a dataset to finetune the underlying VLM, improving performance on the domain-specific in-the-wild library setting and on domain-adjacent multilingual OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM performance on book identification from 32.0% to 71.8% and boosts domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to 38.0% (Chinese), while saving an ~18.7 hrs of human time. These results highlight how robot-powered data flywheels can both reduce human effort in real deployments and unlock new pathways for continually adapting FMs to the messiness of reality. More details are at: https://scanford-robot.github.io","authors":["Jennifer Grannen","Michelle Pan","Kenneth Llontop","Cherie Ho","Mark Zolotas","Jeannette Bohg","Dorsa Sadigh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19584v1","updated":"2025-11-24T18:57:19Z","published":"2025-11-24T18:57:19Z","title":"Learning Massively Multitask World Models for Continuous Control","summary":"General-purpose control demands agents that act across many tasks and embodiments, yet research on reinforcement learning (RL) for continuous control remains dominated by single-task or offline regimes, reinforcing a view that online RL does not scale. Inspired by the foundation model recipe (large-scale pretraining followed by light RL) we ask whether a single agent can be trained on hundreds of tasks with online interaction. To accelerate research in this direction, we introduce a new benchmark with 200 diverse tasks spanning many domains and embodiments, each with language instructions, demonstrations, and optionally image observations. We then present \\emph{Newt}, a language-conditioned multitask world model that is first pretrained on demonstrations to acquire task-aware representations and action priors, and then jointly optimized with online interaction across all tasks. Experiments show that Newt yields better multitask performance and data-efficiency than a set of strong baselines, exhibits strong open-loop control, and enables rapid adaptation to unseen tasks. We release our environments, demonstrations, code for training and evaluation, as well as 200+ checkpoints.","authors":["Nicklas Hansen","Hao Su","Xiaolong Wang"],"pdf_url":"","comment":"Webpage: https://www.nicklashansen.com/NewtWM"},{"id":"http://arxiv.org/abs/2511.19543v1","updated":"2025-11-24T11:05:11Z","published":"2025-11-24T11:05:11Z","title":"A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers","summary":"Object handover is a common form of interaction that is widely present in collaborative tasks. However, achieving it efficiently remains a challenge. We address the problem of ensuring resilient robotic actions that can adapt to complex changes in object pose during human-to-robot object handovers. We propose the use of Virtual Model Control to create an interaction layer that controls the robot and adapts to the dynamic changes in the handover process. Additionally, we propose the use of augmented reality to facilitate bidirectional communication between humans and robots during handovers. We assess the performance of our controller in a set of experiments that demonstrate its resilience to various sources of uncertainties, including complex changes to the object's pose during the handover. Finally, we performed a user study with 16 participants to understand human preferences for different robot control profiles and augmented reality visuals in object handovers. Our results showed a general preference for the proposed approach and revealed insights that can guide further development in adapting the interaction with the user.","authors":["Omar Faris","Sławomir Tadeja","Fulvio Forni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19528v1","updated":"2025-11-24T07:54:49Z","published":"2025-11-24T07:54:49Z","title":"Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories","summary":"Scaling vision-language-action (VLA) model pre-training requires large volumes of diverse, high-quality manipulation trajectories. Most current data is obtained via human teleoperation, which is expensive and difficult to scale. Reinforcement learning (RL) methods learn useful skills through autonomous exploration, making them a viable approach for generating data. However, standard RL training collapses to a narrow execution pattern, limiting its utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce (DLR), an information-theoretic pattern discovery framework that generates multiple distinct, high-success behavioral patterns for VLA pretraining. Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO. Specifically, it learns multiple distinct, high-success strategies for the same task where standard RL discovers only one, and hence it covers substantially broader regions of the state-action space. When adapted to unseen downstream task suites, VLA models pretrained on our diverse RL data surpass counterparts trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive data-scaling behavior that single-pattern RL lacks. These results position multi-pattern RL as a practical, scalable data engine for embodied foundation models.","authors":["Rushuai Yang","Zhiyuan Feng","Tianxiang Zhang","Kaixin Wang","Chuheng Zhang","Li Zhao","Xiu Su","Yi Chen","Jiang Bian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.15350v2","updated":"2025-11-24T23:52:35Z","published":"2025-10-17T06:30:19Z","title":"Nauplius Optimisation for Autonomous Hydrodynamics","summary":"Autonomous Underwater vehicles must operate in strong currents, limited acoustic bandwidth, and persistent sensing requirements where conventional swarm optimisation methods are unreliable. This paper formulates an irreversible hydrodynamic deployment problem for Autonomous Underwater Vehicle (AUV) swarms and presents Nauplius Optimisation for Autonomous Hydrodynamics (NOAH), a novel nature-inspired swarm optimisation algorithm that combines current-aware drift, irreversible settlement in persistent sensing nodes, and colony-based communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH addresses the critical limitations of existing swarm algorithms by providing hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based communication capabilities essential for underwater exploration missions. The algorithm establishes a comprehensive foundation for scalable and energy-efficient underwater swarm robotics with validated performance analysis. Validation studies demonstrate an 86% success rate for permanent anchoring scenarios, providing a unified formulation for hydrodynamic constraints and irreversible settlement behaviours with an empirical study under flow.","authors":["Shyalan Ramesh","Scott Mann","Alex Stumpf"],"pdf_url":"","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2511.19437v1","updated":"2025-11-24T18:59:58Z","published":"2025-11-24T18:59:58Z","title":"LumiTex: Towards High-Fidelity PBR Texture Generation with Illumination Context","summary":"Physically-based rendering (PBR) provides a principled standard for realistic material-lighting interactions in computer graphics. Despite recent advances in generating PBR textures, existing methods fail to address two fundamental challenges: 1) materials decomposition from image prompts under limited illumination cues, and 2) seamless and view-consistent texture completion. To this end, we propose LumiTex, an end-to-end framework that comprises three key components: (1) a multi-branch generation scheme that disentangles albedo and metallic-roughness under shared illumination priors for robust material understanding, (2) a lighting-aware material attention mechanism that injects illumination context into the decoding process for physically grounded generation of albedo, metallic, and roughness maps, and (3) a geometry-guided inpainting module based on a large view synthesis model that enriches texture coverage and ensures seamless, view-consistent UV completion. Extensive experiments demonstrate that LumiTex achieves state-of-the-art performance in texture quality, surpassing both existing open-source and commercial methods.","authors":["Jingzhi Bao","Hongze Chen","Lingting Zhu","Chenyu Liu","Runze Zhang","Keyang Luo","Zeyu Hu","Weikai Chen","Yingda Yin","Xin Wang","Zehong Lin","Jun Zhang","Xiaoguang Han"],"pdf_url":"","comment":"Project page: https://lumitex.vercel.app"},{"id":"http://arxiv.org/abs/2511.19436v1","updated":"2025-11-24T18:59:56Z","published":"2025-11-24T18:59:56Z","title":"VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection","summary":"We present VDC-Agent, a self-evolving framework for Video Detailed Captioning that requires neither human annotations nor larger teacher models. The agent forms a closed loop of caption generation, principle-guided scoring (score and textual suggestions), and prompt refinement. When caption quality regresses, a self-reflection path leverages the previous chain-of-thought to amend the update. Running this process on unlabeled videos produces trajectories of (caption, score) pairs. We convert the trajectories into preference tuples and filter out samples with JSON parsing errors, resulting in VDC-Agent-19K, which contains 18,886 automatically constructed pairs. We then fine-tune the base MLLM on this dataset using an easy-to-hard curriculum direct preference optimization. Built on Qwen2.5-VL-7B-Instruct, our VDC-Agent-7B attains state-of-the-art performance on the VDC benchmark with 49.08% average accuracy and 2.50 score, surpassing specialized video captioners and improving over the base model by +5.13% accuracy and +0.27 score at similar inference cost.","authors":["Qiang Wang","Xinyuan Gao","SongLin Dong","Jizhou Han","Jiangyang Li","Yuhang He","Yihong Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19435v1","updated":"2025-11-24T18:59:54Z","published":"2025-11-24T18:59:54Z","title":"Are Image-to-Video Models Good Zero-Shot Image Editors?","summary":"Large-scale video diffusion models show strong world simulation and temporal reasoning abilities, but their use as zero-shot image editors remains underexplored. We introduce IF-Edit, a tuning-free framework that repurposes pretrained image-to-video diffusion models for instruction-driven image editing. IF-Edit addresses three key challenges: prompt misalignment, redundant temporal latents, and blurry late-stage frames. It includes (1) a chain-of-thought prompt enhancement module that transforms static editing instructions into temporally grounded reasoning prompts; (2) a temporal latent dropout strategy that compresses frame latents after the expert-switch point, accelerating denoising while preserving semantic and temporal coherence; and (3) a self-consistent post-refinement step that sharpens late-stage frames using a short still-video trajectory. Experiments on four public benchmarks, covering non-rigid editing, physical and temporal reasoning, and general instruction edits, show that IF-Edit performs strongly on reasoning-centric tasks while remaining competitive on general-purpose edits. Our study provides a systematic view of video diffusion models as image editors and highlights a simple recipe for unified video-image generative reasoning.","authors":["Zechuan Zhang","Zhenyuan Chen","Zongxin Yang","Yi Yang"],"pdf_url":"","comment":"technical report"},{"id":"http://arxiv.org/abs/2511.19434v1","updated":"2025-11-24T18:59:53Z","published":"2025-11-24T18:59:53Z","title":"Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging Pretrained Experts","summary":"Diffusion models for image generation often exhibit a trade-off between perceptual sample quality and data likelihood: training objectives emphasizing high-noise denoising steps yield realistic images but poor likelihoods, whereas likelihood-oriented training overweights low-noise steps and harms visual fidelity. We introduce a simple plug-and-play sampling method that combines two pretrained diffusion experts by switching between them along the denoising trajectory. Specifically, we apply an image-quality expert at high noise levels to shape global structure, then switch to a likelihood expert at low noise levels to refine pixel statistics. The approach requires no retraining or fine-tuning -- only the choice of an intermediate switching step. On CIFAR-10 and ImageNet32, the merged model consistently matches or outperforms its base components, improving or preserving both likelihood and sample quality relative to each expert alone. These results demonstrate that expert switching across noise levels is an effective way to break the likelihood-quality trade-off in image diffusion models.","authors":["Yasin Esfandiari","Stefan Bauer","Sebastian U. Stich","Andrea Dittadi"],"pdf_url":"","comment":"ICLR 2025 DeLTa workshop"},{"id":"http://arxiv.org/abs/2511.19433v1","updated":"2025-11-24T18:59:51Z","published":"2025-11-24T18:59:51Z","title":"Mixture of Horizons in Action Chunking","summary":"Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\\textbf{action chunk length}$ used during training, termed $\\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $π_0$, $π_{0.5}$, and one-step regression policy $π_{\\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $π_{0.5}$ with MoH reaches a new state-of-the-art with 99$\\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons","authors":["Dong Jing","Gang Wang","Jiaqi Liu","Weiliang Tang","Zelong Sun","Yunchao Yao","Zhenyu Wei","Yunhui Liu","Zhiwu Lu","Mingyu Ding"],"pdf_url":"","comment":"15 pages, 14 figures"},{"id":"http://arxiv.org/abs/2511.19431v1","updated":"2025-11-24T18:59:37Z","published":"2025-11-24T18:59:37Z","title":"Cloud4D","summary":"There has been great progress in improving numerical weather prediction and climate models using machine learning. However, most global models act at a kilometer-scale, making it challenging to model individual clouds and factors such as extreme precipitation, wind gusts, turbulence, and surface irradiance. Therefore, there is a need to move towards higher-resolution models, which in turn require high-resolution real-world observations that current instruments struggle to obtain. We present Cloud4D, the first learning-based framework that reconstructs a physically consistent, four-dimensional cloud state using only synchronized ground-based cameras. Leveraging a homography-guided 2D-to-3D transformer, Cloud4D infers the full 3D distribution of liquid water content at 25 m spatial and 5 s temporal resolution. By tracking the 3D liquid water content retrievals over time, Cloud4D additionally estimates horizontal wind vectors. Across a two-month deployment comprising six skyward cameras, our system delivers an order-of-magnitude improvement in space-time resolution relative to state-of-the-art satellite measurements, while retaining single-digit relative error ($<10\\%$) against collocated radar measurements. Code and data are available on our project page https://cloud4d.jacob-lin.com/.","authors":["Jacob Lin","Edward Gryspeerdt","Ronald Clark"],"pdf_url":"","comment":"NeurIPS 2025 Spotlight, project page: https://cloud4d.jacob-lin.com/"},{"id":"http://arxiv.org/abs/2511.19430v1","updated":"2025-11-24T18:59:17Z","published":"2025-11-24T18:59:17Z","title":"Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution","summary":"Task scheduling is critical for embodied AI, enabling agents to follow natural language instructions and execute actions efficiently in 3D physical worlds. However, existing datasets often simplify task planning by ignoring operations research (OR) knowledge and 3D spatial grounding. In this work, we propose Operations Research knowledge-based 3D Grounded Task Scheduling (ORS3D), a new task that requires the synergy of language understanding, 3D grounding, and efficiency optimization. Unlike prior settings, ORS3D demands that agents minimize total completion time by leveraging parallelizable subtasks, e.g., cleaning the sink while the microwave operates. To facilitate research on ORS3D, we construct ORS3D-60K, a large-scale dataset comprising 60K composite tasks across 4K real-world scenes. Furthermore, we propose GRANT, an embodied multi-modal large language model equipped with a simple yet effective scheduling token mechanism to generate efficient task schedules and grounded actions. Extensive experiments on ORS3D-60K validate the effectiveness of GRANT across language understanding, 3D grounding, and scheduling efficiency. The code is available at https://github.com/H-EmbodVis/GRANT","authors":["Dingkang Liang","Cheng Zhang","Xiaopeng Xu","Jianzhong Ju","Zhenbo Luo","Xiang Bai"],"pdf_url":"","comment":"Accepted to AAAI 2026 (Oral). The code is available at \\url{https://github.com/H-EmbodVis/GRANT}"},{"id":"http://arxiv.org/abs/2511.19428v1","updated":"2025-11-24T18:58:55Z","published":"2025-11-24T18:58:55Z","title":"Flow Map Distillation Without Data","summary":"State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data.","authors":["Shangyuan Tong","Nanye Ma","Saining Xie","Tommi Jaakkola"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19426v1","updated":"2025-11-24T18:58:22Z","published":"2025-11-24T18:58:22Z","title":"Ref-SAM3D: Bridging SAM3D with Text for Reference 3D Reconstruction","summary":"SAM3D has garnered widespread attention for its strong 3D object reconstruction capabilities. However, a key limitation remains: SAM3D cannot reconstruct specific objects referred to by textual descriptions, a capability that is essential for practical applications such as 3D editing, game development, and virtual environments. To address this gap, we introduce Ref-SAM3D, a simple yet effective extension to SAM3D that incorporates textual descriptions as a high-level prior, enabling text-guided 3D reconstruction from a single RGB image. Through extensive qualitative experiments, we show that Ref-SAM3D, guided only by natural language and a single 2D view, delivers competitive and high-fidelity zero-shot reconstruction performance. Our results demonstrate that Ref-SAM3D effectively bridges the gap between 2D visual cues and 3D geometric understanding, offering a more flexible and accessible paradigm for reference-guided 3D reconstruction. Code is available at: https://github.com/FudanCVL/Ref-SAM3D.","authors":["Yun Zhou","Yaoting Wang","Guangquan Jie","Jinyu Liu","Henghui Ding"],"pdf_url":"","comment":"Code: https://github.com/FudanCVL/Ref-SAM3D"},{"id":"http://arxiv.org/abs/2511.19425v1","updated":"2025-11-24T18:57:54Z","published":"2025-11-24T18:57:54Z","title":"SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage Object Segmentation, Shadow Detection, and Medical Image Segmentation","summary":"The rapid rise of large-scale foundation models has reshaped the landscape of image segmentation, with models such as Segment Anything achieving unprecedented versatility across diverse vision tasks. However, previous generations-including SAM and its successor-still struggle with fine-grained, low-level segmentation challenges such as camouflaged object detection, medical image segmentation, cell image segmentation, and shadow detection. To address these limitations, we originally proposed SAM-Adapter in 2023, demonstrating substantial gains on these difficult scenarios. With the emergence of Segment Anything 3 (SAM3)-a more efficient and higher-performing evolution with a redesigned architecture and improved training pipeline-we revisit these long-standing challenges. In this work, we present SAM3-Adapter, the first adapter framework tailored for SAM3 that unlocks its full segmentation capability. SAM3-Adapter not only reduces computational overhead but also consistently surpasses both SAM and SAM2-based solutions, establishing new state-of-the-art results across multiple downstream tasks, including medical imaging, camouflaged (concealed) object segmentation, and shadow detection. Built upon the modular and composable design philosophy of the original SAM-Adapter, SAM3-Adapter provides stronger generalizability, richer task adaptability, and significantly improved segmentation precision. Extensive experiments confirm that integrating SAM3 with our adapter yields superior accuracy, robustness, and efficiency compared to all prior SAM-based adaptations. We hope SAM3-Adapter can serve as a foundation for future research and practical segmentation applications. Code, pre-trained models, and data processing pipelines are available.","authors":["Tianrun Chen","Runlong Cao","Xinda Yu","Lanyun Zhu","Chaotao Ding","Deyi Ji","Cheng Chen","Qi Zhu","Chunyan Xu","Papa Mao","Ying Zang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19418v1","updated":"2025-11-24T18:55:19Z","published":"2025-11-24T18:55:19Z","title":"Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens","summary":"Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent representations that encode rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills knowledge from lightweight vision experts, capturing complementary properties such as 2D appearance, 3D geometry, spatial layout, and edge structure. During training, the VLM with COVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (e.g., depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than ten diverse perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL and LLaVA consistently improves performance by 3% to 16% and demonstrates that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.","authors":["Yiming Qin","Bomin Wei","Jiaxin Ge","Konstantinos Kallidromitis","Stephanie Fu","Trevor Darrell","Xudong Wang"],"pdf_url":"","comment":"Project page: https://wakalsprojectpage.github.io/comt-website/"},{"id":"http://arxiv.org/abs/2511.19413v1","updated":"2025-11-24T18:50:01Z","published":"2025-11-24T18:50:01Z","title":"UniGame: Turning a Unified Multimodal Model Into Its Own Adversary","summary":"Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame","authors":["Zhaolong Su","Wang Lu","Hao Chen","Sharon Li","Jindong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19401v1","updated":"2025-11-24T18:38:45Z","published":"2025-11-24T18:38:45Z","title":"In-Video Instructions: Visual Signals as Generative Control","summary":"Large-scale video generative models have recently demonstrated strong visual capabilities, enabling the prediction of future frames that adhere to the logical and physical cues in the current observation. In this work, we investigate whether such capabilities can be harnessed for controllable image-to-video generation by interpreting visual signals embedded within the frames as instructions, a paradigm we term In-Video Instruction. In contrast to prompt-based control, which provides textual descriptions that are inherently global and coarse, In-Video Instruction encodes user guidance directly into the visual domain through elements such as overlaid text, arrows, or trajectories. This enables explicit, spatial-aware, and unambiguous correspondences between visual subjects and their intended actions by assigning distinct instructions to different objects. Extensive experiments on three state-of-the-art generators, including Veo 3.1, Kling 2.5, and Wan 2.2, show that video models can reliably interpret and execute such visually embedded instructions, particularly in complex multi-object scenarios.","authors":["Gongfan Fang","Xinyin Ma","Xinchao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19396v1","updated":"2025-11-24T18:33:50Z","published":"2025-11-24T18:33:50Z","title":"Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments","summary":"Advances in object tracking and acoustic beamforming are driving new capabilities in surveillance, human-computer interaction, and robotics. This work presents an embedded system that integrates deep learning-based tracking with beamforming to achieve precise sound source localization and directional audio capture in dynamic environments. The approach combines single-camera depth estimation and stereo vision to enable accurate 3D localization of moving objects. A planar concentric circular microphone array constructed with MEMS microphones provides a compact, energy-efficient platform supporting 2D beam steering across azimuth and elevation. Real-time tracking outputs continuously adapt the array's focus, synchronizing the acoustic response with the target's position. By uniting learned spatial awareness with dynamic steering, the system maintains robust performance in the presence of multiple or moving sources. Experimental evaluation demonstrates significant gains in signal-to-interference ratio, making the design well-suited for teleconferencing, smart home devices, and assistive technologies.","authors":["Jorge Ortigoso-Narro","Jose A. Belloch","Adrian Amor-Martin","Sandra Roger","Maximo Cobos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19394v1","updated":"2025-11-24T18:31:51Z","published":"2025-11-24T18:31:51Z","title":"BackSplit: The Importance of Sub-dividing the Background in Biomedical Lesion Segmentation","summary":"Segmenting small lesions in medical images remains notoriously difficult. Most prior work tackles this challenge by either designing better architectures, loss functions, or data augmentation schemes; and collecting more labeled data. We take a different view, arguing that part of the problem lies in how the background is modeled. Common lesion segmentation collapses all non-lesion pixels into a single \"background\" class, ignoring the rich anatomical context in which lesions appear. In reality, the background is highly heterogeneous-composed of tissues, organs, and other structures that can now be labeled manually or inferred automatically using existing segmentation models.\n  In this paper, we argue that training with fine-grained labels that sub-divide the background class, which we call BackSplit, is a simple yet powerful paradigm that can offer a significant performance boost without increasing inference costs. From an information theoretic standpoint, we prove that BackSplit increases the expected Fisher Information relative to conventional binary training, leading to tighter asymptotic bounds and more stable optimization. With extensive experiments across multiple datasets and architectures, we empirically show that BackSplit consistently boosts small-lesion segmentation performance, even when auxiliary labels are generated automatically using pretrained segmentation models. Additionally, we demonstrate that auxiliary labels derived from interactive segmentation frameworks exhibit the same beneficial effect, demonstrating its robustness, simplicity, and broad applicability.","authors":["Rachit Saluja","Asli Cihangir","Ruining Deng","Johannes C. Paetzold","Fengbei Liu","Mert R. Sabuncu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19380v1","updated":"2025-11-24T18:20:08Z","published":"2025-11-24T18:20:08Z","title":"UISearch: Graph-Based Embeddings for Multimodal Enterprise UI Screenshots Retrieval","summary":"Enterprise software companies maintain thousands of user interface screens across products and versions, creating critical challenges for design consistency, pattern discovery, and compliance check. Existing approaches rely on visual similarity or text semantics, lacking explicit modeling of structural properties fundamental to user interface (UI) composition. We present a novel graph-based representation that converts UI screenshots into attributed graphs encoding hierarchical relationships and spatial arrangements, potentially generalizable to document layouts, architectural diagrams, and other structured visual domains. A contrastive graph autoencoder learns embeddings preserving multi-level similarity across visual, structural, and semantic properties. The comprehensive analysis demonstrates that our structural embeddings achieve better discriminative power than state-of-the-art Vision Encoders, representing a fundamental advance in the expressiveness of the UI representation. We implement this representation in UISearch, a multi-modal search framework that combines structural embeddings with semantic search through a composable query language. On 20,396 financial software UIs, UISearch achieves 0.92 Top-5 accuracy with 47.5ms median latency (P95: 124ms), scaling to 20,000+ screens. The hybrid indexing architecture enables complex queries and supports fine-grained UI distinction impossible with vision-only approaches.","authors":["Maroun Ayli","Youssef Bakouny","Tushar Sharma","Nader Jalloul","Hani Seifeddine","Rima Kilany"],"pdf_url":"","comment":"12 pages, 2 figures, 3 algorithms, 4 tables"},{"id":"http://arxiv.org/abs/2405.18716v2","updated":"2025-11-24T18:15:06Z","published":"2024-05-29T02:53:59Z","title":"SketchDeco: Training-Free Latent Composition for Precise Sketch Colourisation","summary":"We introduce SketchDeco, a training-free approach to sketch colourisation that bridges the gap between professional design needs and intuitive, region-based control. Our method empowers artists to use simple masks and colour palettes for precise spatial and chromatic specification, avoiding both the tediousness of manual assignment and the ambiguity of text-based prompts. We reformulate this task as a novel, training-free composition problem. Our core technical contribution is a guided latent-space blending process: we first leverage diffusion inversion to precisely ``paint'' user-defined colours into specified regions, and then use a custom self-attention mechanism to harmoniously blend these local edits with a globally consistent base image. This ensures both local colour fidelity and global harmony without requiring any model fine-tuning. Our system produces high-quality results in 15--20 inference steps on consumer GPUs, making professional-quality, controllable colourisation accessible.","authors":["Chaitat Utintu","Pinaki Nath Chowdhury","Aneeshan Sain","Subhadeep Koley","Ayan Kumar Bhunia","Yi-Zhe Song"],"pdf_url":"","comment":"Project Page: \\url{https://chaitron.github.io/SketchDeco/}"},{"id":"http://arxiv.org/abs/2511.19367v1","updated":"2025-11-24T18:01:47Z","published":"2025-11-24T18:01:47Z","title":"An Anatomy Aware Hybrid Deep Learning Framework for Lung Cancer Tumor Stage Classification","summary":"Accurate lung cancer tumor staging is crucial for prognosis and treatment planning. However, it remains challenging for end-to-end deep learning approaches, as such approaches often overlook spatial and anatomical information that are central to the tumor-node-metastasis system. The tumor stage depends on multiple quantitative criteria, including the tumor size and its proximity to the nearest anatomical structures, and small variations can alter the staging outcome. We propose a medically grounded hybrid pipeline that performs staging by explicitly measuring the tumor's size and distance properties rather than treating it as a pure image classification task. Our method employs specialized encoder-decoder networks to precisely segment the lung and adjacent anatomy, including the lobes, tumor, mediastinum, and diaphragm. Subsequently, we extract the necessary tumor properties, i.e. measure the largest tumor dimension and calculate the distance between the tumor and neighboring anatomical structures by a quantitative analysis of the segmentation masks. Finally, we apply rule-based tumor staging aligned with the medical guidelines. This novel framework has been evaluated on the Lung-PET-CT-Dx dataset, demonstrating superior performance compared to traditional deep learning models, achieving an overall classification accuracy of 91.36%. We report the per-stage F1-scores of 0.93 (T1), 0.89 (T2), 0.96 (T3), and 0.90 (T4), a critical evaluation aspect often omitted in prior literature. To our knowledge, this is the first study that embeds explicit clinical context into tumor stage classification. Unlike standard convolutional neural networks that operate in an uninterpretable \"black box\" manner, our method offers both state-of-the-art performance and transparent decision support.","authors":["Saniah Kayenat Chowdhury","Rusab Sarmun","Muhammad E. H. Chowdhury","Sohaib Bassam Zoghoul","Israa Al-Hashimi","Adam Mushtak","Amith Khandakar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19365v1","updated":"2025-11-24T17:59:06Z","published":"2025-11-24T17:59:06Z","title":"DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation","summary":"Pixel diffusion aims to generate images directly in pixel space in an end-to-end fashion. This approach avoids the limitations of VAE in the two-stage latent diffusion, offering higher model capacity. Existing pixel diffusion models suffer from slow training and inference, as they usually model both high-frequency signals and low-frequency semantics within a single diffusion transformer (DiT). To pursue a more efficient pixel diffusion paradigm, we propose the frequency-DeCoupled pixel diffusion framework. With the intuition to decouple the generation of high and low frequency components, we leverage a lightweight pixel decoder to generate high-frequency details conditioned on semantic guidance from the DiT. This thus frees the DiT to specialize in modeling low-frequency semantics. In addition, we introduce a frequency-aware flow-matching loss that emphasizes visually salient frequencies while suppressing insignificant ones. Extensive experiments show that DeCo achieves superior performance among pixel diffusion models, attaining FID of 1.62 (256x256) and 2.22 (512x512) on ImageNet, closing the gap with latent diffusion methods. Furthermore, our pretrained text-to-image model achieves a leading overall score of 0.86 on GenEval in system-level comparison. Codes are publicly available at https://github.com/Zehong-Ma/DeCo.","authors":["Zehong Ma","Longhui Wei","Shuai Wang","Shiliang Zhang","Qi Tian"],"pdf_url":"","comment":"Project Page: https://zehong-ma.github.io/DeCo. Code Repository: https://github.com/Zehong-Ma/DeCo"},{"id":"http://arxiv.org/abs/2511.19356v1","updated":"2025-11-24T17:56:03Z","published":"2025-11-24T17:56:03Z","title":"Growing with the Generator: Self-paced GRPO for Video Generation","summary":"Group Relative Policy Optimization (GRPO) has emerged as a powerful reinforcement learning paradigm for post-training video generation models. However, existing GRPO pipelines rely on static, fixed-capacity reward models whose evaluation behavior is frozen during training. Such rigid rewards introduce distributional bias, saturate quickly as the generator improves, and ultimately limit the stability and effectiveness of reinforcement-based alignment. We propose Self-Paced GRPO, a competence-aware GRPO framework in which reward feedback co-evolves with the generator. Our method introduces a progressive reward mechanism that automatically shifts its emphasis from coarse visual fidelity to temporal coherence and fine-grained text-video semantic alignment as generation quality increases. This self-paced curriculum alleviates reward-policy mismatch, mitigates reward exploitation, and yields more stable optimization. Experiments on VBench across multiple video generation backbones demonstrate consistent improvements in both visual quality and semantic alignment over GRPO baselines with static rewards, validating the effectiveness and generality of Self-Paced GRPO.","authors":["Rui Li","Yuanzhi Liang","Ziqi Ni","Haibing Huang","Chi Zhang","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19351v1","updated":"2025-11-24T17:53:59Z","published":"2025-11-24T17:53:59Z","title":"CellFMCount: A Fluorescence Microscopy Dataset, Benchmark, and Methods for Cell Counting","summary":"Accurate cell counting is essential in various biomedical research and clinical applications, including cancer diagnosis, stem cell research, and immunology. Manual counting is labor-intensive and error-prone, motivating automation through deep learning techniques. However, training reliable deep learning models requires large amounts of high-quality annotated data, which is difficult and time-consuming to produce manually. Consequently, existing cell-counting datasets are often limited, frequently containing fewer than $500$ images. In this work, we introduce a large-scale annotated dataset comprising $3{,}023$ images from immunocytochemistry experiments related to cellular differentiation, containing over $430{,}000$ manually annotated cell locations. The dataset presents significant challenges: high cell density, overlapping and morphologically diverse cells, a long-tailed distribution of cell count per image, and variation in staining protocols. We benchmark three categories of existing methods: regression-based, crowd-counting, and cell-counting techniques on a test set with cell counts ranging from $10$ to $2{,}126$ cells per image. We also evaluate how the Segment Anything Model (SAM) can be adapted for microscopy cell counting using only dot-annotated datasets. As a case study, we implement a density-map-based adaptation of SAM (SAM-Counter) and report a mean absolute error (MAE) of $22.12$, which outperforms existing approaches (second-best MAE of $27.46$). Our results underscore the value of the dataset and the benchmarking framework for driving progress in automated cell counting and provide a robust foundation for future research and development.","authors":["Abdurahman Ali Mohammed","Catherine Fonder","Ying Wei","Wallapak Tavanapong","Donald S Sakaguchi","Qi Li","Surya K. Mallapragada"],"pdf_url":"","comment":"The IEEE International Conference on Data Mining (ICDM) 2025"},{"id":"http://arxiv.org/abs/2511.19343v1","updated":"2025-11-24T17:42:29Z","published":"2025-11-24T17:42:29Z","title":"Syn-GRPO: Self-Evolving Data Synthesis for MLLM Perception Reasoning","summary":"RL (reinforcement learning) methods (e.g., GRPO) for MLLM (Multimodal LLM) perception ability has attracted wide research interest owing to its remarkable generalization ability. Nevertheless, existing reinforcement learning methods still face the problem of low data quality, where data samples cannot elicit diverse responses from MLLMs, thus restricting the exploration scope for MLLM reinforcement learning. Some methods attempt to mitigate this problem by imposing constraints on entropy, but none address it at its root. Therefore, to tackle this problem, this work proposes Syn-GRPO (Synthesis-GRPO), which employs an online data generator to synthesize high-quality training data with diverse responses in GRPO training. Specifically, Syn-GRPO consists of two components: (1) data server; (2) GRPO workflow. The data server synthesizes new samples from existing ones using an image generation model, featuring a decoupled and asynchronous scheme to achieve high generation efficiency. The GRPO workflow provides the data server with the new image descriptions, and it leverages a diversity reward to supervise the MLLM to predict image descriptions for synthesizing samples with diverse responses. Experiment results across three visual perception tasks demonstrate that Syn-GRPO improves the data quality by a large margin, achieving significant superior performance to existing MLLM perception methods, and Syn-GRPO presents promising potential for scaling long-term self-evolving RL. Our code is available at https://github.com/hqhQAQ/Syn-GRPO.","authors":["Qihan Huang","Haofei Zhang","Rong Wei","Yi Wang","Rui Tang","Mingli Song","Jie Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19339v1","updated":"2025-11-24T17:38:53Z","published":"2025-11-24T17:38:53Z","title":"POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse","summary":"In computer vision, machine unlearning aims to remove the influence of specific visual concepts or training images without retraining from scratch. Studies show that existing approaches often modify the classifier while leaving internal representations intact, resulting in incomplete forgetting. In this work, we extend the notion of unlearning to the representation level, deriving a three-term interplay between forgetting efficacy, retention fidelity, and class separation. Building on Neural Collapse theory, we show that the orthogonal projection of a simplex Equiangular Tight Frame (ETF) remains an ETF in a lower dimensional space, yielding a provably optimal forgetting operator. We further introduce the Representation Unlearning Score (RUS) to quantify representation-level forgetting and retention fidelity. Building on this, we introduce POUR (Provably Optimal Unlearning of Representations), a geometric projection method with closed-form (POUR-P) and a feature-level unlearning variant under a distillation scheme (POUR-D). Experiments on CIFAR-10/100 and PathMNIST demonstrate that POUR achieves effective unlearning while preserving retained knowledge, outperforming state-of-the-art unlearning methods on both classification-level and representation-level metrics.","authors":["Anjie Le","Can Peng","Yuyuan Liu","J. Alison Noble"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19326v1","updated":"2025-11-24T17:20:17Z","published":"2025-11-24T17:20:17Z","title":"MonoMSK: Monocular 3D Musculoskeletal Dynamics Estimation","summary":"Reconstructing biomechanically realistic 3D human motion - recovering both kinematics (motion) and kinetics (forces) - is a critical challenge. While marker-based systems are lab-bound and slow, popular monocular methods use oversimplified, anatomically inaccurate models (e.g., SMPL) and ignore physics, fundamentally limiting their biomechanical fidelity. In this work, we introduce MonoMSK, a hybrid framework that bridges data-driven learning and physics-based simulation for biomechanically realistic 3D human motion estimation from monocular video. MonoMSK jointly recovers both kinematics (motions) and kinetics (forces and torques) through an anatomically accurate musculoskeletal model. By integrating transformer-based inverse dynamics with differentiable forward kinematics and dynamics layers governed by ODE-based simulation, MonoMSK establishes a physics-regulated inverse-forward loop that enforces biomechanical causality and physical plausibility. A novel forward-inverse consistency loss further aligns motion reconstruction with the underlying kinetic reasoning. Experiments on BML-MoVi, BEDLAM, and OpenCap show that MonoMSK significantly outperforms state-of-the-art methods in kinematic accuracy, while for the first time enabling precise monocular kinetics estimation.","authors":["Farnoosh Koleini","Hongfei Xue","Ahmed Helmy","Pu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19320v1","updated":"2025-11-24T17:15:55Z","published":"2025-11-24T17:15:55Z","title":"SteadyDancer: Harmonized and Coherent Human Image Animation with First-Frame Preservation","summary":"Preserving first-frame identity while ensuring precise motion control is a fundamental challenge in human image animation. The Image-to-Motion Binding process of the dominant Reference-to-Video (R2V) paradigm overlooks critical spatio-temporal misalignments common in real-world applications, leading to failures such as identity drift and visual artifacts. We introduce SteadyDancer, an Image-to-Video (I2V) paradigm-based framework that achieves harmonized and coherent animation and is the first to ensure first-frame preservation robustly. Firstly, we propose a Condition-Reconciliation Mechanism to harmonize the two conflicting conditions, enabling precise control without sacrificing fidelity. Secondly, we design Synergistic Pose Modulation Modules to generate an adaptive and coherent pose representation that is highly compatible with the reference image. Finally, we employ a Staged Decoupled-Objective Training Pipeline that hierarchically optimizes the model for motion fidelity, visual quality, and temporal coherence. Experiments demonstrate that SteadyDancer achieves state-of-the-art performance in both appearance fidelity and motion control, while requiring significantly fewer training resources than comparable methods.","authors":["Jiaming Zhang","Shengming Cao","Rui Li","Xiaotong Zhao","Yutao Cui","Xinglin Hou","Gangshan Wu","Haolan Chen","Yu Xu","Limin Wang","Kai Ma"],"pdf_url":"","comment":"10 pages, with supp"},{"id":"http://arxiv.org/abs/2511.19319v1","updated":"2025-11-24T17:14:19Z","published":"2025-11-24T17:14:19Z","title":"SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis","summary":"Hand-Object Interaction (HOI) generation plays a critical role in advancing applications across animation and robotics. Current video-based methods are predominantly single-view, which impedes comprehensive 3D geometry perception and often results in geometric distortions or unrealistic motion patterns. While 3D HOI approaches can generate dynamically plausible motions, their dependence on high-quality 3D data captured in controlled laboratory settings severely limits their generalization to real-world scenarios. To overcome these limitations, we introduce SyncMV4D, the first model that jointly generates synchronized multi-view HOI videos and 4D motions by unifying visual prior, motion dynamics, and multi-view geometry. Our framework features two core innovations: (1) a Multi-view Joint Diffusion (MJD) model that co-generates HOI videos and intermediate motions, and (2) a Diffusion Points Aligner (DPA) that refines the coarse intermediate motion into globally aligned 4D metric point tracks. To tightly couple 2D appearance with 4D dynamics, we establish a closed-loop, mutually enhancing cycle. During the diffusion denoising process, the generated video conditions the refinement of the 4D motion, while the aligned 4D point tracks are reprojected to guide next-step joint generation. Experimentally, our method demonstrates superior performance to state-of-the-art alternatives in visual realism, motion plausibility, and multi-view consistency.","authors":["Lingwei Dang","Zonghan Li","Juntong Li","Hongwen Zhang","Liang An","Yebin Liu","Qingyao Wu"],"pdf_url":"","comment":"Project Page: https://droliven.github.io/SyncMV4D"},{"id":"http://arxiv.org/abs/2508.02995v3","updated":"2025-11-24T17:11:32Z","published":"2025-08-05T01:52:42Z","title":"The Geometry of Cortical Computation: Manifold Disentanglement and Predictive Dynamics in VCNet","summary":"Despite their success, modern convolutional neural networks (CNNs) exhibit fundamental limitations, including data inefficiency, poor out-of-distribution generalization, and vulnerability to adversarial perturbations. These shortcomings can be traced to a lack of inductive biases that reflect the inherent geometric structure of the visual world. The primate visual system, in contrast, demonstrates superior efficiency and robustness, suggesting that its architectural and computational principles,which evolved to internalize these structures,may offer a blueprint for more capable artificial vision. This paper introduces Visual Cortex Network (VCNet), a novel neural network architecture whose design is informed by the macro-scale organization of the primate visual cortex. VCNet is framed as a geometric framework that emulates key biological mechanisms, including hierarchical processing across distinct cortical areas, dual-stream information segregation for learning disentangled representations, and top-down predictive feedback for representation refinement. We interpret these mechanisms through the lens of geometry and dynamical systems, positing that they guide the learning of structured, low-dimensional neural manifolds. We evaluate VCNet on two specialized benchmarks: the Spots-10 animal pattern dataset, which probes sensitivity to natural textures, and a light field image classification task, which requires processing higher-dimensional visual data. Our results show that VCNet achieves state-of-the-art accuracy of 92.1\\% on Spots-10 and 74.4\\% on the light field dataset, surpassing contemporary models of comparable size. This work demonstrates that integrating high-level neuroscientific principles, viewed through a geometric lens, can lead to more efficient and robust models, providing a promising direction for addressing long-standing challenges in machine learning.","authors":["Brennen A. Hill","Zhang Xinyu","Timothy Putra Prasetio"],"pdf_url":"","comment":"Published in the proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Symmetry and Geometry in Neural Representations (NeurReps). Additionally accepted for presentation in NeurIPS 2025 Workshop: Interpreting Cognition in Deep Learning Models (CogInterp)"},{"id":"http://arxiv.org/abs/2511.19316v1","updated":"2025-11-24T17:11:00Z","published":"2025-11-24T17:11:00Z","title":"Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach","summary":"Recent fine-tuning techniques for diffusion models enable them to reproduce specific image sets, such as particular faces or artistic styles, but also introduce copyright and security risks. Dataset watermarking has been proposed to ensure traceability by embedding imperceptible watermarks into training images, which remain detectable in outputs even after fine-tuning. However, current methods lack a unified evaluation framework. To address this, this paper establishes a general threat model and introduces a comprehensive evaluation framework encompassing Universality, Transmissibility, and Robustness. Experiments show that existing methods perform well in universality and transmissibility, and exhibit some robustness against common image processing operations, yet still fall short under real-world threat scenarios. To reveal these vulnerabilities, the paper further proposes a practical watermark removal method that fully eliminates dataset watermarks without affecting fine-tuning, highlighting a key challenge for future research.","authors":["Xincheng Wang","Hanchi Sun","Wenjun Sun","Kejun Xue","Wangqiu Zhou","Jianbo Zhang","Wei Sun","Dandan Zhu","Xiongkuo Min","Jun Jia","Zhijun Fang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.16621v2","updated":"2025-11-24T17:08:56Z","published":"2025-07-22T14:15:28Z","title":"A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System","summary":"Extrinsic Calibration represents the cornerstone of autonomous driving. Its accuracy plays a crucial role in the perception pipeline, as any errors can have implications for the safety of the vehicle. Modern sensor systems collect different types of data from the environment, making it harder to align the data. To this end, we propose a target-based extrinsic calibration system tailored for a multi-LiDAR and multi-camera sensor suite. This system enables cross-calibration between LiDARs and cameras with limited prior knowledge using a custom ChArUco board and a tailored nonlinear optimization method. We test the system with real-world data gathered in a warehouse. Results demonstrated the effectiveness of the proposed method, highlighting the feasibility of a unique pipeline tailored for various types of sensors.","authors":["Lorenzo Gentilini","Pierpaolo Serio","Valentina Donzella","Lorenzo Pollini"],"pdf_url":"","comment":"RiTA 2025 Accepted, 13 Pages, 6 Figures and 2 Tables"},{"id":"http://arxiv.org/abs/2511.15622v2","updated":"2025-11-24T17:02:04Z","published":"2025-11-19T17:07:08Z","title":"The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification","summary":"Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at https://www.conservationxlabs.com/sa-fari.","authors":["Dante Francisco Wasmuht","Otto Brookes","Maximillian Schall","Pablo Palencia","Chris Beirne","Tilo Burghardt","Majid Mirmehdi","Hjalmar Kühl","Mimi Arandjelovic","Sam Pottie","Peter Bermant","Brandon Asheim","Yi Jin Toh","Adam Elzinga","Jason Holmberg","Andrew Whitworth","Eleanor Flatt","Laura Gustafson","Chaitanya Ryali","Yuan-Ting Hu","Baishan Guo","Andrew Westbury","Kate Saenko","Didac Suris"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19306v1","updated":"2025-11-24T16:58:23Z","published":"2025-11-24T16:58:23Z","title":"Dual-Granularity Semantic Prompting for Language Guidance Infrared Small Target Detection","summary":"Infrared small target detection remains challenging due to limited feature representation and severe background interference, resulting in sub-optimal performance. While recent CLIP-inspired methods attempt to leverage textual guidance for detection, they are hindered by inaccurate text descriptions and reliance on manual annotations. To overcome these limitations, we propose DGSPNet, an end-to-end language prompt-driven framework. Our approach integrates dual-granularity semantic prompts: coarse-grained textual priors (e.g., 'infrared image', 'small target') and fine-grained personalized semantic descriptions derived through visual-to-textual mapping within the image space. This design not only facilitates learning fine-grained semantic information but also can inherently leverage language prompts during inference without relying on any annotation requirements. By fully leveraging the precision and conciseness of text descriptions, we further introduce a text-guide channel attention (TGCA) mechanism and text-guide spatial attention (TGSA) mechanism that enhances the model's sensitivity to potential targets across both low- and high-level feature spaces. Extensive experiments demonstrate that our method significantly improves detection accuracy and achieves state-of-the-art performance on three benchmark datasets.","authors":["Zixuan Wang","Haoran Sun","Jiaming Lu","Wenxuan Wang","Zhongling Huang","Dingwen Zhang","Xuelin Qian","Junwei Han"],"pdf_url":"","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.19301v1","updated":"2025-11-24T16:49:20Z","published":"2025-11-24T16:49:20Z","title":"IDEAL-M3D: Instance Diversity-Enriched Active Learning for Monocular 3D Detection","summary":"Monocular 3D detection relies on just a single camera and is therefore easy to deploy. Yet, achieving reliable 3D understanding from monocular images requires substantial annotation, and 3D labels are especially costly. To maximize performance under constrained labeling budgets, it is essential to prioritize annotating samples expected to deliver the largest performance gains. This prioritization is the focus of active learning. Curiously, we observed two significant limitations in active learning algorithms for 3D monocular object detection. First, previous approaches select entire images, which is inefficient, as non-informative instances contained in the same image also need to be labeled. Secondly, existing methods rely on uncertainty-based selection, which in monocular 3D object detection creates a bias toward depth ambiguity. Consequently, distant objects are selected, while nearby objects are overlooked.\n  To address these limitations, we propose IDEAL-M3D, the first instance-level pipeline for monocular 3D detection. For the first time, we demonstrate that an explicitly diverse, fast-to-train ensemble improves diversity-driven active learning for monocular 3D. We induce diversity with heterogeneous backbones and task-agnostic features, loss weight perturbation, and time-dependent bagging. IDEAL-M3D shows superior performance and significant resource savings: with just 60% of the annotations, we achieve similar or better AP3D on KITTI validation and test set results compared to training the same detector on the whole dataset.","authors":["Johannes Meier","Florian Günther","Riccardo Marin","Oussema Dhaouadi","Jacques Kaiser","Daniel Cremers"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.27280v2","updated":"2025-11-24T16:40:06Z","published":"2025-10-31T08:41:13Z","title":"FOCUS: Efficient Keyframe Selection for Long Video Understanding","summary":"Multimodal large language models (MLLMs) represent images and video frames as visual tokens. Scaling from single images to hour-long videos, however, inflates the token budget far beyond practical limits. Popular pipelines therefore either uniformly subsample or apply keyframe selection with retrieval-style scoring using smaller vision-language models. However, these keyframe selection methods still rely on pre-filtering before selection to reduce the inference cost and can miss the most informative moments. We propose FOCUS, Frame-Optimistic Confidence Upper-bound Selection, a training-free, model-agnostic keyframe selection module that selects query-relevant frames under a strict token budget. FOCUS formulates keyframe selection as a combinatorial pure-exploration (CPE) problem in multi-armed bandits: it treats short temporal clips as arms, and uses empirical means and Bernstein confidence radius to identify informative regions while preserving exploration of uncertain areas. The resulting two-stage exploration-exploitation procedure reduces from a sequential policy with theoretical guarantees, first identifying high-value temporal regions, then selecting top-scoring frames within each region. On two long-video question-answering benchmarks, FOCUS delivers substantial accuracy improvements while processing less than 2% of video frames. For videos longer than 20 minutes, it achieves an 11.9% gain in accuracy on LongVideoBench, demonstrating its effectiveness as a keyframe selection method and providing a simple and general solution for scalable long-video understanding with MLLMs. Code is available at https://github.com/NUS-HPC-AI-Lab/FOCUS.","authors":["Zirui Zhu","Hailun Xu","Yang Luo","Yong Liu","Kanchan Sarkar","Zhenheng Yang","Yang You"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19294v1","updated":"2025-11-24T16:39:13Z","published":"2025-11-24T16:39:13Z","title":"DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting","summary":"This paper addresses the limitations of existing 3D Gaussian Splatting (3DGS) methods, particularly their reliance on adaptive density control, which can lead to floating artifacts and inefficient resource usage. We propose a novel densify beforehand approach that enhances the initialization of 3D scenes by combining sparse LiDAR data with monocular depth estimation from corresponding RGB images. Our ROI-aware sampling scheme prioritizes semantically and geometrically important regions, yielding a dense point cloud that improves visual fidelity and computational efficiency. This densify beforehand approach bypasses the adaptive density control that may introduce redundant Gaussians in the original pipeline, allowing the optimization to focus on the other attributes of 3D Gaussian primitives, reducing overlap while enhancing visual quality. Our method achieves comparable results to state-of-the-art techniques while significantly lowering resource consumption and training time. We validate our approach through extensive comparisons and ablation studies on four newly collected datasets, showcasing its effectiveness in preserving regions of interest in complex scenes.","authors":["Phurtivilai Patt","Leyang Huang","Yinqiang Zhang","Yang Lei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19278v1","updated":"2025-11-24T16:28:49Z","published":"2025-11-24T16:28:49Z","title":"ReMatch: Boosting Representation through Matching for Multimodal Retrieval","summary":"We present ReMatch, a framework that leverages the generative strength of MLLMs for multimodal retrieval. Previous approaches treated an MLLM as a simple encoder, ignoring its generative nature, and under-utilising its compositional reasoning and world knowledge. We instead train the embedding MLLM end-to-end with a chat-style generative matching stage. The matching stage uses the same MLLM to autoregressively decide relevance from multi-view inputs, including both raw data and its own projected embeddings for each query and document. It provides instance-wise discrimination supervision that complements a standard contrastive loss, offering stronger gradients on hard negatives and preserving the compositional strengths of the original MLLM. To obtain semantically richer multimodal embeddings, we use multiple learnable tokens to augment each input, generating fine-grained contextual, mutually orthogonal embeddings with low inference cost. Leveraging our established high-performance baseline,we assemble the ideas mentioned above into a powerful training recipe and achieve a new state-of-the-art on the Massive Multimodal Embedding Benchmark (MMEB). Our experiments show particularly strong zero-shot generalization results on five datasets, highlighting the robustness and transferability of ReMatch.","authors":["Qianying Liu","Xiao Liang","Zhiqiang Zhang","Yibo Chen","Xu Tang","Zhongfei Qing","Fengfan Zhou","Yao Hu","Paul Henderson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.01421v3","updated":"2025-11-24T16:26:00Z","published":"2025-09-01T12:27:04Z","title":"InfoScale: Unleashing Training-free Variable-scaled Image Generation via Effective Utilization of Information","summary":"Diffusion models (DMs) have become dominant in visual generation but suffer performance drop when tested on resolutions that differ from the training scale, whether lower or higher. In fact, the key challenge in generating variable-scale images lies in the differing amounts of information across resolutions, which requires information conversion procedures to be varied for generating variable-scaled images. In this paper, we investigate the issues of three critical aspects in DMs for a unified analysis in variable-scaled generation: dilated convolution, attention mechanisms, and initial noise. Specifically, 1) dilated convolution in DMs for the higher-resolution generation loses high-frequency information. 2) Attention for variable-scaled image generation struggles to adjust the information aggregation adaptively. 3) The spatial distribution of information in the initial noise is misaligned with variable-scaled image. To solve the above problems, we propose \\textbf{InfoScale}, an information-centric framework for variable-scaled image generation by effectively utilizing information from three aspects correspondingly. For information loss in 1), we introduce Progressive Frequency Compensation module to compensate for high-frequency information lost by dilated convolution in higher-resolution generation. For information aggregation inflexibility in 2), we introduce Adaptive Information Aggregation module to adaptively aggregate information in lower-resolution generation and achieve an effective balance between local and global information in higher-resolution generation. For information distribution misalignment in 3), we design Noise Adaptation module to re-distribute information in initial noise for variable-scaled generation. Our method is plug-and-play for DMs and extensive experiments demonstrate the effectiveness in variable-scaled image generation.","authors":["Guohui Zhang","Jiangtong Tan","Linjiang Huang","Zhonghang Yuan","Mingde Yao","Jie Huang","Feng Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19274v1","updated":"2025-11-24T16:25:34Z","published":"2025-11-24T16:25:34Z","title":"Diffusion Reconstruction-based Data Likelihood Estimation for Core-Set Selection","summary":"Existing core-set selection methods predominantly rely on heuristic scoring signals such as training dynamics or model uncertainty, lacking explicit modeling of data likelihood. This omission may hinder the constructed subset from capturing subtle yet critical distributional structures that underpin effective model training. In this work, we propose a novel, theoretically grounded approach that leverages diffusion models to estimate data likelihood via reconstruction deviation induced by partial reverse denoising. Specifically, we establish a formal connection between reconstruction error and data likelihood, grounded in the Evidence Lower Bound (ELBO) of Markovian diffusion processes, thereby enabling a principled, distribution-aware scoring criterion for data selection. Complementarily, we introduce an efficient information-theoretic method to identify the optimal reconstruction timestep, ensuring that the deviation provides a reliable signal indicative of underlying data likelihood. Extensive experiments on ImageNet demonstrate that reconstruction deviation offers an effective scoring criterion, consistently outperforming existing baselines across selection ratios, and closely matching full-data training using only 50% of the data. Further analysis shows that the likelihood-informed nature of our score reveals informative insights in data selection, shedding light on the interplay between data distributional characteristics and model learning preferences.","authors":["Mingyang Chen","Jiawei Du","Bo Huang","Yi Wang","Xiaobo Zhang","Wei Wang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.19268v1","updated":"2025-11-24T16:20:11Z","published":"2025-11-24T16:20:11Z","title":"BideDPO: Conditional Image Generation with Simultaneous Text and Condition Alignment","summary":"Conditional image generation enhances text-to-image synthesis with structural, spatial, or stylistic priors, but current methods face challenges in handling conflicts between sources. These include 1) input-level conflicts, where the conditioning image contradicts the text prompt, and 2) model-bias conflicts, where generative biases disrupt alignment even when conditions match the text. Addressing these conflicts requires nuanced solutions, which standard supervised fine-tuning struggles to provide. Preference-based optimization techniques like Direct Preference Optimization (DPO) show promise but are limited by gradient entanglement between text and condition signals and lack disentangled training data for multi-constraint tasks. To overcome this, we propose a bidirectionally decoupled DPO framework (BideDPO). Our method creates two disentangled preference pairs-one for the condition and one for the text-to reduce gradient entanglement. The influence of pairs is managed using an Adaptive Loss Balancing strategy for balanced optimization. We introduce an automated data pipeline to sample model outputs and generate conflict-aware data. This process is embedded in an iterative optimization strategy that refines both the model and the data. We construct a DualAlign benchmark to evaluate conflict resolution between text and condition. Experiments show BideDPO significantly improves text success rates (e.g., +35%) and condition adherence. We also validate our approach using the COCO dataset. Project Pages: https://limuloo.github.io/BideDPO/.","authors":["Dewei Zhou","Mingwei Li","Zongxin Yang","Yu Lu","Yunqiu Xu","Zhizhong Wang","Zeyi Huang","Yi Yang"],"pdf_url":"","comment":"29 pages"},{"id":"http://arxiv.org/abs/2412.01558v2","updated":"2025-11-24T16:17:57Z","published":"2024-12-02T14:45:53Z","title":"VideoLights: Feature Refinement and Cross-Task Alignment Transformer for Joint Video Highlight Detection and Moment Retrieval","summary":"Prevailing joint prediction transformers for Video Highlight Detection and Moment Retrieval (HD/MR) exhibit deficiencies in handling cross-task dynamics, achieving robust video-text alignment, and utilizing effective attention mechanisms, with the potential of Large Language/Vision-Language Models (LLMs/LVLMs) being largely untapped. This paper introduces VideoLights, a novel HD/MR framework addressing these limitations by incorporating: (i) Convolutional Projection and Feature Refinement modules with an alignment loss for enhanced video-text feature congruity; (ii) a Bi-Directional Cross-Modal Fusion network for strongly coupled query-aware representations; (iii) a Uni-directional joint-task feedback mechanism for synergistic task improvement; (iv) hard positive/negative losses for adaptive learning; and (v) the leveraging of LVLMs (e.g., BLIP-2) for superior multimodal feature integration and intelligent pre-training with synthetic data. Comprehensive evaluations on QVHighlights, TVSum, and Charades-STA benchmarks demonstrate that VideoLights significantly surpasses existing baselines, establishing new state-of-the-art performances. Codes and model checkpoints are available at https://github.com/dpaul06/VideoLights .","authors":["Dhiman Paul","Md Rizwan Parvez","Nabeel Mohammed","Shafin Rahman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19261v1","updated":"2025-11-24T16:13:26Z","published":"2025-11-24T16:13:26Z","title":"LAST: LeArning to Think in Space and Time for Generalist Vision-Language Models","summary":"Humans can perceive and understand 3D space and long videos from sequential visual observations. But do vision-language models (VLMs) can? Recent work demonstrates that even state-of-the-art VLMs still struggle to understand 3D space and long videos, although they are powerful in typical vision-language tasks. Current methods often rely on specialized architectural designs to improve performance for 3D tasks and video understanding tasks separately. In contrast, we propose LAST, short for LeArn to Think in Space and Time, to jointly improve 3D spatial and long video understanding for general VLMs with only a set of 2D images as inputs. LAST makes VLMs think in space and time rather than only with text before giving the final answer, building visual thinking trajectories in 3D space and temporal dimension. We demonstrate the effectiveness of LAST in two scenarios: 1) zero-shot, where we directly prompt proprietary models; and 2) fine-tuning general VLMs with data that include thinking trajectories in 3D space and time. We show that LAST brings substantial gains in various benchmarks, including 3 spatial understanding, 4 video understanding, and 3 image understanding tasks. Notably, 15.8% gains on EgoSchema with GPT-4o in a zero-shot manner and 8.3 gains on VSI-Bench compared with Qwen2.5-VL-7B.","authors":["Shuai Wang","Daoan Zhang","Tianyi Bai","Shitong Shao","Jiebo Luo","Jiaheng Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.05813v2","updated":"2025-11-24T16:09:54Z","published":"2025-08-07T19:35:01Z","title":"Optimization-Free Style Transfer for 3D Gaussian Splats","summary":"The task of style transfer for 3D Gaussian splats has been explored in many previous works, but these require reconstructing or fine-tuning the splat while incorporating style information or optimizing a feature extraction network on the splat representation. We propose a reconstruction- and optimization-free approach to stylizing 3D Gaussian splats, allowing for direct stylization on a .ply or .splat file without requiring the original camera views. This is done by generating a graph structure across the implicit surface of the splat representation. A feed-forward, surface-based stylization method is then used and interpolated back to the individual splats in the scene. This also allows for fast stylization of splats with no additional training, achieving speeds under 2 minutes even on CPU-based consumer hardware. We demonstrate the quality results this approach achieves and compare to other 3D Gaussian splat style transfer methods. Code is publicly available at https://github.com/davidmhart/FastSplatStyler.","authors":["Raphael Du Sablon","David Hart"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19254v1","updated":"2025-11-24T16:05:40Z","published":"2025-11-24T16:05:40Z","title":"Adversarial Patch Attacks on Vision-Based Cargo Occupancy Estimation via Differentiable 3D Simulation","summary":"Computer vision systems are increasingly adopted in modern logistics operations, including the estimation of trailer occupancy for planning, routing, and billing. Although effective, such systems may be vulnerable to physical adversarial attacks, particularly adversarial patches that can be printed and placed on interior surfaces. In this work, we study the feasibility of such attacks on a convolutional cargo-occupancy classifier using fully simulated 3D environments. Using Mitsuba 3 for differentiable rendering, we optimize patch textures across variations in geometry, lighting, and viewpoint, and compare their effectiveness to a 2D compositing baseline. Our experiments demonstrate that 3D-optimized patches achieve high attack success rates, especially in a denial-of-service scenario (empty to full), where success reaches 84.94 percent. Concealment attacks (full to empty) prove more challenging but still reach 30.32 percent. We analyze the factors influencing attack success, discuss implications for the security of automated logistics pipelines, and highlight directions for strengthening physical robustness. To our knowledge, this is the first study to investigate adversarial patch attacks for cargo-occupancy estimation in physically realistic, fully simulated 3D scenes.","authors":["Mohamed Rissal Hedna","Sesugh Samuel Nder"],"pdf_url":"","comment":"9 pages, 5 figures, 1 algorithm"},{"id":"http://arxiv.org/abs/2511.19248v1","updated":"2025-11-24T16:02:01Z","published":"2025-11-24T16:02:01Z","title":"FedPoisonTTP: A Threat Model and Poisoning Attack for Federated Test-Time Personalization","summary":"Test-time personalization in federated learning enables models at clients to adjust online to local domain shifts, enhancing robustness and personalization in deployment. Yet, existing federated learning work largely overlooks the security risks that arise when local adaptation occurs at test time. Heterogeneous domain arrivals, diverse adaptation algorithms, and limited cross-client visibility create vulnerabilities where compromised participants can craft poisoned inputs and submit adversarial updates that undermine both global and per-client performance. To address this threat, we introduce FedPoisonTTP, a realistic grey-box attack framework that explores test-time data poisoning in the federated adaptation setting. FedPoisonTTP distills a surrogate model from adversarial queries, synthesizes in-distribution poisons using feature-consistency, and optimizes attack objectives to generate high-entropy or class-confident poisons that evade common adaptation filters. These poisons are injected during local adaptation and spread through collaborative updates, leading to broad degradation. Extensive experiments on corrupted vision benchmarks show that compromised participants can substantially diminish overall test-time performance.","authors":["Md Akil Raihan Iftee","Syed Md. Ahnaf Hasan","Amin Ahsan Ali","AKM Mahbubur Rahman","Sajib Mistry","Aneesh Krishna"],"pdf_url":"","comment":"13 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.15349v2","updated":"2025-11-24T16:01:24Z","published":"2024-11-22T21:17:49Z","title":"Zero-Shot Coreset Selection via Iterative Subspace Sampling","summary":"Deep learning increasingly relies on massive data with substantial storage, annotation, and training costs. To reduce costs, coreset selection finds a representative subset of data to train models while ideally performing on par with the full data training. To maximize performance, current state-of-the-art coreset methods select data using dataset-specific ground truth labels and training. However, these methodological requirements prevent selection at scale on real-world, unlabeled data. To that end, this paper addresses the selection of coresets that achieve state-of-the-art performance but without using any labels or training on candidate data. Instead, our solution, Zero-Shot Coreset Selection via Iterative Subspace Sampling (ZCore), uses previously-trained foundation models to generate zero-shot, high-dimensional embedding spaces to interpret unlabeled data. ZCore then iteratively quantifies the relative value of all candidate data based on coverage and redundancy in numerous subspace distributions. Finally, ZCore selects a coreset sized for any data budget to train downstream models. We evaluate ZCore on four datasets and outperform several state-of-the-art label-based methods, especially at low data rates that provide the most substantial cost reduction. On ImageNet, ZCore selections for 10% training data achieve a downstream validation accuracy of 53.99%, which outperforms prior label-based methods and removes annotation and training costs for 1.15 million images. Our paper's code is publicly available at https://github.com/voxel51/zcore.","authors":["Brent A. Griffin","Jacob Marks","Jason J. Corso"],"pdf_url":"","comment":"WACV 2026"},{"id":"http://arxiv.org/abs/2511.15986v2","updated":"2025-11-24T15:59:06Z","published":"2025-11-20T02:38:00Z","title":"Fairness in Multi-modal Medical Diagnosis with Demonstration Selection","summary":"Multimodal large language models (MLLMs) have shown strong potential for medical image reasoning, yet fairness across demographic groups remains a major concern. Existing debiasing methods often rely on large labeled datasets or fine-tuning, which are impractical for foundation-scale models. We explore In-Context Learning (ICL) as a lightweight, tuning-free alternative for improving fairness. Through systematic analysis, we find that conventional demonstration selection (DS) strategies fail to ensure fairness due to demographic imbalance in selected exemplars. To address this, we propose Fairness-Aware Demonstration Selection (FADS), which builds demographically balanced and semantically relevant demonstrations via clustering-based sampling. Experiments on multiple medical imaging benchmarks show that FADS consistently reduces gender-, race-, and ethnicity-related disparities while maintaining strong accuracy, offering an efficient and scalable path toward fair medical image reasoning. These results highlight the potential of fairness-aware in-context learning as a scalable and data-efficient solution for equitable medical image reasoning.","authors":["Dawei Li","Zijian Gu","Peng Wang","Chuhan Song","Zhen Tan","Mohan Zhang","Tianlong Chen","Yu Tian","Song Wang"],"pdf_url":"","comment":"10 pages (including 2 pages of references), 4 figures. This work explores fairness in multi-modal medical image reasoning using in-context learning"},{"id":"http://arxiv.org/abs/2511.13533v2","updated":"2025-11-24T15:58:49Z","published":"2025-11-17T16:06:37Z","title":"Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems","summary":"In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data. Code is available at https://github.com/jwen307/multi_target_minimax.","authors":["Jeffrey Wen","Rizwan Ahmad","Philip Schniter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2201.00708v2","updated":"2025-11-24T15:58:39Z","published":"2022-01-03T15:21:24Z","title":"Multiview point cloud registration with anisotropic and space-varying localization noise","summary":"In this paper, we address the problem of registering multiple point clouds corrupted with high anisotropic localization noise. Our approach follows the widely used framework of Gaussian mixture model (GMM) reconstruction with an expectation-maximization (EM) algorithm. Existing methods are based on an implicit assumption of space-invariant isotropic Gaussian noise. However, this assumption is violated in practice in applications such as single molecule localization microscopy (SMLM). To address this issue, we propose to introduce an explicit localization noise model that decouples shape modeling with the GMM from noise handling. We design a stochastic EM algorithm that considers noise-free data as a latent variable, with closed-form solutions at each EM step. The first advantage of our approach is to handle space-variant and anisotropic Gaussian noise with arbitrary covariances. The second advantage is to leverage the explicit noise model to impose prior knowledge about the noise that may be available from physical sensors. We show on various simulated data that our noise handling strategy improves significantly the robustness to high levels of anisotropic noise. We also demonstrate the performance of our method on real SMLM data.","authors":["Denis Fortun","Etienne Baudrier","Fabian Zwettler","Markus Sauer","Sylvain Faisan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19235v1","updated":"2025-11-24T15:48:08Z","published":"2025-11-24T15:48:08Z","title":"IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes","summary":"Reconstructing dynamic driving scenes is essential for developing autonomous systems through sensor-realistic simulation. Although recent methods achieve high-fidelity reconstructions, they either rely on costly human annotations for object trajectories or use time-varying representations without explicit object-level decomposition, leading to intertwined static and dynamic elements that hinder scene separation. We present IDSplat, a self-supervised 3D Gaussian Splatting framework that reconstructs dynamic scenes with explicit instance decomposition and learnable motion trajectories, without requiring human annotations. Our key insight is to model dynamic objects as coherent instances undergoing rigid transformations, rather than unstructured time-varying primitives. For instance decomposition, we employ zero-shot, language-grounded video tracking anchored to 3D using lidar, and estimate consistent poses via feature correspondences. We introduce a coordinated-turn smoothing scheme to obtain temporally and physically consistent motion trajectories, mitigating pose misalignments and tracking failures, followed by joint optimization of object poses and Gaussian parameters. Experiments on the Waymo Open Dataset demonstrate that our method achieves competitive reconstruction quality while maintaining instance-level decomposition and generalizes across diverse sequences and view densities without retraining, making it practical for large-scale autonomous driving applications. Code will be released.","authors":["Carl Lindström","Mahan Rafidashti","Maryam Fatemi","Lars Hammarstrand","Martin R. Oswald","Lennart Svensson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.13292v2","updated":"2025-11-24T15:46:09Z","published":"2025-06-16T09:33:37Z","title":"Automatic Multi-View X-Ray/CT Registration Using Bone Substructure Contours","summary":"Purpose: Accurate intraoperative X-ray/CT registration is essential for surgical navigation in orthopedic procedures. However, existing methods struggle with consistently achieving sub-millimeter accuracy, robustness under broad initial pose estimates or need manual key-point annotations. This work aims to address these challenges by proposing a novel multi-view X-ray/CT registration method for intraoperative bone registration. Methods: The proposed registration method consists of a multi-view, contour-based iterative closest point (ICP) optimization. Unlike previous methods, which attempt to match bone contours across the entire silhouette in both imaging modalities, we focus on matching specific subcategories of contours corresponding to bone substructures. This leads to reduced ambiguity in the ICP matches, resulting in a more robust and accurate registration solution. This approach requires only two X-ray images and operates fully automatically. Additionally, we contribute a dataset of 5 cadaveric specimens, including real X-ray images, X-ray image poses and the corresponding CT scans. Results: The proposed registration method is evaluated on real X-ray images using mean reprojection error (mRPD). The method consistently achieves sub-millimeter accuracy with a mRPD 0.67mm compared to 5.35mm by a commercial solution requiring manual intervention. Furthermore, the method offers improved practical applicability, being fully automatic. Conclusion: Our method offers a practical, accurate, and efficient solution for multi-view X-ray/CT registration in orthopedic surgeries, which can be easily combined with tracking systems. By improving registration accuracy and minimizing manual intervention, it enhances intraoperative navigation, contributing to more accurate and effective surgical outcomes in computer-assisted surgery (CAS).","authors":["Roman Flepp","Leon Nissen","Bastian Sigrist","Arend Nieuwland","Nicola Cavalcanti","Philipp Fürnstahl","Thomas Dreher","Lilian Calvet"],"pdf_url":"","comment":"This paper was accepted to IPCAI 2025. The Project Webpage is: https://rflepp.github.io/BoneSubstructureContours2D3DRegistration/"},{"id":"http://arxiv.org/abs/2511.19229v1","updated":"2025-11-24T15:42:23Z","published":"2025-11-24T15:42:23Z","title":"Learning Plug-and-play Memory for Guiding Video Diffusion Models","summary":"Diffusion Transformer(DiT) based video generation models have recently achieved impressive visual quality and temporal coherence, but they still frequently violate basic physical laws and commonsense dynamics, revealing a lack of explicit world knowledge. In this work, we explore how to equip them with a plug-and-play memory that injects useful world knowledge. Motivated by in-context memory in Transformer-based LLMs, we conduct empirical studies to show that DiT can be steered via interventions on its hidden states, and simple low-pass and high-pass filters in the embedding space naturally disentangle low-level appearance and high-level physical/semantic cues, enabling targeted guidance. Building on these observations, we propose a learnable memory encoder DiT-Mem, composed of stacked 3D CNNs, low-/high-pass filters, and self-attention layers. The encoder maps reference videos into a compact set of memory tokens, which are concatenated as the memory within the DiT self-attention layers. During training, we keep the diffusion backbone frozen, and only optimize the memory encoder. It yields a rather efficient training process on few training parameters (150M) and 10K data samples, and enables plug-and-play usage at inference time. Extensive experiments on state-of-the-art models demonstrate the effectiveness of our method in improving physical rule following and video fidelity. Our code and data are publicly released here: https://thrcle421.github.io/DiT-Mem-Web/.","authors":["Selena Song","Ziming Xu","Zijun Zhang","Kun Zhou","Jiaxian Guo","Lianhui Qin","Biwei Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19221v1","updated":"2025-11-24T15:28:25Z","published":"2025-11-24T15:28:25Z","title":"Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving","summary":"Autonomous driving heavily relies on accurate and robust spatial perception. Many failures arise from inaccuracies and instability, especially in long-tail scenarios and complex interactions. However, current vision-language models are weak at spatial grounding and understanding, and VLA systems built on them therefore show limited perception and localization ability. To address these challenges, we introduce Percept-WAM, a perception-enhanced World-Awareness-Action Model that is the first to implicitly integrate 2D/3D scene understanding abilities within a single vision-language model (VLM). Instead of relying on QA-style spatial reasoning, Percept-WAM unifies 2D/3D perception tasks into World-PV and World-BEV tokens, which encode both spatial coordinates and confidence. We propose a grid-conditioned prediction mechanism for dense object perception, incorporating IoU-aware scoring and parallel autoregressive decoding, improving stability in long-tail, far-range, and small-object scenarios. Additionally, Percept-WAM leverages pretrained VLM parameters to retain general intelligence (e.g., logical reasoning) and can output perception results and trajectory control outputs directly. Experiments show that Percept-WAM matches or surpasses classical detectors and segmenters on downstream perception benchmarks, achieving 51.7/58.9 mAP on COCO 2D detection and nuScenes BEV 3D detection. When integrated with trajectory decoders, it further improves planning performance on nuScenes and NAVSIM, e.g., surpassing DiffusionDrive by 2.1 in PMDS on NAVSIM. Qualitative results further highlight its strong open-vocabulary and long-tail generalization.","authors":["Jianhua Han","Meng Tian","Jiangtong Zhu","Fan He","Huixin Zhang","Sitong Guo","Dechang Zhu","Hao Tang","Pei Xu","Yuze Guo","Minzhe Niu","Haojie Zhu","Qichao Dong","Xuechao Yan","Siyuan Dong","Lu Hou","Qingqiu Huang","Xiaosong Jia","Hang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19220v1","updated":"2025-11-24T15:26:58Z","published":"2025-11-24T15:26:58Z","title":"Are Large Vision Language Models Truly Grounded in Medical Images? Evidence from Italian Clinical Visual Question Answering","summary":"Large vision language models (VLMs) have achieved impressive performance on medical visual question answering benchmarks, yet their reliance on visual information remains unclear. We investigate whether frontier VLMs demonstrate genuine visual grounding when answering Italian medical questions by testing four state-of-the-art models: Claude Sonnet 4.5, GPT-4o, GPT-5-mini, and Gemini 2.0 flash exp. Using 60 questions from the EuropeMedQA Italian dataset that explicitly require image interpretation, we substitute correct medical images with blank placeholders to test whether models truly integrate visual and textual information. Our results reveal striking variability in visual dependency: GPT-4o shows the strongest visual grounding with a 27.9pp accuracy drop (83.2% [74.6%, 91.7%] to 55.3% [44.1%, 66.6%]), while GPT-5-mini, Gemini, and Claude maintain high accuracy with modest drops of 8.5pp, 2.4pp, and 5.6pp respectively. Analysis of model-generated reasoning reveals confident explanations for fabricated visual interpretations across all models, suggesting varying degrees of reliance on textual shortcuts versus genuine visual analysis. These findings highlight critical differences in model robustness and the need for rigorous evaluation before clinical deployment.","authors":["Federico Felizzi","Olivia Riccomi","Michele Ferramola","Francesco Andrea Causio","Manuel Del Medico","Vittorio De Vita","Lorenzo De Mori","Alessandra Piscitelli Pietro Eric Risuleo","Bianca Destro Castaniti","Antonio Cristiano Alessia Longo","Luigi De Angelis","Mariapia Vassalli","Marcello Di Pumpo"],"pdf_url":"","comment":"Accepted at the Workshop on Multimodal Representation Learning for Healthcare (MMRL4H), EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.19217v1","updated":"2025-11-24T15:23:36Z","published":"2025-11-24T15:23:36Z","title":"ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment","summary":"Text-to-motion generation, which synthesizes 3D human motions from text inputs, holds immense potential for applications in gaming, film, and robotics. Recently, diffusion-based methods have been shown to generate more diversity and realistic motion. However, there exists a misalignment between text and motion distributions in diffusion models, which leads to semantically inconsistent or low-quality motions. To address this limitation, we propose Reward-guided sampling Alignment (ReAlign), comprising a step-aware reward model to assess alignment quality during the denoising sampling and a reward-guided strategy that directs the diffusion process toward an optimally aligned distribution. This reward model integrates step-aware tokens and combines a text-aligned module for semantic consistency and a motion-aligned module for realism, refining noisy motions at each timestep to balance probability density and alignment. Extensive experiments of both motion generation and retrieval tasks demonstrate that our approach significantly improves text-motion alignment and motion quality compared to existing state-of-the-art methods.","authors":["Wanjiang Weng","Xiaofeng Tan","Junbo Wang","Guo-Sen Xie","Pan Zhou","Hongsong Wang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2505.21698v2","updated":"2025-11-24T15:19:38Z","published":"2025-05-27T19:37:51Z","title":"MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis in Chest X-Ray","summary":"Recent vision-language foundation models deliver state-of-the-art results in natural image classification, but falter in medical images due to pronounced domain shifts. Training a medical foundation model also requires substantial resources, including extensive annotated data and high computational capacity. To bridge this gap with minimal overhead, we introduce MedBridge, a lightweight multimodal adaptation framework that flexibly re-purposes arbitrary pre-trained foundation VLMs for medical image diagnosis. MedBridge comprises three novel core components. First, a Focal Sampling module that subsamples and extracts high-resolution local regions to capture subtle pathological features, compensating for the limited input resolution of foundation VLMs. Second, a Query-Encoder model with a small set of learnable queries to align the feature maps of frozen VLMs with medical semantics, without requiring retraining of the backbone layers. Third, a Mixture of Experts mechanism, driven by learnable queries, harnesses the complementary strength of various VLMs to maximize diagnostic performance. We evaluate MedBridge on five chest radiograph benchmarks in three key adaptation tasks, demonstrating its superior performance in both cross-domain and in-domain adaptation settings under varying levels of training data availability. MedBridge achieved an improvement of 6-15% in AUC compared to state-of-the-art VLM adaptation methods in multi-label thoracic disease diagnosis, underscoring its effectiveness in leveraging diverse foundation models for accurate and data-efficient medical diagnosis. Our project and code are available at https://github.com/ai-med/MedBridge.","authors":["Yitong Li","Morteza Ghahremani","Christian Wachinger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19202v1","updated":"2025-11-24T15:11:12Z","published":"2025-11-24T15:11:12Z","title":"NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting","summary":"3D Gaussian Splatting can exploit frustum culling and level-of-detail strategies to accelerate rendering of scenes containing a large number of primitives. However, the semi-transparent nature of Gaussians prevents the application of another highly effective technique: occlusion culling. We address this limitation by proposing a novel method to learn the viewpoint-dependent visibility function of all Gaussians in a trained model using a small, shared MLP across instances of an asset in a scene. By querying it for Gaussians within the viewing frustum prior to rasterization, our method can discard occluded primitives during rendering. Leveraging Tensor Cores for efficient computation, we integrate these neural queries directly into a novel instanced software rasterizer. Our approach outperforms the current state of the art for composed scenes in terms of VRAM usage and image quality, utilizing a combination of our instanced rasterizer and occlusion culling MLP, and exhibits complementary properties to existing LoD techniques.","authors":["Brent Zoomers","Florian Hahlbohm","Joni Vanherck","Lode Jorissen","Marcus Magnor","Nick Michiels"],"pdf_url":"","comment":"15 pages, 13 figures"},{"id":"http://arxiv.org/abs/2511.19200v1","updated":"2025-11-24T15:09:32Z","published":"2025-11-24T15:09:32Z","title":"Can Modern Vision Models Understand the Difference Between an Object and a Look-alike?","summary":"Recent advances in computer vision have yielded models with strong performance on recognition benchmarks; however, significant gaps remain in comparison to human perception. One subtle ability is to judge whether an image looks like a given object without being an instance of that object. We study whether vision-language models such as CLIP capture this distinction. We curated a dataset named RoLA (Real or Lookalike) of real and lookalike exemplars (e.g., toys, statues, drawings, pareidolia) across multiple categories, and first evaluate a prompt-based baseline with paired \"real\"/\"lookalike\" prompts. We then estimate a direction in CLIP's embedding space that moves representations between real and lookalike. Applying this direction to image and text embeddings improves discrimination in cross-modal retrieval on Conceptual12M, and also enhances captions produced by a CLIP prefix captioner.","authors":["Itay Cohen","Ethan Fetaya","Amir Rosenfeld"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19199v1","updated":"2025-11-24T15:09:07Z","published":"2025-11-24T15:09:07Z","title":"CLASH: A Benchmark for Cross-Modal Contradiction Detection","summary":"Contradictory multimodal inputs are common in real-world settings, yet existing benchmarks typically assume input consistency and fail to evaluate cross-modal contradiction detection - a fundamental capability for preventing hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark for multimodal contradiction detection, featuring COCO images paired with contradictory captions containing controlled object-level or attribute-level contradictions. The samples include targeted questions evaluated in both multiple-choice and open-ended formats. The benchmark provides an extensive fine-tuning set filtered through automated quality checks, alongside a smaller human-verified diagnostic set. Our analysis of state-of-the-art models reveals substantial limitations in recognizing cross-modal conflicts, exposing systematic modality biases and category-specific weaknesses. Furthermore, we empirically demonstrate that targeted fine-tuning on CLASH substantially enhances conflict detection capabilities.","authors":["Teodora Popordanoska","Jiameng Li","Matthew B. Blaschko"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2510.20776v2","updated":"2025-11-24T15:08:33Z","published":"2025-10-23T17:47:38Z","title":"CUPID: Generative 3D Reconstruction via Joint Object and Pose Modeling","summary":"We introduce Cupid, a generative 3D reconstruction framework that jointly models the full distribution over both canonical objects and camera poses. Our two-stage flow-based model first generates a coarse 3D structure and 2D-3D correspondences to estimate the camera pose robustly. Conditioned on this pose, a refinement stage injects pixel-aligned image features directly into the generative process, marrying the rich prior of a generative model with the geometric fidelity of reconstruction. This strategy achieves exceptional faithfulness, outperforming state-of-the-art reconstruction methods by over 3 dB PSNR and 10% in Chamfer Distance. As a unified generative model that decouples the object and camera pose, Cupid naturally extends to multi-view and scene-level reconstruction tasks without requiring post-hoc optimization or fine-tuning.","authors":["Binbin Huang","Haobin Duan","Yiqun Zhao","Zibo Zhao","Yi Ma","Shenghua Gao"],"pdf_url":"","comment":"project page at https://cupid3d.github.io"},{"id":"http://arxiv.org/abs/2511.19198v1","updated":"2025-11-24T15:07:45Z","published":"2025-11-24T15:07:45Z","title":"Three-Dimensional Anatomical Data Generation Based on Artificial Neural Networks","summary":"Surgical planning and training based on machine learning requires a large amount of 3D anatomical models reconstructed from medical imaging, which is currently one of the major bottlenecks. Obtaining these data from real patients and during surgery is very demanding, if even possible, due to legal, ethical, and technical challenges. It is especially difficult for soft tissue organs with poor imaging contrast, such as the prostate. To overcome these challenges, we present a novel workflow for automated 3D anatomical data generation using data obtained from physical organ models. We additionally use a 3D Generative Adversarial Network (GAN) to obtain a manifold of 3D models useful for other downstream machine learning tasks that rely on 3D data. We demonstrate our workflow using an artificial prostate model made of biomimetic hydrogels with imaging contrast in multiple zones. This is used to physically simulate endoscopic surgery. For evaluation and 3D data generation, we place it into a customized ultrasound scanner that records the prostate before and after the procedure. A neural network is trained to segment the recorded ultrasound images, which outperforms conventional, non-learning-based computer vision techniques in terms of intersection over union (IoU). Based on the segmentations, a 3D mesh model is reconstructed, and performance feedback is provided.","authors":["Ann-Sophia Müller","Moonkwang Jeong","Meng Zhang","Jiyuan Tian","Arkadiusz Miernik","Stefanie Speidel","Tian Qiu"],"pdf_url":"","comment":"6 pages, 4 figures, 1 table, IEEE International Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2508.05224v2","updated":"2025-11-24T14:59:34Z","published":"2025-08-07T10:10:37Z","title":"Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning","summary":"Federated learning (FL) enables collaborative model training across distributed clients while preserving data privacy by keeping data local. Traditional FL approaches rely on a centralized, star-shaped topology, where a central server aggregates model updates from clients. However, this architecture introduces several limitations, including a single point of failure, limited personalization, and poor robustness to distribution shifts or vulnerability to malfunctioning clients. Moreover, update selection in centralized FL often relies on low-level parameter differences, which can be unreliable when client data is not independent and identically distributed, and offer clients little control. In this work, we propose a decentralized, peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P topology to enable each client to identify and aggregate a personalized set of trustworthy and beneficial updates.This framework is the Local Inference Guided Aggregation for Heterogeneous Training Environments to Yield Enhancement Through Agreement and Regularization (LIGHTYEAR). Central to our method is an agreement score, computed on a local validation set, which quantifies the semantic alignment of incoming updates in the function space with respect to the clients reference model. Each client uses this score to select a tailored subset of updates and performs aggregation with a regularization term that further stabilizes the training. Our empirical evaluation across five datasets shows that the proposed approach consistently outperforms both, centralized baselines and existing P2P methods in terms of client-level performance, particularly under adversarial and heterogeneous conditions.","authors":["Mirko Konstantin","Anirban Mukhopadhyay"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.01632v3","updated":"2025-11-24T14:54:55Z","published":"2025-04-02T11:37:39Z","title":"Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions","summary":"The robustness of deep neural networks is a crucial factor in safety-critical applications, particularly in complex and dynamic environments (e.g., medical or driving scenarios) where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remains underexplored. This paper fills this gap by introducing novel, region-aware metrics for benchmarking the spatial robustness of segmentation models, along with an evaluation framework to assess the impact of natural localized corruptions. Furthermore, it uncovers the inherent complexity of evaluating worst-case spatial robustness using only a single localized adversarial attack. To address this, the work proposes a region-aware multi-attack adversarial analysis to systematically assess model robustness across specific image regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones, and vice versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.","authors":["Giulia Marchiori Pietrosanti","Giulio Rossolini","Alessandro Biondi","Giorgio Buttazzo"],"pdf_url":"","comment":"Accepted for publication in Pattern Recognition"},{"id":"http://arxiv.org/abs/2511.19187v1","updated":"2025-11-24T14:54:00Z","published":"2025-11-24T14:54:00Z","title":"SpectraNet: FFT-assisted Deep Learning Classifier for Deepfake Face Detection","summary":"Detecting deepfake images is crucial in combating misinformation. We present a lightweight, generalizable binary classification model based on EfficientNet-B6, fine-tuned with transformation techniques to address severe class imbalances. By leveraging robust preprocessing, oversampling, and optimization strategies, our model achieves high accuracy, stability, and generalization. While incorporating Fourier transform-based phase and amplitude features showed minimal impact, our proposed framework helps non-experts to effectively identify deepfake images, making significant strides toward accessible and reliable deepfake detection.","authors":["Nithira Jayarathne","Naveen Basnayake","Keshawa Jayasundara","Pasindu Dodampegama","Praveen Wijesinghe","Hirushika Pelagewatta","Kavishka Abeywardana","Sandushan Ranaweera","Chamira Edussooriya"],"pdf_url":"","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.19183v1","updated":"2025-11-24T14:50:36Z","published":"2025-11-24T14:50:36Z","title":"nnActive: A Framework for Evaluation of Active Learning in 3D Biomedical Segmentation","summary":"Semantic segmentation is crucial for various biomedical applications, yet its reliance on large annotated datasets presents a bottleneck due to the high cost and specialized expertise required for manual labeling. Active Learning (AL) aims to mitigate this challenge by querying only the most informative samples, thereby reducing annotation effort. However, in the domain of 3D biomedical imaging, there is no consensus on whether AL consistently outperforms Random sampling. Four evaluation pitfalls hinder the current methodological assessment. These are (1) restriction to too few datasets and annotation budgets, (2) using 2D models on 3D images without partial annotations, (3) Random baseline not being adapted to the task, and (4) measuring annotation cost only in voxels. In this work, we introduce nnActive, an open-source AL framework that overcomes these pitfalls by (1) means of a large scale study spanning four biomedical imaging datasets and three label regimes, (2) extending nnU-Net by using partial annotations for training with 3D patch-based query selection, (3) proposing Foreground Aware Random sampling strategies tackling the foreground-background class imbalance of medical images and (4) propose the foreground efficiency metric, which captures the low annotation cost of background-regions. We reveal the following findings: (A) while all AL methods outperform standard Random sampling, none reliably surpasses an improved Foreground Aware Random sampling; (B) benefits of AL depend on task specific parameters; (C) Predictive Entropy is overall the best performing AL method, but likely requires the most annotation effort; (D) AL performance can be improved with more compute intensive design choices. As a holistic, open-source framework, nnActive can serve as a catalyst for research and application of AL in 3D biomedical imaging. Code is at: https://github.com/MIC-DKFZ/nnActive","authors":["Carsten T. Lüth","Jeremias Traub","Kim-Celine Kahl","Till J. Bungert","Lukas Klein","Lars Krämer","Paul F. Jaeger","Fabian Isensee","Klaus Maier-Hein"],"pdf_url":"","comment":"Accepted at TMLR"},{"id":"http://arxiv.org/abs/2511.19180v1","updated":"2025-11-24T14:42:44Z","published":"2025-11-24T14:42:44Z","title":"Evaluating Deep Learning and Traditional Approaches Used in Source Camera Identification","summary":"One of the most important tasks in computer vision is identifying the device using which the image was taken, useful for facilitating further comprehensive analysis of the image. This paper presents comparative analysis of three techniques used in source camera identification (SCI): Photo Response Non-Uniformity (PRNU), JPEG compression artifact analysis, and convolutional neural networks (CNNs). It evaluates each method in terms of device classification accuracy. Furthermore, the research discusses the possible scientific development needed for the implementation of the methods in real-life scenarios.","authors":["Mansur Ozaman"],"pdf_url":"","comment":"4 figures"},{"id":"http://arxiv.org/abs/2510.01047v2","updated":"2025-11-24T14:42:41Z","published":"2025-10-01T15:51:10Z","title":"In-Situ Tweedie Discrete Diffusion Models","summary":"While diffusion models excel at generating continuous data such as images, adapting them to discrete tasks has relied on indirect approaches that either operate in continuous embedding spaces or use token masking mechanisms, both of which deviate from modeling the true discrete data distribution that can be theoretically guaranteed by Tweedie's formula. We propose in-situ Tweedie Discrete Diffusion (TDD), a framework that performs diffusion guaranteed by Tweedie's formula directly within the discrete one-hot space, hence \"in-situ.\" Unlike prior methods that diffuse continuous embeddings or mask tokens, TDD directly corrupts one-hot vectors with Gaussian noise and performs iterative denoising through a timestep-conditioned cross-entropy objective rather than mean-squared-error reconstruction. At each denoising step, the model predicts class probabilities, applies argmax to obtain discrete predictions, converts them to one-hot vectors, and feeds them into the next iteration with progressively reduced noise. This process naturally unifies discriminative classification and generative modeling under a single framework. Experiments demonstrate that TDD achieves strong performance on both image classification and text generation tasks, with extensive ablation studies confirming the effectiveness of each design component. Our work establishes a principled approach to discrete diffusion that preserves the core characteristics of diffusion models while operating natively in discrete space.","authors":["Xiao Li","Jiaqi Zhang","Shuxiang Zhang","Tianshui Chen","Liang Lin","Guangrun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19172v1","updated":"2025-11-24T14:34:19Z","published":"2025-11-24T14:34:19Z","title":"MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes","summary":"Recently, 3D Gaussian Splatting and its derivatives have achieved significant breakthroughs in large-scale scene reconstruction. However, how to efficiently and stably achieve high-quality geometric fidelity remains a core challenge. To address this issue, we introduce MetroGS, a novel Gaussian Splatting framework for efficient and robust reconstruction in complex urban environments. Our method is built upon a distributed 2D Gaussian Splatting representation as the core foundation, serving as a unified backbone for subsequent modules. To handle potential sparse regions in complex scenes, we propose a structured dense enhancement scheme that utilizes SfM priors and a pointmap model to achieve a denser initialization, while incorporating a sparsity compensation mechanism to improve reconstruction completeness. Furthermore, we design a progressive hybrid geometric optimization strategy that organically integrates monocular and multi-view optimization to achieve efficient and accurate geometric refinement. Finally, to address the appearance inconsistency commonly observed in large-scale scenes, we introduce a depth-guided appearance modeling approach that learns spatial features with 3D consistency, facilitating effective decoupling between geometry and appearance and further enhancing reconstruction stability. Experiments on large-scale urban datasets demonstrate that MetroGS achieves superior geometric accuracy, rendering quality, offering a unified solution for high-fidelity large-scale scene reconstruction.","authors":["Kehua Chen","Tianlu Mao","Zhuxin Ma","Hao Jiang","Zehao Li","Zihan Liu","Shuqi Gao","Honglong Zhao","Feng Dai","Yucheng Zhang","Zhaoqi Wang"],"pdf_url":"","comment":"Project page: https://m3phist0.github.io/MetroGS"},{"id":"http://arxiv.org/abs/2511.19169v1","updated":"2025-11-24T14:32:27Z","published":"2025-11-24T14:32:27Z","title":"Test-Time Preference Optimization for Image Restoration","summary":"Image restoration (IR) models are typically trained to recover high-quality images using L1 or LPIPS loss. To handle diverse unknown degradations, zero-shot IR methods have also been introduced. However, existing pre-trained and zero-shot IR approaches often fail to align with human preferences, resulting in restored images that may not be favored. This highlights the critical need to enhance restoration quality and adapt flexibly to various image restoration tasks or backbones without requiring model retraining and ideally without labor-intensive preference data collection. In this paper, we propose the first Test-Time Preference Optimization (TTPO) paradigm for image restoration, which enhances perceptual quality, generates preference data on-the-fly, and is compatible with any IR model backbone. Specifically, we design a training-free, three-stage pipeline: (i) generate candidate preference images online using diffusion inversion and denoising based on the initially restored image; (ii) select preferred and dispreferred images using automated preference-aligned metrics or human feedback; and (iii) use the selected preference images as reward signals to guide the diffusion denoising process, optimizing the restored image to better align with human preferences. Extensive experiments across various image restoration tasks and models demonstrate the effectiveness and flexibility of the proposed pipeline.","authors":["Bingchen Li","Xin Li","Jiaqi Xu","Jiaming Guo","Wenbo Li","Renjing Pei","Zhibo Chen"],"pdf_url":"","comment":"Accepted by AAAI26"},{"id":"http://arxiv.org/abs/2510.16822v2","updated":"2025-11-24T14:18:04Z","published":"2025-10-19T13:18:44Z","title":"ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification","summary":"Coral reefs are rapidly declining due to anthropogenic pressures such as climate change, underscoring the urgent need for scalable, automated monitoring. We introduce ReefNet, a large public coral reef image dataset with point-label annotations mapped to the World Register of Marine Species (WoRMS). ReefNet aggregates imagery from 76 curated CoralNet sources and an additional site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level hard coral annotations with expert-verified labels. Unlike prior datasets, which are often limited by size, geography, or coarse labels and are not ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global scale to WoRMS. We propose two evaluation settings: (i) a within-source benchmark that partitions each source's images for localized evaluation, and (ii) a cross-source benchmark that withholds entire sources to test domain generalization. We analyze both supervised and zero-shot classification performance on ReefNet and find that while supervised within-source performance is promising, supervised performance drops sharply across domains, and performance is low across the board for zero-shot models, especially for rare and visually similar genera. This provides a challenging benchmark intended to catalyze advances in domain generalization and fine-grained coral classification. We will release our dataset, benchmarking code, and pretrained models to advance robust, domain-adaptive, global coral reef monitoring and conservation.","authors":["Yahia Battach","Abdulwahab Felemban","Faizan Farooq Khan","Yousef A. Radwan","Xiang Li","Fabio Marchese","Sara Beery","Burton H. Jones","Francesca Benzoni","Mohamed Elhoseiny"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19149v1","updated":"2025-11-24T14:13:57Z","published":"2025-11-24T14:13:57Z","title":"From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation","summary":"This paper introduces the retrieval-augmented framework for automatic fashion caption and hashtag generation, combining multi-garment detection, attribute reasoning, and Large Language Model (LLM) prompting. The system aims to produce visually grounded, descriptive, and stylistically interesting text for fashion imagery, overcoming the limitations of end-to-end captioners that have problems with attribute fidelity and domain generalization. The pipeline combines a YOLO-based detector for multi-garment localization, k-means clustering for dominant color extraction, and a CLIP-FAISS retrieval module for fabric and gender attribute inference based on a structured product index. These attributes, together with retrieved style examples, create a factual evidence pack that is used to guide an LLM to generate human-like captions and contextually rich hashtags. A fine-tuned BLIP model is used as a supervised baseline model for comparison. Experimental results show that the YOLO detector is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine categories of garments. The RAG-LLM pipeline generates expressive attribute-aligned captions and achieves mean attribute coverage of 0.80 with full coverage at the 50% threshold in hashtag generation, whereas BLIP gives higher lexical overlap and lower generalization. The retrieval-augmented approach exhibits better factual grounding, less hallucination, and great potential for scalable deployment in various clothing domains. These results demonstrate the use of retrieval-augmented generation as an effective and interpretable paradigm for automated and visually grounded fashion content generation.","authors":["Moazzam Umer Gondal","Hamad Ul Qudous","Daniya Siddiqui","Asma Ahmad Farhan"],"pdf_url":"","comment":"Submitted to Expert Systems with Applications"},{"id":"http://arxiv.org/abs/2511.19147v1","updated":"2025-11-24T14:12:22Z","published":"2025-11-24T14:12:22Z","title":"Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation","summary":"Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data. Recent advances in Foundation Models (FMs) have introduced new opportunities for leveraging external semantic knowledge to guide SFDA. However, relying on a single FM is often insufficient, as it tends to bias adaptation toward a restricted semantic coverage, failing to capture diverse contextual cues under domain shift. To overcome this limitation, we propose a Collaborative Multi-foundation Adaptation (CoMA) framework that jointly leverages two different FMs (e.g., CLIP and BLIP) with complementary properties to capture both global semantics and local contextual cues. Specifically, we employ a bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge from the FMs to the target model. To ensure stable adaptation under mini-batch training, we introduce Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art SFDA methods across four benchmarks, including Office-31, Office-Home, DomainNet-126, and VisDA, under the closed-set setting, while also achieving best results on partial-set and open-set variants.","authors":["Huisoo Lee","Jisu Han","Hyunsouk Cho","Wonjun Hwang"],"pdf_url":"","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.19145v1","updated":"2025-11-24T14:09:42Z","published":"2025-11-24T14:09:42Z","title":"ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank Adaptation","summary":"We propose Activation Boundary Matching for Low-Rank Adaptation (ABM-LoRA), a principled initialization strategy that substantially accelerates the convergence of low-rank adapters. While LoRA offers high parameter efficiency, its random initialization restricts gradient updates to a mismatched tangent space, causing significant information loss and hindering early convergence. Our ABM-LoRA addresses this by aligning the adapter's activation boundaries with those of the pretrained model before downstream training, thereby maximizing the projection of full-parameter gradients into the adapter subspace. This alignment sharply reduces information loss at initialization, yields a lower starting loss, and accelerates convergence. We demonstrate ABM-LoRA's effectiveness across diverse architectures and tasks: language understanding (T5-Base on GLUE), dialogue generation (LLaMA2-7B on WizardLM), and vision recognition (ViT-B/16 on VTAB-1K). On VTAB-1K, it achieves the highest accuracy among all methods, with strong gains on structured reasoning tasks requiring geometric understanding.","authors":["Dongha Lee","Jinhee Park","Minjun Kim","Junseok Kwon"],"pdf_url":"","comment":"16 pages, 5 figures, under review"},{"id":"http://arxiv.org/abs/2503.18414v2","updated":"2025-11-24T14:03:50Z","published":"2025-03-24T07:46:00Z","title":"U-REPA: Aligning Diffusion U-Nets to ViTs","summary":"Representation Alignment (REPA) that aligns Diffusion Transformer (DiT) hidden-states with ViT visual encoders has proven highly effective in DiT training, demonstrating superior convergence properties, but it has not been validated on the canonical diffusion U-Net architecture that shows faster convergence compared to DiTs. However, adapting REPA to U-Net architectures presents unique challenges: (1) different block functionalities necessitate revised alignment strategies; (2) spatial-dimension inconsistencies emerge from U-Net's spatial downsampling operations; (3) space gaps between U-Net and ViT hinder the effectiveness of tokenwise alignment. To encounter these challenges, we propose \\textbf{U-REPA}, a representation alignment paradigm that bridges U-Net hidden states and ViT features as follows: Firstly, we propose via observation that due to skip connection, the middle stage of U-Net is the best alignment option. Secondly, we propose upsampling of U-Net features after passing them through MLPs. Thirdly, we observe difficulty when performing tokenwise similarity alignment, and further introduces a manifold loss that regularizes the relative similarity between samples. Experiments indicate that the resulting U-REPA could achieve excellent generation quality and greatly accelerates the convergence speed. With CFG guidance interval, U-REPA could reach $FID<1.5$ in 200 epochs or 1M iterations on ImageNet 256 $\\times$ 256, and needs only half the total epochs to perform better than REPA under sd-vae-ft-ema. Codes: https://github.com/YuchuanTian/U-REPA","authors":["Yuchuan Tian","Hanting Chen","Mengyu Zheng","Yuchen Liang","Chao Xu","Yunhe Wang"],"pdf_url":"","comment":"22 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.14208v2","updated":"2025-11-24T14:03:29Z","published":"2025-11-18T07:40:38Z","title":"InstantViR: Real-Time Video Inverse Problem Solver with Distilled Diffusion Prior","summary":"Video inverse problems are fundamental to streaming, telepresence, and AR/VR, where high perceptual quality must coexist with tight latency constraints. Diffusion-based priors currently deliver state-of-the-art reconstructions, but existing approaches either adapt image diffusion models with ad hoc temporal regularizers - leading to temporal artifacts - or rely on native video diffusion models whose iterative posterior sampling is far too slow for real-time use. We introduce InstantViR, an amortized inference framework for ultra-fast video reconstruction powered by a pre-trained video diffusion prior. We distill a powerful bidirectional video diffusion model (teacher) into a causal autoregressive student that maps a degraded video directly to its restored version in a single forward pass, inheriting the teacher's strong temporal modeling while completely removing iterative test-time optimization. The distillation is prior-driven: it only requires the teacher diffusion model and known degradation operators, and does not rely on externally paired clean/noisy video data. To further boost throughput, we replace the video-diffusion backbone VAE with a high-efficiency LeanVAE via an innovative teacher-space regularized distillation scheme, enabling low-latency latent-space processing. Across streaming random inpainting, Gaussian deblurring and super-resolution, InstantViR matches or surpasses the reconstruction quality of diffusion-based baselines while running at over 35 FPS on NVIDIA A100 GPUs, achieving up to 100 times speedups over iterative video diffusion solvers. These results show that diffusion-based video reconstruction is compatible with real-time, interactive, editable, streaming scenarios, turning high-quality video restoration into a practical component of modern vision systems.","authors":["Weimin Bai","Suzhe Xu","Yiwei Ren","Jinhua Hao","Ming Sun","Wenzheng Chen","He Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19137v1","updated":"2025-11-24T14:00:40Z","published":"2025-11-24T14:00:40Z","title":"FilmSceneDesigner: Chaining Set Design for Procedural Film Scene Generation","summary":"Film set design plays a pivotal role in cinematic storytelling and shaping the visual atmosphere. However, the traditional process depends on expert-driven manual modeling, which is labor-intensive and time-consuming. To address this issue, we introduce FilmSceneDesigner, an automated scene generation system that emulates professional film set design workflow. Given a natural language description, including scene type, historical period, and style, we design an agent-based chaining framework to generate structured parameters aligned with film set design workflow, guided by prompt strategies that ensure parameter accuracy and coherence. On the other hand, we propose a procedural generation pipeline which executes a series of dedicated functions with the structured parameters for floorplan and structure generation, material assignment, door and window placement, and object retrieval and layout, ultimately constructing a complete film scene from scratch. Moreover, to enhance cinematic realism and asset diversity, we construct SetDepot-Pro, a curated dataset of 6,862 film-specific 3D assets and 733 materials. Experimental results and human evaluations demonstrate that our system produces structurally sound scenes with strong cinematic fidelity, supporting downstream tasks such as virtual previs, construction drawing and mood board creation.","authors":["Zhifeng Xie","Keyi Zhang","Yiye Yan","Yuling Guo","Fan Yang","Jiting Zhou","Mengtian Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19134v1","updated":"2025-11-24T13:59:01Z","published":"2025-11-24T13:59:01Z","title":"MambaRefine-YOLO: A Dual-Modality Small Object Detector for UAV Imagery","summary":"Small object detection in Unmanned Aerial Vehicle (UAV) imagery is a persistent challenge, hindered by low resolution and background clutter. While fusing RGB and infrared (IR) data offers a promising solution, existing methods often struggle with the trade-off between effective cross-modal interaction and computational efficiency. In this letter, we introduce MambaRefine-YOLO. Its core contributions are a Dual-Gated Complementary Mamba fusion module (DGC-MFM) that adaptively balances RGB and IR modalities through illumination-aware and difference-aware gating mechanisms, and a Hierarchical Feature Aggregation Neck (HFAN) that uses a ``refine-then-fuse'' strategy to enhance multi-scale features. Our comprehensive experiments validate this dual-pronged approach. On the dual-modality DroneVehicle dataset, the full model achieves a state-of-the-art mAP of 83.2%, an improvement of 7.9% over the baseline. On the single-modality VisDrone dataset, a variant using only the HFAN also shows significant gains, demonstrating its general applicability. Our work presents a superior balance between accuracy and speed, making it highly suitable for real-world UAV applications.","authors":["Shuyu Cao","Minxin Chen","Yucheng Song","Zhaozhong Chen","Xinyou Zhang"],"pdf_url":"","comment":"Submitted to IEEE Geoscience and Remote Sensing Letters"},{"id":"http://arxiv.org/abs/2511.19126v1","updated":"2025-11-24T13:54:00Z","published":"2025-11-24T13:54:00Z","title":"When Semantics Regulate: Rethinking Patch Shuffle and Internal Bias for Generated Image Detection with CLIP","summary":"The rapid progress of GANs and Diffusion Models poses new challenges for detecting AI-generated images. Although CLIP-based detectors exhibit promising generalization, they often rely on semantic cues rather than generator artifacts, leading to brittle performance under distribution shifts. In this work, we revisit the nature of semantic bias and uncover that Patch Shuffle provides an unusually strong benefit for CLIP, that disrupts global semantic continuity while preserving local artifact cues, which reduces semantic entropy and homogenizes feature distributions between natural and synthetic images. Through a detailed layer-wise analysis, we further show that CLIP's deep semantic structure functions as a regulator that stabilizes cross-domain representations once semantic bias is suppressed. Guided by these findings, we propose SemAnti, a semantic-antagonistic fine-tuning paradigm that freezes the semantic subspace and adapts only artifact-sensitive layers under shuffled semantics. Despite its simplicity, SemAnti achieves state-of-the-art cross-domain generalization on AIGCDetectBenchmark and GenImage, demonstrating that regulating semantics is key to unlocking CLIP's full potential for robust AI-generated image detection.","authors":["Beilin Chu","Weike You","Mengtao Li","Tingting Zheng","Kehan Zhao","Xuan Xu","Zhigao Lu","Jia Song","Moxuan Xu","Linna Zhou"],"pdf_url":"","comment":"14 pages, 7 figures and 7 tables"},{"id":"http://arxiv.org/abs/2511.19119v1","updated":"2025-11-24T13:49:17Z","published":"2025-11-24T13:49:17Z","title":"MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images","summary":"Spatial reasoning (SR), the ability to infer 3D spatial information from 2D inputs, is essential for real-world applications such as embodied AI and autonomous driving. However, existing research primarily focuses on indoor environments and typically relies on multi-view observations, which limits their generalizability to outdoor scenarios and constrains their applicability to monocular images, the most common real-world setting. In this work, we propose MonoSR, a large-scale monocular spatial reasoning dataset that spans diverse scenarios including indoor, outdoor, and object-centric settings, and supports multiple question types. MonoSR provides a path toward open-world monocular spatial reasoning. Beyond introducing the dataset, we evaluate advanced vision-language models to reveal their limitations on this challenging task. We further analyze whether auxiliary information is crucial for monocular spatial reasoning and offer practical guidance for designing future models. These contributions collectively establish a foundation for advancing monocular spatial reasoning in real-world, open-world environments.","authors":["Qirui Wang","Jingyi He","Yining Pan","Si Yong Yeo","Xulei Yang","Shijie Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19117v1","updated":"2025-11-24T13:48:47Z","published":"2025-11-24T13:48:47Z","title":"3M-TI: High-Quality Mobile Thermal Imaging via Calibration-free Multi-Camera Cross-Modal Diffusion","summary":"The miniaturization of thermal sensors for mobile platforms inherently limits their spatial resolution and textural fidelity, leading to blurry and less informative images. Existing thermal super-resolution (SR) methods can be grouped into single-image and RGB-guided approaches: the former struggles to recover fine structures from limited information, while the latter relies on accurate and laborious cross-camera calibration, which hinders practical deployment and robustness. Here, we propose 3M-TI, a calibration-free Multi-camera cross-Modality diffusion framework for Mobile Thermal Imaging. At its core, 3M-TI integrates a cross-modal self-attention module (CSM) into the diffusion UNet, replacing the original self-attention layers to adaptively align thermal and RGB features throughout the denoising process, without requiring explicit camera calibration. This design enables the diffusion network to leverage its generative prior to enhance spatial resolution, structural fidelity, and texture detail in the super-resolved thermal images. Extensive evaluations on real-world mobile thermal cameras and public benchmarks validate our superior performance, achieving state-of-the-art results in both visual quality and quantitative metrics. More importantly, the thermal images enhanced by 3M-TI lead to substantial gains in critical downstream tasks like object detection and segmentation, underscoring its practical value for robust mobile thermal perception systems. More materials: https://github.com/work-submit/3MTI.","authors":["Minchong Chen","Xiaoyun Yuan","Junzhe Wan","Jianing Zhang","Jun Zhang"],"pdf_url":"","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.19111v1","updated":"2025-11-24T13:43:54Z","published":"2025-11-24T13:43:54Z","title":"DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection","summary":"Diffusion-based editing enables realistic modification of local image regions, making AI-generated content harder to detect. Existing AIGC detection benchmarks focus on classifying entire images, overlooking the localization of diffusion-based edits. We introduce DiffSeg30k, a publicly available dataset of 30k diffusion-edited images with pixel-level annotations, designed to support fine-grained detection. DiffSeg30k features: 1) In-the-wild images--we collect images or image prompts from COCO to reflect real-world content diversity; 2) Diverse diffusion models--local edits using eight SOTA diffusion models; 3) Multi-turn editing--each image undergoes up to three sequential edits to mimic real-world sequential editing; and 4) Realistic editing scenarios--a vision-language model (VLM)-based pipeline automatically identifies meaningful regions and generates context-aware prompts covering additions, removals, and attribute changes. DiffSeg30k shifts AIGC detection from binary classification to semantic segmentation, enabling simultaneous localization of edits and identification of the editing models. We benchmark three baseline segmentation approaches, revealing significant challenges in semantic segmentation tasks, particularly concerning robustness to image distortions. Experiments also reveal that segmentation models, despite being trained for pixel-level localization, emerge as highly reliable whole-image classifiers of diffusion edits, outperforming established forgery classifiers while showing great potential in cross-generator generalization. We believe DiffSeg30k will advance research in fine-grained localization of AI-generated content by demonstrating the promise and limitations of segmentation-based methods. DiffSeg30k is released at: https://huggingface.co/datasets/Chaos2629/Diffseg30k","authors":["Hai Ci","Ziheng Peng","Pei Yang","Yingxin Xuan","Mike Zheng Shou"],"pdf_url":"","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.19109v1","updated":"2025-11-24T13:43:39Z","published":"2025-11-24T13:43:39Z","title":"HABIT: Human Action Benchmark for Interactive Traffic in CARLA","summary":"Current autonomous driving (AD) simulations are critically limited by their inadequate representation of realistic and diverse human behavior, which is essential for ensuring safety and reliability. Existing benchmarks often simplify pedestrian interactions, failing to capture complex, dynamic intentions and varied responses critical for robust system deployment. To overcome this, we introduce HABIT (Human Action Benchmark for Interactive Traffic), a high-fidelity simulation benchmark. HABIT integrates real-world human motion, sourced from mocap and videos, into CARLA (Car Learning to Act, a full autonomous driving simulator) via a modular, extensible, and physically consistent motion retargeting pipeline. From an initial pool of approximately 30,000 retargeted motions, we curate 4,730 traffic-compatible pedestrian motions, standardized in SMPL format for physically consistent trajectories. HABIT seamlessly integrates with CARLA's Leaderboard, enabling automated scenario generation and rigorous agent evaluation. Our safety metrics, including Abbreviated Injury Scale (AIS) and False Positive Braking Rate (FPBR), reveal critical failure modes in state-of-the-art AD agents missed by prior evaluations. Evaluating three state-of-the-art autonomous driving agents, InterFuser, TransFuser, and BEVDriver, demonstrates how HABIT exposes planner weaknesses that remain hidden in scripted simulations. Despite achieving close or equal to zero collisions per kilometer on the CARLA Leaderboard, the autonomous agents perform notably worse on HABIT, with up to 7.43 collisions/km and a 12.94% AIS 3+ injury risk, and they brake unnecessarily in up to 33% of cases. All components are publicly released to support reproducible, pedestrian-aware AI research.","authors":["Mohan Ramesh","Mark Azer","Fabian B. Flohr"],"pdf_url":"","comment":"Accepted to WACV 2026. This is the pre-camera-ready version"},{"id":"http://arxiv.org/abs/2511.19105v1","updated":"2025-11-24T13:40:26Z","published":"2025-11-24T13:40:26Z","title":"Graph-based 3D Human Pose Estimation using WiFi Signals","summary":"WiFi-based human pose estimation (HPE) has attracted increasing attention due to its resilience to occlusion and privacy-preserving compared to camera-based methods. However, existing WiFi-based HPE approaches often employ regression networks that directly map WiFi channel state information (CSI) to 3D joint coordinates, ignoring the inherent topological relationships among human joints. In this paper, we present GraphPose-Fi, a graph-based framework that explicitly models skeletal topology for WiFi-based 3D HPE. Our framework comprises a CNN encoder shared across antennas for subcarrier-time feature extraction, a lightweight attention module that adaptively reweights features over time and across antennas, and a graph-based regression head that combines GCN layers with self-attention to capture local topology and global dependencies. Our proposed method significantly outperforms existing methods on the MM-Fi dataset in various settings. The source code is available at: https://github.com/Cirrick/GraphPose-Fi.","authors":["Jichao Chen","YangYang Qu","Ruibo Tang","Dirk Slock"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.03121v2","updated":"2025-11-24T13:39:34Z","published":"2024-12-04T08:40:11Z","title":"Splats in Splats: Robust and Effective 3D Steganography towards Gaussian Splatting","summary":"3D Gaussian splatting (3DGS) has demonstrated impressive 3D reconstruction performance with explicit scene representations. Given the widespread application of 3DGS in 3D reconstruction and generation tasks, there is an urgent need to protect the copyright of 3DGS assets. However, existing copyright protection techniques for 3DGS overlook the usability of 3D assets, posing challenges for practical deployment. Here we describe splats in splats, the first 3DGS steganography framework that embeds 3D content in 3DGS itself without modifying any attributes. To achieve this, we take a deep insight into spherical harmonics (SH) and devise an importance-graded SH coefficient encryption strategy to embed the hidden SH coefficients. Furthermore, we employ a convolutional autoencoder to establish a mapping between the original Gaussian primitives' opacity and the hidden Gaussian primitives' opacity. Extensive experiments indicate that our method significantly outperforms existing 3D steganography techniques, with 5.31% higher scene fidelity and 3x faster rendering speed, while ensuring security, robustness, and user experience.","authors":["Yijia Guo","Wenkai Huang","Yang Li","Gaolei Li","Hang Zhang","Liwen Hu","Jianhua Li","Tiejun Huang","Lei Ma"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.12547v2","updated":"2025-11-24T13:31:40Z","published":"2025-11-16T10:46:16Z","title":"HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models","summary":"Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.","authors":["Zhiguang Lu","Qianqian Xu","Peisong Wen","Siran Dai","Qingming Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19080v1","updated":"2025-11-24T13:20:03Z","published":"2025-11-24T13:20:03Z","title":"Towards Generalizable Deepfake Detection via Forgery-aware Audio-Visual Adaptation: A Variational Bayesian Approach","summary":"The widespread application of AIGC contents has brought not only unprecedented opportunities, but also potential security concerns, e.g., audio-visual deepfakes. Therefore, it is of great importance to develop an effective and generalizable method for multi-modal deepfake detection. Typically, the audio-visual correlation learning could expose subtle cross-modal inconsistencies, e.g., audio-visual misalignment, which serve as crucial clues in deepfake detection. In this paper, we reformulate the correlation learning with variational Bayesian estimation, where audio-visual correlation is approximated as a Gaussian distributed latent variable, and thus develop a novel framework for deepfake detection, i.e., Forgery-aware Audio-Visual Adaptation with Variational Bayes (FoVB). Specifically, given the prior knowledge of pre-trained backbones, we adopt two core designs to estimate audio-visual correlations effectively. First, we exploit various difference convolutions and a high-pass filter to discern local and global forgery traces from both modalities. Second, with the extracted forgery-aware features, we estimate the latent Gaussian variable of audio-visual correlation via variational Bayes. Then, we factorize the variable into modality-specific and correlation-specific ones with orthogonality constraint, allowing them to better learn intra-modal and cross-modal forgery traces with less entanglement. Extensive experiments demonstrate that our FoVB outperforms other state-of-the-art methods in various benchmarks.","authors":["Fan Nie","Jiangqun Ni","Jian Zhang","Bin Zhang","Weizhe Zhang","Bin Li"],"pdf_url":"","comment":"TIFS AQE"},{"id":"http://arxiv.org/abs/2511.19071v1","updated":"2025-11-24T13:07:22Z","published":"2025-11-24T13:07:22Z","title":"DEAP-3DSAM: Decoder Enhanced and Auto Prompt SAM for 3D Medical Image Segmentation","summary":"The Segment Anything Model (SAM) has recently demonstrated significant potential in medical image segmentation. Although SAM is primarily trained on 2D images, attempts have been made to apply it to 3D medical image segmentation. However, the pseudo 3D processing used to adapt SAM results in spatial feature loss, limiting its performance. Additionally, most SAM-based methods still rely on manual prompts, which are challenging to implement in real-world scenarios and require extensive external expert knowledge. To address these limitations, we introduce the Decoder Enhanced and Auto Prompt SAM (DEAP-3DSAM) to tackle these limitations. Specifically, we propose a Feature Enhanced Decoder that fuses the original image features with rich and detailed spatial information to enhance spatial features. We also design a Dual Attention Prompter to automatically obtain prompt information through Spatial Attention and Channel Attention. We conduct comprehensive experiments on four public abdominal tumor segmentation datasets. The results indicate that our DEAP-3DSAM achieves state-of-the-art performance in 3D image segmentation, outperforming or matching existing manual prompt methods. Furthermore, both quantitative and qualitative ablation studies confirm the effectiveness of our proposed modules.","authors":["Fangda Chen","Jintao Tang","Pancheng Wang","Ting Wang","Shasha Li","Ting Deng"],"pdf_url":"","comment":"Accepted by BIBM 2024"},{"id":"http://arxiv.org/abs/2511.19067v1","updated":"2025-11-24T13:01:32Z","published":"2025-11-24T13:01:32Z","title":"DynaMix: Generalizable Person Re-identification via Dynamic Relabeling and Mixed Data Sampling","summary":"Generalizable person re-identification (Re-ID) aims to recognize individuals across unseen cameras and environments. While existing methods rely heavily on limited labeled multi-camera data, we propose DynaMix, a novel method that effectively combines manually labeled multi-camera and large-scale pseudo-labeled single-camera data. Unlike prior works, DynaMix dynamically adapts to the structure and noise of the training data through three core components: (1) a Relabeling Module that refines pseudo-labels of single-camera identities on-the-fly; (2) an Efficient Centroids Module that maintains robust identity representations under a large identity space; and (3) a Data Sampling Module that carefully composes mixed data mini-batches to balance learning complexity and intra-batch diversity. All components are specifically designed to operate efficiently at scale, enabling effective training on millions of images and hundreds of thousands of identities. Extensive experiments demonstrate that DynaMix consistently outperforms state-of-the-art methods in generalizable person Re-ID.","authors":["Timur Mamedov","Anton Konushin","Vadim Konushin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.21171v3","updated":"2025-11-24T13:00:02Z","published":"2025-10-24T05:51:31Z","title":"TokenCLIP: Token-wise Prompt Learning for Zero-shot Anomaly Detection","summary":"Adapting CLIP for anomaly detection on unseen objects has shown strong potential in a zero-shot manner. However, existing methods typically rely on a single textual space to align with visual semantics across diverse objects and domains. The indiscriminate alignment hinders the model from accurately capturing varied anomaly semantics. We propose TokenCLIP, a token-wise adaptation framework that enables dynamic alignment between visual and learnable textual spaces for fine-grained anomaly learning. Rather than mapping all visual tokens to a single, token-agnostic textual space, TokenCLIP aligns each token with a customized textual subspace that represents its visual characteristics. Explicitly assigning a unique learnable textual space to each token is computationally intractable and prone to insufficient optimization. We instead expand the token-agnostic textual space into a set of orthogonal subspaces, and then dynamically assign each token to a subspace combination guided by semantic affinity, which jointly supports customized and efficient token-wise adaptation. To this end, we formulate dynamic alignment as an optimal transport problem, where all visual tokens in an image are transported to textual subspaces based on semantic similarity. The transport constraints of OT ensure sufficient optimization across subspaces and encourage them to focus on different semantics. Solving the problem yields a transport plan that adaptively assigns each token to semantically relevant subspaces. A top-k masking is then applied to sparsify the plan and specialize subspaces for distinct visual regions. Extensive experiments demonstrate the superiority of TokenCLIP.","authors":["Qihang Zhou","Binbin Gao","Guansong Pang","Xin Wang","Jiming Chen","Shibo He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19065v1","updated":"2025-11-24T12:59:27Z","published":"2025-11-24T12:59:27Z","title":"Understanding, Accelerating, and Improving MeanFlow Training","summary":"MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.","authors":["Jin-Young Kim","Hyojun Go","Lea Bogensperger","Julius Erbach","Nikolai Kalischek","Federico Tombari","Konrad Schindler","Dominik Narnhofer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19062v1","updated":"2025-11-24T12:55:02Z","published":"2025-11-24T12:55:02Z","title":"Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation","summary":"Prompt-free image segmentation aims to generate accurate masks without manual guidance. Typical pre-trained models, notably Segmentation Anything Model (SAM), generate prompts directly at a single granularity level. However, this approach has two limitations: (1) Localizability, lacking mechanisms for autonomous region localization; (2) Scalability, limited fine-grained modeling at high resolution. To address these challenges, we introduce Granular Computing-driven SAM (Grc-SAM), a coarse-to-fine framework motivated by Granular Computing (GrC). First, the coarse stage adaptively extracts high-response regions from features to achieve precise foreground localization and reduce reliance on external prompts. Second, the fine stage applies finer patch partitioning with sparse local swin-style attention to enhance detail modeling and enable high-resolution segmentation. Third, refined masks are encoded as latent prompt embeddings for the SAM decoder, replacing handcrafted prompts with an automated reasoning process. By integrating multi-granularity attention, Grc-SAM bridges granular computing with vision transformers. Extensive experimental results demonstrate Grc-SAM outperforms baseline methods in both accuracy and scalability. It offers a unique granular computational perspective for prompt-free segmentation.","authors":["Qiyang Yu","Yu Fang","Tianrui Li","Xuemei Cao","Yan Chen","Jianghao Li","Fan Min","Yi Zhang"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.19057v1","updated":"2025-11-24T12:50:34Z","published":"2025-11-24T12:50:34Z","title":"LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space","summary":"Perception of Low-Altitude Aircraft (LAA) in 3D space enables precise 3D object localization and behavior understanding. However, datasets tailored for 3D LAA perception remain scarce. To address this gap, we present LAA3D, a large-scale dataset designed to advance 3D detection and tracking of low-altitude aerial vehicles. LAA3D contains 15,000 real images and 600,000 synthetic frames, captured across diverse scenarios, including urban and suburban environments. It covers multiple aerial object categories, including electric Vertical Take-Off and Landing (eVTOL) aircraft, Micro Aerial Vehicles (MAVs), and Helicopters. Each instance is annotated with 3D bounding box, class label, and instance identity, supporting tasks such as 3D object detection, 3D multi-object tracking (MOT), and 6-DoF pose estimation. Besides, we establish the LAA3D Benchmark, integrating multiple tasks and methods with unified evaluation protocols for comparison. Furthermore, we propose MonoLAA, a monocular 3D detection baseline, achieving robust 3D localization from zoom cameras with varying focal lengths. Models pretrained on synthetic images transfer effectively to real-world data with fine-tuning, demonstrating strong sim-to-real generalization. Our LAA3D provides a comprehensive foundation for future research in low-altitude 3D object perception.","authors":["Hai Wu","Shuai Tang","Jiale Wang","Longkun Zou","Mingyue Guo","Rongqin Liang","Ke Chen","Yaowei Wang"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2511.19049v1","updated":"2025-11-24T12:37:49Z","published":"2025-11-24T12:37:49Z","title":"Beyond Reward Margin: Rethinking and Resolving Likelihood Displacement in Diffusion Models via Video Generation","summary":"Direct Preference Optimization (DPO) has shown promising results in aligning generative outputs with human preferences by distinguishing between chosen and rejected samples. However, a critical limitation of DPO is likelihood displacement, where the probabilities of chosen samples paradoxically decrease during training, undermining the quality of generation. Although this issue has been investigated in autoregressive models, its impact within diffusion-based models remains largely unexplored. This gap leads to suboptimal performance in tasks involving video generation. To address this, we conduct a formal analysis of DPO loss through updating policy within the diffusion framework, which describes how the updating of specific training samples influences the model's predictions on other samples. Using this tool, we identify two main failure modes: (1) Optimization Conflict, which arises from small reward margins between chosen and rejected samples, and (2) Suboptimal Maximization, caused by large reward margins. Informed by these insights, we introduce a novel solution named Policy-Guided DPO (PG-DPO), combining Adaptive Rejection Scaling (ARS) and Implicit Preference Regularization (IPR) to effectively mitigate likelihood displacement. Experiments show that PG-DPO outperforms existing methods in both quantitative metrics and qualitative evaluations, offering a robust solution for improving preference alignment in video generation tasks.","authors":["Ruojun Xu","Yu Kai","Xuhua Ren","Jiaxiang Cheng","Bing Ma","Tianxiang Zheng","Qinhlin Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19046v1","updated":"2025-11-24T12:34:38Z","published":"2025-11-24T12:34:38Z","title":"MedSAM3: Delving into Segment Anything with Medical Concepts","summary":"Medical image segmentation is fundamental for biomedical discovery. Existing methods lack generalizability and demand extensive, time-consuming manual annotation for new clinical application. Here, we propose MedSAM-3, a text promptable medical segmentation model for medical image and video segmentation. By fine-tuning the Segment Anything Model (SAM) 3 architecture on medical images paired with semantic conceptual labels, our MedSAM-3 enables medical Promptable Concept Segmentation (PCS), allowing precise targeting of anatomical structures via open-vocabulary text descriptions rather than solely geometric prompts. We further introduce the MedSAM-3 Agent, a framework that integrates Multimodal Large Language Models (MLLMs) to perform complex reasoning and iterative refinement in an agent-in-the-loop workflow. Comprehensive experiments across diverse medical imaging modalities, including X-ray, MRI, Ultrasound, CT, and video, demonstrate that our approach significantly outperforms existing specialist and foundation models. We will release our code and model at https://github.com/Joey-S-Liu/MedSAM3.","authors":["Anglin Liu","Rundong Xue","Xu R. Cao","Yifan Shen","Yi Lu","Xiang Li","Qianqian Chen","Jintai Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19035v1","updated":"2025-11-24T12:16:21Z","published":"2025-11-24T12:16:21Z","title":"CSD: Change Semantic Detection with only Semantic Change Masks for Damage Assessment in Conflict Zones","summary":"Accurately and swiftly assessing damage from conflicts is crucial for humanitarian aid and regional stability. In conflict zones, damaged zones often share similar architectural styles, with damage typically covering small areas and exhibiting blurred boundaries. These characteristics lead to limited data, annotation difficulties, and significant recognition challenges, including high intra-class similarity and ambiguous semantic changes. To address these issues, we introduce a pre-trained DINOv3 model and propose a multi-scale cross-attention difference siamese network (MC-DiSNet). The powerful visual representation capability of the DINOv3 backbone enables robust and rich feature extraction from bi-temporal remote sensing images. We also release a new Gaza-change dataset containing high-resolution satellite image pairs from 2023-2024 with pixel-level semantic change annotations. It is worth emphasizing that our annotations only include semantic pixels of changed areas. Unlike conventional semantic change detection (SCD), our approach eliminates the need for large-scale semantic annotations of bi-temporal images, instead focusing directly on the changed regions. We term this new task change semantic detection (CSD). The CSD task represents a direct extension of binary change detection (BCD). Due to the limited spatial extent of semantic regions, it presents greater challenges than traditional SCD tasks. We evaluated our method under the CSD framework on both the Gaza-Change and SECOND datasets. Experimental results demonstrate that our proposed approach effectively addresses the CSD task, and its outstanding performance paves the way for practical applications in rapid damage assessment across conflict zones.","authors":["Kai Zhenga","Zhenkai Wu","Fupeng Wei","Miaolan Zhou","Kai Lie","Haitao Guo","Lei Ding","Wei Zhang","Hang-Cheng Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19033v1","updated":"2025-11-24T12:13:05Z","published":"2025-11-24T12:13:05Z","title":"ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay","summary":"Embodied exploration is a target-driven process that requires embodied agents to possess fine-grained perception and knowledge-enhanced decision making. While recent attempts leverage MLLMs for exploration due to their strong perceptual and reasoning abilities, we find that MLLM-based embodied agents remain suboptimal in exploring new environments: (i) they rely on profound but stale pre-trained knowledge, (ii) training-based approaches such as imitation learning or reinforcement learning are expensive for long-horizon tasks with sparse outcome rewards, and (iii) frontier-based exploration yields a large, visually nuanced action space that is difficult for MLLMs to make reliable decisions. We address these challenges with ReEXplore, a training-free framework that performs retrospective experience replay to inject distilled, abstract experience at inference time, and hierarchical frontier selection to decompose frontier ranking into coarse-to-fine decisions. Our approach enables robust, traceable, and efficient exploration. Across multiple embodied exploration benchmarks, ReEXplore yields great improvements over strong MLLM baselines, up to 3x higher performance in both success rate and in navigation efficiency under open-source backbones.","authors":["Gengyuan Zhang","Mingcong Ding","Jingpei Wu","Ruotong Liao","Volker Tresp"],"pdf_url":"","comment":"8 main pages plus 13 pages Appendix"},{"id":"http://arxiv.org/abs/2511.19032v1","updated":"2025-11-24T12:07:56Z","published":"2025-11-24T12:07:56Z","title":"Benchmarking Corruption Robustness of LVLMs: A Discriminative Benchmark and Robustness Alignment Metric","summary":"Despite the remarkable reasoning abilities of large vision-language models (LVLMs), their robustness under visual corruptions remains insufficiently studied. Existing evaluation paradigms exhibit two major limitations: 1) the dominance of low-discriminative samples in current datasets masks the real robustness gap between models; and 2) conventional accuracy-based metric fail to capture the degradation of the underlying prediction structure. To bridge these gaps, we introduce Bench-C, a comprehensive benchmark emphasizing discriminative samples for assessing corruption robustness, where a selection strategy is proposed to jointly consider the prediction inconsistency under corruption and the semantic diversity. Furthermore, we propose the Robustness Alignment Score (RAS), a unified metric that measures degradation in logit-level prediction structure by considering the shifts in prediction uncertainty and calibration alignment. Comprehensive experiments and analysis reveal several interesting findings: 1) model behaviors exhibit distinguish patterns under corruptions, such as erroneous confidence and hesitation; 2) despite subtle corruption may lead to a slight accuracy gain, the overall prediction structure still degrades; 3) by decomposing corruption robustness into destructive and corrective components, the distinct failure and recovery patterns across models can be revealed.","authors":["Xiangjie Sui","Songyang Li","Hanwei Zhu","Baoliang Chen","Yuming Fang","Xin Sun"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2511.19024v1","updated":"2025-11-24T11:59:55Z","published":"2025-11-24T11:59:55Z","title":"Life-IQA: Boosting Blind Image Quality Assessment through GCN-enhanced Layer Interaction and MoE-based Feature Decoupling","summary":"Blind image quality assessment (BIQA) plays a crucial role in evaluating and optimizing visual experience. Most existing BIQA approaches fuse shallow and deep features extracted from backbone networks, while overlooking the unequal contributions to quality prediction. Moreover, while various vision encoder backbones are widely adopted in BIQA, the effective quality decoding architectures remain underexplored. To address these limitations, this paper investigates the contributions of shallow and deep features to BIQA, and proposes a effective quality feature decoding framework via GCN-enhanced \\underline{l}ayer\\underline{i}nteraction and MoE-based \\underline{f}eature d\\underline{e}coupling, termed \\textbf{(Life-IQA)}. Specifically, the GCN-enhanced layer interaction module utilizes the GCN-enhanced deepest-layer features as query and the penultimate-layer features as key, value, then performs cross-attention to achieve feature interaction. Moreover, a MoE-based feature decoupling module is proposed to decouple fused representations though different experts specialized for specific distortion types or quality dimensions. Extensive experiments demonstrate that Life-IQA shows more favorable balance between accuracy and cost than a vanilla Transformer decoder and achieves state-of-the-art performance on multiple BIQA benchmarks.The code is available at: \\href{https://github.com/TANGLONG2/Life-IQA/tree/main}{\\texttt{Life-IQA}}.","authors":["Long Tang","Guoquan Zhen","Jie Hao","Jianbo Zhang","Huiyu Duan","Liang Yuan","Guangtao Zhai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19021v1","updated":"2025-11-24T11:55:22Z","published":"2025-11-24T11:55:22Z","title":"Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed Patch Splitting","summary":"Vision Transformers (ViTs) have demonstrated strong capabilities in capturing global dependencies but often struggle to efficiently represent fine-grained local details. Existing multi-scale approaches alleviate this issue by integrating hierarchical or hybrid features; however, they rely on fixed patch sizes and introduce redundant computation. To address these limitations, we propose Granularity-driven Vision Transformer (Grc-ViT), a dynamic coarse-to-fine framework that adaptively adjusts visual granularity based on image complexity. It comprises two key stages: (1) Coarse Granularity Evaluation module, which assesses visual complexity using edge density, entropy, and frequency-domain cues to estimate suitable patch and window sizes; (2) Fine-grained Refinement module, which refines attention computation according to the selected granularity, enabling efficient and precise feature learning. Two learnable parameters, α and \\b{eta}, are optimized end-to-end to balance global reasoning and local perception. Comprehensive evaluations demonstrate that Grc-ViT enhances fine-grained discrimination while achieving a superior trade-off between accuracy and computational efficiency.","authors":["Qiyang Yu","Yu Fang","Tianrui Li","Xuemei Cao","Yan Chen","Jianghao Li","Fan Min"],"pdf_url":"","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.16301v2","updated":"2025-11-24T11:32:47Z","published":"2025-11-20T12:27:53Z","title":"Upsample Anything: A Simple and Hard to Beat Baseline for Feature Upsampling","summary":"We present \\textbf{Upsample Anything}, a lightweight test-time optimization (TTO) framework that restores low-resolution features to high-resolution, pixel-wise outputs without any training. Although Vision Foundation Models demonstrate strong generalization across diverse downstream tasks, their representations are typically downsampled by 14x/16x (e.g., ViT), which limits their direct use in pixel-level applications. Existing feature upsampling approaches depend on dataset-specific retraining or heavy implicit optimization, restricting scalability and generalization. Upsample Anything addresses these issues through a simple per-image optimization that learns an anisotropic Gaussian kernel combining spatial and range cues, effectively bridging Gaussian Splatting and Joint Bilateral Upsampling. The learned kernel acts as a universal, edge-aware operator that transfers seamlessly across architectures and modalities, enabling precise high-resolution reconstruction of features, depth, or probability maps. It runs in only $\\approx0.419 \\text{s}$ per 224x224 image and achieves state-of-the-art performance on semantic segmentation, depth estimation, and both depth and probability map upsampling. \\textbf{Project page:} \\href{https://seominseok0429.github.io/Upsample-Anything/}{https://seominseok0429.github.io/Upsample-Anything/}","authors":["Minseok Seo","Mark Hamilton","Changick Kim"],"pdf_url":"","comment":"15 pages, 12 figures"},{"id":"http://arxiv.org/abs/2511.19004v1","updated":"2025-11-24T11:32:15Z","published":"2025-11-24T11:32:15Z","title":"A Self-Conditioned Representation Guided Diffusion Model for Realistic Text-to-LiDAR Scene Generation","summary":"Text-to-LiDAR generation can customize 3D data with rich structures and diverse scenes for downstream tasks. However, the scarcity of Text-LiDAR pairs often causes insufficient training priors, generating overly smooth 3D scenes. Moreover, low-quality text descriptions may degrade generation quality and controllability. In this paper, we propose a Text-to-LiDAR Diffusion Model for scene generation, named T2LDM, with a Self-Conditioned Representation Guidance (SCRG). Specifically, SCRG, by aligning to the real representations, provides the soft supervision with reconstruction details for the Denoising Network (DN) in training, while decoupled in inference. In this way, T2LDM can perceive rich geometric structures from data distribution, generating detailed objects in scenes. Meanwhile, we construct a content-composable Text-LiDAR benchmark, T2nuScenes, along with a controllability metric. Based on this, we analyze the effects of different text prompts for LiDAR generation quality and controllability, providing practical prompt paradigms and insights. Furthermore, a directional position prior is designed to mitigate street distortion, further improving scene fidelity. Additionally, by learning a conditional encoder via frozen DN, T2LDM can support multiple conditional tasks, including Sparse-to-Dense, Dense-to-Sparse, and Semantic-to-LiDAR generation. Extensive experiments in unconditional and conditional generation demonstrate that T2LDM outperforms existing methods, achieving state-of-the-art scene generation.","authors":["Wentao Qu","Guofeng Mei","Yang Wu","Yongshun Gong","Xiaoshui Huang","Liang Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18993v1","updated":"2025-11-24T11:19:21Z","published":"2025-11-24T11:19:21Z","title":"AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization","summary":"With the rapid advancement of sophisticated synthetic audio-visual content, e.g., for subtle malicious manipulations, ensuring the integrity of digital media has become paramount. This work presents a novel approach to temporal localization of deepfakes by leveraging Audio-Visual Speech Representation Reconstruction (AuViRe). Specifically, our approach reconstructs speech representations from one modality (e.g., lip movements) based on the other (e.g., audio waveform). Cross-modal reconstruction is significantly more challenging in manipulated video segments, leading to amplified discrepancies, thereby providing robust discriminative cues for precise temporal forgery localization. AuViRe outperforms the state of the art by +8.9 AP@0.95 on LAV-DF, +9.6 AP@0.5 on AV-Deepfake1M, and +5.1 AUC on an in-the-wild experiment. Code available at https://github.com/mever-team/auvire.","authors":["Christos Koutlis","Symeon Papadopoulos"],"pdf_url":"","comment":"WACV 2026"},{"id":"http://arxiv.org/abs/2511.18991v1","updated":"2025-11-24T11:16:55Z","published":"2025-11-24T11:16:55Z","title":"View-Consistent Diffusion Representations for 3D-Consistent Video Generation","summary":"Video generation models have made significant progress in generating realistic content, enabling applications in simulation, gaming, and film making. However, current generated videos still contain visual artifacts arising from 3D inconsistencies, e.g., objects and structures deforming under changes in camera pose, which can undermine user experience and simulation fidelity. Motivated by recent findings on representation alignment for diffusion models, we hypothesize that improving the multi-view consistency of video diffusion representations will yield more 3D-consistent video generation. Through detailed analysis on multiple recent camera-controlled video diffusion models we reveal strong correlations between 3D-consistent representations and videos. We also propose ViCoDR, a new approach for improving the 3D consistency of video models by learning multi-view consistent diffusion representations. We evaluate ViCoDR on camera controlled image-to-video, text-to-video, and multi-view generation models, demonstrating significant improvements in the 3D consistency of the generated videos. Project page: https://danier97.github.io/ViCoDR.","authors":["Duolikun Danier","Ge Gao","Steven McDonagh","Changjian Li","Hakan Bilen","Oisin Mac Aodha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.00416v3","updated":"2025-11-24T11:10:14Z","published":"2025-07-01T04:05:47Z","title":"Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding","summary":"Vision-Language-Action (VLA) models have emerged as a promising framework for enabling generalist robots capable of perceiving, reasoning, and acting in the real world. These models usually build upon pretrained Vision-Language Models (VLMs), which excel at semantic understanding due to large-scale image and text pretraining. However, existing VLMs typically lack precise spatial understanding capabilities, as they are primarily tuned on 2D image-text pairs without 3D supervision. To address this limitation, recent approaches have incorporated explicit 3D inputs such as point clouds or depth maps, but this necessitates additional depth sensors or pre-trained depth estimation models, which may yield defective results. In contrast, our work introduces a plug-and-play module that implicitly incorporates 3D geometry features into VLA models by leveraging an off-the-shelf visual geometry foundation model. This integration provides the model with depth-aware visual representations, improving its ability to understand the geometric structure of the scene and the spatial relationships among objects from RGB images alone. We evaluate our method on a set of spatially challenging tasks in both simulation and the real world. Extensive evaluations show that our method significantly improves the performance of state-of-the-art VLA models across diverse scenarios.","authors":["Tao Lin","Gen Li","Yilei Zhong","Yanwen Zou","Yuxin Du","Jiting Liu","Encheng Gu","Bo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.03213v2","updated":"2025-11-24T11:08:46Z","published":"2025-06-03T03:01:38Z","title":"ConMamba: Contrastive Vision Mamba for Plant Disease Detection","summary":"Plant Disease Detection (PDD) is a key aspect of precision agriculture. However, existing deep learning methods often rely on extensively annotated datasets, which are time-consuming and costly to generate. Self-supervised Learning (SSL) offers a promising alternative by exploiting the abundance of unlabeled data. However, most existing SSL approaches suffer from high computational costs due to convolutional neural networks or transformer-based architectures. Additionally, they struggle to capture long-range dependencies in visual representation and rely on static loss functions that fail to align local and global features effectively. To address these challenges, we propose ConMamba, a novel SSL framework specially designed for PDD. ConMamba integrates the Vision Mamba Encoder (VME), which employs a bidirectional State Space Model (SSM) to capture long-range dependencies efficiently. Furthermore, we introduce a dual-level contrastive loss with dynamic weight adjustment to optimize local-global feature alignment. Experimental results on three benchmark datasets demonstrate that ConMamba significantly outperforms state-of-the-art methods across multiple evaluation metrics. This provides an efficient and robust solution for PDD.","authors":["Abdullah Al Mamun","Miaohua Zhang","David Ahmedt-Aristizabal","Zeeshan Hayder","Mohammad Awrangjeb"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18989v1","updated":"2025-11-24T11:08:01Z","published":"2025-11-24T11:08:01Z","title":"Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap with Vision Transformers and Zero-Shot Learning","summary":"Recent advances in deep learning have enabled significant progress in plant disease classification using leaf images. Much of the existing research in this field has relied on the PlantVillage dataset, which consists of well-centered plant images captured against uniform, uncluttered backgrounds. Although models trained on this dataset achieve high accuracy, they often fail to generalize to real-world field images, such as those submitted by farmers to plant diagnostic systems. This has created a significant gap between published studies and practical application requirements, highlighting the necessity of investigating and addressing this issue. In this study, we investigate whether attention-based architectures and zero-shot learning approaches can bridge the gap between curated academic datasets and real-world agricultural conditions in plant disease classification. We evaluate three model categories: Convolutional Neural Networks (CNNs), Vision Transformers, and Contrastive Language-Image Pre-training (CLIP)-based zero-shot models. While CNNs exhibit limited robustness under domain shift, Vision Transformers demonstrate stronger generalization by capturing global contextual features. Most notably, CLIP models classify diseases directly from natural language descriptions without any task-specific training, offering strong adaptability and interpretability. These findings highlight the potential of zero-shot learning as a practical and scalable domain adaptation strategy for plant health diagnosis in diverse field environments.","authors":["Wassim Benabbas","Mohammed Brahimi","Samir Akhrouf","Bilal Fortas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.12104v4","updated":"2025-11-24T11:06:07Z","published":"2025-01-21T12:55:04Z","title":"Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection","summary":"Visual anomaly detection is a highly challenging task, often categorized as a one-class classification and segmentation problem. Recent studies have demonstrated that the student-teacher (S-T) framework effectively addresses this challenge. However, most S-T frameworks rely solely on pre-trained teacher networks to guide student networks in learning multi-scale similar features, overlooking the potential of the student networks to enhance learning through multi-scale feature fusion. In this study, we propose a novel model named PFADSeg, which integrates a pre-trained teacher network, a denoising student network with multi-scale feature fusion, and a guided anomaly segmentation network into a unified framework. By adopting a unique teacher-encoder and student-decoder denoising mode, the model improves the student network's ability to learn from teacher network features. Furthermore, an adaptive feature fusion mechanism is introduced to train a self-supervised segmentation network that synthesizes anomaly masks autonomously, significantly increasing detection performance. Rigorous evaluations on the widely-used MVTec AD dataset demonstrate that PFADSeg exhibits excellent performance, achieving an image-level AUC of 98.9%, a pixel-level mean precision of 76.4%, and an instance-level mean precision of 78.7%.","authors":["Shixuan Song","Hao Chen","Shu Hu","Xin Wang","Jinrong Hu","Xi Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18983v1","updated":"2025-11-24T10:56:22Z","published":"2025-11-24T10:56:22Z","title":"UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection","summary":"In deepfake detection, the varying degrees of compression employed by social media platforms pose significant challenges for model generalization and reliability. Although existing methods have progressed from single-modal to multimodal approaches, they face critical limitations: single-modal methods struggle with feature degradation under data compression in social media streaming, while multimodal approaches require expensive data collection and labeling and suffer from inconsistent modal quality or accessibility in real-world scenarios. To address these challenges, we propose a novel Unimodal-generated Multimodal Contrastive Learning (UMCL) framework for robust cross-compression-rate (CCR) deepfake detection. In the training stage, our approach transforms a single visual modality into three complementary features: compression-robust rPPG signals, temporal landmark dynamics, and semantic embeddings from pre-trained vision-language models. These features are explicitly aligned through an affinity-driven semantic alignment (ASA) strategy, which models inter-modal relationships through affinity matrices and optimizes their consistency through contrastive learning. Subsequently, our cross-quality similarity learning (CQSL) strategy enhances feature robustness across compression rates. Extensive experiments demonstrate that our method achieves superior performance across various compression rates and manipulation types, establishing a new benchmark for robust deepfake detection. Notably, our approach maintains high detection accuracy even when individual features degrade, while providing interpretable insights into feature relationships through explicit alignment.","authors":["Ching-Yi Lai","Chih-Yu Jian","Pei-Cheng Chuang","Chia-Ming Lee","Chih-Chung Hsu","Chiou-Ting Hsu","Chia-Wen Lin"],"pdf_url":"","comment":"24-page manuscript accepted to IJCV"},{"id":"http://arxiv.org/abs/2506.09782v2","updated":"2025-11-24T10:55:38Z","published":"2025-06-11T14:21:38Z","title":"Q-SAM2: Accurate Quantization for Segment Anything Model 2","summary":"The Segment Anything Model 2 (SAM2) is a powerful foundation model for promptable segmentation. However, its high computational and memory costs are a major barrier to deployment on resource-constrained devices. In this paper, we present Q-SAM2, an accurate low-bit quantization method that achieves high compression and high fidelity. To address performance degradation arising from challenging weight and activation distributions during quantization, Q-SAM2 introduces two novel contributions: Variance-Reduced Calibration (VRC), an initialization method that reduces weight statistical variance by minimizing the Frobenius norm over a small calibration batch; and Learnable Statistical Clipping (LSC), a Quantization-Aware Training (QAT) method that learns momentum-stabilized clipping factors to manage outliers in weights and activations. Comprehensive experiments demonstrate that Q-SAM2 achieves highly accurate inference with substantial efficiency gains, significantly surpassing state-of-the-art general QAT schemes, particularly in the ultra-low 2-bit regime. Specifically, Q-SAM2 achieves an accuracy gain of up to 9.7 ppt in J&F on the video segmentation benchmark and 7.3 ppt in mIoU for instance segmentation over the best competing QAT model, all while achieving an 8x reduction in model size compared to the BF16 baseline.","authors":["Nicola Farronato","Florian Scheidegger","Mattia Rigotti","Cristiano Malossi","Michele Magno","Haotong Qin"],"pdf_url":"","comment":"22 pages"},{"id":"http://arxiv.org/abs/2411.03511v3","updated":"2025-11-24T10:52:17Z","published":"2024-11-05T21:08:19Z","title":"Beyond Complete Shapes: A Benchmark for Quantitative Evaluation of 3D Shape Surface Matching Algorithms","summary":"Finding correspondences between 3D deformable shapes is an important and long-standing problem in geometry processing, computer vision, graphics, and beyond. While various shape matching datasets exist, they are mostly static or limited in size, restricting their adaptation to different problem settings, including both full and partial shape matching. In particular the existing partial shape matching datasets are small (fewer than 100 shapes) and thus unsuitable for data-hungry machine learning approaches. Moreover, the type of partiality present in existing datasets is often artificial and far from realistic. To address these limitations, we introduce a generic and flexible framework for the procedural generation of challenging full and partial shape matching datasets. Our framework allows the propagation of custom annotations across shapes, making it useful for various applications. By utilising our framework and manually creating cross-dataset correspondences between seven existing (complete geometry) shape matching datasets, we propose a new large benchmark BeCoS with a total of 2543 shapes. Based on this, we offer several challenging benchmark settings, covering both full and partial matching, for which we evaluate respective state-of-the-art methods as baselines.","authors":["Viktoria Ehm","Nafie El Amrani","Yizheng Xie","Lennart Bastian","Maolin Gao","Weikang Wang","Lu Sang","Dongliang Cao","Tobias Weißberg","Zorah Lähner","Daniel Cremers","Florian Bernard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18978v1","updated":"2025-11-24T10:50:30Z","published":"2025-11-24T10:50:30Z","title":"Zero-shot segmentation of skin tumors in whole-slide images with vision-language foundation models","summary":"Accurate annotation of cutaneous neoplasm biopsies represents a major challenge due to their wide morphological variability, overlapping histological patterns, and the subtle distinctions between benign and malignant lesions. Vision-language foundation models (VLMs), pre-trained on paired image-text corpora, learn joint representations that bridge visual features and diagnostic terminology, enabling zero-shot localization and classification of tissue regions without pixel-level labels. However, most existing VLM applications in histopathology remain limited to slide-level tasks or rely on coarse interactive prompts, and they struggle to produce fine-grained segmentations across gigapixel whole-slide images (WSIs). In this work, we introduce a zero-shot visual-language segmentation pipeline for whole-slide images (ZEUS), a fully automated, zero-shot segmentation framework that leverages class-specific textual prompt ensembles and frozen VLM encoders to generate high-resolution tumor masks in WSIs. By partitioning each WSI into overlapping patches, extracting visual embeddings, and computing cosine similarities against text prompts, we generate a final segmentation mask. We demonstrate competitive performance on two in-house datasets, primary spindle cell neoplasms and cutaneous metastases, highlighting the influence of prompt design, domain shifts, and institutional variability in VLMs for histopathology. ZEUS markedly reduces annotation burden while offering scalable, explainable tumor delineation for downstream diagnostic workflows.","authors":["Santiago Moreno","Pablo Meseguer","Rocío del Amor","Valery Naranjo"],"pdf_url":"","comment":"Conference manuscript accepted for oral presentation at CASEIB 2025"},{"id":"http://arxiv.org/abs/2511.18976v1","updated":"2025-11-24T10:47:39Z","published":"2025-11-24T10:47:39Z","title":"Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs","summary":"We address two fundamental challenges in adapting general deep CNNs for FHE-based inference: approximating non-linear activations such as ReLU with low-degree polynomials while minimizing accuracy degradation, and overcoming the ciphertext capacity barrier that constrains high-resolution image processing on FHE inference. Our contributions are twofold: (1) a single-stage fine-tuning (SFT) strategy that directly converts pre-trained CNNs into FHE-friendly forms using low-degree polynomials, achieving competitive accuracy with minimal training overhead; and (2) a generalized interleaved packing (GIP) scheme that is compatible with feature maps of virtually arbitrary spatial resolutions, accompanied by a suite of carefully designed homomorphic operators that preserve the GIP-form encryption throughout computation. These advances enable efficient, end-to-end FHE inference across diverse CNN architectures. Experiments on CIFAR-10, ImageNet, and MS COCO demonstrate that the FHE-friendly CNNs obtained via our SFT strategy achieve accuracy comparable to baselines using ReLU or SiLU activations. Moreover, this work presents the first demonstration of FHE-based inference for YOLO architectures in object detection leveraging low-degree polynomial activations.","authors":["Huaming Ling","Ying Wang","Si Chen","Junfeng Fan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.01347v3","updated":"2025-11-24T10:34:13Z","published":"2025-03-03T09:38:01Z","title":"From Spots to Pixels: Dense Spatial Gene Expression Prediction from Histology Images","summary":"Spatial transcriptomics (ST) measures gene expression at fine-grained spatial resolution, offering insights into tissue molecular landscapes. Previous methods for spatial gene expression prediction typically crop spots of interest from histopathology slide images, and train models to map each spot to a corresponding gene expression profile. However, these methods inherently lose the spatial resolution in gene expression: 1) each spot often contains multiple cells with distinct gene expression profiles; 2) spots are typically defined at fixed spatial resolutions, limiting the ability to predict gene expression at varying scales. To address these limitations, this paper presents PixNet, a dense prediction network capable of predicting spatially resolved gene expression across spots of varying sizes and scales directly from histopathology slide images. Different from previous methods that map individual spots to gene expression values, we generate a spatially dense continuous gene expression map from the histopathology slide image, and aggregate values within spots of interest to predict the gene expression. Our PixNet outperforms state-of-the-art methods on four common ST datasets in multiple spatial scales. The source code will be publicly available.","authors":["Ruikun Zhang","Yan Yang","Liyuan Pan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18968v1","updated":"2025-11-24T10:34:12Z","published":"2025-11-24T10:34:12Z","title":"CataractCompDetect: Intraoperative Complication Detection in Cataract Surgery","summary":"Cataract surgery is one of the most commonly performed surgeries worldwide, yet intraoperative complications such as iris prolapse, posterior capsule rupture (PCR), and vitreous loss remain major causes of adverse outcomes. Automated detection of such events could enable early warning systems and objective training feedback. In this work, we propose CataractCompDetect, a complication detection framework that combines phase-aware localization, SAM 2-based tracking, complication-specific risk scoring, and vision-language reasoning for final classification. To validate CataractCompDetect, we curate CataComp, the first cataract surgery video dataset annotated for intraoperative complications, comprising 53 surgeries, including 23 with clinical complications. On CataComp, CataractCompDetect achieves an average F1 score of 70.63%, with per-complication performance of 81.8% (Iris Prolapse), 60.87% (PCR), and 69.23% (Vitreous Loss). These results highlight the value of combining structured surgical priors with vision-language reasoning for recognizing rare but high-impact intraoperative events. Our dataset and code will be publicly released upon acceptance.","authors":["Bhuvan Sachdeva","Sneha Kumari","Rudransh Agarwal","Shalaka Kumaraswamy","Niharika Singri Prasad","Simon Mueller","Raphael Lechtenboehmer","Maximilian W. M. Wintergerst","Thomas Schultz","Kaushik Murali","Mohit Jain"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17421v2","updated":"2025-11-24T10:32:57Z","published":"2025-11-21T17:18:35Z","title":"Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers","summary":"Deep learning models are prone to learning shortcut solutions to problems using spuriously correlated yet irrelevant features of their training data. In high-risk applications such as medical image analysis, this phenomenon may prevent models from using clinically meaningful features when making predictions, potentially leading to poor robustness and harm to patients. We demonstrate that different types of shortcuts (those that are diffuse and spread throughout the image, as well as those that are localized to specific areas) manifest distinctly across network layers and can, therefore, be more effectively targeted through mitigation strategies that target the intermediate layers. We propose a novel knowledge distillation framework that leverages a teacher network fine-tuned on a small subset of task-relevant data to mitigate shortcut learning in a student network trained on a large dataset corrupted with a bias feature. Through extensive experiments on CheXpert, ISIC 2017, and SimBA datasets using various architectures (ResNet-18, AlexNet, DenseNet-121, and 3D CNNs), we demonstrate consistent improvements over traditional Empirical Risk Minimization, augmentation-based bias-mitigation, and group-based bias-mitigation approaches. In many cases, we achieve comparable performance with a baseline model trained on bias-free data, even on out-of-distribution test data. Our results demonstrate the practical applicability of our approach to real-world medical imaging scenarios where bias annotations are limited and shortcut features are difficult to identify a priori.","authors":["Christopher Boland","Sotirios Tsaftaris","Sonia Dahdouh"],"pdf_url":"","comment":"Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:020"},{"id":"http://arxiv.org/abs/2503.00450v2","updated":"2025-11-24T10:28:28Z","published":"2025-03-01T11:11:06Z","title":"Unsupervised and Source-Free Ranking of Biomedical Segmentation Models","summary":"Model transfer presents a solution to the challenges of segmentation in the biomedical community, where the immense cost of data annotation is a major bottleneck in the use of deep learning. At the same time, hundreds of models get trained on biomedical data, submitted to challenges, and posted in model zoos and repositories. A major hurdle to wider adoption of pre-trained models lies in the lack of methods for best model selection. While such methods have been proposed for classification models, semantic and instance segmentation model ranking remain largely unaddressed, especially in a practically important setting where no labels are available on the target dataset. Similarly, if unsupervised domain adaptation is used, practitioners are faced with the task of selecting the best adapted model without target domain labels. Building on previous work linking model generalisation and consistency under perturbation, we propose the first unsupervised and source-free transferability estimator for semantic and instance segmentation tasks. We evaluate on multiple segmentation problems across biomedical imaging, finding a strong correlation between the rankings based on our estimator and rankings based on target dataset performance.","authors":["Joshua Talks","Kevin Marchesini","Luca Lumetti","Federico Bolelli","Anna Kreshuk"],"pdf_url":"","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.18960v1","updated":"2025-11-24T10:22:28Z","published":"2025-11-24T10:22:28Z","title":"AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention","summary":"Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.","authors":["Lei Xiao","Jifeng Li","Juntao Gao","Feiyang Ye","Yan Jin","Jingjing Qian","Jing Zhang","Yong Wu","Xiaoyuan Yu"],"pdf_url":"","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.18957v1","updated":"2025-11-24T10:19:56Z","published":"2025-11-24T10:19:56Z","title":"Eevee: Towards Close-up High-resolution Video-based Virtual Try-on","summary":"Video virtual try-on technology provides a cost-effective solution for creating marketing videos in fashion e-commerce. However, its practical adoption is hindered by two critical limitations. First, the reliance on a single garment image as input in current virtual try-on datasets limits the accurate capture of realistic texture details. Second, most existing methods focus solely on generating full-shot virtual try-on videos, neglecting the business's demand for videos that also provide detailed close-ups. To address these challenges, we introduce a high-resolution dataset for video-based virtual try-on. This dataset offers two key features. First, it provides more detailed information on the garments, which includes high-fidelity images with detailed close-ups and textual descriptions; Second, it uniquely includes full-shot and close-up try-on videos of real human models. Furthermore, accurately assessing consistency becomes significantly more critical for the close-up videos, which demand high-fidelity preservation of garment details. To facilitate such fine-grained evaluation, we propose a new garment consistency metric VGID (Video Garment Inception Distance) that quantifies the preservation of both texture and structure. Our experiments validate these contributions. We demonstrate that by utilizing the detailed images from our dataset, existing video generation models can extract and incorporate texture features, significantly enhancing the realism and detail fidelity of virtual try-on results. Furthermore, we conduct a comprehensive benchmark of recent models. The benchmark effectively identifies the texture and structural preservation problems among current methods.","authors":["Jianhao Zeng","Yancheng Bai","Ruidong Chen","Xuanpu Zhang","Lei Sun","Dongyang Jin","Ryan Xu","Nannan Zhang","Dan Song","Xiangxiang Chu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18950v1","updated":"2025-11-24T10:06:41Z","published":"2025-11-24T10:06:41Z","title":"Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation","summary":"Vision-Language-Action (VLA) models have emerged as a powerful paradigm in Embodied AI. However, the significant computational overhead of processing redundant visual tokens remains a critical bottleneck for real-time robotic deployment. While standard token pruning techniques can alleviate this, these task-agnostic methods struggle to preserve task-critical visual information. To address this challenge, simultaneously preserving both the holistic context and fine-grained details for precise action, we propose Compressor-VLA, a novel hybrid instruction-conditioned token compression framework designed for efficient, task-oriented compression of visual information in VLA models. The proposed Compressor-VLA framework consists of two token compression modules: a Semantic Task Compressor (STC) that distills holistic, task-relevant context, and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial details. This compression is dynamically modulated by the natural language instruction, allowing for the adaptive condensation of task-relevant visual information. Experimentally, extensive evaluations demonstrate that Compressor-VLA achieves a competitive success rate on the LIBERO benchmark while reducing FLOPs by 59% and the visual token count by over 3x compared to its baseline. The real-robot deployments on a dual-arm robot platform validate the model's sim-to-real transferability and practical applicability. Moreover, qualitative analyses reveal that our instruction guidance dynamically steers the model's perceptual focus toward task-relevant objects, thereby validating the effectiveness of our approach.","authors":["Juntao Gao","Feiyang Ye","Jing Zhang","Wenjing Qian"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.18946v1","updated":"2025-11-24T09:56:35Z","published":"2025-11-24T09:56:35Z","title":"Leveraging Adversarial Learning for Pathological Fidelity in Virtual Staining","summary":"In addition to evaluating tumor morphology using H&E staining, immunohistochemistry is used to assess the presence of specific proteins within the tissue. However, this is a costly and labor-intensive technique, for which virtual staining, as an image-to-image translation task, offers a promising alternative. Although recent, this is an emerging field of research with 64% of published studies just in 2024. Most studies use publicly available datasets of H&E-IHC pairs from consecutive tissue sections. Recognizing the training challenges, many authors develop complex virtual staining models based on conditional Generative Adversarial Networks, but ignore the impact of adversarial loss on the quality of virtual staining. Furthermore, overlooking the issues of model evaluation, they claim improved performance based on metrics such as SSIM and PSNR, which are not sufficiently robust to evaluate the quality of virtually stained images. In this paper, we developed CSSP2P GAN, which we demonstrate to achieve heightened pathological fidelity through a blind pathological expert evaluation. Furthermore, while iteratively developing our model, we study the impact of the adversarial loss and demonstrate its crucial role in the quality of virtually stained images. Finally, while comparing our model with reference works in the field, we underscore the limitations of the currently used evaluation metrics and demonstrate the superior performance of CSSP2P GAN.","authors":["José Teixeira","Pascal Klöckner","Diana Montezuma","Melis Erdal Cesur","João Fraga","Hugo M. Horlings","Jaime S. Cardoso","Sara P. Oliveira"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.08227v2","updated":"2025-11-24T09:55:44Z","published":"2025-08-11T17:44:59Z","title":"OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution","summary":"Denoising Diffusion Probabilistic Models (DDPMs) show promising potential in one-step Real-World Image Super-Resolution (Real-ISR). Current one-step Real-ISR methods typically inject the low-quality (LQ) image latent representation at the start or end timestep of the DDPM scheduler. Recent studies have begun to note that the LQ image latent and the pre-trained noisy latent representations are intuitively closer at a mid-timestep. However, a quantitative analysis of these latent representations remains lacking. Considering these latent representations can be decomposed into signal and noise, we propose a method based on the Signal-to-Noise Ratio (SNR) to pre-compute an average optimal mid-timestep for injection. To better approximate the pre-trained noisy latent representation, we further introduce the Latent Representation Refinement (LRR) loss via a LoRA-enhanced VAE encoder. We also fine-tune the backbone of the DDPM-based generative model using LoRA to perform one-step denoising at the average optimal mid-timestep. Based on these components, we present OMGSR, a GAN-based Real-ISR framework that employs a DDPM-based generative model as the generator and a DINOv3-ConvNeXt model with multi-level discriminator heads as the discriminator. We also propose the DINOv3-ConvNeXt DISTS (Dv3CD) loss, which is enhanced for structural perception at varying resolutions. Within the OMGSR framework, we develop OMGSR-S based on SD2.1-base. An ablation study confirms that our pre-computation strategy and LRR loss significantly improve the baseline. Comparative studies demonstrate that OMGSR-S achieves state-of-the-art performance across multiple metrics. Code is available at \\hyperlink{Github}{https://github.com/wuer5/OMGSR}.","authors":["Zhiqiang Wu","Zhaomang Sun","Tong Zhou","Bingtao Fu","Ji Cong","Yitong Dong","Huaqi Zhang","Xuan Tang","Mingsong Chen","Xian Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18942v1","updated":"2025-11-24T09:48:38Z","published":"2025-11-24T09:48:38Z","title":"VeCoR - Velocity Contrastive Regularization for Flow Matching","summary":"Flow Matching (FM) has recently emerged as a principled and efficient alternative to diffusion models. Standard FM encourages the learned velocity field to follow a target direction; however, it may accumulate errors along the trajectory and drive samples off the data manifold, leading to perceptual degradation, especially in lightweight or low-step configurations.\n  To enhance stability and generalization, we extend FM into a balanced attract-repel scheme that provides explicit guidance on both \"where to go\" and \"where not to go.\" To be formal, we propose \\textbf{Velocity Contrastive Regularization (VeCoR)}, a complementary training scheme for flow-based generative modeling that augments the standard FM objective with contrastive, two-sided supervision. VeCoR not only aligns the predicted velocity with a stable reference direction (positive supervision) but also pushes it away from inconsistent, off-manifold directions (negative supervision). This contrastive formulation transforms FM from a purely attractive, one-sided objective into a two-sided training signal, regularizing trajectory evolution and improving perceptual fidelity across datasets and backbones.\n  On ImageNet-1K 256$\\times$256, VeCoR yields 22\\% and 35\\% relative FID reductions on SiT-XL/2 and REPA-SiT-XL/2 backbones, respectively, and achieves further FID gains (32\\% relative) on MS-COCO text-to-image generation, demonstrating consistent improvements in stability, convergence, and image quality, particularly in low-step and lightweight settings. Project page: https://p458732.github.io/VeCoR_Project_Page/","authors":["Zong-Wei Hong","Jing-lun Li","Lin-Ze Li","Shen Zhang","Yao Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.21590v2","updated":"2025-11-24T09:37:15Z","published":"2025-10-24T15:59:04Z","title":"Restore Text First, Enhance Image Later: Two-Stage Scene Text Image Super-Resolution with Glyph Structure Guidance","summary":"Current image super-resolution methods show strong performance on natural images but distort text, creating a fundamental trade-off between image quality and textual readability. To address this, we introduce TIGER (Text-Image Guided supEr-Resolution), a novel two-stage framework that breaks this trade-off through a \"text-first, image-later\" paradigm. TIGER explicitly decouples glyph restoration from image enhancement: it first reconstructs precise text structures and uses them to guide full-image super-resolution. This ensures high fidelity and readability. To support comprehensive training and evaluation, we present the UZ-ST (UltraZoom-Scene Text) dataset, the first Chinese scene text dataset with extreme zoom. Extensive experiments show TIGER achieves state-of-the-art performance, enhancing readability and image quality.","authors":["Minxing Luo","Linlong Fan","Wang Qiushi","Ge Wu","Yiyan Luo","Yuhang Yu","Jinwei Chen","Yaxing Wang","Qingnan Fan","Jian Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.10353v4","updated":"2025-11-24T09:35:11Z","published":"2025-06-12T05:21:43Z","title":"Motion-R1: Enhancing Motion Generation with Decomposed Chain-of-Thought and RL Binding","summary":"Text-to-Motion generation has become a fundamental task in human-machine interaction, enabling the synthesis of realistic human motions from natural language descriptions. Although recent advances in large language models and reinforcement learning have contributed to high-quality motion generation, two major challenges remain. Existing approaches often fail to capture the temporal and causal complexities inherent in natural language, leading to oversimplified or incoherent motions. Additionally, RL-based methods are frequently overly complex, hindering their scalability and adaptability across various motion generation tasks. To address these challenges, we propose Motion-R1, a novel framework that combines decomposed Chain-of-Thought reasoning with reinforcement learning to enhance both the quality and interpretability of generated motions. Specifically, we introduce the Decomposed CoT Data Engine, which leverages an automated pipeline to synthesize high-quality reasoning data, allowing the model to better capture the temporal dependencies and causal relationships of human motion. We also propose RL Binding, a reinforcement learning strategy that incorporates multi-modal text-motion alignment into the RL reward function, guiding the model to produce motions that are both semantically accurate and motionally realistic. Extensive experiments across benchmark datasets demonstrate that Motion-R1 achieves state-of-the-art performance, with a 3.5% improvement in MM-Dist on HumanML3D and improvements in R-Precision and FID on KIT-ML and BABEL, surpassing existing methods across key metrics and highlighting its superior capability in handling complex motion generation tasks. Project page: https://motion-r1.github.io/.","authors":["Runqi Ouyang","Haoyun Li","Zhenyuan Zhang","Xiaofeng Wang","Zeyu Zhang","Zheng Zhu","Guan Huang","Sirui Han","Xingang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18929v1","updated":"2025-11-24T09:33:59Z","published":"2025-11-24T09:33:59Z","title":"Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search","summary":"Recent progress in robotics and embodied AI is largely driven by Large Multimodal Models (LMMs). However, a key challenge remains underexplored: how can we advance LMMs to discover tasks that directly assist humans in open-future scenarios, where human intentions are highly concurrent and dynamic. In this work, we formalize the problem of Human-centric Open-future Task Discovery (HOTD), focusing particularly on identifying tasks that reduce human effort across multiple plausible futures. To facilitate this study, we propose an HOTD-Bench, which features over 2K real-world videos, a semi-automated annotation pipeline, and a simulation-based protocol tailored for open-set future evaluation. Additionally, we propose the Collaborative Multi-Agent Search Tree (CMAST) framework, which decomposes the complex reasoning through a multi-agent system and structures the reasoning process through a scalable search tree module. In our experiments, CMAST achieves the best performance on the HOTD-Bench, significantly surpassing existing LMMs. It also integrates well with existing LMMs, consistently improving performance.","authors":["Zijian Song","Xiaoxin Lin","Tao Pu","Zhenlong Yuan","Guangrun Wang","Liang Lin"],"pdf_url":"","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.18927v1","updated":"2025-11-24T09:32:26Z","published":"2025-11-24T09:32:26Z","title":"FineXtrol: Controllable Motion Generation via Fine-Grained Text","summary":"Recent works have sought to enhance the controllability and precision of text-driven motion generation. Some approaches leverage large language models (LLMs) to produce more detailed texts, while others incorporate global 3D coordinate sequences as additional control signals. However, the former often introduces misaligned details and lacks explicit temporal cues, and the latter incurs significant computational cost when converting coordinates to standard motion representations. To address these issues, we propose FineXtrol, a novel control framework for efficient motion generation guided by temporally-aware, precise, user-friendly, and fine-grained textual control signals that describe specific body part movements over time. In support of this framework, we design a hierarchical contrastive learning module that encourages the text encoder to produce more discriminative embeddings for our novel control signals, thereby improving motion controllability. Quantitative results show that FineXtrol achieves strong performance in controllable motion generation, while qualitative analysis demonstrates its flexibility in directing specific body part movements.","authors":["Keming Shen","Bizhu Wu","Junliang Chen","Xiaoqin Wang","Linlin Shen"],"pdf_url":"","comment":"20 pages, 14 figures, AAAI 2026"},{"id":"http://arxiv.org/abs/2511.18925v1","updated":"2025-11-24T09:32:01Z","published":"2025-11-24T09:32:01Z","title":"AttenDence: Maximizing Attention Confidence for Test Time Adaptation","summary":"Test-time adaptation (TTA) enables models to adapt to distribution shifts at inference time. While entropy minimization over the output distribution has proven effective for TTA, transformers offer an additional unsupervised learning signal through their attention mechanisms. We propose minimizing the entropy of attention distributions from the CLS token to image patches as a novel TTA objective.This approach encourages the model to attend more confidently to relevant image regions under distribution shift and is effective even when only a single test image is available. We demonstrate that attention entropy minimization improves robustness across diverse corruption types while not hurting performance on clean data on a single sample stream of images at test time.","authors":["Yash Mali"],"pdf_url":"","comment":"Initial submission. 5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2409.08840v4","updated":"2025-11-24T09:31:39Z","published":"2024-09-13T13:53:52Z","title":"Directed-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles via Proactive Attention","summary":"Collaborative perception (CP) leverages visual data from connected and autonomous vehicles (CAV) to enhance an ego vehicle's field of view (FoV). Despite recent progress, current CP methods expand the ego vehicle's 360-degree perceptual range almost equally, which faces two key challenges. Firstly, in areas with uneven traffic distribution, focusing on directions with little traffic offers limited benefits. Secondly, under limited communication budgets, allocating excessive bandwidth to less critical directions lowers the perception accuracy in more vital areas. To address these issues, we propose Direct-CP, a proactive and direction-aware CP system aiming at improving CP in specific directions. Our key idea is to enable an ego vehicle to proactively signal its interested directions and readjust its attention to enhance local directional CP performance. To achieve this, we first propose an RSU-aided direction masking mechanism that assists an ego vehicle in identifying vital directions. Additionally, we design a direction-aware selective attention module to wisely aggregate pertinent features based on ego vehicle's directional priorities, communication budget, and the positional data of CAVs. Moreover, we introduce a direction-weighted detection loss (DWLoss) to capture the divergence between directional CP outcomes and the ground truth, facilitating effective model training. Extensive experiments on the V2X-Sim 2.0 dataset demonstrate that our approach achieves 19.8\\% higher local perception accuracy in interested directions and 2.5\\% higher overall perception accuracy than the state-of-the-art methods in collaborative 3D object detection tasks. Codes are available at https://github.com/yihangtao/Directed-CP.git.","authors":["Yihang Tao","Senkang Hu","Zhengru Fang","Yuguang Fang"],"pdf_url":"","comment":"Accepted by ICRA'25"},{"id":"http://arxiv.org/abs/2511.18922v1","updated":"2025-11-24T09:31:23Z","published":"2025-11-24T09:31:23Z","title":"One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control","summary":"We present One4D, a unified framework for 4D generation and reconstruction that produces dynamic 4D content as synchronized RGB frames and pointmaps. By consistently handling varying sparsities of conditioning frames through a Unified Masked Conditioning (UMC) mechanism, One4D can seamlessly transition between 4D generation from a single image, 4D reconstruction from a full video, and mixed generation and reconstruction from sparse frames. Our framework adapts a powerful video generation model for joint RGB and pointmap generation, with carefully designed network architectures. The commonly used diffusion finetuning strategies for depthmap or pointmap reconstruction often fail on joint RGB and pointmap generation, quickly degrading the base video model. To address this challenge, we introduce Decoupled LoRA Control (DLC), which employs two modality-specific LoRA adapters to form decoupled computation branches for RGB frames and pointmaps, connected by lightweight, zero-initialized control links that gradually learn mutual pixel-level consistency. Trained on a mixture of synthetic and real 4D datasets under modest computational budgets, One4D produces high-quality RGB frames and accurate pointmaps across both generation and reconstruction tasks. This work represents a step toward general, high-quality geometry-based 4D world modeling using video diffusion models. Project page: https://mizhenxing.github.io/One4D","authors":["Zhenxing Mi","Yuxin Wang","Dan Xu"],"pdf_url":"","comment":"Project page: https://mizhenxing.github.io/One4D"},{"id":"http://arxiv.org/abs/2310.17218v2","updated":"2025-11-24T09:30:49Z","published":"2023-10-26T08:12:53Z","title":"Prototypical Contrastive Learning-based CLIP Fine-tuning for Object Re-identification","summary":"This work aims to adapt large-scale pre-trained vision-language models, such as contrastive language-image pretraining (CLIP), to enhance the performance of object reidentification (Re-ID) across various supervision settings. Although prompt learning has enabled a recent work named CLIP-ReID to achieve promising performance, the underlying mechanisms and the necessity of prompt learning remain unclear due to the absence of semantic labels in ReID tasks. In this work, we first analyze the role prompt learning in CLIP-ReID and identify its limitations. Based on our investigations, we propose a simple yet effective approach to adapt CLIP for supervised object Re-ID. Our approach directly fine-tunes the image encoder of CLIP using a prototypical contrastive learning (PCL) loss, eliminating the need for prompt learning. Experimental results on both person and vehicle Re-ID datasets demonstrate the competitiveness of our method compared to CLIP-ReID. Furthermore, we extend our PCL-based CLIP fine-tuning approach to unsupervised scenarios, where we achieve state-of-the art performance.","authors":["Jiachen Li","Xiaojin Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18921v1","updated":"2025-11-24T09:30:38Z","published":"2025-11-24T09:30:38Z","title":"BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models","summary":"Backdoor attacks undermine the reliability and trustworthiness of machine learning systems by injecting hidden behaviors that can be maliciously activated at inference time. While such threats have been extensively studied in unimodal settings, their impact on multimodal foundation models, particularly vision-language models (VLMs), remains largely underexplored. In this work, we introduce \\textbf{BackdoorVLM}, the first comprehensive benchmark for systematically evaluating backdoor attacks on VLMs across a broad range of settings. It adopts a unified perspective that injects and analyzes backdoors across core vision-language tasks, including image captioning and visual question answering. BackdoorVLM organizes multimodal backdoor threats into 5 representative categories: targeted refusal, malicious injection, jailbreak, concept substitution, and perceptual hijack. Each category captures a distinct pathway through which an adversary can manipulate a model's behavior. We evaluate these threats using 12 representative attack methods spanning text, image, and bimodal triggers, tested on 2 open-source VLMs and 3 multimodal datasets. Our analysis reveals that VLMs exhibit strong sensitivity to textual instructions, and in bimodal backdoors the text trigger typically overwhelms the image trigger when forming the backdoor mapping. Notably, backdoors involving the textual modality remain highly potent, with poisoning rates as low as 1\\% yielding over 90\\% success across most tasks. These findings highlight significant, previously underexplored vulnerabilities in current VLMs. We hope that BackdoorVLM can serve as a useful benchmark for analyzing and mitigating multimodal backdoor threats. Code is available at: https://github.com/bin015/BackdoorVLM .","authors":["Juncheng Li","Yige Li","Hanxun Huang","Yunhao Chen","Xin Wang","Yixu Wang","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18920v1","updated":"2025-11-24T09:30:02Z","published":"2025-11-24T09:30:02Z","title":"EventSTU: Event-Guided Efficient Spatio-Temporal Understanding for Video Large Language Models","summary":"Video large language models have demonstrated strong video understanding capabilities but suffer from high inference costs due to the massive number of tokens in long videos. Inspired by event-based vision, we propose an event-guided, training-free framework for efficient spatio-temporal understanding, named EventSTU. In the temporal domain, we design a coarse-to-fine keyframe sampling algorithm that exploits the change-triggered property of event cameras to eliminate redundant frames. In the spatial domain, we design an adaptive token pruning algorithm that leverages the visual saliency of events as a zero-cost prior to guide spatial reduction. From a holistic spatio-temporal perspective, we further integrate question relevance from keyframe sampling to adaptively allocate token pruning budgets. To facilitate evaluation, we construct EventBench, the first event-inclusive, human-annotated multimodal benchmark that covers diverse real-world scenarios. Beyond physical event cameras, EventSTU also supports general video understanding using simulated events. Comprehensive experiments show that EventSTU achieves 3.01x FLOPs reduction and 3.10x prefilling speedup over the strongest baseline while still improving performance.","authors":["Wenhao Xu","Xin Dong","Yue Li","Haoyuan Shi","Zhiwei Xiong"],"pdf_url":"","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.18919v1","updated":"2025-11-24T09:29:30Z","published":"2025-11-24T09:29:30Z","title":"Learning What to Trust: Bayesian Prior-Guided Optimization for Visual Generation","summary":"Group Relative Policy Optimization (GRPO) has emerged as an effective and lightweight framework for post-training visual generative models. However, its performance is fundamentally limited by the ambiguity of textual visual correspondence: a single prompt may validly describe diverse visual outputs, and a single image or video may support multiple equally correct interpretations. This many to many relationship leads reward models to generate uncertain and weakly discriminative signals, causing GRPO to underutilize reliable feedback and overfit noisy ones. We introduce Bayesian Prior-Guided Optimization (BPGO), a novel extension of GRPO that explicitly models reward uncertainty through a semantic prior anchor. BPGO adaptively modulates optimization trust at two levels: inter-group Bayesian trust allocation emphasizes updates from groups consistent with the prior while down-weighting ambiguous ones, and intra-group prior-anchored renormalization sharpens sample distinctions by expanding confident deviations and compressing uncertain scores. Across both image and video generation tasks, BPGO delivers consistently stronger semantic alignment, enhanced perceptual fidelity, and faster convergence than standard GRPO and recent variants.","authors":["Ruiying Liu","Yuanzhi Liang","Haibin Huang","Tianshu Yu","Chi Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2103.02211v2","updated":"2025-11-24T09:20:42Z","published":"2021-03-03T06:50:33Z","title":"K-FACE: A Large-Scale KIST Face Database in Consideration with Unconstrained Environments","summary":"In this paper, we introduce a new large-scale face database from KIST, denoted as K-FACE, and describe a novel capturing device specifically designed to obtain the data. The K-FACE database contains more than 1 million high-quality images of 1,000 subjects selected by considering the ratio of gender and age groups. It includes a variety of attributes, including 27 poses, 35 lighting conditions, three expressions, and occlusions by the combination of five types of accessories. As the K-FACE database is systematically constructed through a hemispherical capturing system with elaborate lighting control and multiple cameras, it is possible to accurately analyze the effects of factors that cause performance degradation, such as poses, lighting changes, and accessories. We consider not only the balance of external environmental factors, such as pose and lighting, but also the balance of personal characteristics such as gender and age group. The gender ratio is the same, while the age groups of subjects are uniformly distributed from the 20s to 50s for both genders. The K-FACE database can be extensively utilized in various vision tasks, such as face recognition, face frontalization, illumination normalization, face age estimation, and three-dimensional face model generation. We expect systematic diversity and uniformity of the K-FACE database to promote these research fields.","authors":["Yeji Choi","Hyunjung Park","Gi Pyo Nam","Haksub Kim","Heeseung Choi","Junghyun Cho","Ig-Jae Kim"],"pdf_url":"","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2404.01064v4","updated":"2025-11-24T09:12:46Z","published":"2024-04-01T11:57:34Z","title":"Roadside Monocular 3D Detection Prompted by 2D Detection","summary":"Roadside monocular 3D detection requires detecting objects of predefined classes in an RGB frame and predicting their 3D attributes, such as bird's-eye-view (BEV) locations. It has broad applications in traffic control, vehicle-vehicle communication, and vehicle-infrastructure cooperative perception. To address this task, we introduce Promptable 3D Detector (Pro3D), a novel detector design that leverages 2D detections as prompts. We build our Pro3D upon two key insights. First, compared to a typical 3D detector, a 2D detector is ``easier'' to train due to fewer loss terms and performs significantly better at localizing objects w.r.t 2D metrics. Second, once 2D detections precisely locate objects in the image, a 3D detector can focus on lifting these detections into 3D BEV, especially when fixed camera pose or scene geometry provide an informative prior. To encode and incorporate 2D detections, we explore three methods: (a) concatenating features from both 2D and 3D detectors, (b) attentively fusing 2D and 3D detector features, and (c) encoding properties of predicted 2D bounding boxes \\{$x$, $y$, width, height, label\\} and attentively fusing them with the 3D detector feature. Interestingly, the third method significantly outperforms the others, underscoring the effectiveness of 2D detections as prompts that offer precise object targets and allow the 3D detector to focus on lifting them into 3D. Pro3D is adaptable for use with a wide range of 2D and 3D detectors with minimal modifications. Comprehensive experiments demonstrate that our Pro3D significantly enhances existing methods, achieving state-of-the-art results on two contemporary benchmarks.","authors":["Yechi Ma","Yanan Li","Wei Hua","Shu Kong"],"pdf_url":"","comment":"Accepted by WACV 2026"},{"id":"http://arxiv.org/abs/2511.18900v1","updated":"2025-11-24T08:58:14Z","published":"2025-11-24T08:58:14Z","title":"MatMart: Material Reconstruction of 3D Objects via Diffusion","summary":"Applying diffusion models to physically-based material estimation and generation has recently gained prominence. In this paper, we propose \\ttt, a novel material reconstruction framework for 3D objects, offering the following advantages. First, \\ttt\\ adopts a two-stage reconstruction, starting with accurate material prediction from inputs and followed by prior-guided material generation for unobserved views, yielding high-fidelity results. Second, by utilizing progressive inference alongside the proposed view-material cross-attention (VMCA), \\ttt\\ enables reconstruction from an arbitrary number of input images, demonstrating strong scalability and flexibility. Finally, \\ttt\\ achieves both material prediction and generation capabilities through end-to-end optimization of a single diffusion model, without relying on additional pre-trained models, thereby exhibiting enhanced stability across various types of objects. Extensive experiments demonstrate that \\ttt\\ achieves superior performance in material reconstruction compared to existing methods.","authors":["Xiuchao Wu","Pengfei Zhu","Jiangjing Lyu","Xinguo Liu","Jie Guo","Yanwen Guo","Weiwei Xu","Chengfei Lyu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.02916v2","updated":"2025-11-24T08:57:24Z","published":"2025-03-04T11:07:27Z","title":"Monocular Person Localization under Camera Ego-motion","summary":"Localizing a person from a moving monocular camera is critical for Human-Robot Interaction (HRI). To estimate the 3D human position from a 2D image, existing methods either depend on the geometric assumption of a fixed camera or use a position regression model trained on datasets containing little camera ego-motion. These methods are vulnerable to severe camera ego-motion, resulting in inaccurate person localization. We consider person localization as a part of a pose estimation problem. By representing a human with a four-point model, our method jointly estimates the 2D camera attitude and the person's 3D location through optimization. Evaluations on both public datasets and real robot experiments demonstrate our method outperforms baselines in person localization accuracy. Our method is further implemented into a person-following system and deployed on an agile quadruped robot.","authors":["Yu Zhan","Hanjing Ye","Hong Zhang"],"pdf_url":"","comment":"Accepted by IROS2025. Project page: https://medlartea.github.io/rpf-quadruped/"},{"id":"http://arxiv.org/abs/2511.18894v1","updated":"2025-11-24T08:51:02Z","published":"2025-11-24T08:51:02Z","title":"MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting","summary":"Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy ground-truth labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg consistently outperforms existing state-of-the-art methods.","authors":["Chenyu Mu","Guihai Chen","Xun Yang","Erkun Yang","Cheng Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18888v1","updated":"2025-11-24T08:44:04Z","published":"2025-11-24T08:44:04Z","title":"MFmamba: A Multi-function Network for Panchromatic Image Resolution Restoration Based on State-Space Model","summary":"Remote sensing images are becoming increasingly widespread in military, earth resource exploration. Because of the limitation of a single sensor, we can obtain high spatial resolution grayscale panchromatic (PAN) images and low spatial resolution color multispectral (MS) images. Therefore, an important issue is to obtain a color image with high spatial resolution when there is only a PAN image at the input. The existing methods improve spatial resolution using super-resolution (SR) technology and spectral recovery using colorization technology. However, the SR technique cannot improve the spectral resolution, and the colorization technique cannot improve the spatial resolution. Moreover, the pansharpening method needs two registered inputs and can not achieve SR. As a result, an integrated approach is expected. To solve the above problems, we designed a novel multi-function model (MFmamba) to realize the tasks of SR, spectral recovery, joint SR and spectral recovery through three different inputs. Firstly, MFmamba utilizes UNet++ as the backbone, and a Mamba Upsample Block (MUB) is combined with UNet++. Secondly, a Dual Pool Attention (DPA) is designed to replace the skip connection in UNet++. Finally, a Multi-scale Hybrid Cross Block (MHCB) is proposed for initial feature extraction. Many experiments show that MFmamba is competitive in evaluation metrics and visual results and performs well in the three tasks when only the input PAN image is used.","authors":["Qian Jiang","Qianqian Wang","Xin Jin","Michal Wozniak","Shaowen Yao","Wei Zhou"],"pdf_url":"","comment":"9 pages, 9 figures. This paper has been accepted for publication in AAAI-2026"},{"id":"http://arxiv.org/abs/2511.18886v1","updated":"2025-11-24T08:41:28Z","published":"2025-11-24T08:41:28Z","title":"MagicWorld: Interactive Geometry-driven Video World Exploration","summary":"Recent interactive video world model methods generate scene evolution conditioned on user instructions. Although they achieve impressive results, two key limitations remain. First, they fail to fully exploit the correspondence between instruction-driven scene motion and the underlying 3D geometry, which results in structural instability under viewpoint changes. Second, they easily forget historical information during multi-step interaction, resulting in error accumulation and progressive drift in scene semantics and structure. To address these issues, we propose MagicWorld, an interactive video world model that integrates 3D geometric priors and historical retrieval. MagicWorld starts from a single scene image, employs user actions to drive dynamic scene evolution, and autoregressively synthesizes continuous scenes. We introduce the Action-Guided 3D Geometry Module (AG3D), which constructs a point cloud from the first frame of each interaction and the corresponding action, providing explicit geometric constraints for viewpoint transitions and thereby improving structural consistency. We further propose History Cache Retrieval (HCR) mechanism, which retrieves relevant historical frames during generation and injects them as conditioning signals, helping the model utilize past scene information and mitigate error accumulation. Experimental results demonstrate that MagicWorld achieves notable improvements in scene stability and continuity across interaction iterations.","authors":["Guangyuan Li","Siming Zheng","Shuolin Xu","Jinwei Chen","Bo Li","Xiaobin Hu","Lei Zhao","Peng-Tao Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18882v1","updated":"2025-11-24T08:37:35Z","published":"2025-11-24T08:37:35Z","title":"Facade Segmentation for Solar Photovoltaic Suitability","summary":"Building integrated photovoltaic (BIPV) facades represent a promising pathway towards urban decarbonization, especially where roof areas are insufficient and ground-mounted arrays are infeasible. Although machine learning-based approaches to support photovoltaic (PV) planning on rooftops are well researched, automated approaches for facades still remain scarce and oversimplified. This paper therefore presents a pipeline that integrates detailed information on the architectural composition of the facade to automatically identify suitable surfaces for PV application and estimate the solar energy potential. The pipeline fine-tunes SegFormer-B5 on the CMP Facades dataset and converts semantic predictions into facade-level PV suitability masks and PV panel layouts considering module sizes and clearances. Applied to a dataset of 373 facades with known dimensions from ten cities, the results show that installable BIPV potential is significantly lower than theoretical potential, thus providing valuable insights for reliable urban energy planning. With the growing availability of facade imagery, the proposed pipeline can be scaled to support BIPV planning in cities worldwide.","authors":["Ayca Duran","Christoph Waibel","Bernd Bickel","Iro Armeni","Arno Schlueter"],"pdf_url":"","comment":"NeurIPS 2025 Tackling Climate Change with Machine Learning Workshop version. Non-archival"},{"id":"http://arxiv.org/abs/2511.18875v1","updated":"2025-11-24T08:29:36Z","published":"2025-11-24T08:29:36Z","title":"Parallel Vision Token Scheduling for Fast and Accurate Multimodal LMMs Inference","summary":"Multimodal large language models (MLLMs) deliver impressive vision-language reasoning but suffer steep inference latency because self-attention scales quadratically with sequence length and thousands of visual tokens contributed by high-resolution images. Naively pruning less-informative visual tokens reduces this burden, yet indiscriminate removal can strip away contextual cues essential for background or fine-grained questions, undermining accuracy. In this paper, we present ParVTS (Parallel Vision Token Scheduling), a training-free scheduling framework that partitions visual tokens into subject and non-subject groups, processes them in parallel to transfer their semantics into question tokens, and discards the non-subject path mid-inference to reduce computation. This scheduling reduces computational complexity, requires no heuristics or additional modules, and is compatible with diverse existing MLLM architectures. Experiments across multiple MLLM backbones show that ParVTS prunes up to 88.9% of visual tokens with minimal performance drop, achieving 1.77x speedup and 70% FLOPs reduction.","authors":["Wengyi Zhan","Mingbao Lin","Zhihang Lin","Rongrong Ji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18874v1","updated":"2025-11-24T08:28:42Z","published":"2025-11-24T08:28:42Z","title":"GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction","summary":"Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.","authors":["Yuzhi Chen","Yuanchang Xie","Lei Zhao","Pan Liu","Yajie Zou","Chen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.11443v2","updated":"2025-11-24T08:27:03Z","published":"2025-07-15T16:07:07Z","title":"COLI: A Hierarchical Efficient Compressor for Large Images","summary":"The escalating adoption of high-resolution, large-field-of-view imagery amplifies the need for efficient compression methodologies. Conventional techniques frequently fail to preserve critical image details, while data-driven approaches exhibit limited generalizability. Implicit Neural Representations (INRs) present a promising alternative by learning continuous mappings from spatial coordinates to pixel intensities for individual images, thereby storing network weights rather than raw pixels and avoiding the generalization problem. However, INR-based compression of large images faces challenges including slow compression speed and suboptimal compression ratios. To address these limitations, we introduce COLI (Compressor for Large Images), a novel framework leveraging Neural Representations for Videos (NeRV). First, recognizing that INR-based compression constitutes a training process, we accelerate its convergence through a pretraining-finetuning paradigm, mixed-precision training, and reformulation of the sequential loss into a parallelizable objective. Second, capitalizing on INRs' transformation of image storage constraints into weight storage, we implement Hyper-Compression, a novel post-training technique to substantially enhance compression ratios while maintaining minimal output distortion. Evaluations across two medical imaging datasets demonstrate that COLI consistently achieves competitive or superior PSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while accelerating NeRV training by up to 4 times.","authors":["Haoran Wang","Hanyu Pei","Yang Lyu","Kai Zhang","Li Li","Feng-Lei Fan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18873v1","updated":"2025-11-24T08:26:32Z","published":"2025-11-24T08:26:32Z","title":"Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction","summary":"3D Gaussian Splatting (3DGS) has emerged as a leading approach for high-quality novel view synthesis, with numerous variants extending its applicability to a broad spectrum of 3D and 4D scene reconstruction tasks. Despite its success, the representational capacity of 3DGS remains limited by the use of 3D Gaussian kernels to model local variations. Recent works have proposed to augment 3DGS with additional per-primitive capacity, such as per-splat textures, to enhance its expressiveness. However, these per-splat texture approaches primarily target dense novel view synthesis with a reduced number of Gaussian primitives, and their effectiveness tends to diminish when applied to more general reconstruction scenarios. In this paper, we aim to achieve concrete performance improvement over state-of-the-art 3DGS variants across a wide range of reconstruction tasks, including novel view synthesis, geometry and dynamic reconstruction, under both sparse and dense input settings. To this end, we introduce Neural Texture Splatting (NTS). At the core of our approach is a global neural field (represented as a hybrid of a tri-plane and a neural decoder) that predicts local appearance and geometric fields for each primitive. By leveraging this shared global representation that models local texture fields across primitives, we significantly reduce model size and facilitate efficient global information exchange, demonstrating strong generalization across tasks. Furthermore, our neural modeling of local texture fields introduces expressive view- and time-dependent effects, a critical aspect that existing methods fail to account for. Extensive experiments show that Neural Texture Splatting consistently improves models and achieves state-of-the-art results across multiple benchmarks.","authors":["Yiming Wang","Shaofei Wang","Marko Mihajlovic","Siyu Tang"],"pdf_url":"","comment":"SIGGRAPH Asia 2025 (conference track), Project page: https://19reborn.github.io/nts/"},{"id":"http://arxiv.org/abs/2509.23867v2","updated":"2025-11-24T08:22:15Z","published":"2025-09-28T13:21:10Z","title":"Sim-DETR: Unlock DETR for Temporal Sentence Grounding","summary":"Temporal sentence grounding aims to identify exact moments in a video that correspond to a given textual query, typically addressed with detection transformer (DETR) solutions. However, we find that typical strategies designed to enhance DETR do not improve, and may even degrade, its performance in this task. We systematically analyze and identify the root causes of this abnormal behavior: (1) conflicts between queries from similar target moments and (2) internal query conflicts due to the tension between global semantics and local localization. Building on these insights, we propose a simple yet powerful baseline, Sim-DETR, which extends the standard DETR with two minor modifications in the decoder layers: (1) constraining self-attention between queries based on their semantic and positional overlap and (2) adding query-to-frame alignment to bridge the global and local contexts. Experiments demonstrate that Sim-DETR unlocks the full potential of DETR for temporal sentence grounding, offering a strong baseline for future research.","authors":["Jiajin Tang","Zhengxuan Wei","Yuchen Zhu","Cheng Shi","Guanbin Li","Liang Lin","Sibei Yang"],"pdf_url":"","comment":"This work is accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2511.18870v1","updated":"2025-11-24T08:22:07Z","published":"2025-11-24T08:22:07Z","title":"HunyuanVideo 1.5 Technical Report","summary":"We present HunyuanVideo 1.5, a lightweight yet powerful open-source video generation model that achieves state-of-the-art visual quality and motion coherence with only 8.3 billion parameters, enabling efficient inference on consumer-grade GPUs. This achievement is built upon several key components, including meticulous data curation, an advanced DiT architecture featuring selective and sliding tile attention (SSTA), enhanced bilingual understanding through glyph-aware text encoding, progressive pre-training and post-training, and an efficient video super-resolution network. Leveraging these designs, we developed a unified framework capable of high-quality text-to-video and image-to-video generation across multiple durations and resolutions.Extensive experiments demonstrate that this compact and proficient model establishes a new state-of-the-art among open-source video generation models. By releasing the code and model weights, we provide the community with a high-performance foundation that lowers the barrier to video creation and research, making advanced video generation accessible to a broader audience. All open-source assets are publicly available at https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5.","authors":["Bing Wu","Chang Zou","Changlin Li","Duojun Huang","Fang Yang","Hao Tan","Jack Peng","Jianbing Wu","Jiangfeng Xiong","Jie Jiang"," Linus"," Patrol","Peizhen Zhang","Peng Chen","Penghao Zhao","Qi Tian","Songtao Liu","Weijie Kong","Weiyan Wang","Xiao He","Xin Li","Xinchi Deng","Xuefei Zhe","Yang Li","Yanxin Long","Yuanbo Peng","Yue Wu","Yuhong Liu","Zhenyu Wang","Zuozhuo Dai","Bo Peng","Coopers Li","Gu Gong","Guojian Xiao","Jiahe Tian","Jiaxin Lin","Jie Liu","Jihong Zhang","Jiesong Lian","Kaihang Pan","Lei Wang","Lin Niu","Mingtao Chen","Mingyang Chen","Mingzhe Zheng","Miles Yang","Qiangqiang Hu","Qi Yang","Qiuyong Xiao","Runzhou Wu","Ryan Xu","Rui Yuan","Shanshan Sang","Shisheng Huang","Siruis Gong","Shuo Huang","Weiting Guo","Xiang Yuan","Xiaojia Chen","Xiawei Hu","Wenzhi Sun","Xiele Wu","Xianshun Ren","Xiaoyan Yuan","Xiaoyue Mi","Yepeng Zhang","Yifu Sun","Yiting Lu","Yitong Li","You Huang","Yu Tang","Yixuan Li","Yuhang Deng","Yuan Zhou","Zhichao Hu","Zhiguang Liu","Zhihe Yang","Zilin Yang","Zhenzhi Lu","Zixiang Zhou","Zhao Zhong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.19161v2","updated":"2025-11-24T08:12:05Z","published":"2025-05-25T14:17:56Z","title":"Benchmarking Endoscopic Surgical Image Restoration and Beyond","summary":"In endoscopic surgery, a clear and high-quality visual field is critical for surgeons to make accurate intraoperative decisions. However, persistent visual degradation, including smoke generated by energy devices, lens fogging from thermal gradients, and lens contamination due to blood or tissue fluid splashes during surgical procedures, severely impairs visual clarity. These degenerations can seriously hinder surgical workflow and pose risks to patient safety. To systematically investigate and address various forms of surgical scene degradation, we introduce a real- world open-source surgical image restoration dataset covering endoscopic environments, called SurgClean, which involves multi-type image restoration tasks from two medical sites, i.e., desmoking, defogging, and desplashing. SurgClean comprises 3,113 images with diverse degradation types and corresponding paired reference labels. Based on SurgClean, we establish a standardized evaluation benchmark and provide performance for 22 representative generic task-specific image restoration approaches, including 12 generic and 10 task-specific image restoration approaches. Experimental results reveal substantial performance gaps relative to clinical requirements, highlighting a critical opportunity for algorithm advancements in intelligent surgical restoration. Furthermore, we explore the degradation discrepancies between surgical and natural scenes from structural perception and semantic under- standing perspectives, providing fundamental insights for domain-specific image restoration research. Our work aims to empower restoration algorithms and improve the efficiency of clinical procedures.","authors":["Jialun Pei","Diandian Guo","Donghui Yang","Zhixi Li","Yuxin Feng","Long Ma","Bo Du","Pheng-Ann Heng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18865v1","updated":"2025-11-24T08:08:22Z","published":"2025-11-24T08:08:22Z","title":"DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection","summary":"Recent salient object detection (SOD) methods aim to improve performance in four key directions: semantic enhancement, boundary refinement, auxiliary task supervision, and multi-modal fusion. In pursuit of continuous gains, these approaches have evolved toward increasingly sophisticated architectures with multi-stage pipelines, specialized fusion modules, edge-guided learning, and elaborate attention mechanisms. However, this complexity paradoxically introduces feature redundancy and cross-component interference that obscure salient cues, ultimately reaching performance bottlenecks. In contrast, human vision achieves efficient salient object identification without such architectural complexity. This contrast raises a fundamental question: can we design a biologically grounded yet architecturally simple SOD framework that dispenses with most of this engineering complexity, while achieving state-of-the-art accuracy, computational efficiency, and interpretability? In this work, we answer this question affirmatively by introducing DualGazeNet, a biologically inspired pure Transformer framework that models the dual biological principles of robust representation learning and magnocellular-parvocellular dual-pathway processing with cortical attention modulation in the human visual system. Extensive experiments on five RGB SOD benchmarks show that DualGazeNet consistently surpasses 25 state-of-the-art CNN- and Transformer-based methods. On average, DualGazeNet achieves about 60\\% higher inference speed and 53.4\\% fewer FLOPs than four Transformer-based baselines of similar capacity (VST++, MDSAM, Sam2unet, and BiRefNet). Moreover, DualGazeNet exhibits strong cross-domain generalization, achieving leading or highly competitive performance on camouflaged and underwater SOD benchmarks without relying on additional modalities.","authors":["Yu Zhang","Haoan Ping","Yuchen Li","Zhenshan Bing","Fuchun Sun","Alois Knoll"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.21783v4","updated":"2025-11-24T07:59:44Z","published":"2025-09-26T02:39:40Z","title":"Prompt-guided Disentangled Representation for Action Recognition","summary":"Action recognition is a fundamental task in video understanding. Existing methods typically extract unified features to process all actions in one video, which makes it challenging to model the interactions between different objects in multi-action scenarios. To alleviate this issue, we explore disentangling any specified actions from complex scenes as an effective solution. In this paper, we propose Prompt-guided Disentangled Representation for Action Recognition (ProDA), a novel framework that disentangles any specified actions from a multi-action scene. ProDA leverages Spatio-temporal Scene Graphs (SSGs) and introduces Dynamic Prompt Module (DPM) to guide a Graph Parsing Neural Network (GPNN) in generating action-specific representations. Furthermore, we design a video-adapted GPNN that aggregates information using dynamic weights. Experiments in video action recognition demonstrate the effectiveness of our approach when compared with the state-of-the-art methods. Our code can be found in https://github.com/iamsnaping/ProDA.git","authors":["Tianci Wu","Guangming Zhu","Jiang Lu","Siyuan Wang","Ning Wang","Nuoye Xiong","Zhang Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16712v2","updated":"2025-11-24T07:58:20Z","published":"2025-11-20T08:56:46Z","title":"PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation","summary":"Personalized dual-person portrait customization has considerable potential applications, such as preserving emotional memories and facilitating wedding photography planning. However, the absence of a benchmark dataset hinders the pursuit of high-quality customization in dual-person portrait generation. In this paper, we propose the PairHuman dataset, which is the first large-scale benchmark dataset specifically designed for generating dual-person portraits that meet high photographic standards. The PairHuman dataset contains more than 100K images that capture a variety of scenes, attire, and dual-person interactions, along with rich metadata, including detailed image descriptions, person localization, human keypoints, and attribute tags. We also introduce DHumanDiff, which is a baseline specifically crafted for dual-person portrait generation that features enhanced facial consistency and simultaneously balances in personalized person generation and semantic-driven scene creation. Finally, the experimental results demonstrate that our dataset and method produce highly customized portraits with superior visual quality that are tailored to human preferences. Our dataset is publicly available at https://github.com/annaoooo/PairHuman.","authors":["Ting Pan","Ye Wang","Peiguang Jing","Rui Ma","Zili Yi","Yu Liu"],"pdf_url":"","comment":"46 pages, 31 figures"},{"id":"http://arxiv.org/abs/2502.17852v3","updated":"2025-11-24T07:57:57Z","published":"2025-02-25T04:58:17Z","title":"Sketch-1-to-3: One Single Sketch to 3D Detailed Face Reconstruction","summary":"3D face reconstruction from a single sketch is a critical yet underexplored task with significant practical applications. The primary challenges stem from the substantial modality gap between 2D sketches and 3D facial structures, including: (1) accurately extracting facial keypoints from 2D sketches; (2) preserving diverse facial expressions and fine-grained texture details; and (3) training a high-performing model with limited data. In this paper, we propose Sketch-1-to-3, a novel framework for realistic 3D face reconstruction from a single sketch, to address these challenges. Specifically, we first introduce the Geometric Contour and Texture Detail (GCTD) module, which enhances the extraction of geometric contours and texture details from facial sketches. Additionally, we design a deep learning architecture with a domain adaptation module and a tailored loss function to align sketches with the 3D facial space, enabling high-fidelity expression and texture reconstruction. To facilitate evaluation and further research, we construct SketchFaces, a real hand-drawn facial sketch dataset, and Syn-SketchFaces, a synthetic facial sketch dataset. Extensive experiments demonstrate that Sketch-1-to-3 achieves state-of-the-art performance in sketch-based 3D face reconstruction.","authors":["Liting Wen","Zimo Yang","Xianlin Zhang","Chi Ding","Mingdao Wang","Xueming Li"],"pdf_url":"","comment":"Accepted by ACM MMAsia 2025"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2511.19421v1","updated":"2025-11-24T18:56:27Z","published":"2025-11-24T18:56:27Z","title":"Data driven synthesis of provable invariant sets via stochastically sampled data","summary":"Positive invariant (PI) sets are essential for ensuring safety, i.e. constraint adherence, of dynamical systems. With the increasing availability of sampled data from complex (and often unmodeled) systems, it is advantageous to leverage these data sets for PI set synthesis. This paper uses data driven geometric conditions of invariance to synthesize PI sets from data. Where previous data driven, set-based approaches to PI set synthesis used deterministic sampling schemes, this work instead synthesizes PI sets from any pre-collected data sets. Beyond a data set and Lipschitz continuity, no additional information about the system is needed. A tree data structure is used to partition the space and select samples used to construct the PI set, while Lipschitz continuity is used to provide deterministic guarantees of invariance. Finally, probabilistic bounds are given on the number of samples needed for the algorithm to determine of a certain volume.","authors":["Amy K. Strong","Ali Kashani","Claus Danielson","Leila Bridgeman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.02912v4","updated":"2025-11-24T18:31:13Z","published":"2025-08-04T21:29:07Z","title":"Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination with Embodied World Models","summary":"Robust coordination is critical for effective decision-making in multi-agent systems, especially under partial observability. A central question in Multi-Agent Reinforcement Learning (MARL) is whether to engineer communication protocols or learn them end-to-end. We investigate this dichotomy using embodied world models. We propose and compare two communication strategies for a cooperative task-allocation problem. The first, Learned Direct Communication (LDC), learns a protocol end-to-end. The second, Intention Communication, uses an engineered inductive bias: a compact, learned world model, the Imagined Trajectory Generation Module (ITGM), which uses the agent's own policy to simulate future states. A Message Generation Network (MGN) then compresses this plan into a message. We evaluate these approaches on goal-directed interaction in a grid world, a canonical abstraction for embodied AI problems, while scaling environmental complexity. Our experiments reveal that while emergent communication is viable in simple settings, the engineered, world model-based approach shows superior performance, sample efficiency, and scalability as complexity increases. These findings advocate for integrating structured, predictive models into MARL agents to enable active, goal-driven coordination.","authors":["Brennen A. Hill","Mant Koh En Wei","Thangavel Jishnuanandh"],"pdf_url":"","comment":"Published in the Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments for Agents (SEA). Additionally accepted for presentation in the NeurIPS 2025 Workshop: Embodied World Models for Decision Making (EWM) and the NeurIPS 2025 Workshop: Optimization for Machine Learning (OPT)"},{"id":"http://arxiv.org/abs/2511.19383v1","updated":"2025-11-24T18:22:00Z","published":"2025-11-24T18:22:00Z","title":"A Hybrid Learning-to-Optimize Framework for Mixed-Integer Quadratic Programming","summary":"In this paper, we propose a learning-to-optimize (L2O) framework to accelerate solving parametric mixed-integer quadratic programming (MIQP) problems, with a particular focus on mixed-integer model predictive control (MI-MPC) applications. The framework learns to predict integer solutions with enhanced optimality and feasibility by integrating supervised learning (for optimality), self-supervised learning (for feasibility), and a differentiable quadratic programming (QP) layer, resulting in a hybrid L2O framework. Specifically, a neural network (NN) is used to learn the mapping from problem parameters to optimal integer solutions, while a differentiable QP layer is integrated to compute the corresponding continuous variables given the predicted integers and problem parameters. Moreover, a hybrid loss function is proposed, which combines a supervised loss with respect to the global optimal solution, and a self-supervised loss derived from the problem's objective and constraints. The effectiveness of the proposed framework is demonstrated on two benchmark MI-MPC problems, with comparative results against purely supervised and self-supervised learning models.","authors":["Viet-Anh Le","Mu Xie","Rahul Mangharam"],"pdf_url":"","comment":"submitted to L4DC 2026"},{"id":"http://arxiv.org/abs/2511.19336v1","updated":"2025-11-24T17:33:58Z","published":"2025-11-24T17:33:58Z","title":"Nonlinear MPC for Feedback-Interconnected Systems: a Suboptimal and Reduced-Order Model Approach","summary":"In this paper, we propose a suboptimal and reduced-order Model Predictive Control (MPC) architecture for discrete-time feedback-interconnected systems. The numerical MPC solver: (i) acts suboptimally, performing only a finite number of optimization iterations at each sampling instant, and (ii) relies only on a reduced-order model that neglects part of the system dynamics, either due to unmodeled effects or the presence of a low-level compensator. We prove that the closed-loop system resulting from the interconnection of the suboptimal and reduced-order MPC optimizer with the full-order plant has a globally exponentially stable equilibrium point. Specifically, we employ timescale separation arguments to characterize the interaction between the components of the feedback-interconnected system. The analysis relies on an appropriately tuned timescale parameter accounting for how fast the system dynamics are sampled. The theoretical results are validated through numerical simulations on a mechatronic system consisting of a pendulum actuated by a DC motor.","authors":["Stefano Di Gregorio","Guido Carnevale","Giuseppe Notarstefano"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19327v1","updated":"2025-11-24T17:20:25Z","published":"2025-11-24T17:20:25Z","title":"Dynamic Leader-Follower Consensus with Adversaries: A Multi-Hop Relay Approach","summary":"This paper examines resilient dynamic leader-follower consensus within multi-agent systems, where agents share first-order or second-order dynamics. The aim is to develop distributed protocols enabling nonfaulty/normal followers to accurately track a dynamic/time-varying reference value of the leader while they may receive misinformation from adversarial neighbors. Our methodologies employ the mean subsequence reduced algorithm with agents engaging with neighbors using multi-hop communication. We accordingly derive a necessary and sufficient graph condition for our algorithms to succeed; also, our tracking error bounds are smaller than that of the existing method. Furthermore, it is emphasized that even when agents do not use relays, our condition is tighter than the sufficient conditions in the literature. With multi-hop relays, we can further obtain more relaxed graph requirements. Finally, we present numerical examples to verify the effectiveness of our algorithms.","authors":["Liwei Yuan","Hideaki Ishii"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2503.22601v2","updated":"2025-11-24T16:35:43Z","published":"2025-03-28T16:44:39Z","title":"Neural Identification of Feedback-Stabilized Nonlinear Systems","summary":"Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.","authors":["Mahrokh G. Boroujeni","Laura Meroi","Leonardo Massai","Clara L. Galimberti","Giancarlo Ferrari-Trecate"],"pdf_url":"","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.19287v1","updated":"2025-11-24T16:34:50Z","published":"2025-11-24T16:34:50Z","title":"Innovative Modular Design and Kinematic Approach based on Screw Theory for Triple Scissors Links Deployable Space Antenna Mechanism","summary":"This paper presents the geometry design and analysis of a novel triple scissors links deployable antenna mechanism (TSDAM) to deal with the problems of large aperture and high precision space antennas for deep space communication and Earth observation. This mechanism has only one degree of freedom (DoF) and thus makes for efficient and reliable deployment without loss of structural integrity. It employed a systematic design approach starting from a triple scissors links modular unit to a 25m aperture assembly. Different configurations constituting variable numbers of modular units were analyzed in SolidWorks to identify the deployable mechanism with lowest deformation. While the 24 units configuration offered superior stowage compactness, it exhibited higher deformation (0.01437mm), confirming the 12 units configuration as the optimal balance between structural stability and deployment efficiency. Screw theory was employed to analyze the kinematic properties, and numerical simulations were performed in MATLAB and SolidWorks. The deployable space antenna showed transition from stowed to fully deployed state in just 53 seconds with high stability throughout the deployment process. The TSDAM attained a storage ratio of up to 15.3 for height and volume with 0.01048mm of deformation for a 12 units configuration. Mesh convergence analysis proved the consistency of the simulation results for 415314 tetrahedral shaped elements. The virtual experiments in SolidWorks verified the analytical Screw theory based model and ensured that the design was smooth and flexible for deployment in operational conditions. The research establishes a robust design framework for future deployable antennas, offering enhanced performance, simplified structure, and improved reliability","authors":["Mamoon Aamir","Mariyam Sattar","Naveed Ur Rehman Junejo","Aqsa Zafar Abbasi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19231v1","updated":"2025-11-24T15:43:55Z","published":"2025-11-24T15:43:55Z","title":"Data-driven certificates of constraint enforcement and stability for unmodeled, discrete dynamical systems using tree data structures","summary":"This paper addresses the critical challenge of developing data-driven certificates for the stability and safety of unmodeled dynamical systems by leveraging a tree data structure and an upper bound of the system's Lipschitz constant. Previously, an invariant set was synthesized by iteratively expanding an initial invariant set. In contrast, this work iteratively prunes the constraint set to synthesize an invariant set -- eliminating the need for a known, initial invariant set. Furthermore, we provide stability assurances by characterizing the asymptotic stability of the system relative to an invariant approximation of the minimal positive invariant set through synthesis of a discontinuous piecewise affine Lyapunov function over the computed invariant set. The proposed method takes inspiration from subdivision techniques and requires no prior system knowledge beyond Lipschitz continuity.","authors":["Amy K. Strong","Ali Kashani","Claus Danielson","Leila J. Bridgeman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.10390v2","updated":"2025-11-24T15:30:21Z","published":"2024-08-19T20:19:00Z","title":"Self-Refined Generative Foundation Models for Wireless Traffic Prediction","summary":"With a broad range of emerging applications in 6G networks, wireless traffic prediction has become a critical component of network management. However, the dynamically shifting distribution of wireless traffic in non-stationary 6G networks presents significant challenges to achieving accurate and stable predictions. Motivated by recent advancements in Generative AI (GenAI)-enabled 6G networks, this paper proposes a novel self-refined Large Language Model (LLM) for wireless traffic prediction, namely TrafficLLM, through in-context learning without parameter fine-tuning or model training. The proposed TrafficLLM harnesses the powerful few-shot learning abilities of LLMs to enhance the scalability of traffic prediction in dynamically changing wireless environments. Specifically, our proposed TrafficLLM embraces an LLM to iteratively refine its predictions through a three-step process: traffic prediction, feedback generation, and prediction refinement. Initially, the proposed TrafficLLM conducts traffic predictions using task-specific demonstration prompts. Recognizing that LLMs may generate incorrect predictions on the first attempt, this paper designs feedback demonstration prompts to provide multifaceted and valuable feedback related to these initial predictions. The validation scheme is further incorporated to systematically enhance the accuracy of mathematical calculations during the feedback generation process. Following this comprehensive feedback, our proposed TrafficLLM introduces refinement demonstration prompts, enabling the same LLM to further refine its predictions and thereby enhance prediction performance. Evaluations on two realistic datasets demonstrate that the proposed TrafficLLM outperforms LLM-based in-context learning methods, achieving performance improvements of 23.17% and 17.09%, respectively.","authors":["Chengming Hu","Hao Zhou","Di Wu","Xi Chen","Jun Yan","Xue Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.13223v3","updated":"2025-11-24T15:19:30Z","published":"2025-03-17T14:36:08Z","title":"Distributionally Robust Free Energy Principle for Decision-Making","summary":"Despite their groundbreaking performance, autonomous agents can misbehave when training and environmental conditions become inconsistent, with minor mismatches leading to undesirable behaviors or even catastrophic failures. Robustness towards these training-environment ambiguities is a core requirement for intelligent agents and its fulfillment is a long-standing challenge towards their real-world deployments. Here, we introduce a Distributionally Robust Free Energy model (DR-FREE) that instills this core property by design. Combining a robust extension of the free energy principle with a resolution engine, DR-FREE wires robustness into the agent decision-making mechanisms. Across benchmark experiments, DR-FREE enables the agents to complete the task even when, in contrast, state-of-the-art models fail. This milestone may inspire both deployments in multi-agent settings and, at a perhaps deeper level, the quest for an explanation of how natural agents -- with little or no training -- survive in capricious environments.","authors":["Allahkaram Shafiei","Hozefa Jesawada","Karl Friston","Giovanni Russo"],"pdf_url":"","comment":"Contains main text and supplementary information. Supplementary movie is at the paper repository"},{"id":"http://arxiv.org/abs/2511.19204v1","updated":"2025-11-24T15:15:01Z","published":"2025-11-24T15:15:01Z","title":"Reference-Free Sampling-Based Model Predictive Control","summary":"We present a sampling-based model predictive control (MPC) framework that enables emergent locomotion without relying on handcrafted gait patterns or predefined contact sequences. Our method discovers diverse motion patterns, ranging from trotting to galloping, robust standing policies, jumping, and handstand balancing, purely through the optimization of high-level objectives. Building on model predictive path integral (MPPI), we propose a dual-space spline parameterization that operates on position and velocity control points. Our approach enables contact-making and contact-breaking strategies that adapt automatically to task requirements, requiring only a limited number of sampled trajectories. This sample efficiency allows us to achieve real-time control on standard CPU hardware, eliminating the need for GPU acceleration typically required by other state-of-the-art MPPI methods. We validate our approach on the Go2 quadrupedal robot, demonstrating various emergent gaits and basic jumping capabilities. In simulation, we further showcase more complex behaviors, such as backflips, dynamic handstand balancing and locomotion on a Humanoid, all without requiring reference tracking or offline pre-training.","authors":["Fabian Schramm","Pierre Fabre","Nicolas Perrin-Gilbert","Justin Carpentier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19159v1","updated":"2025-11-24T14:26:15Z","published":"2025-11-24T14:26:15Z","title":"Decarbonization pathways for liquid fuels: A multi-sector energy system perspective","summary":"Low-carbon liquid fuels play a key role in energy system decarbonization scenarios. This study uses a multi-sector capacity expansion model of the contiguous United States to examine fuels production in deeply decarbonized energy systems. Our analysis evaluates how the shares of biofuels, synthetic fuels, and fossil liquid fuels change under varying assumptions about resource constraints (biomass and CO2 sequestration availability), fuel demand distributions, and supply flexibility to produce different fuel products. Across all scenarios examined, biofuels provide a substantial share of liquid fuel supply, while synthetic fuels deploy only when biomass or CO2 sequestration is assumed to be more limited. Fossil liquid fuels remain in all scenarios examined, primarily driven by the extent to which their emissions can be offset with removals. Limiting biomass increases biogenic CO2 capture within biofuel pathways, while limiting sequestration availability increases the share of captured atmospheric (including biogenic) carbon directed toward utilization for synthetic fuel production. While varying assumptions about liquid fuel demand distributions and fuel product supply flexibility alter competition among individual fuel production technologies, broader energy system outcomes are robust to these assumptions. Biomass and CO2 sequestration availability are key drivers of energy system outcomes in deeply decarbonized energy systems.","authors":["Jun Wen Law","Bryan K. Mignone","Dharik S. Mallapragada"],"pdf_url":"","comment":"Main text: 24 pages, 9 figures, 1 table. Supporting information (SI): 68 pages, 30 figures, 48 tables"},{"id":"http://arxiv.org/abs/2511.19143v1","updated":"2025-11-24T14:08:29Z","published":"2025-11-24T14:08:29Z","title":"Optimal policy design for innovation diffusion: shaping today's incentives for transforming the future","summary":"In this paper, we propose a new framework for the design of incentives aimed at promoting innovation diffusion in social influence networks. In particular, our framework relies on an extension of the Friedkin and Johnsen opinion dynamics model characterizing the effects of (i) short-memory incentives, which have an immediate yet transient impact, and (ii) long-term structural incentives, whose impact persists via an exponentially decaying memory. We propose to design these incentives via a model-predictive control (MPC) scheme over an augmented state that captures the memory in our opinion dynamics model, yielding a convex quadratic program with linear constraints. Our numerical simulations based on data on sustainable mobility habits show the effectiveness of the proposed approach, which balances large-scale adoption and resource allocation","authors":["Lisa Piccinin","Valentina Breschi","Chiara Ravazzi","Fabrizio Dabbene","Mara Tanelli"],"pdf_url":"","comment":"Submitted to IFAC World Congress 2026 and Control Engineering Practice"},{"id":"http://arxiv.org/abs/2511.19133v1","updated":"2025-11-24T13:58:52Z","published":"2025-11-24T13:58:52Z","title":"Directional Pinching-Antenna Systems","summary":"We propose a directional pinching-antenna system (DiPASS), a comprehensive framework that transitions PASS modeling from idealized abstraction to physical consistency. DiPASS introduces the first channel model that accurately captures the directional, pencil-like radiation of pinching antennas, incorporates a practical waveguide attenuation of 1.3 dB/m, and accounts for stochastic line-of-sight blockage. A key enabler of DiPASS is our new \"equal quota division\" power allocation strategy, which guarantees predetermined coupling lengths independent of antenna positions, thereby overcoming a critical barrier to practical deployment. Our analysis yields foundational insights: we derive closed-form solutions for optimal antenna placement and orientation in single-PA scenarios, quantifying the core trade-off between waveguide and free-space losses. For multi-PA systems, we develop a scalable optimization framework that leverages directional sparsity, revealing that waveguide diversity surpasses antenna density in enhancing system capacity. Extensive simulations validate our analysis and demonstrate that DiPASS provides a realistic performance benchmark, fundamentally reshaping the understanding and design principles for future PASS-enabled 6G networks.","authors":["Runxin Zhang","Yulin Shao","Yuanwei Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19084v1","updated":"2025-11-24T13:25:29Z","published":"2025-11-24T13:25:29Z","title":"PolyOCP.jl -- A Julia Package for Stochastic OCPs and MPC","summary":"The consideration of stochastic uncertainty in optimal and predictive control is a well-explored topic. Recently Polynomial Chaos Expansions (PCE) have seen a lot of considerations for problems involving stochastically uncertain system parameters and also for problems with additive stochastic i.i.d. disturbances. While there exist a number of open-source PCE toolboxes, tailored open-source codes for the solution of OCPs involving additive stochastic i.i.d. disturbances in julia are not available. Hence, this paper introduces the toolbox PolyOCP.jl which enables to efficiently solve stochastic OCPs for a large class of disturbance distributions. We explain the main mathematical concepts between the PCE transcription of stochastic OCPs and how they are provided in the toolbox. We draw upon two examples to illustrate the functionalities of PolyOCP.jl.","authors":["Ruchuan Ou","Learta Januzi","Jonas Schießl","Michael Heinrich Baumann","Lars Grüne","Timm Faulwasser"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19070v1","updated":"2025-11-24T13:05:59Z","published":"2025-11-24T13:05:59Z","title":"Impact Analysis of COVID-19 in Bangladesh Power Sector and Recommendations based on Practical Data and Machine Learning Approach","summary":"This paper investigates the impact of COVID-19 on the power sector in Bangladesh, how the country has dealt with it, and explores the path to stability. The study employs data visualisation and complex statistics to examine critical data about power systems in Bangladesh. This includes load patterns on a daily, monthly, annual, weekend, and weekday basis. Significant alterations in these patterns have been observed during our study e.g., in April and May of 2020, the power demand decreased by approximately 15.4% and 17.2%, respectively, compared to the corresponding period in 2019. We have used a Long-Short-Term Memory (LSTM) framework to predict the load profile of 2020 excluding COVID-19 effects. This model is compared with the actual load profile to determine the degree to which COVID-19 has impacted. The comparison indicates that the average power demand decreased by approximately 19.5% in April 2020 and 18.3% in May 2020, relative to its projected value. The study also investigates system stability by analyzing transmission loss and load factor, and the environmental effect by analyzing the Carbon Dioxide emission rate. Finally, the study provides recommendations for overcoming future disasters, such as developing more resilient power systems, investing in renewable energy, and improving energy efficiency.","authors":["Anis Ahmed","Arefin Ahamed Shuvo","Naruttam Kumar Roy","Neloy Prosad Bishnu","Ali Nasir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19055v1","updated":"2025-11-24T12:45:10Z","published":"2025-11-24T12:45:10Z","title":"Large Language Model-Assisted Planning of Electric Vehicle Charging Infrastructure with Real-World Case Study","summary":"The growing demand for electric vehicle (EV) charging infrastructure presents significant planning challenges, requiring efficient strategies for investment and operation to deliver cost-effective charging services. However, the potential benefits of EV charging assignment, particularly in response to varying spatial-temporal patterns of charging demand, remain under-explored in infrastructure planning. This paper proposes an integrated approach that jointly optimizes investment decisions and charging assignments while accounting for spatial-temporal demand dynamics and their interdependencies. To support efficient model development, we leverage a large language model (LLM) to assist in generating and refining the mathematical formulation from structured natural-language descriptions, significantly reducing the modeling burden. The resulting optimization model enables optimal joint decision-making for investment and operation. Additionally, we propose a distributed optimization algorithm based on the Alternating Direction Method of Multipliers (ADMM) to address computational complexity in high-dimensional scenarios, which can be executed on standard computing platforms. We validate our approach through a case study using 1.5 million real-world travel records from Chengdu, China, demonstrating a 30% reduction in total cost compared to a baseline without EV assignment.","authors":["Xinda Zheng","Canchen Jiang","Hao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18892v1","updated":"2025-11-24T08:49:29Z","published":"2025-11-24T08:49:29Z","title":"Semi-Passive IRS Enabled Sensing with Group Movable Sensors","summary":"The performance of the sensing system is limited by the signal attenuation and the number of receiving components. In this letter, we investigate the sensor position selection in a semi-passive intelligent reflecting surface (IRS) enabled non-line-of-sight (NLoS) sensing system. The IRS consists of passive elements and active sensors, where the sensors can receive and process the echo signal for direction-of-arrival (DoA) estimation. Motivated by the movable antenna array and fluid antenna system, we consider the case where the sensors are integrated into a group for movement and derive the corresponding Cramer-Rao bound (CRB). Then, the optimal solution for the positions of the movable sensors (MSs) to the CRB minimization problem is derived in closed form. Moreover, we characterize the relationship between the CRB and system parameters. Theoretical analysis and numerical results are provided to demonstrate the superiority of the proposed MS scheme over the fixed-position (FP) scheme.","authors":["Qiaoyan Peng","Qingqing Wu","Wen Chen","Guangji Chen","Ying Gao","Lexi Xu","Shaodan Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18800v1","updated":"2025-11-24T06:10:50Z","published":"2025-11-24T06:10:50Z","title":"Equivariant Tracking Control for Fully Actuated Mechanical Systems on Matrix Lie Groups","summary":"Mechanical control systems such as aerial, marine, space, and terrestrial robots often naturally admit a state-space that has the structure of a Lie group. The kinetic energy of such systems is commonly invariant to the induced action by the Lie group, and the system dynamics can be written as a coupled ordinary differential equation on the group and the dual space of its Lie algebra, termed a Lie-Poisson system. In this paper, we show that Lie-Poisson systems can also be written as a left-invariant system on a semi-direct Lie group structure placed on the trivialised cotangent bundle of the symmetry group. The authors do not know of a prior reference for this observation and we are confident the insight has never been exploited in the context of tracking control. We use this representation to build a right-invariant tracking error for the full state of a Lie-Poisson mechanical system and show that the error dynamics for this error are themselves of Lie-Poisson structure, albeit with time-varying inertia. This allows us to tackle the general trajectory tracking problem using an energy shaping design metholodology. To demonstrate the approach, we apply the proposed design methodology to a simple attitude tracking control.","authors":["Matthew Hampsey","Pieter van Goor","Ravi Banavar","Robert Mahony"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18768v1","updated":"2025-11-24T05:06:25Z","published":"2025-11-24T05:06:25Z","title":"Accelerated Transformer Energization Sequence for Inverter Based Resources in Black-Start Procedures with Active Flux Trajectory Manipulation in the Stationary Reference Frame","summary":"This paper proposes advanced soft-magnetization techniques to enable ultra-fast and reliable black-start of grid-forming (GFM) converters. Conventional hard-magnetization with well-established three-phase voltages during transformer energization induces severe inrush currents due to flux offset, which can damage power semiconductor devices. To overcome this drawback, an ultra-fast soft-magnetization method is firstly introduced, leveraging the voltage programmability of the inverter to actively reshape the initial voltage profile and thereby eliminate flux offset of the transformer core. By suppressing the formation of flux offset itself, the proposed approach prevents magnetic saturation and achieves nominal terminal voltage within a few milliseconds while effectively suppressing inrush current. However, this method can still trigger surge currents to power semiconductor devices in the presence of an LC filter due to abrupt voltage magnitude and phase transitions. To address this issue, an enhanced Archimedean spiral soft-magnetization method is developed, where both voltage magnitude and phase evolve smoothly to simultaneously suppress inrush and surge currents. Furthermore, residual flux in the transformer core is considered, and a demagnetization sequence using the inverter is validated to ensure reliable start-up. Experimental results confirm that the proposed methods achieve rapid black-start performance within one fundamental cycle while ensuring safe and stable operation of GFM converters.","authors":["Jiyu Lee","Shenghui Cui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18748v1","updated":"2025-11-24T04:20:49Z","published":"2025-11-24T04:20:49Z","title":"Evaluation of Real-Time Mitigation Techniques for Cyber Security in IEC 61850 / IEC 62351 Substations","summary":"The digitalization of substations enlarges the cyber-attack surface, necessitating effective detection and mitigation of cyber attacks in digital substations. While machine learning-based intrusion detection has been widely explored, such methods have not demonstrated detection and mitigation within the required real-time budget. In contrast, cryptographic authentication has emerged as a practical candidate for real-time cyber defense, as specified in IEC 62351. In addition, lightweight rule-based intrusion detection that validates IEC 61850 semantics can provide specification-based detection of anomalous or malicious traffic with minimal processing delay. This paper presents the design logic and implementation aspects of three potential real-time mitigation techniques capable of countering GOOSE-based attacks: (i) IEC 62351-compliant message authentication code (MAC) scheme, (ii) a semantics-enforced rule-based intrusion detection system (IDS), and (iii) a hybrid approach integrating both MAC verification and Intrusion Detection System (IDS). A comparative evaluation of these real-time mitigation approaches is conducted using a cyber-physical system (CPS) security testbed. The results show that the hybrid integration significantly enhances mitigation capability. Furthermore, the processing delays of all three methods remain within the strict delivery requirements of GOOSE communication. The study also identifies limitations that none of the techniques can fully address, highlighting areas for future work.","authors":["Akila Herath","Chen-Ching Liu","Junho Hong","Kuchan Park"],"pdf_url":"","comment":"CIGRE USNC Grid of the Future Symposium 2025"},{"id":"http://arxiv.org/abs/2511.19770v1","updated":"2025-11-24T22:54:59Z","published":"2025-11-24T22:54:59Z","title":"Multi-Hypotheses Ego-Tracking for Resilient Navigation","summary":"Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vul- nerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identi- fication and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks","authors":["Peter Iwer Hoedt Karstensen","Roberto Galeazzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19745v1","updated":"2025-11-24T22:04:14Z","published":"2025-11-24T22:04:14Z","title":"Joint Satellite Power Consumption and Handover Optimization for LEO Constellations","summary":"In satellite constellation-based communication systems, continuous user coverage requires frequent handoffs due to the dynamic topology induced by the Low Earth Orbit (LEO) satellites. Each handoff between a satellite and ground users introduces additional signaling and power consumption, which can become a significant burden as the size of the constellation continues to increase. This work focuses on the optimization of the total transmission rate in a LEO-to-user system, by jointly considering the total transmitted power, user-satellite associations, and power consumption, the latter being handled through a penalty on handoff events. We consider a system where LEO satellites serve users located in remote areas with no terrestrial connectivity, and formulate the power allocation problem as a mixed-integer concave linear program (MICP) subject to power and association constraints. Our approach can be solved with off-the-shelf solvers and is benchmarked against a naive baseline where users associate to their closest visible satellite. Extensive Monte Carlo simulations demonstrate the effectiveness of the proposed method in controlling the handoff frequency while maintaining high user throughput. These performance gains highlight the effectiveness of our handover-aware optimization strategy, which ensures that user rates improve significantly, by about 40%, without incurring a disproportionate rise in the handoff frequency.","authors":["Yassine Afif","Mohammed Almekhlafi","Antoine Lesage-Landry","Gunes Karabulut Kurt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11811v2","updated":"2025-11-24T21:49:38Z","published":"2025-11-14T19:04:52Z","title":"Lessons Learned from Developing a Privacy-Preserving Multimodal Wearable for Local Voice-and-Vision Inference","summary":"Many promising applications of multimodal wearables require continuous sensing and heavy computation, yet users reject such devices due to privacy concerns. This paper shares our experiences building an ear-mounted voice-and-vision wearable that performs local AI inference using a paired smartphone as a trusted personal edge. We describe the hardware-software co-design of this privacy-preserving system, including challenges in integrating a camera, microphone, and speaker within a 30-gram form factor, enabling wake word-triggered capture, and running quantized vision-language and large-language models entirely offline. Through iterative prototyping, we identify key design hurdles in power budgeting, connectivity, latency, and social acceptability. Our initial evaluation shows that fully local multimodal inference is feasible on commodity mobile hardware with interactive latency. We conclude with design lessons for researchers developing embedded AI systems that balance privacy, responsiveness, and usability in everyday settings.","authors":["Yonatan Tussa","Andy Heredia","Nirupam Roy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19726v1","updated":"2025-11-24T21:41:45Z","published":"2025-11-24T21:41:45Z","title":"An Adaptive, Data-Integrated Agent-Based Modeling Framework for Explainable and Contestable Policy Design","summary":"Multi-agent systems often operate under feedback, adaptation, and non-stationarity, yet many simulation studies retain static decision rules and fixed control parameters. This paper introduces a general adaptive multi-agent learning framework that integrates: (i) four dynamic regimes distinguishing static versus adaptive agents and fixed versus adaptive system parameters; (ii) information-theoretic diagnostics (entropy rate, statistical complexity, and predictive information) to assess predictability and structure; (iii) structural causal models for explicit intervention semantics; (iv) procedures for generating agent-level priors from aggregate or sample data; and (v) unsupervised methods for identifying emergent behavioral regimes. The framework offers a domain-neutral architecture for analyzing how learning agents and adaptive controls jointly shape system trajectories, enabling systematic comparison of stability, performance, and interpretability across non-equilibrium, oscillatory, or drifting dynamics. Mathematical definitions, computational operators, and an experimental design template are provided, yielding a structured methodology for developing explainable and contestable multi-agent decision processes.","authors":["Roberto Garrone"],"pdf_url":"","comment":"27 pages, 2 case studies (emissions and smart grids). Preprint prepared during the author's PhD research at the Open University of Cyprus and the University of Milano-Bicocca. Introduces a unified framework for adaptive multi-agent learning with information-theoretic, causal, and clustering diagnostics"},{"id":"http://arxiv.org/abs/2511.19723v1","updated":"2025-11-24T21:35:07Z","published":"2025-11-24T21:35:07Z","title":"A Distributed Gradient-based Algorithm for Optimization Problems with Coupled Equality Constraints","summary":"This paper studies a class of distributed optimization problems with coupled equality constraints in networked systems. Many existing distributed algorithms rely on solving local subproblems via the $\\operatorname{argmin}$ operator in each iteration. Such approaches become computationally burdensome or intractable when local cost functions are complex. To address this challenge, we propose a novel distributed gradient-based algorithm that avoids solving a local optimization problem at each iteration by leveraging first-order approximations and projection onto local feasible sets. The algorithm operates in a fully distributed manner, requiring only local communication without exchanging gradients or primal variables. We rigorously establish sublinear convergence for general convex cost functions and linear convergence under strong convexity and smoothness conditions. Numerical simulation on the IEEE 118-bus system demonstrates the superior computational efficiency and scalability of the proposed method compared to several state-of-the-art distributed optimization algorithms.","authors":["Chenyang Qiu","Zongli Lin"],"pdf_url":"","comment":"11 pages, 3 figures, submitted to Automatica"},{"id":"http://arxiv.org/abs/2511.19715v1","updated":"2025-11-24T21:24:37Z","published":"2025-11-24T21:24:37Z","title":"Understanding Risk and Revenue in the Nordic 15-minute mFRR market: An EV Aggregation Study","summary":"Decarbonisation, decentralisation, and intermittency are driving the development of flexibility markets towards shorter market time units (MTU). Shorter MTUs and shorter gate closures lower the entrance barriers of demand side aggregators that face significant uncertainty on longer time scales. We study the business case for aggregated EV fleets participating in the Nordic 15-minute mFRR Energy Activation Market (EAM). Motivated by increasing system granularity and rapid EV uptake, we represent fleet flexibility as a virtual battery with time-varying power and energy envelopes and formulate a risk-aware stochastic optimisation that co-ordinates day-ahead scheduling with quarter-hour mFRR bidding. Using synthetic residential charging cohorts and observed day-ahead prices on two stylised days, we compare an independent day-ahead baseline to a co-optimised strategy under conservative availability and a CVaR-augmented objective. Across both price cases, co-optimisation increases expected profit and lowers downside risk: the model buys less energy day-ahead and shifts procurement toward mFRR down while flattening the charging plan to retain eligibility for mFRR up. Profit decomposition shows that the uplift is driven by higher mFRR down revenues and reduced reliance on unwinding day-ahead positions. We discuss operational implications for bidding and outline two extensions: rolling 45-minute re-optimisation and a V2G framework.","authors":["Theodor Hagström","Lars Herre"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19714v1","updated":"2025-11-24T21:24:06Z","published":"2025-11-24T21:24:06Z","title":"Non-Ergodic Convergence Algorithms for Distributed Consensus and Coupling-Constrained Optimization","summary":"We study distributed convex optimization with two ubiquitous forms of coupling: consensus constraints and global affine equalities. We first design a linearized method of multipliers for the consensus optimization problem. Without smoothness or strong convexity, we establish non-ergodic sublinear rates of order O(1/\\sqrt{k}) for both the objective optimality and the consensus violation. Leveraging duality, we then show that the economic dispatch problem admits a dual consensus formulation, and that applying the same algorithm to the dual economic dispatch yields non-ergodic O(1/\\sqrt{k}) decay for the error of the summation of the cost over the network and the equality-constraint residual under convexity and Slater's condition. Numerical results on the IEEE 118-bus system demonstrate faster reduction of both objective error and feasibility error relative to the state-of-the-art baselines, while the dual variables reach network-wide consensus.","authors":["Chenyang Qiu","Zongli Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19708v1","updated":"2025-11-24T21:17:41Z","published":"2025-11-24T21:17:41Z","title":"An Accelerated Distributed Algorithm with Equality and Inequality Coupling Constraints","summary":"This paper studies distributed convex optimization with both affine equality and nonlinear inequality couplings through the duality analysis. We first formulate the dual of the coupling-constraint problem and reformulate it as a consensus optimization problem over a connected network. To efficiently solve this dual problem and hence the primal problem, we design an accelerated linearized algorithm that, at each round, a look-ahead linearization of the separable objective is combined with a quadratic penalty on the Laplacian constraint, a proximal step, and an aggregation of iterations. On the theory side, we prove non-ergodic rates for both the primal optimality error and the feasibility error. On the other hand, numerical experiments show a faster decrease of optimality error and feasibility residual than augmented-Lagrangian tracking and distributed subgradient baselines under the same communication budget.","authors":["Chenyang Qiu","Yangyang Qian","Zongli Lin","Yacov A. Shamash"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19683v1","updated":"2025-11-24T20:35:39Z","published":"2025-11-24T20:35:39Z","title":"State Feedback Controllers with Operational Constraints","summary":"In this paper, a state feedback control design with min/max operational limiting constraints is developed for multi-input-multi-output linear time invariant systems. Specifically, servo-tracking control problems with input and output constraints are considered. For static servo-controllers, the output design limits are imposed component-wise on the system selected output, which is of the same dimension as the control input. For dynamic servo-controllers, operational constraints are applied to the system inputs and outputs. The proposed control solution also includes an anti-windup protection logic for dynamic servo-controllers with integral action. The developed method is based on the Nagumo Theorem for forward invariance, the Comparison Lemma for inclusion of input/output inequality constraints, and on the min-norm optimal controllers for synthesis. The derived design is similar and directly related to the method of Control Barrier Functions. Simulation trade studies are presented to illustrate benefits of the proposed control methodology for aerial flight critical systems.","authors":["Eugene Lavretsky"],"pdf_url":"","comment":"33 pages, 13 figures. These are the original detailed design notes where my recent CBF-related papers came from"},{"id":"http://arxiv.org/abs/2511.19675v1","updated":"2025-11-24T20:17:50Z","published":"2025-11-24T20:17:50Z","title":"Anytime-Feasible First-Order Optimization via Safe Sequential QCQP","summary":"This paper presents the Safe Sequential Quadratically Constrained Quadratic Programming (SS-QCQP) algorithm, a first-order method for smooth inequality-constrained nonconvex optimization that guarantees feasibility at every iteration. The method is derived from a continuous-time dynamical system whose vector field is obtained by solving a convex QCQP that enforces monotonic descent of the objective and forward invariance of the feasible set. The resulting continuous-time dynamics achieve an $O(1/t)$ convergence rate to first-order stationary points under standard constraint qualification conditions. We then propose a safeguarded Euler discretization with adaptive step-size selection that preserves this convergence rate while maintaining both descent and feasibility in discrete time. To enhance scalability, we develop an active-set variant (SS-QCQP-AS) that selectively enforces constraints near the boundary, substantially reducing computational cost without compromising theoretical guarantees. Numerical experiments on a multi-agent nonlinear optimal control problem demonstrate that SS-QCQP and SS-QCQP-AS maintain feasibility, exhibit the predicted convergence behavior, and deliver solution quality comparable to second-order solvers such as SQP and IPOPT.","authors":["Jiarui Wang","Mahyar Fazlyab"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19522v1","updated":"2025-11-24T05:49:30Z","published":"2025-11-24T05:49:30Z","title":"Active Secure Neighbor Selection in Multi-Agent Systems with Byzantine Attacks","summary":"This paper investigates the problem of resilient control for multi-agent systems in the presence of Byzantine adversaries via an active secure neighbor selection framework. A pre-discriminative graph is first constructed to characterize the admissible set of candidate neighbors for each agent. Based on this graph, a dynamic in-neighbor selection strategy is proposed, wherein each agent actively selects a subset of its pre-discriminative neighbors. The number of selected neighbors is adjustable, allowing for a trade-off between communication overhead and robustness, with the minimal case requiring only a single in-neighbor. The proposed strategy facilitates the reconstruction of a directed spanning tree among normal agents following the detection and isolation of Byzantine agents. It achieves resilient consensus without imposing any assumptions on the initial connectivity among normal agents. Moreover, the approach significantly reduces communication burden while maintaining resilience to adversarial behavior. A numerical example is provided to illustrate the effectiveness of the proposed method.","authors":["Jinming Gao","Yijing Wang","Wentao Zhang","Rui Zhao","Yang Shi","Zhiqiang Zuo"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2511.19436v1","updated":"2025-11-24T18:59:56Z","published":"2025-11-24T18:59:56Z","title":"VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection","summary":"We present VDC-Agent, a self-evolving framework for Video Detailed Captioning that requires neither human annotations nor larger teacher models. The agent forms a closed loop of caption generation, principle-guided scoring (score and textual suggestions), and prompt refinement. When caption quality regresses, a self-reflection path leverages the previous chain-of-thought to amend the update. Running this process on unlabeled videos produces trajectories of (caption, score) pairs. We convert the trajectories into preference tuples and filter out samples with JSON parsing errors, resulting in VDC-Agent-19K, which contains 18,886 automatically constructed pairs. We then fine-tune the base MLLM on this dataset using an easy-to-hard curriculum direct preference optimization. Built on Qwen2.5-VL-7B-Instruct, our VDC-Agent-7B attains state-of-the-art performance on the VDC benchmark with 49.08% average accuracy and 2.50 score, surpassing specialized video captioners and improving over the base model by +5.13% accuracy and +0.27 score at similar inference cost.","authors":["Qiang Wang","Xinyuan Gao","SongLin Dong","Jizhou Han","Jiangyang Li","Yuhang He","Yihong Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19434v1","updated":"2025-11-24T18:59:53Z","published":"2025-11-24T18:59:53Z","title":"Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging Pretrained Experts","summary":"Diffusion models for image generation often exhibit a trade-off between perceptual sample quality and data likelihood: training objectives emphasizing high-noise denoising steps yield realistic images but poor likelihoods, whereas likelihood-oriented training overweights low-noise steps and harms visual fidelity. We introduce a simple plug-and-play sampling method that combines two pretrained diffusion experts by switching between them along the denoising trajectory. Specifically, we apply an image-quality expert at high noise levels to shape global structure, then switch to a likelihood expert at low noise levels to refine pixel statistics. The approach requires no retraining or fine-tuning -- only the choice of an intermediate switching step. On CIFAR-10 and ImageNet32, the merged model consistently matches or outperforms its base components, improving or preserving both likelihood and sample quality relative to each expert alone. These results demonstrate that expert switching across noise levels is an effective way to break the likelihood-quality trade-off in image diffusion models.","authors":["Yasin Esfandiari","Stefan Bauer","Sebastian U. Stich","Andrea Dittadi"],"pdf_url":"","comment":"ICLR 2025 DeLTa workshop"},{"id":"http://arxiv.org/abs/2508.12491v3","updated":"2025-11-24T18:59:36Z","published":"2025-08-17T20:16:44Z","title":"Cost-Aware Contrastive Routing for LLMs","summary":"We study cost-aware routing for large language models across diverse and dynamic pools of models. Existing approaches often overlook prompt-specific context, rely on expensive model profiling, assume a fixed set of experts, or use inefficient trial-and-error strategies. We introduce Cost-Spectrum Contrastive Routing (CSCR), a lightweight framework that maps both prompts and models into a shared embedding space to enable fast, cost-sensitive selection. CSCR uses compact, fast-to-compute logit footprints for open-source models and perplexity fingerprints for black-box APIs. A contrastive encoder is trained to favor the cheapest accurate expert within adaptive cost bands. At inference time, routing reduces to a single k-NN lookup via a FAISS index, requiring no retraining when the expert pool changes and enabling microsecond latency. Across multiple benchmarks, CSCR consistently outperforms baselines, improving the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen LLMs and out-of-distribution prompts.","authors":["Reza Shirkavand","Shangqian Gao","Peiran Yu","Heng Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19428v1","updated":"2025-11-24T18:58:55Z","published":"2025-11-24T18:58:55Z","title":"Flow Map Distillation Without Data","summary":"State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data.","authors":["Shangyuan Tong","Nanye Ma","Saining Xie","Tommi Jaakkola"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.13644v2","updated":"2025-11-24T18:57:49Z","published":"2025-05-19T18:31:31Z","title":"Collapsing Taylor Mode Automatic Differentiation","summary":"Computing partial differential equation (PDE) operators via nested backpropagation is expensive, yet popular, and severely restricts their utility for scientific machine learning. Recent advances, like the forward Laplacian and randomizing Taylor mode automatic differentiation (AD), propose forward schemes to address this. We introduce an optimization technique for Taylor mode that 'collapses' derivatives by rewriting the computational graph, and demonstrate how to apply it to general linear PDE operators, and randomized Taylor mode. The modifications simply require propagating a sum up the computational graph, which could -- or should -- be done by a machine learning compiler, without exposing complexity to users. We implement our collapsing procedure and evaluate it on popular PDE operators, confirming it accelerates Taylor mode and outperforms nested backpropagation.","authors":["Felix Dangel","Tim Siebert","Marius Zeinhofer","Andrea Walther"],"pdf_url":"","comment":"10 pages + appendix; camera-ready version (NeurIPS 2025)"},{"id":"http://arxiv.org/abs/2511.19418v1","updated":"2025-11-24T18:55:19Z","published":"2025-11-24T18:55:19Z","title":"Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens","summary":"Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent representations that encode rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills knowledge from lightweight vision experts, capturing complementary properties such as 2D appearance, 3D geometry, spatial layout, and edge structure. During training, the VLM with COVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (e.g., depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than ten diverse perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL and LLaVA consistently improves performance by 3% to 16% and demonstrates that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.","authors":["Yiming Qin","Bomin Wei","Jiaxin Ge","Konstantinos Kallidromitis","Stephanie Fu","Trevor Darrell","Xudong Wang"],"pdf_url":"","comment":"Project page: https://wakalsprojectpage.github.io/comt-website/"},{"id":"http://arxiv.org/abs/2511.19417v1","updated":"2025-11-24T18:55:16Z","published":"2025-11-24T18:55:16Z","title":"Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.","authors":["James Y. Huang","Sheng Zhang","Qianchu Liu","Guanghui Qin","Tinghui Zhu","Tristan Naumann","Muhao Chen","Hoifung Poon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19413v1","updated":"2025-11-24T18:50:01Z","published":"2025-11-24T18:50:01Z","title":"UniGame: Turning a Unified Multimodal Model Into Its Own Adversary","summary":"Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame","authors":["Zhaolong Su","Wang Lu","Hao Chen","Sharon Li","Jindong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.17796v2","updated":"2025-11-24T18:49:51Z","published":"2025-06-21T19:36:11Z","title":"SING: SDE Inference via Natural Gradients","summary":"Latent stochastic differential equation (SDE) models are important tools for the unsupervised discovery of dynamical systems from data, with applications ranging from engineering to neuroscience. In these complex domains, exact posterior inference of the latent state path is typically intractable, motivating the use of approximate methods such as variational inference (VI). However, existing VI methods for inference in latent SDEs often suffer from slow convergence and numerical instability. We propose SDE Inference via Natural Gradients (SING), a method that leverages natural gradient VI to efficiently exploit the underlying geometry of the model and variational posterior. SING enables fast and reliable inference in latent SDE models by approximating intractable integrals and parallelizing computations in time. We provide theoretical guarantees that SING approximately optimizes the intractable, continuous-time objective of interest. Moreover, we demonstrate that better state inference enables more accurate estimation of nonlinear drift functions using, for example, Gaussian process SDE models. SING outperforms prior methods in state inference and drift estimation on a variety of datasets, including a challenging application to modeling neural dynamics in freely behaving animals. Altogether, our results illustrate the potential of SING as a tool for accurate inference in complex dynamical systems, especially those characterized by limited prior knowledge and non-conjugate structure.","authors":["Amber Hu","Henry Smith","Scott Linderman"],"pdf_url":"","comment":"To appear in Advances in Neural Processing Information Systems (NeurIPS), 2025"},{"id":"http://arxiv.org/abs/2511.19405v1","updated":"2025-11-24T18:43:46Z","published":"2025-11-24T18:43:46Z","title":"Learning Robust Social Strategies with Large Language Models","summary":"As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust and Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents.","authors":["Dereck Piche","Mohammed Muqeeth","Milad Aghajohari","Juan Duque","Michael Noukhovitch","Aaron Courville"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19404v1","updated":"2025-11-24T18:42:49Z","published":"2025-11-24T18:42:49Z","title":"Nonparametric Instrumental Variable Regression with Observed Covariates","summary":"We study the problem of nonparametric instrumental variable regression with observed covariates, which we refer to as NPIV-O. Compared with standard nonparametric instrumental variable regression (NPIV), the additional observed covariates facilitate causal identification and enables heterogeneous causal effect estimation. However, the presence of observed covariates introduces two challenges for its theoretical analysis. First, it induces a partial identity structure, which renders previous NPIV analyses - based on measures of ill-posedness, stability conditions, or link conditions - inapplicable. Second, it imposes anisotropic smoothness on the structural function. To address the first challenge, we introduce a novel Fourier measure of partial smoothing; for the second challenge, we extend the existing kernel 2SLS instrumental variable algorithm with observed covariates, termed KIV-O, to incorporate Gaussian kernel lengthscales adaptive to the anisotropic smoothness. We prove upper $L^2$-learning rates for KIV-O and the first $L^2$-minimax lower learning rates for NPIV-O. Both rates interpolate between known optimal rates of NPIV and nonparametric regression (NPR). Interestingly, we identify a gap between our upper and lower bounds, which arises from the choice of kernel lengthscales tuned to minimize a projected risk. Our theoretical analysis also applies to proximal causal inference, an emerging framework for causal effect estimation that shares the same conditional moment restriction as NPIV-O.","authors":["Zikai Shen","Zonghao Chen","Dimitri Meunier","Ingo Steinwart","Arthur Gretton","Zhu Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04763v2","updated":"2025-11-24T18:41:20Z","published":"2025-02-11T09:32:55Z","title":"MiniF2F in Rocq: Automatic Translation Between Proof Assistants -- A Case Study","summary":"In this work, we conduct an experiment using state-of-the-art LLMs to translate MiniF2F into Rocq. The translation task focuses on generating a Rocq theorem based on three sources: a natural language description, the Lean formalization, and the Isabelle formalization. We conducted our experiment in 3 stages of increasing complexity, from basic one-shot prompting to multi-turn conversations that incorporate feedback from unsuccessful attempts. At each stage, we perform multiple rounds of translation using increasingly advanced models: GPT-4o mini, Claude 3.5 Sonnet, o1 mini, and o1. We successfully translated 478 out of 488 theorems. The dataset is opensource: https://github.com/LLM4Rocq/miniF2F-rocq.","authors":["Jules Viennot","Guillaume Baudart","Emilio Jesùs Gallego Arias","Marc Lelarge"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19399v1","updated":"2025-11-24T18:35:54Z","published":"2025-11-24T18:35:54Z","title":"DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research","summary":"Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.","authors":["Rulin Shao","Akari Asai","Shannon Zejiang Shen","Hamish Ivison","Varsha Kishore","Jingming Zhuo","Xinran Zhao","Molly Park","Samuel G. Finlayson","David Sontag","Tyler Murray","Sewon Min","Pradeep Dasigi","Luca Soldaini","Faeze Brahman","Wen-tau Yih","Tongshuang Wu","Luke Zettlemoyer","Yoon Kim","Hannaneh Hajishirzi","Pang Wei Koh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19398v1","updated":"2025-11-24T18:35:29Z","published":"2025-11-24T18:35:29Z","title":"PTF Testing Lower Bounds for Non-Gaussian Component Analysis","summary":"This work studies information-computation gaps for statistical problems. A common approach for providing evidence of such gaps is to show sample complexity lower bounds (that are stronger than the information-theoretic optimum) against natural models of computation. A popular such model in the literature is the family of low-degree polynomial tests. While these tests are defined in such a way that make them easy to analyze, the class of algorithms that they rule out is somewhat restricted. An important goal in this context has been to obtain lower bounds against the stronger and more natural class of low-degree Polynomial Threshold Function (PTF) tests, i.e., any test that can be expressed as comparing some low-degree polynomial of the data to a threshold. Proving lower bounds against PTF tests has turned out to be challenging. Indeed, we are not aware of any non-trivial PTF testing lower bounds in the literature.\n  In this paper, we establish the first non-trivial PTF testing lower bounds for a range of statistical tasks. Specifically, we prove a near-optimal PTF testing lower bound for Non-Gaussian Component Analysis (NGCA). Our NGCA lower bound implies similar lower bounds for a number of other statistical problems. Our proof leverages a connection to recent work on pseudorandom generators for PTFs and recent techniques developed in that context. At the technical level, we develop several tools of independent interest, including novel structural results for analyzing the behavior of low-degree polynomials restricted to random directions.","authors":["Ilias Diakonikolas","Daniel M. Kane","Sihan Liu","Thanasis Pittas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.02912v4","updated":"2025-11-24T18:31:13Z","published":"2025-08-04T21:29:07Z","title":"Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination with Embodied World Models","summary":"Robust coordination is critical for effective decision-making in multi-agent systems, especially under partial observability. A central question in Multi-Agent Reinforcement Learning (MARL) is whether to engineer communication protocols or learn them end-to-end. We investigate this dichotomy using embodied world models. We propose and compare two communication strategies for a cooperative task-allocation problem. The first, Learned Direct Communication (LDC), learns a protocol end-to-end. The second, Intention Communication, uses an engineered inductive bias: a compact, learned world model, the Imagined Trajectory Generation Module (ITGM), which uses the agent's own policy to simulate future states. A Message Generation Network (MGN) then compresses this plan into a message. We evaluate these approaches on goal-directed interaction in a grid world, a canonical abstraction for embodied AI problems, while scaling environmental complexity. Our experiments reveal that while emergent communication is viable in simple settings, the engineered, world model-based approach shows superior performance, sample efficiency, and scalability as complexity increases. These findings advocate for integrating structured, predictive models into MARL agents to enable active, goal-driven coordination.","authors":["Brennen A. Hill","Mant Koh En Wei","Thangavel Jishnuanandh"],"pdf_url":"","comment":"Published in the Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments for Agents (SEA). Additionally accepted for presentation in the NeurIPS 2025 Workshop: Embodied World Models for Decision Making (EWM) and the NeurIPS 2025 Workshop: Optimization for Machine Learning (OPT)"},{"id":"http://arxiv.org/abs/2511.19390v1","updated":"2025-11-24T18:30:04Z","published":"2025-11-24T18:30:04Z","title":"Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme","summary":"Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.","authors":["Rudy Morel","Francesco Pio Ramunno","Jeff Shen","Alberto Bietti","Kyunghyun Cho","Miles Cranmer","Siavash Golkar","Olexandr Gugnin","Geraud Krawezik","Tanya Marwah","Michael McCabe","Lucas Meyer","Payel Mukhopadhyay","Ruben Ohana","Liam Parker","Helen Qu","François Rozet","K. D. Leka","François Lanusse","David Fouhey","Shirley Ho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19379v1","updated":"2025-11-24T18:19:42Z","published":"2025-11-24T18:19:42Z","title":"Efficiency vs. Fidelity: A Comparative Analysis of Diffusion Probabilistic Models and Flow Matching on Low-Resource Hardware","summary":"Denoising Diffusion Probabilistic Models (DDPMs) have established a new state-of-the-art in generative image synthesis, yet their deployment is hindered by significant computational overhead during inference, often requiring up to 1,000 iterative steps. This study presents a rigorous comparative analysis of DDPMs against the emerging Flow Matching (Rectified Flow) paradigm, specifically isolating their geometric and efficiency properties on low-resource hardware. By implementing both frameworks on a shared Time-Conditioned U-Net backbone using the MNIST dataset, we demonstrate that Flow Matching significantly outperforms Diffusion in efficiency. Our geometric analysis reveals that Flow Matching learns a highly rectified transport path (Curvature $\\mathcal{C} \\approx 1.02$), which is near-optimal, whereas Diffusion trajectories remain stochastic and tortuous ($\\mathcal{C} \\approx 3.45$). Furthermore, we establish an ``efficiency frontier'' at $N=10$ function evaluations, where Flow Matching retains high fidelity while Diffusion collapses. Finally, we show via numerical sensitivity analysis that the learned vector field is sufficiently linear to render high-order ODE solvers (Runge-Kutta 4) unnecessary, validating the use of lightweight Euler solvers for edge deployment. \\textbf{This work concludes that Flow Matching is the superior algorithmic choice for real-time, resource-constrained generative tasks.}","authors":["Srishti Gupta","Yashasvee Taiwade"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.10100v4","updated":"2025-11-24T18:17:51Z","published":"2025-01-17T10:39:09Z","title":"Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics","summary":"Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.01870v3","updated":"2025-11-24T18:17:37Z","published":"2024-10-02T17:29:23Z","title":"PEANuT: Parameter-Efficient Adaptation with Weight-aware Neural Tweakers","summary":"Fine-tuning large pre-trained foundation models often yields excellent downstream performance but is prohibitively expensive when updating all parameters. Parameter-efficient fine-tuning (PEFT) methods such as LoRA alleviate this by introducing lightweight update modules, yet they commonly rely on weight-agnostic linear approximations, limiting their expressiveness. In this work, we propose PEANuT, a novel PEFT framework that introduces weight-aware neural tweakers, compact neural modules that generate task-adaptive updates conditioned on frozen pre-trained weights. PEANuT provides a flexible yet efficient way to capture complex update patterns without full model tuning. We theoretically show that PEANuT achieves equivalent or greater expressivity than existing linear PEFT methods with comparable or fewer parameters. Extensive experiments across four benchmarks with over twenty datasets demonstrate that PEANuT consistently outperforms strong baselines in both NLP and vision tasks, while maintaining low computational overhead.","authors":["Yibo Zhong","Haoxiang Jiang","Lincan Li","Ryumei Nakada","Tianci Liu","Linjun Zhang","Huaxiu Yao","Haoyu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19368v1","updated":"2025-11-24T18:03:59Z","published":"2025-11-24T18:03:59Z","title":"LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems","summary":"Multi-agent reinforcement learning (MARL) has been increasingly adopted in many real-world applications. While MARL enables decentralized deployment on resource-constrained edge devices, it suffers from severe non-stationarity due to the synchronous updates of agent policies. This non stationarity results in unstable training and poor policy con vergence, especially as the number of agents increases. In this paper, we propose RELED, a scalable MARL framework that integrates large language model (LLM)-driven expert demonstrations with autonomous agent exploration. RELED incorporates a Stationarity-Aware Expert Demonstration module, which leverages theoretical non-stationarity bounds to enhance the quality of LLM-generated expert trajectories, thus providing high reward and training-stable samples for each agent. Moreover, a Hybrid Expert-Agent Policy Optimization module adaptively balances each agent's learning from both expert-generated and agent-generated trajectories, accelerating policy convergence and improving generalization. Extensive experiments with real city networks based on OpenStreetMap demonstrate that RELED achieves superior performance compared to state-of-the-art MARL methods.","authors":["Tianyang Duan","Zongyuan Zhang","Zheng Lin","Songxiao Guo","Xiuxian Guan","Guangyu Wu","Zihan Fang","Haotian Meng","Xia Du","Ji-Zhe Zhou","Heming Cui","Jun Luo","Yue Gao"],"pdf_url":"","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.19364v1","updated":"2025-11-24T17:58:59Z","published":"2025-11-24T17:58:59Z","title":"Neural surrogates for designing gravitational wave detectors","summary":"Physics simulators are essential in science and engineering, enabling the analysis, control, and design of complex systems. In experimental sciences, they are increasingly used to automate experimental design, often via combinatorial search and optimization. However, as the setups grow more complex, the computational cost of traditional, CPU-based simulators becomes a major limitation. Here, we show how neural surrogate models can significantly reduce reliance on such slow simulators while preserving accuracy. Taking the design of interferometric gravitational wave detectors as a representative example, we train a neural network to surrogate the gravitational wave physics simulator Finesse, which was developed by the LIGO community. Despite that small changes in physical parameters can change the output by orders of magnitudes, the model rapidly predicts the quality and feasibility of candidate designs, allowing an efficient exploration of large design spaces. Our algorithm loops between training the surrogate, inverse designing new experiments, and verifying their properties with the slow simulator for further training. Assisted by auto-differentiation and GPU parallelism, our method proposes high-quality experiments much faster than direct optimization. Solutions that our algorithm finds within hours outperform designs that take five days for the optimizer to reach. Though shown in the context of gravitational wave detectors, our framework is broadly applicable to other domains where simulator bottlenecks hinder optimization and discovery.","authors":["Carlos Ruiz-Gonzalez","Sören Arlt","Sebastian Lehner","Arturs Berzins","Yehonathan Drori","Rana X Adhikari","Johannes Brandstetter","Mario Krenn"],"pdf_url":"","comment":"20 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.19359v1","updated":"2025-11-24T17:56:42Z","published":"2025-11-24T17:56:42Z","title":"Enhancing Conformal Prediction via Class Similarity","summary":"Conformal Prediction (CP) has emerged as a powerful statistical framework for high-stakes classification applications. Instead of predicting a single class, CP generates a prediction set, guaranteed to include the true label with a pre-specified probability. The performance of different CP methods is typically assessed by their average prediction set size. In setups where the classes can be partitioned into semantic groups, e.g., diseases that require similar treatment, users can benefit from prediction sets that are not only small on average, but also contain a small number of semantically different groups. This paper begins by addressing this problem and ultimately offers a widely applicable tool for boosting any CP method on any dataset. First, given a class partition, we propose augmenting the CP score function with a term that penalizes predictions with out-of-group errors. We theoretically analyze this strategy and prove its advantages for group-related metrics. Surprisingly, we show mathematically that, for common class partitions, it can also reduce the average set size of any CP score function. Our analysis reveals the class similarity factors behind this improvement and motivates us to propose a model-specific variant, which does not require any human semantic partition and can further reduce the prediction set size. Finally, we present an extensive empirical study, encompassing prominent CP methods, multiple models, and several datasets, which demonstrates that our class-similarity-based approach consistently enhances CP methods.","authors":["Ariel Fargion","Lahav Dabah","Tom Tirer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19355v1","updated":"2025-11-24T17:55:46Z","published":"2025-11-24T17:55:46Z","title":"Leveraging LLMs for reward function design in reinforcement learning control tasks","summary":"The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.","authors":["Franklin Cardenoso","Wouter Caarls"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00634v2","updated":"2025-11-24T17:55:01Z","published":"2025-11-01T17:26:56Z","title":"Node Preservation and its Effect on Crossover in Cartesian Genetic Programming","summary":"While crossover is a critical and often indispensable component in other forms of Genetic Programming, such as Linear- and Tree-based, it has consistently been claimed that it deteriorates search performance in CGP. As a result, a mutation-alone $(1+λ)$ evolutionary strategy has become the canonical approach for CGP. Although several operators have been developed that demonstrate an increased performance over the canonical method, a general solution to the problem is still lacking. In this paper, we compare basic crossover methods, namely one-point and uniform, to variants in which nodes are ``preserved,'' including the subgraph crossover developed by Roman Kalkreuth, the difference being that when ``node preservation'' is active, crossover is not allowed to break apart instructions. We also compare a node mutation operator to the traditional point mutation; the former simply replaces an entire node with a new one. We find that node preservation in both mutation and crossover improves search using symbolic regression benchmark problems, moving the field towards a general solution to CGP crossover.","authors":["Mark Kocherovsky","Illya Bakurov","Wolfgang Banzhaf"],"pdf_url":"","comment":"Draft to cite in another paper before both papers are peer-reviewed for the evo*2026 conference, 21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.19350v1","updated":"2025-11-24T17:52:58Z","published":"2025-11-24T17:52:58Z","title":"Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric","summary":"Clustering short text embeddings is a foundational task in natural language processing, yet remains challenging due to the need to specify the number of clusters in advance. We introduce a scalable spectral method that estimates the number of clusters directly from the structure of the Laplacian eigenspectrum, constructed using cosine similarities and guided by an adaptive sampling strategy. This sampling approach enables our estimator to efficiently scale to large datasets without sacrificing reliability. To support intrinsic evaluation of cluster quality without ground-truth labels, we propose the Cohesion Ratio, a simple and interpretable evaluation metric that quantifies how much intra-cluster similarity exceeds the global similarity background. It has an information-theoretic motivation inspired by mutual information, and in our experiments it correlates closely with extrinsic measures such as normalized mutual information and homogeneity. Extensive experiments on six short-text datasets and four modern embedding models show that standard algorithms like K-Means and HAC, when guided by our estimator, significantly outperform popular parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results demonstrate the practical value of our spectral estimator and Cohesion Ratio for unsupervised organization and evaluation of short text data. Implementation of our estimator of k and Cohesion Ratio, along with code for reproducing the experiments, is available at https://anonymous.4open.science/r/towards_clustering-0C2E.","authors":["Nikita Neveditsin","Pawan Lingras","Vijay Mago"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19347v1","updated":"2025-11-24T17:46:54Z","published":"2025-11-24T17:46:54Z","title":"Artificial Intelligence Driven Workflow for Accelerating Design of Novel Photosensitizers","summary":"The discovery of high-performance photosensitizers has long been hindered by the time-consuming and resource-intensive nature of traditional trial-and-error approaches. Here, we present \\textbf{A}I-\\textbf{A}ccelerated \\textbf{P}hoto\\textbf{S}ensitizer \\textbf{I}nnovation (AAPSI), a closed-loop workflow that integrates expert knowledge, scaffold-based molecule generation, and Bayesian optimization to accelerate the design of novel photosensitizers. The scaffold-driven generation in AAPSI ensures structural novelty and synthetic feasibility, while the iterative AI-experiment loop accelerates the discovery of novel photosensitizers. AAPSI leverages a curated database of 102,534 photosensitizer-solvent pairs and generate 6,148 synthetically accessible candidates. These candidates are screened via graph transformers trained to predict singlet oxygen quantum yield ($φ_Δ$) and absorption maxima ($λ_{max}$), following experimental validation. This work generates several novel candidates for photodynamic therapy (PDT), among which the hypocrellin-based candidate HB4Ph exhibits exceptional performance at the Pareto frontier of high quantum yield of singlet oxygen and long absorption maxima among current photosensitizers ($φ_Δ$=0.85, $λ_{max}$=650nm).","authors":["Hongyi Wang","Xiuli Zheng","Weimin Liu","Zitian Tang","Sheng Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19344v1","updated":"2025-11-24T17:44:48Z","published":"2025-11-24T17:44:48Z","title":"Annotation-Free Class-Incremental Learning","summary":"Despite significant progress in continual learning ranging from architectural novelty to clever strategies for mitigating catastrophic forgetting most existing methods rest on a strong but unrealistic assumption the availability of labeled data throughout the learning process. In real-world scenarios, however, data often arrives sequentially and without annotations, rendering conventional approaches impractical. In this work, we revisit the fundamental assumptions of continual learning and ask: Can current systems adapt when labels are absent and tasks emerge incrementally over time? To this end, we introduce Annotation-Free Class-Incremental Learning (AFCIL), a more realistic and challenging paradigm where unlabeled data arrives continuously, and the learner must incrementally acquire new classes without any supervision. To enable effective learning under AFCIL, we propose CrossWorld CL, a Cross Domain World Guided Continual Learning framework that incorporates external world knowledge as a stable auxiliary source. The method retrieves semantically related ImageNet classes for each downstream category, maps downstream and ImageNet features through a cross domain alignment strategy and finally introduce a novel replay strategy. This design lets the model uncover semantic structure without annotations while keeping earlier knowledge intact. Across four datasets, CrossWorld-CL surpasses CLIP baselines and existing continual and unlabeled learning methods, underscoring the benefit of world knowledge for annotation free continual learning.","authors":["Hari Chandana Kuchibhotla","K S Ananth","Vineeth N Balasubramanian"],"pdf_url":"","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.19335v1","updated":"2025-11-24T17:31:16Z","published":"2025-11-24T17:31:16Z","title":"High-throughput validation of phase formability and simulation accuracy of Cantor alloys","summary":"High-throughput methods enable accelerated discovery of novel materials in complex systems such as high-entropy alloys, which exhibit intricate phase stability across vast compositional spaces. Computational approaches, including Density Functional Theory (DFT) and calculation of phase diagrams (CALPHAD), facilitate screening of phase formability as a function of composition and temperature. However, the integration of computational predictions with experimental validation remains challenging in high-throughput studies. In this work, we introduce a quantitative confidence metric to assess the agreement between predictions and experimental observations, providing a quantitative measure of the confidence of machine learning models trained on either DFT or CALPHAD input in accounting for experimental evidence. The experimental dataset was generated via high-throughput in-situ synchrotron X-ray diffraction on compositionally varied FeNiMnCr alloy libraries, heated from room temperature to ~1000 °C. Agreement between the observed and predicted phases was evaluated using either temperature-independent phase classification or a model that incorporates a temperature-dependent probability of phase formation. This integrated approach demonstrates where strong overall agreement between computation and experiment exists, while also identifying key discrepancies, particularly in FCC/BCC predictions at Mn-rich regions to inform future model refinement.","authors":["Changjun Cheng","Daniel Persaud","Kangming Li","Michael J. Moorehead","Natalie Page","Christian Lavoie","Beatriz Diaz Moreno","Adrien Couet","Samuel E Lofland","Jason Hattrick-Simpers"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19330v1","updated":"2025-11-24T17:26:20Z","published":"2025-11-24T17:26:20Z","title":"Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data","summary":"A common method of attacking deep learning models is through adversarial attacks, which occur when an attacker specifically modifies the input of a model to produce an incorrect result. Adversarial attacks have been deeply investigated in the image domain; however, there is less research in the time-series domain and very little for forecasting financial data. To address these concerns, this study aims to build upon previous research on adversarial attacks for time-series data by introducing two new slope-based methods aimed to alter the trends of the predicted stock forecast generated by an N-HiTS model. Compared to the normal N-HiTS predictions, the two new slope-based methods, the General Slope Attack and Least-Squares Slope Attack, can manipulate N-HiTS predictions by doubling the slope. These new slope attacks can bypass standard security mechanisms, such as a discriminator that filters real and perturbed inputs, reducing a 4-layered CNN's specificity to 28% and accuracy to 57%. Furthermore, the slope based methods were incorporated into a GAN architecture as a means of generating realistic synthetic data, while simultaneously fooling the model. Finally, this paper also proposes a sample malware designed to inject an adversarial attack in the model inference library, proving that ML-security research should not only focus on making the model safe, but also securing the entire pipeline.","authors":["Dominik Luszczynski"],"pdf_url":"","comment":"13 pages, 6 figures, 4 tables, preprint; Total including Appendix: 21 pages, 11 figures, 7 tables"},{"id":"http://arxiv.org/abs/2511.00904v2","updated":"2025-11-24T17:25:02Z","published":"2025-11-02T11:55:27Z","title":"Random Spiking Neural Networks are Stable and Spectrally Simple","summary":"Spiking neural networks (SNNs) are a promising paradigm for energy-efficient computation, yet their theoretical foundations-especially regarding stability and robustness-remain limited compared to artificial neural networks. In this work, we study discrete-time leaky integrate-and-fire (LIF) SNNs through the lens of Boolean function analysis. We focus on noise sensitivity and stability in classification tasks, quantifying how input perturbations affect outputs. Our main result shows that wide LIF-SNN classifiers are stable on average, a property explained by the concentration of their Fourier spectrum on low-frequency components. Motivated by this, we introduce the notion of spectral simplicity, which formalizes simplicity in terms of Fourier spectrum concentration and connects our analysis to the simplicity bias observed in deep networks. Within this framework, we show that random LIF-SNNs are biased toward simple functions. Experiments on trained networks confirm that these stability properties persist in practice. Together, these results provide new insights into the stability and robustness properties of SNNs.","authors":["Ernesto Araya","Massimiliano Datres","Gitta Kutyniok"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19328v1","updated":"2025-11-24T17:20:42Z","published":"2025-11-24T17:20:42Z","title":"Understanding the Staged Dynamics of Transformers in Learning Latent Structure","summary":"While transformers can discover latent structure from context, the dynamics of how they acquire different components of the latent structure remain poorly understood. In this work, we use the Alchemy benchmark, to investigate the dynamics of latent structure learning. We train a small decoder-only transformer on three task variants: 1) inferring missing rules from partial contextual information, 2) composing simple rules to solve multi-step sequences, and 3) decomposing complex multi-step examples to infer intermediate steps. By factorizing each task into interpretable events, we show that the model acquires capabilities in discrete stages, first learning the coarse grained rules, before learning the complete latent structure. We also identify a crucial asymmetry, where the model can compose fundamental rules robustly, but struggles to decompose complex examples to discover the fundamental rules. These findings offer new insights into understanding how a transformer model learns latent structures, providing a granular view of how these capabilities evolve during training.","authors":["Rohan Saha","Farzane Aminmansour","Alona Fyshe"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.22006v2","updated":"2025-11-24T17:17:31Z","published":"2025-03-27T21:51:24Z","title":"Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to Leverage Ontologies, and How to Do Without Them","summary":"We investigate the use of LLM-generated data for continual pretraining of encoder models in specialized domains with limited training data, using the scientific domain of invasion biology as a case study. To this end, we leverage domain-specific ontologies by enriching them with LLM-generated data and pretraining the encoder model as an ontology-informed embedding model for concept definitions. To evaluate the effectiveness of this method, we compile a benchmark specifically designed for assessing model performance in invasion biology. After demonstrating substantial improvements over standard LLM pretraining, we investigate the feasibility of applying the proposed approach to domains without comprehensive ontologies by substituting ontological concepts with concepts automatically extracted from a small corpus of scientific abstracts and establishing relationships between concepts through distributional statistics. Our results demonstrate that this automated approach achieves comparable performance using only a small set of scientific abstracts, resulting in a fully automated pipeline for enhancing domain-specific understanding of small encoder models that is especially suited for application in low-resource settings and achieves performance comparable to masked language modeling pretraining on much larger datasets.","authors":["Marc Brinner","Tarek Al Mustafa","Sina Zarrieß"],"pdf_url":"","comment":"Published in the Findings of the Association for Computational Linguistics: EMNLP 2025"},{"id":"http://arxiv.org/abs/2505.07635v4","updated":"2025-11-24T17:17:12Z","published":"2025-05-12T15:05:46Z","title":"Interpreting Graph Inference with Skyline Explanations","summary":"Inference queries have been routinely issued to graph machine learning models such as graph neural networks (GNNs) for various network analytical tasks. Nevertheless, GNN outputs are often hard to interpret comprehensively. Existing methods typically conform to individual pre-defined explainability measures (such as fidelity), which often leads to biased, ``one-side'' interpretations. This paper introduces skyline explanation, a new paradigm that interprets GNN outputs by simultaneously optimizing multiple explainability measures of users' interests. (1) We propose skyline explanations as a Pareto set of explanatory subgraphs that dominate others over multiple explanatory measures. We formulate skyline explanation as a multi-criteria optimization problem, and establish its hardness results. (2) We design efficient algorithms with an onion-peeling approach, which strategically prioritizes nodes and removes unpromising edges to incrementally assemble skyline explanations. (3) We also develop an algorithm to diversify the skyline explanations to enrich the comprehensive interpretation. (4) We introduce efficient parallel algorithms with load-balancing strategies to scale skyline explanation for large-scale GNN-based inference. Using real-world and synthetic graphs, we experimentally verify our algorithms' effectiveness and scalability.","authors":["Dazhuo Qiu","Haolai Che","Arijit Khan","Yinghui Wu"],"pdf_url":"","comment":"Accepted at ICDE 2026"},{"id":"http://arxiv.org/abs/2507.04898v2","updated":"2025-11-24T17:16:42Z","published":"2025-07-07T11:29:18Z","title":"When do World Models Successfully Learn Dynamical Systems?","summary":"In this work, we explore the use of compact latent representations with learned time dynamics ('World Models') to simulate physical systems. Drawing on concepts from control theory, we propose a theoretical framework that explains why projecting time slices into a low-dimensional space and then concatenating to form a history ('Tokenization') is so effective at learning physics datasets, and characterise when exactly the underlying dynamics admit a reconstruction mapping from the history of previous tokenized frames to the next. To validate these claims, we develop a sequence of models with increasing complexity, starting with least-squares regression and progressing through simple linear layers, shallow adversarial learners, and ultimately full-scale generative adversarial networks (GANs). We evaluate these models on a variety of datasets, including modified forms of the heat and wave equations, the chaotic regime 2D Kuramoto-Sivashinsky equation, and a challenging computational fluid dynamics (CFD) dataset of a 2D Kármán vortex street around a fixed cylinder, where our model is successfully able to recreate the flow.","authors":["Edmund Ross","Claudia Drygala","Leonhard Schwarz","Samir Kaiser","Francesca di Mare","Tobias Breiten","Hanno Gottschalk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.13612v4","updated":"2025-11-24T17:16:26Z","published":"2025-04-18T10:35:19Z","title":"Entropic Time Schedulers for Generative Diffusion Models","summary":"The practical performance of generative diffusion models depends on the appropriate choice of the noise scheduling function, which can also be equivalently expressed as a time reparameterization. In this paper, we present a time scheduler that selects sampling points based on entropy rather than uniform time spacing, ensuring that each point contributes an equal amount of information to the final generation. We prove that this time reparameterization does not depend on the initial choice of time. Furthermore, we provide a tractable exact formula to estimate this \\emph{entropic time} for a trained model using the training loss without substantial overhead. Alongside the entropic time, inspired by the optimality results, we introduce a rescaled entropic time. In our experiments with mixtures of Gaussian distributions and ImageNet, we show that using the (rescaled) entropic times greatly improves the inference performance of trained models. In particular, we found that the image quality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can be substantially increased by the rescaled entropic time reparameterization without increasing the number of function evaluations, with greater improvements in the few NFEs regime. Code is available at https://github.com/DejanStancevic/Entropic-Time-Schedulers-for-Generative-Diffusion-Models.","authors":["Dejan Stancevic","Florian Handke","Luca Ambrogioni"],"pdf_url":"","comment":"31 pages"},{"id":"http://arxiv.org/abs/2508.02995v3","updated":"2025-11-24T17:11:32Z","published":"2025-08-05T01:52:42Z","title":"The Geometry of Cortical Computation: Manifold Disentanglement and Predictive Dynamics in VCNet","summary":"Despite their success, modern convolutional neural networks (CNNs) exhibit fundamental limitations, including data inefficiency, poor out-of-distribution generalization, and vulnerability to adversarial perturbations. These shortcomings can be traced to a lack of inductive biases that reflect the inherent geometric structure of the visual world. The primate visual system, in contrast, demonstrates superior efficiency and robustness, suggesting that its architectural and computational principles,which evolved to internalize these structures,may offer a blueprint for more capable artificial vision. This paper introduces Visual Cortex Network (VCNet), a novel neural network architecture whose design is informed by the macro-scale organization of the primate visual cortex. VCNet is framed as a geometric framework that emulates key biological mechanisms, including hierarchical processing across distinct cortical areas, dual-stream information segregation for learning disentangled representations, and top-down predictive feedback for representation refinement. We interpret these mechanisms through the lens of geometry and dynamical systems, positing that they guide the learning of structured, low-dimensional neural manifolds. We evaluate VCNet on two specialized benchmarks: the Spots-10 animal pattern dataset, which probes sensitivity to natural textures, and a light field image classification task, which requires processing higher-dimensional visual data. Our results show that VCNet achieves state-of-the-art accuracy of 92.1\\% on Spots-10 and 74.4\\% on the light field dataset, surpassing contemporary models of comparable size. This work demonstrates that integrating high-level neuroscientific principles, viewed through a geometric lens, can lead to more efficient and robust models, providing a promising direction for addressing long-standing challenges in machine learning.","authors":["Brennen A. Hill","Zhang Xinyu","Timothy Putra Prasetio"],"pdf_url":"","comment":"Published in the proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Symmetry and Geometry in Neural Representations (NeurReps). Additionally accepted for presentation in NeurIPS 2025 Workshop: Interpreting Cognition in Deep Learning Models (CogInterp)"},{"id":"http://arxiv.org/abs/2511.19314v1","updated":"2025-11-24T17:09:43Z","published":"2025-11-24T17:09:43Z","title":"PRInTS: Reward Modeling for Long-Horizon Information Seeking","summary":"Information-seeking is a core capability for AI agents, requiring them to gather and reason over tool-generated information across long trajectories. However, such multi-step information-seeking tasks remain challenging for agents backed by language models. While process reward models (PRMs) can guide agents by ranking candidate steps at test-time, existing PRMs, designed for short reasoning with binary judgment, cannot capture richer dimensions of information-seeking steps, such as tool interactions and reasoning over tool outputs, nor handle the rapidly growing context in long-horizon tasks. To address these limitations, we introduce PRInTS, a generative PRM trained with dual capabilities: (1) dense scoring based on the PRM's reasoning across multiple step quality dimensions (e.g., interpretation of tool outputs, tool call informativeness) and (2) trajectory summarization that compresses the growing context while preserving essential information for step evaluation. Extensive evaluations across FRAMES, GAIA (levels 1-3), and WebWalkerQA (easy-hard) benchmarks on multiple models, along with ablations, reveal that best-of-n sampling with PRInTS enhances information-seeking abilities of open-source models as well as specialized agents, matching or surpassing the performance of frontier models with a much smaller backbone agent and outperforming other strong reward modeling baselines.","authors":["Jaewoo Lee","Archiki Prasad","Justin Chih-Yao Chen","Zaid Khan","Elias Stengel-Eskin","Mohit Bansal"],"pdf_url":"","comment":"18 pages, code: https://github.com/G-JWLee/PRInTS"},{"id":"http://arxiv.org/abs/2511.19304v1","updated":"2025-11-24T16:54:23Z","published":"2025-11-24T16:54:23Z","title":"AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning","summary":"Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.","authors":["Jiayi Zhang","Yiran Peng","Fanqi Kong","Yang Cheng","Yifan Wu","Zhaoyang Yu","Jinyu Xiang","Jianhao Ruan","Jinlin Wang","Maojia Song","HongZhang Liu","Xiangru Tang","Bang Liu","Chenglin Wu","Yuyu Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.15480v2","updated":"2025-11-24T16:47:54Z","published":"2025-08-21T11:56:25Z","title":"Learning Protein-Ligand Binding in Hyperbolic Space","summary":"Protein-ligand binding prediction is central to virtual screening and affinity ranking, two fundamental tasks in drug discovery. While recent retrieval-based methods embed ligands and protein pockets into Euclidean space for similarity-based search, the geometry of Euclidean embeddings often fails to capture the hierarchical structure and fine-grained affinity variations intrinsic to molecular interactions. In this work, we propose HypSeek, a hyperbolic representation learning framework that embeds ligands, protein pockets, and sequences into Lorentz-model hyperbolic space. By leveraging the exponential geometry and negative curvature of hyperbolic space, HypSeek enables expressive, affinity-sensitive embeddings that can effectively model both global activity and subtle functional differences-particularly in challenging cases such as activity cliffs, where structurally similar ligands exhibit large affinity gaps. Our mode unifies virtual screening and affinity ranking in a single framework, introducing a protein-guided three-tower architecture to enhance representational structure. HypSeek improves early enrichment in virtual screening on DUD-E from 42.63 to 51.44 (+20.7%) and affinity ranking correlation on JACS from 0.5774 to 0.7239 (+25.4%), demonstrating the benefits of hyperbolic geometry across both tasks and highlighting its potential as a powerful inductive bias for protein-ligand modeling.","authors":["Jianhui Wang","Wenyu Zhu","Bowen Gao","Xin Hong","Ya-Qin Zhang","Wei-Ying Ma","Yanyan Lan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19299v1","updated":"2025-11-24T16:46:44Z","published":"2025-11-24T16:46:44Z","title":"Open-weight genome language model safeguards: Assessing robustness via adversarial fine-tuning","summary":"Novel deep learning architectures are increasingly being applied to biological data, including genetic sequences. These models, referred to as genomic language mod- els (gLMs), have demonstrated impressive predictive and generative capabilities, raising concerns that such models may also enable misuse, for instance via the generation of genomes for human-infecting viruses. These concerns have catalyzed calls for risk mitigation measures. The de facto mitigation of choice is filtering of pretraining data (i.e., removing viral genomic sequences from training datasets) in order to limit gLM performance on virus-related tasks. However, it is not currently known how robust this approach is for securing open-source models that can be fine-tuned using sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and perform fine-tuning using sequences from 110 harmful human-infecting viruses to assess the rescue of misuse-relevant predictive capabilities. The fine- tuned model exhibited reduced perplexity on unseen viral sequences relative to 1) the pretrained model and 2) a version fine-tuned on bacteriophage sequences. The model fine-tuned on human-infecting viruses also identified immune escape variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo- sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that data exclusion might be circumvented by fine-tuning approaches that can, to some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need for safety frameworks for gLMs and outline further work needed on evaluations and mitigation measures to enable the safe deployment of gLMs.","authors":["James R. M. Black","Moritz S. Hanke","Aaron Maiwald","Tina Hernandez-Boussard","Oliver M. Crook","Jaspreet Pannu"],"pdf_url":"","comment":"39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI"},{"id":"http://arxiv.org/abs/2511.11684v3","updated":"2025-11-24T16:42:03Z","published":"2025-11-12T08:14:41Z","title":"A Bayesian Model for Multi-stage Censoring","summary":"Many sequential decision settings in healthcare feature funnel structures characterized by a series of stages, such as screenings or evaluations, where the number of patients who advance to each stage progressively decreases and decisions become increasingly costly. For example, an oncologist may first conduct a breast exam, followed by a mammogram for patients with concerning exams, followed by a biopsy for patients with concerning mammograms. A key challenge is that the ground truth outcome, such as the biopsy result, is only revealed at the end of this funnel. The selective censoring of the ground truth can introduce statistical biases in risk estimation, especially in underserved patient groups, whose outcomes are more frequently censored. We develop a Bayesian model for funnel decision structures, drawing from prior work on selective labels and censoring. We first show in synthetic settings that our model is able to recover the true parameters and predict outcomes for censored patients more accurately than baselines. We then apply our model to a dataset of emergency department visits, where in-hospital mortality is observed only for those who are admitted to either the hospital or ICU. We find that there are gender-based differences in hospital and ICU admissions. In particular, our model estimates that the mortality risk threshold to admit women to the ICU is higher for women (5.1%) than for men (4.5%).","authors":["Shuvom Sadhuka","Sophia Lin","Bonnie Berger","Emma Pierson"],"pdf_url":"","comment":"Proceedings of ML4H 2025"},{"id":"http://arxiv.org/abs/2510.27280v2","updated":"2025-11-24T16:40:06Z","published":"2025-10-31T08:41:13Z","title":"FOCUS: Efficient Keyframe Selection for Long Video Understanding","summary":"Multimodal large language models (MLLMs) represent images and video frames as visual tokens. Scaling from single images to hour-long videos, however, inflates the token budget far beyond practical limits. Popular pipelines therefore either uniformly subsample or apply keyframe selection with retrieval-style scoring using smaller vision-language models. However, these keyframe selection methods still rely on pre-filtering before selection to reduce the inference cost and can miss the most informative moments. We propose FOCUS, Frame-Optimistic Confidence Upper-bound Selection, a training-free, model-agnostic keyframe selection module that selects query-relevant frames under a strict token budget. FOCUS formulates keyframe selection as a combinatorial pure-exploration (CPE) problem in multi-armed bandits: it treats short temporal clips as arms, and uses empirical means and Bernstein confidence radius to identify informative regions while preserving exploration of uncertain areas. The resulting two-stage exploration-exploitation procedure reduces from a sequential policy with theoretical guarantees, first identifying high-value temporal regions, then selecting top-scoring frames within each region. On two long-video question-answering benchmarks, FOCUS delivers substantial accuracy improvements while processing less than 2% of video frames. For videos longer than 20 minutes, it achieves an 11.9% gain in accuracy on LongVideoBench, demonstrating its effectiveness as a keyframe selection method and providing a simple and general solution for scalable long-video understanding with MLLMs. Code is available at https://github.com/NUS-HPC-AI-Lab/FOCUS.","authors":["Zirui Zhu","Hailun Xu","Yang Luo","Yong Liu","Kanchan Sarkar","Zhenheng Yang","Yang You"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19291v1","updated":"2025-11-24T16:37:28Z","published":"2025-11-24T16:37:28Z","title":"TorchQuantumDistributed","summary":"TorchQuantumDistributed (tqd) is a PyTorch-based [Paszke et al., 2019] library for accelerator-agnostic differentiable quantum state vector simulation at scale. This enables studying the behavior of learnable parameterized near-term and fault- tolerant quantum circuits with high qubit counts.","authors":["Oliver Knitter","Jonathan Mei","Masako Yamada","Martin Roetteler"],"pdf_url":"","comment":"12 pages, 4 figures, to appear in the AI for Science Workshop at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.19289v1","updated":"2025-11-24T16:36:06Z","published":"2025-11-24T16:36:06Z","title":"Performance Guarantees for Quantum Neural Estimation of Entropies","summary":"Estimating quantum entropies and divergences is an important problem in quantum physics, information theory, and machine learning. Quantum neural estimators (QNEs), which utilize a hybrid classical-quantum architecture, have recently emerged as an appealing computational framework for estimating these measures. Such estimators combine classical neural networks with parametrized quantum circuits, and their deployment typically entails tedious tuning of hyperparameters controlling the sample size, network architecture, and circuit topology. This work initiates the study of formal guarantees for QNEs of measured (Rényi) relative entropies in the form of non-asymptotic error risk bounds. We further establish exponential tail bounds showing that the error is sub-Gaussian, and thus sharply concentrates about the ground truth value. For an appropriate sub-class of density operator pairs on a space of dimension $d$ with bounded Thompson metric, our theory establishes a copy complexity of $O(|Θ(\\mathcal{U})|d/ε^2)$ for QNE with a quantum circuit parameter set $Θ(\\mathcal{U})$, which has minimax optimal dependence on the accuracy $ε$. Additionally, if the density operator pairs are permutation invariant, we improve the dimension dependence above to $O(|Θ(\\mathcal{U})|\\mathrm{polylog}(d)/ε^2)$. Our theory aims to facilitate principled implementation of QNEs for measured relative entropies and guide hyperparameter tuning in practice.","authors":["Sreejith Sreekumar","Ziv Goldfeld","Mark M. Wilde"],"pdf_url":"","comment":"42+4 pages"},{"id":"http://arxiv.org/abs/2511.19284v1","updated":"2025-11-24T16:32:07Z","published":"2025-11-24T16:32:07Z","title":"The Unified Non-Convex Framework for Robust Causal Inference: Overcoming the Gaussian Barrier and Optimization Fragility","summary":"This document proposes a Unified Robust Framework that re-engineers the estimation of the Average Treatment Effect on the Overlap (ATO). It synthesizes gamma-Divergence for outlier robustness, Graduated Non-Convexity (GNC) for global optimization, and a \"Gatekeeper\" mechanism to address the impossibility of higher-order orthogonality in Gaussian regimes.","authors":["Eichi Uehara"],"pdf_url":"","comment":"10 pages, 1 table"},{"id":"http://arxiv.org/abs/2511.19279v1","updated":"2025-11-24T16:29:02Z","published":"2025-11-24T16:29:02Z","title":"MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings","summary":"A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.","authors":["Victor Rambaud","Salvador Mascarenhas","Yair Lakretz"],"pdf_url":"","comment":"19 pages (29 with appendix), 8 figures"},{"id":"http://arxiv.org/abs/2511.19277v1","updated":"2025-11-24T16:28:44Z","published":"2025-11-24T16:28:44Z","title":"Closing Gaps in Emissions Monitoring with Climate TRACE","summary":"Global greenhouse gas emissions estimates are essential for monitoring and mitigation planning. Yet most datasets lack one or more characteristics that enhance their actionability, such as accuracy, global coverage, high spatial and temporal resolution, and frequent updates. To address these gaps, we present Climate TRACE (climatetrace.org), an open-access platform delivering global emissions estimates with enhanced detail, coverage, and timeliness. Climate TRACE synthesizes existing emissions data, prioritizing accuracy, coverage, and resolution, and fills gaps using sector-specific estimation approaches. The dataset is the first to provide globally comprehensive emissions estimates for individual sources (e.g., individual power plants) for all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the present, with a two-month reporting lag and monthly updates. The open-access platform enables non-technical audiences to engage with detailed emissions datasets for most subnational governments worldwide. Climate TRACE supports data-driven climate action at scales where decisions are made, representing a major breakthrough for emissions accounting and mitigation.","authors":["Brittany V. Lancellotti","Jordan M. Malof","Aaron Davitt","Gavin McCormick","Shelby Anderson","Pol Carbó-Mestre","Gary Collins","Verity Crane","Zoheyr Doctor","George Ebri","Kevin Foster","Trey M. Gowdy","Michael Guzzardi","John Heal","Heather Hunter","David Kroodsma","Khandekar Mahammad Galib","Paul J. Markakis","Gavin McDonald","Daniel P. Moore","Eric D. Nguyen","Sabina Parvu","Michael Pekala","Christine D. Piatko","Amy Piscopo","Mark Powell","Krsna Raniga","Elizabeth P. Reilly","Michael Robinette","Ishan Saraswat","Patrick Sicurello","Isabella Söldner-Rembold","Raymond Song","Charlotte Underwood","Kyle Bradbury"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19273v1","updated":"2025-11-24T16:23:19Z","published":"2025-11-24T16:23:19Z","title":"Scalable Bayesian Network Structure Learning Using Tsetlin Machine to Constrain the Search Space","summary":"The PC algorithm is a widely used method in causal inference for learning the structure of Bayesian networks. Despite its popularity, the PC algorithm suffers from significant time complexity, particularly as the size of the dataset increases, which limits its applicability in large-scale real-world problems. In this study, we propose a novel approach that utilises the Tsetlin Machine (TM) to construct Bayesian structures more efficiently. Our method leverages the most significant literals extracted from the TM and performs conditional independence (CI) tests on these selected literals instead of the full set of variables, resulting in a considerable reduction in computational time. We implemented our approach and compared it with various state-of-the-art methods. Our evaluation includes categorical datasets from the bnlearn repository, such as Munin1, Hepar2. The findings indicate that the proposed TM-based method not only reduces computational complexity but also maintains competitive accuracy in causal discovery, making it a viable alternative to traditional PC algorithm implementations by offering improved efficiency without compromising performance.","authors":["Kunal Dumbre","Lei Jiao","Ole-Christoffer Granmo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19272v1","updated":"2025-11-24T16:22:05Z","published":"2025-11-24T16:22:05Z","title":"Tiny-TSM: Efficiently Training a Lightweight SOTA Time Series Foundation Model","summary":"We present Tiny-TSM, a time series foundation model characterized by small scale, economical training, and state-of-the-art performance. It comprises 23M total parameters, trained on a single A100 GPU in less than a week using a new synthetic data generation and data augmentation pipeline (SynthTS). Without any neural architecture search, hyperparameter tuning, or scaling up model size, Tiny-TSM achieves state-of-the-art performance on a wide range of time series benchmark datasets, often outperforming much larger models and even matching the performance of much larger, industrial-scale, likely highly tuned foundation models. Specifically, Tiny-TSM outperforms all other time series foundation models we evaluated on medium- and long-term forecasting tasks under MSE loss, while short-term accuracy is still competitive with state-of-the-art models.\n  We also introduce a causal input normalization scheme that enables time series models to be trained with dense next-token prediction loss, significantly accelerating convergence speed and reducing training time.\n  All experiments were conducted on a single A100 GPU, illustrating the practicality of the proposed approach in a resource-constrained setting.","authors":["Felix Birkel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19269v1","updated":"2025-11-24T16:21:25Z","published":"2025-11-24T16:21:25Z","title":"CDLM: Consistency Diffusion Language Models For Faster Sampling","summary":"Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.","authors":["Minseo Kim","Chenfeng Xu","Coleman Hooper","Harman Singh","Ben Athiwaratkun","Ce Zhang","Kurt Keutzer","Amir Gholami"],"pdf_url":"","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.19267v1","updated":"2025-11-24T16:19:48Z","published":"2025-11-24T16:19:48Z","title":"Leveraging Spatiotemporal Graph Neural Networks for Multi-Store Sales Forecasting","summary":"This work evaluates the effectiveness of spatiotemporal Graph Neural Networks (GNNs) for multi-store retail sales forecasting and compares their performance against ARIMA, LSTM, and XGBoost baselines. Using weekly sales data from 45 Walmart stores, we construct a relational forecasting framework that models inter-store dependencies through a learned adaptive graph. The proposed STGNN predicts log-differenced sales and reconstructs final values through a residual path, enabling stable training and improved generalisation. Experiments show that STGNN achieves the lowest overall forecasting error, outperforming all baselines in Normalised Total Absolute Error, P90 MAPE, and variance of MAPE across stores. Analysis of the learned adjacency matrix reveals meaningful functional store clusters and high-influence nodes that emerge without geographic metadata. These results demonstrate that relational structure significantly improves forecast quality in interconnected retail environments and establishes STGNNs as a robust modelling choice for multi-store demand prediction.","authors":["Manish Singh","Arpita Dayama"],"pdf_url":"","comment":"6 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2506.06725v2","updated":"2025-11-24T16:18:31Z","published":"2025-06-07T09:13:34Z","title":"WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making","summary":"Large Language Models (LLMs) possess general world knowledge but often struggle to generate precise predictions in structured, domain-specific contexts such as simulations. These limitations arise from their inability to ground their broad, unstructured understanding in specific environments. To address this, we present WorldLLM, a framework that enhances LLM-based world modeling by combining Bayesian inference and autonomous active exploration with reinforcement learning. WorldLLM leverages the in-context learning abilities of LLMs to guide an LLM-based world model's predictions using natural language hypotheses given in its prompt. These hypotheses are iteratively refined through a Bayesian inference framework that leverages a second LLM as the proposal distribution given collected evidence. This evidence is collected using a curiosity-driven reinforcement learning policy that explores the environment to find transitions with a low log-likelihood under our LLM-based predictive model using the current hypotheses. By alternating between refining hypotheses and collecting new evidence, our framework autonomously drives continual improvement of the predictions. Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment that requires agents to manipulate and combine objects. The framework not only enhances predictive accuracy, but also generates human-interpretable theories of environment dynamics.","authors":["Guillaume Levy","Cedric Colas","Pierre-Yves Oudeyer","Thomas Carta","Clement Romac"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19265v1","updated":"2025-11-24T16:16:49Z","published":"2025-11-24T16:16:49Z","title":"Unboxing the Black Box: Mechanistic Interpretability for Algorithmic Understanding of Neural Networks","summary":"The black box nature of deep neural networks poses a significant challenge for the deployment of transparent and trustworthy artificial intelligence (AI) systems. With the growing presence of AI in society, it becomes increasingly important to develop methods that can explain and interpret the decisions made by these systems. To address this, mechanistic interpretability (MI) emerged as a promising and distinctive research program within the broader field of explainable artificial intelligence (XAI). MI is the process of studying the inner computations of neural networks and translating them into human-understandable algorithms. It encompasses reverse engineering techniques aimed at uncovering the computational algorithms implemented by neural networks. In this article, we propose a unified taxonomy of MI approaches and provide a detailed analysis of key techniques, illustrated with concrete examples and pseudo-code. We contextualize MI within the broader interpretability landscape, comparing its goals, methods, and insights to other strands of XAI. Additionally, we trace the development of MI as a research area, highlighting its conceptual roots and the accelerating pace of recent work. We argue that MI holds significant potential to support a more scientific understanding of machine learning systems -- treating models not only as tools for solving tasks, but also as systems to be studied and understood. We hope to invite new researchers into the field of mechanistic interpretability.","authors":["Bianka Kowalska","Halina Kwaśnicka"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19264v1","updated":"2025-11-24T16:16:18Z","published":"2025-11-24T16:16:18Z","title":"Interpreting GFlowNets for Drug Discovery: Extracting Actionable Insights for Medicinal Chemistry","summary":"Generative Flow Networks, or GFlowNets, offer a promising framework for molecular design, but their internal decision policies remain opaque. This limits adoption in drug discovery, where chemists require clear and interpretable rationales for proposed structures. We present an interpretability framework for SynFlowNet, a GFlowNet trained on documented chemical reactions and purchasable starting materials that generates both molecules and the synthetic routes that produce them. Our approach integrates three complementary components. Gradient based saliency combined with counterfactual perturbations identifies which atomic environments influence reward and how structural edits change molecular outcomes. Sparse autoencoders reveal axis aligned latent factors that correspond to physicochemical properties such as polarity, lipophilicity, and molecular size. Motif probes show that functional groups including aromatic rings and halogens are explicitly encoded and linearly decodable from the internal embeddings. Together, these results expose the chemical logic inside SynFlowNet and provide actionable and mechanistic insight that supports transparent and controllable molecular design.","authors":["Amirtha Varshini A S","Duminda S. Ranasinghe","Hok Hei Tam"],"pdf_url":"","comment":"13 pages, 7 figures. Accepted for presentation at NeurIPS 2025 WiML Workshop and Molecular Machine Learning Conference (MoML) 2025"},{"id":"http://arxiv.org/abs/2511.19263v1","updated":"2025-11-24T16:15:41Z","published":"2025-11-24T16:15:41Z","title":"Solar-GECO: Perovskite Solar Cell Property Prediction with Geometric-Aware Co-Attention","summary":"Perovskite solar cells are promising candidates for next-generation photovoltaics. However, their performance as multi-scale devices is determined by complex interactions between their constituent layers. This creates a vast combinatorial space of possible materials and device architectures, making the conventional experimental-based screening process slow and expensive. Machine learning models try to address this problem, but they only focus on individual material properties or neglect the important geometric information of the perovskite crystal. To address this problem, we propose to predict perovskite solar cell power conversion efficiency with a geometric-aware co-attention (Solar-GECO) model. Solar-GECO combines a geometric graph neural network (GNN) - that directly encodes the atomic structure of the perovskite absorber - with language model embeddings that process the textual strings representing the chemical compounds of the transport layers and other device components. Solar-GECO also integrates a co-attention module to capture intra-layer dependencies and inter-layer interactions, while a probabilistic regression head predicts both power conversion efficiency (PCE) and its associated uncertainty. Solar-GECO achieves state-of-the-art performance, significantly outperforming several baselines, reducing the mean absolute error (MAE) for PCE prediction from 3.066 to 2.936 compared to semantic GNN (the previous state-of-the-art model). Solar-GECO demonstrates that integrating geometric and textual information provides a more powerful and accurate framework for PCE prediction.","authors":["Lucas Li","Jean-Baptiste Puel","Florence Carton","Dounya Barrit","Jhony H. Giraldo"],"pdf_url":"","comment":"Accepted at the AI for Accelerated Materials Design (AI4Mat) Workshop at NeurIPS 2025. 14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.19262v1","updated":"2025-11-24T16:15:08Z","published":"2025-11-24T16:15:08Z","title":"Psychometric Tests for AI Agents and Their Moduli Space","summary":"We develop a moduli-theoretic view of psychometric test batteries for AI agents and connect it explicitly to the AAI score developed previously. First, we make precise the notion of an AAI functional on a battery and set out axioms that any reasonable autonomy/general intelligence score should satisfy. Second, we show that the composite index ('AAI-Index') defined previously is a special case of our AAI functional. Third, we introduce the notion of a cognitive core of an agent relative to a battery and define the associated AAI$_{\\textrm{core}}$ score as the restriction of an AAI functional to that core. Finally, we use these notions to describe invariants of batteries under evaluation-preserving symmetries and outline how moduli of equivalent batteries are organized.","authors":["Przemyslaw Chojecki"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19260v1","updated":"2025-11-24T16:12:03Z","published":"2025-11-24T16:12:03Z","title":"A Nutrition Multimodal Photoplethysmography Language Model","summary":"Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.","authors":["Kyle Verrier","Achille Nazaret","Joseph Futoma","Andrew C. Miller","Guillermo Sapiro"],"pdf_url":"","comment":"21 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.19257v1","updated":"2025-11-24T16:11:01Z","published":"2025-11-24T16:11:01Z","title":"Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation","summary":"With the rapid advancement of retrieval-augmented vision-language models, multimodal medical retrieval-augmented generation (MMed-RAG) systems are increasingly adopted in clinical decision support. These systems enhance medical applications by performing cross-modal retrieval to integrate relevant visual and textual evidence for tasks, e.g., report generation and disease diagnosis. However, their complex architecture also introduces underexplored adversarial vulnerabilities, particularly via visual input perturbations. In this paper, we propose Medusa, a novel framework for crafting cross-modal transferable adversarial attacks on MMed-RAG systems under a black-box setting. Specifically, Medusa formulates the attack as a perturbation optimization problem, leveraging a multi-positive InfoNCE loss (MPIL) to align adversarial visual embeddings with medically plausible but malicious textual targets, thereby hijacking the retrieval process. To enhance transferability, we adopt a surrogate model ensemble and design a dual-loop optimization strategy augmented with invariant risk minimization (IRM). Extensive experiments on two real-world medical tasks, including medical report generation and disease diagnosis, demonstrate that Medusa achieves over 90% average attack success rate across various generation models and retrievers under appropriate parameter configuration, while remaining robust against four mainstream defenses, outperforming state-of-the-art baselines. Our results reveal critical vulnerabilities in the MMed-RAG systems and highlight the necessity of robustness benchmarking in safety-critical medical applications. The code and data are available at https://anonymous.4open.science/r/MMed-RAG-Attack-F05A.","authors":["Yingjia Shang","Yi Liu","Huimin Wang","Furong Li","Wenfang Sun","Wu Chengyu","Yefeng Zheng"],"pdf_url":"","comment":"Accepted at KDD 2026 First Cycle (full version). Authors marked with * contributed equally. Yi Liu is the lead author"},{"id":"http://arxiv.org/abs/2511.19256v1","updated":"2025-11-24T16:09:55Z","published":"2025-11-24T16:09:55Z","title":"SimDiff: Simpler Yet Better Diffusion Model for Time Series Point Forecasting","summary":"Diffusion models have recently shown promise in time series forecasting, particularly for probabilistic predictions. However, they often fail to achieve state-of-the-art point estimation performance compared to regression-based methods. This limitation stems from difficulties in providing sufficient contextual bias to track distribution shifts and in balancing output diversity with the stability and precision required for point forecasts. Existing diffusion-based approaches mainly focus on full-distribution modeling under probabilistic frameworks, often with likelihood maximization objectives, while paying little attention to dedicated strategies for high-accuracy point estimation. Moreover, other existing point prediction diffusion methods frequently rely on pre-trained or jointly trained mature models for contextual bias, sacrificing the generative flexibility of diffusion models.\n  To address these challenges, we propose SimDiff, a single-stage, end-to-end framework. SimDiff employs a single unified Transformer network carefully tailored to serve as both denoiser and predictor, eliminating the need for external pre-trained or jointly trained regressors. It achieves state-of-the-art point estimation performance by leveraging intrinsic output diversity and improving mean squared error accuracy through multiple inference ensembling. Key innovations, including normalization independence and the median-of-means estimator, further enhance adaptability and stability. Extensive experiments demonstrate that SimDiff significantly outperforms existing methods in time series point forecasting.","authors":["Hang Ding","Xue Wang","Tian Zhou","Tao Yao"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.19253v1","updated":"2025-11-24T16:05:37Z","published":"2025-11-24T16:05:37Z","title":"MAESTRO: Multi-Agent Environment Shaping through Task and Reward Optimization","summary":"Cooperative Multi-Agent Reinforcement Learning (MARL) faces two major design bottlenecks: crafting dense reward functions and constructing curricula that avoid local optima in high-dimensional, non-stationary environments. Existing approaches rely on fixed heuristics or use Large Language Models (LLMs) directly in the control loop, which is costly and unsuitable for real-time systems. We propose MAESTRO (Multi-Agent Environment Shaping through Task and Reward Optimization), a framework that moves the LLM outside the execution loop and uses it as an offline training architect. MAESTRO introduces two generative components: (i) a semantic curriculum generator that creates diverse, performance-driven traffic scenarios, and (ii) an automated reward synthesizer that produces executable Python reward functions adapted to evolving curriculum difficulty. These components guide a standard MARL backbone (MADDPG) without increasing inference cost at deployment. We evaluate MAESTRO on large-scale traffic signal control (Hangzhou, 16 intersections) and conduct controlled ablations. Results show that combining LLM-generated curricula with LLM-generated reward shaping yields improved performance and stability. Across four seeds, the full system achieves +4.0% higher mean return (163.26 vs. 156.93) and 2.2% better risk-adjusted performance (Sharpe 1.53 vs. 0.70) over a strong curriculum baseline. These findings highlight LLMs as effective high-level designers for cooperative MARL training.","authors":["Boyuan Wu"],"pdf_url":"","comment":"Preprint. 16 pages, 6 figures. Preliminary version; extended experiments and analysis forthcoming"},{"id":"http://arxiv.org/abs/2511.15986v2","updated":"2025-11-24T15:59:06Z","published":"2025-11-20T02:38:00Z","title":"Fairness in Multi-modal Medical Diagnosis with Demonstration Selection","summary":"Multimodal large language models (MLLMs) have shown strong potential for medical image reasoning, yet fairness across demographic groups remains a major concern. Existing debiasing methods often rely on large labeled datasets or fine-tuning, which are impractical for foundation-scale models. We explore In-Context Learning (ICL) as a lightweight, tuning-free alternative for improving fairness. Through systematic analysis, we find that conventional demonstration selection (DS) strategies fail to ensure fairness due to demographic imbalance in selected exemplars. To address this, we propose Fairness-Aware Demonstration Selection (FADS), which builds demographically balanced and semantically relevant demonstrations via clustering-based sampling. Experiments on multiple medical imaging benchmarks show that FADS consistently reduces gender-, race-, and ethnicity-related disparities while maintaining strong accuracy, offering an efficient and scalable path toward fair medical image reasoning. These results highlight the potential of fairness-aware in-context learning as a scalable and data-efficient solution for equitable medical image reasoning.","authors":["Dawei Li","Zijian Gu","Peng Wang","Chuhan Song","Zhen Tan","Mohan Zhang","Tianlong Chen","Yu Tian","Song Wang"],"pdf_url":"","comment":"10 pages (including 2 pages of references), 4 figures. This work explores fairness in multi-modal medical image reasoning using in-context learning"},{"id":"http://arxiv.org/abs/2511.13646v3","updated":"2025-11-24T15:55:51Z","published":"2025-11-17T17:58:18Z","title":"Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?","summary":"Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that LIVE-SWE-AGENT can achieve an impressive solve rate of 77.4% without test-time scaling, outperforming all existing software agents, including the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%.","authors":["Chunqiu Steven Xia","Zhe Wang","Yan Yang","Yuxiang Wei","Lingming Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19246v1","updated":"2025-11-24T15:55:44Z","published":"2025-11-24T15:55:44Z","title":"Neural Architecture Search for Quantum Autoencoders","summary":"In recent years, machine learning and deep learning have driven advances in domains such as image classification, speech recognition, and anomaly detection by leveraging multi-layer neural networks to model complex data. Simultaneously, quantum computing (QC) promises to address classically intractable problems via quantum parallelism, motivating research in quantum machine learning (QML). Among QML techniques, quantum autoencoders show promise for compressing high-dimensional quantum and classical data. However, designing effective quantum circuit architectures for quantum autoencoders remains challenging due to the complexity of selecting gates, arranging circuit layers, and tuning parameters.\n  This paper proposes a neural architecture search (NAS) framework that automates the design of quantum autoencoders using a genetic algorithm (GA). By systematically evolving variational quantum circuit (VQC) configurations, our method seeks to identify high-performing hybrid quantum-classical autoencoders for data reconstruction without becoming trapped in local minima. We demonstrate effectiveness on image datasets, highlighting the potential of quantum autoencoders for efficient feature extraction within a noise-prone, near-term quantum era. Our approach lays a foundation for broader application of genetic algorithms to quantum architecture search, aiming for a robust, automated method that can adapt to varied data and hardware constraints.","authors":["Hibah Agha","Samuel Yen-Chi Chen","Huan-Hsin Tseng","Shinjae Yoo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19241v1","updated":"2025-11-24T15:52:17Z","published":"2025-11-24T15:52:17Z","title":"Local Entropy Search over Descent Sequences for Bayesian Optimization","summary":"Searching large and complex design spaces for a global optimum can be infeasible and unnecessary. A practical alternative is to iteratively refine the neighborhood of an initial design using local optimization methods such as gradient descent. We propose local entropy search (LES), a Bayesian optimization paradigm that explicitly targets the solutions reachable by the descent sequences of iterative optimizers. The algorithm propagates the posterior belief over the objective through the optimizer, resulting in a probability distribution over descent sequences. It then selects the next evaluation by maximizing mutual information with that distribution, using a combination of analytic entropy calculations and Monte-Carlo sampling of descent sequences. Empirical results on high-complexity synthetic objectives and benchmark problems show that LES achieves strong sample efficiency compared to existing local and global Bayesian optimization methods.","authors":["David Stenger","Armin Lindicke","Alexander von Rohr","Sebastian Trimpe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19240v1","updated":"2025-11-24T15:52:02Z","published":"2025-11-24T15:52:02Z","title":"Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform","summary":"Many real-world bandit problems involve non-stationary reward distributions, where the optimal decision may shift due to evolving environments. However, the performance of some typical Multi-Armed Bandit (MAB) models such as Upper Confidence Bound (UCB) algorithms degrades significantly in non-stationary environments where reward distributions change over time. To address this limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view algorithm that integrates a discount-based long-term perspective with a sliding-window-based short-term view. A data-driven semi-synthetic simulation platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to test algorithm adaptability under abrupt and gradual drift scenarios. Experimental results demonstrate that a well-configured sliding-window mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB) suffers from a fundamental learning failure, leading to linear regret. Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation strategy, achieves superior performance in dynamic settings, highlighting that the ensemble strategy itself is a decisive factor for success.","authors":["Minxin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26533v2","updated":"2025-11-24T15:37:40Z","published":"2025-10-30T14:22:57Z","title":"Higher-Order Regularization Learning on Hypergraphs","summary":"Higher-Order Hypergraph Learning (HOHL) was recently introduced as a principled alternative to classical hypergraph regularization, enforcing higher-order smoothness via powers of multiscale Laplacians induced by the hypergraph structure. Prior work established the well- and ill-posedness of HOHL through an asymptotic consistency analysis in geometric settings. We extend this theoretical foundation by proving the consistency of a truncated version of HOHL and deriving explicit convergence rates when HOHL is used as a regularizer in fully supervised learning. We further demonstrate its strong empirical performance in active learning and in datasets lacking an underlying geometric structure, highlighting HOHL's versatility and robustness across diverse learning settings.","authors":["Adrien Weihs","Andrea L. Bertozzi","Matthew Thorpe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.04112v2","updated":"2025-11-24T15:33:40Z","published":"2025-09-04T11:22:08Z","title":"Synthetic Counterfactual Labels for Efficient Conformal Counterfactual Inference","summary":"This work addresses the problem of constructing reliable prediction intervals for individual counterfactual outcomes. Existing conformal counterfactual inference (CCI) methods provide marginal coverage guarantees but often produce overly conservative intervals, particularly under treatment imbalance when counterfactual samples are scarce. We introduce synthetic data-powered CCI (SP-CCI), a new framework that augments the calibration set with synthetic counterfactual labels generated by a pre-trained counterfactual model. To ensure validity, SP-CCI incorporates synthetic samples into a conformal calibration procedure based on risk-controlling prediction sets (RCPS) with a debiasing step informed by prediction-powered inference (PPI). We prove that SP-CCI achieves tighter prediction intervals while preserving marginal coverage, with theoretical guarantees under both exact and approximate importance weighting. Empirical results on different datasets confirm that SP-CCI consistently reduces interval width compared to standard CCI across all settings.","authors":["Amirmohammad Farzaneh","Matteo Zecchin","Osvaldo Simeone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.25354v2","updated":"2025-11-24T15:26:34Z","published":"2025-10-29T10:19:32Z","title":"Analysis of Semi-Supervised Learning on Hypergraphs","summary":"Hypergraphs provide a natural framework for modeling higher-order interactions, yet their theoretical underpinnings in semi-supervised learning remain limited. We provide an asymptotic consistency analysis of variational learning on random geometric hypergraphs, precisely characterizing the conditions ensuring the well-posedness of hypergraph learning as well as showing convergence to a weighted $p$-Laplacian equation. Motivated by this, we propose Higher-Order Hypergraph Learning (HOHL), which regularizes via powers of Laplacians from skeleton graphs for multiscale smoothness. HOHL converges to a higher-order Sobolev seminorm. Empirically, it performs strongly on standard baselines.","authors":["Adrien Weihs","Andrea L. Bertozzi","Matthew Thorpe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19199v1","updated":"2025-11-24T15:09:07Z","published":"2025-11-24T15:09:07Z","title":"CLASH: A Benchmark for Cross-Modal Contradiction Detection","summary":"Contradictory multimodal inputs are common in real-world settings, yet existing benchmarks typically assume input consistency and fail to evaluate cross-modal contradiction detection - a fundamental capability for preventing hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark for multimodal contradiction detection, featuring COCO images paired with contradictory captions containing controlled object-level or attribute-level contradictions. The samples include targeted questions evaluated in both multiple-choice and open-ended formats. The benchmark provides an extensive fine-tuning set filtered through automated quality checks, alongside a smaller human-verified diagnostic set. Our analysis of state-of-the-art models reveals substantial limitations in recognizing cross-modal conflicts, exposing systematic modality biases and category-specific weaknesses. Furthermore, we empirically demonstrate that targeted fine-tuning on CLASH substantially enhances conflict detection capabilities.","authors":["Teodora Popordanoska","Jiameng Li","Matthew B. Blaschko"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2511.17123v2","updated":"2025-11-24T15:02:34Z","published":"2025-11-21T10:37:07Z","title":"Layer-wise Weight Selection for Power-Efficient Neural Network Acceleration","summary":"Systolic array accelerators execute CNNs with energy dominated by the switching activity of multiply accumulate (MAC) units. Although prior work exploits weight dependent MAC power for compression, existing methods often use global activation models, coarse energy proxies, or layer-agnostic policies, which limits their effectiveness on real hardware. We propose an energy aware, layer-wise compression framework that explicitly leverages MAC and layer level energy characteristics. First, we build a layer-aware MAC energy model that combines per-layer activation statistics with an MSB-Hamming distance grouping of 22-bit partial sum transitions, and integrate it with a tile-level systolic mapping to estimate convolution-layer energy. On top of this model, we introduce an energy accuracy co-optimized weight selection algorithm within quantization aware training and an energy-prioritized layer-wise schedule that compresses high energy layers more aggressively under a global accuracy constraint. Experiments on different CNN models demonstrate up to 58.6\\% energy reduction with 2-3\\% accuracy drop, outperforming a state-of-the-art power-aware baseline.","authors":["Jiaxun Fang","Grace Li Zhang","Shaoyi Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.05224v2","updated":"2025-11-24T14:59:34Z","published":"2025-08-07T10:10:37Z","title":"Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning","summary":"Federated learning (FL) enables collaborative model training across distributed clients while preserving data privacy by keeping data local. Traditional FL approaches rely on a centralized, star-shaped topology, where a central server aggregates model updates from clients. However, this architecture introduces several limitations, including a single point of failure, limited personalization, and poor robustness to distribution shifts or vulnerability to malfunctioning clients. Moreover, update selection in centralized FL often relies on low-level parameter differences, which can be unreliable when client data is not independent and identically distributed, and offer clients little control. In this work, we propose a decentralized, peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P topology to enable each client to identify and aggregate a personalized set of trustworthy and beneficial updates.This framework is the Local Inference Guided Aggregation for Heterogeneous Training Environments to Yield Enhancement Through Agreement and Regularization (LIGHTYEAR). Central to our method is an agreement score, computed on a local validation set, which quantifies the semantic alignment of incoming updates in the function space with respect to the clients reference model. Each client uses this score to select a tailored subset of updates and performs aggregation with a regularization term that further stabilizes the training. Our empirical evaluation across five datasets shows that the proposed approach consistently outperforms both, centralized baselines and existing P2P methods in terms of client-level performance, particularly under adversarial and heterogeneous conditions.","authors":["Mirko Konstantin","Anirban Mukhopadhyay"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19187v1","updated":"2025-11-24T14:54:00Z","published":"2025-11-24T14:54:00Z","title":"SpectraNet: FFT-assisted Deep Learning Classifier for Deepfake Face Detection","summary":"Detecting deepfake images is crucial in combating misinformation. We present a lightweight, generalizable binary classification model based on EfficientNet-B6, fine-tuned with transformation techniques to address severe class imbalances. By leveraging robust preprocessing, oversampling, and optimization strategies, our model achieves high accuracy, stability, and generalization. While incorporating Fourier transform-based phase and amplitude features showed minimal impact, our proposed framework helps non-experts to effectively identify deepfake images, making significant strides toward accessible and reliable deepfake detection.","authors":["Nithira Jayarathne","Naveen Basnayake","Keshawa Jayasundara","Pasindu Dodampegama","Praveen Wijesinghe","Hirushika Pelagewatta","Kavishka Abeywardana","Sandushan Ranaweera","Chamira Edussooriya"],"pdf_url":"","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2510.01047v2","updated":"2025-11-24T14:42:41Z","published":"2025-10-01T15:51:10Z","title":"In-Situ Tweedie Discrete Diffusion Models","summary":"While diffusion models excel at generating continuous data such as images, adapting them to discrete tasks has relied on indirect approaches that either operate in continuous embedding spaces or use token masking mechanisms, both of which deviate from modeling the true discrete data distribution that can be theoretically guaranteed by Tweedie's formula. We propose in-situ Tweedie Discrete Diffusion (TDD), a framework that performs diffusion guaranteed by Tweedie's formula directly within the discrete one-hot space, hence \"in-situ.\" Unlike prior methods that diffuse continuous embeddings or mask tokens, TDD directly corrupts one-hot vectors with Gaussian noise and performs iterative denoising through a timestep-conditioned cross-entropy objective rather than mean-squared-error reconstruction. At each denoising step, the model predicts class probabilities, applies argmax to obtain discrete predictions, converts them to one-hot vectors, and feeds them into the next iteration with progressively reduced noise. This process naturally unifies discriminative classification and generative modeling under a single framework. Experiments demonstrate that TDD achieves strong performance on both image classification and text generation tasks, with extensive ablation studies confirming the effectiveness of each design component. Our work establishes a principled approach to discrete diffusion that preserves the core characteristics of diffusion models while operating natively in discrete space.","authors":["Xiao Li","Jiaqi Zhang","Shuxiang Zhang","Tianshui Chen","Liang Lin","Guangrun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19176v1","updated":"2025-11-24T14:37:22Z","published":"2025-11-24T14:37:22Z","title":"From Raw Features to Effective Embeddings: A Three-Stage Approach for Multimodal Recipe Recommendation","summary":"Recipe recommendation has become an essential task in web-based food platforms. A central challenge is effectively leveraging rich multimodal features beyond user-recipe interactions. Our analysis shows that even simple uses of multimodal signals yield competitive performance, suggesting that systematic enhancement of these signals is highly promising. We propose TESMR, a 3-stage framework for recipe recommendation that progressively refines raw multimodal features into effective embeddings through: (1) content-based enhancement using foundation models with multimodal comprehension, (2) relation-based enhancement via message propagation over user-recipe interactions, and (3) learning-based enhancement through contrastive learning with learnable embeddings. Experiments on two real-world datasets show that TESMR outperforms existing methods, achieving 7-15% higher Recall@10.","authors":["Jeeho Shin","Kyungho Kim","Kijung Shin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19168v1","updated":"2025-11-24T14:32:13Z","published":"2025-11-24T14:32:13Z","title":"RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning","summary":"Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.","authors":["Deyi Ji","Yuekui Yang","Liqun Liu","Peng Shu","Haiyang Wu","Shaogang Tang","Xudong Chen","Shaoping Ma","Tianrun Chen","Lanyun Zhu"],"pdf_url":"","comment":"EMNLP 2025 (Oral, Industry Track)"},{"id":"http://arxiv.org/abs/2506.10879v2","updated":"2025-11-24T14:29:04Z","published":"2025-06-12T16:44:32Z","title":"A Goemans-Williamson type algorithm for identifying subcohorts in clinical trials","summary":"We design an efficient algorithm that outputs tests for identifying predominantly homogeneous subcohorts of patients from large in-homogeneous datasets. Our theoretical contribution is a rounding technique, similar to that of Goemans and Wiliamson (1995), that approximates the optimal solution within a factor of $0.82$. As an application, we use our algorithm to trade-off sensitivity for specificity to systematically identify clinically interesting homogeneous subcohorts of patients in the RNA microarray dataset for breast cancer from Curtis et al. (2012). One such clinically interesting subcohort suggests a link between LXR over-expression and BRCA2 and MSH6 methylation levels for patients in that subcohort.","authors":["Pratik Worah"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19165v1","updated":"2025-11-24T14:28:49Z","published":"2025-11-24T14:28:49Z","title":"First-order Sobolev Reinforcement Learning","summary":"We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also their derivatives with respect to states and actions. By differentiating the Bellman backup through differentiable dynamics, we obtain analytically consistent gradient targets. Incorporating these into the critic objective using a Sobolev-type loss encourages the critic to align with both the value and local geometry of the target function. This first-order TD matching principle can be seamlessly integrated into existing algorithms, such as Q-learning or actor-critic methods (e.g., DDPG, SAC), potentially leading to faster critic convergence and more stable policy gradients without altering their overall structure.","authors":["Fabian Schramm","Nicolas Perrin-Gilbert","Justin Carpentier"],"pdf_url":"","comment":"Workshop paper at Differentiable Systems and Scientific Machine Learning, EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.19157v1","updated":"2025-11-24T14:25:13Z","published":"2025-11-24T14:25:13Z","title":"A Robust State Filter Against Unmodeled Process And Measurement Noise","summary":"This paper introduces a novel Kalman filter framework designed to achieve robust state estimation under both process and measurement noise. Inspired by the Weighted Observation Likelihood Filter (WoLF), which provides robustness against measurement outliers, we applied generalized Bayesian approach to build a framework considering both process and measurement noise outliers.","authors":["Weitao Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19152v1","updated":"2025-11-24T14:17:56Z","published":"2025-11-24T14:17:56Z","title":"Masked Diffusion Models are Secretly Learned-Order Autoregressive Models","summary":"Masked Diffusion Models (MDMs) have emerged as one of the most promising paradigms for generative modeling over discrete domains. It is known that MDMs effectively train to decode tokens in a random order, and that this ordering has significant performance implications in practice. This observation raises a fundamental question: can we design a training framework that optimizes for a favorable decoding order? We answer this in the affirmative, showing that the continuous-time variational objective of MDMs, when equipped with multivariate noise schedules, can identify and optimize for a decoding order during training. We establish a direct correspondence between decoding order and the multivariate noise schedule and show that this setting breaks invariance of the MDM objective to the noise schedule. Furthermore, we prove that the MDM objective decomposes precisely into a weighted auto-regressive losses over these orders, which establishes them as auto-regressive models with learnable orders.","authors":["Prateek Garg","Bhavya Kohli","Sunita Sarawagi"],"pdf_url":"","comment":"Accepted at EurIPS 2025 Workshop on Principles of Generative Modeling (PriGM)"},{"id":"http://arxiv.org/abs/2511.19150v1","updated":"2025-11-24T14:15:57Z","published":"2025-11-24T14:15:57Z","title":"Feature Ranking in Credit-Risk with Qudit-Based Networks","summary":"In finance, predictive models must balance accuracy and interpretability, particularly in credit risk assessment, where model decisions carry material consequences. We present a quantum neural network (QNN) based on a single qudit, in which both data features and trainable parameters are co-encoded within a unified unitary evolution generated by the full Lie algebra. This design explores the entire Hilbert space while enabling interpretability through the magnitudes of the learned coefficients. We benchmark our model on a real-world, imbalanced credit-risk dataset from Taiwan. The proposed QNN consistently outperforms LR and reaches the results of random forest models in macro-F1 score while preserving a transparent correspondence between learned parameters and input feature importance. To quantify the interpretability of the proposed model, we introduce two complementary metrics: (i) the edit distance between the model's feature ranking and that of LR, and (ii) a feature-poisoning test where selected features are replaced with noise. Results indicate that the proposed quantum model achieves competitive performance while offering a tractable path toward interpretable quantum learning.","authors":["Georgios Maragkopoulos","Lazaros Chavatzoglou","Aikaterini Mandilara","Dimitris Syvridis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19147v1","updated":"2025-11-24T14:12:22Z","published":"2025-11-24T14:12:22Z","title":"Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation","summary":"Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data. Recent advances in Foundation Models (FMs) have introduced new opportunities for leveraging external semantic knowledge to guide SFDA. However, relying on a single FM is often insufficient, as it tends to bias adaptation toward a restricted semantic coverage, failing to capture diverse contextual cues under domain shift. To overcome this limitation, we propose a Collaborative Multi-foundation Adaptation (CoMA) framework that jointly leverages two different FMs (e.g., CLIP and BLIP) with complementary properties to capture both global semantics and local contextual cues. Specifically, we employ a bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge from the FMs to the target model. To ensure stable adaptation under mini-batch training, we introduce Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art SFDA methods across four benchmarks, including Office-31, Office-Home, DomainNet-126, and VisDA, under the closed-set setting, while also achieving best results on partial-set and open-set variants.","authors":["Huisoo Lee","Jisu Han","Hyunsouk Cho","Wonjun Hwang"],"pdf_url":"","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.19124v1","updated":"2025-11-24T13:53:31Z","published":"2025-11-24T13:53:31Z","title":"Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty","summary":"Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.","authors":["Krishang Sharma"],"pdf_url":"","comment":"10 pages, 2 figures, 3 tables. Submitted to arXiv"},{"id":"http://arxiv.org/abs/2511.19107v1","updated":"2025-11-24T13:42:43Z","published":"2025-11-24T13:42:43Z","title":"The Core in Max-Loss Non-Centroid Clustering Can Be Empty","summary":"We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\\geq 3$ there exist metric instances with $n\\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $α$-core for any $α<2^{\\frac{1}{5}}\\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.","authors":["Robert Bredereck","Eva Deltl","Leon Kellerhals","Jannik Peters"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19103v1","updated":"2025-11-24T13:37:33Z","published":"2025-11-24T13:37:33Z","title":"Edge-Based Predictive Data Reduction for Smart Agriculture: A Lightweight Approach to Efficient IoT Communication","summary":"The rapid growth of IoT devices has led to an enormous amount of sensor data that requires transmission to cloud servers for processing, resulting in excessive network congestion, increased latency and high energy consumption. This is particularly problematic in resource-constrained and remote environments where bandwidth is limited, and battery-dependent devices further emphasize the problem. Moreover, in domains such as agriculture, consecutive sensor readings often have minimal variation, making continuous data transmission inefficient and unnecessarily resource intensive. To overcome these challenges, we propose an analytical prediction algorithm designed for edge computing environments and validated through simulation. The proposed solution utilizes a predictive filter at the network edge that forecasts the next sensor data point and triggers data transmission only when the deviation from the predicted value exceeds a predefined tolerance. A complementary cloud-based model ensures data integrity and overall system consistency. This dual-model strategy effectively reduces communication overhead and demonstrates potential for improving energy efficiency by minimizing redundant transmissions. In addition to reducing communication load, our approach leverages both in situ and satellite observations from the same locations to enhance model robustness. It also supports cross-site generalization, enabling models trained in one region to be effectively deployed elsewhere without retraining. This makes our solution highly scalable, energy-aware, and well-suited for optimizing sensor data transmission in remote and bandwidth-constrained IoT environments.","authors":["Dora Krekovic","Mario Kusek","Ivana Podnar Zarko","Danh Le-Phuoc"],"pdf_url":"","comment":"Accepted for presentation and publication in the proceedings of the IEEE Annual Congress on Artificial Intelligence of Things (IEEE AIoT 2025)"},{"id":"http://arxiv.org/abs/2511.19100v1","updated":"2025-11-24T13:36:45Z","published":"2025-11-24T13:36:45Z","title":"Extracting Robust Register Automata from Neural Networks over Data Sequences","summary":"Automata extraction is a method for synthesising interpretable surrogates for black-box neural models that can be analysed symbolically. Existing techniques assume a finite input alphabet, and thus are not directly applicable to data sequences drawn from continuous domains. We address this challenge with deterministic register automata (DRAs), which extend finite automata with registers that store and compare numeric values. Our main contribution is a framework for robust DRA extraction from black-box models: we develop a polynomial-time robustness checker for DRAs with a fixed number of registers, and combine it with passive and active automata learning algorithms. This combination yields surrogate DRAs with statistical robustness and equivalence guarantees. As a key application, we use the extracted automata to assess the robustness of neural networks: for a given sequence and distance metric, the DRA either certifies local robustness or produces a concrete counterexample. Experiments on recurrent neural networks and transformer architectures show that our framework reliably learns accurate automata and enables principled robustness evaluation. Overall, our results demonstrate that robust DRA extraction effectively bridges neural network interpretability and formal reasoning without requiring white-box access to the underlying network.","authors":["Chih-Duo Hong","Hongjian Jiang","Anthony W. Lin","Oliver Markgraf","Julian Parsert","Tony Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13732v2","updated":"2025-11-24T13:32:45Z","published":"2025-11-05T10:49:30Z","title":"Principled Coarse-Grained Acceptance for Speculative Decoding in Speech","summary":"Speculative decoding accelerates autoregressive speech generation by letting a fast draft model propose tokens that a larger target model verifies. However, for speech LLMs that generate acoustic tokens, exact token matching is overly restrictive: many discrete tokens are acoustically or semantically interchangeable, reducing acceptance rates and limiting speedups. We introduce Principled Coarse-Graining (PCG), which verifies proposals at the level of Acoustic Similarity Groups (ASGs) derived from the target model's embedding space. By splitting each token's probability mass across the overlapping groups that contain it, we define an overlap-aware coarse-grained distribution and perform rejection sampling on the resulting group variable. This yields an exactness guarantee at the group level while allowing the accepted draft token to stand in for any member of the group in practice. On LibriTTS, PCG increases acceptance and throughput relative to standard speculative decoding and prior speech-specific relaxations while maintaining intelligibility and speaker similarity. These results suggest acoustically aware, group-level acceptance as a simple and general way to accelerate speech token generation while maintaining speech quality.","authors":["Moran Yanuka","Paul Dixon","Eyal Finkelshtein","Daniel Rotman","Raja Giryes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19090v1","updated":"2025-11-24T13:30:52Z","published":"2025-11-24T13:30:52Z","title":"Optimization of Deep Learning Models for Dynamic Market Behavior Prediction","summary":"The advent of financial technology has witnessed a surge in the utilization of deep learning models to anticipate consumer conduct, a trend that has demonstrated considerable potential in enhancing lending strategies and bolstering market efficiency. We study multi-horizon demand forecasting on e-commerce transactions using the UCI Online Retail II dataset. Unlike prior versions of this manuscript that mixed financial-loan narratives with retail data, we focus exclusively on retail market behavior and define a clear prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We present a hybrid sequence model that combines multi-scale temporal convolutions, a gated recurrent module, and time-aware self-attention. The model is trained with standard regression losses and evaluated under MAE, RMSE, sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage. We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show consistent accuracy gains and improved robustness on peak/holiday periods. We further provide ablations and statistical significance tests to ensure the reliability of improvements, and we release implementation details to facilitate reproducibility.","authors":["Shenghan Zhao","Yuzhen Lin","Ximeng Yang","Qiaochu Lu","Haozhong Xue","Gaozhe Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19087v1","updated":"2025-11-24T13:27:41Z","published":"2025-11-24T13:27:41Z","title":"EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching","summary":"Flow-based generative models synthesize data by integrating a learned velocity field from a reference distribution to the target data distribution. Prior work has focused on endpoint metrics (e.g., fidelity, likelihood, perceptual quality) while overlooking a deeper question: what do the sampling trajectories reveal? Motivated by classical mechanics, we introduce kinetic path energy (KPE), a simple yet powerful diagnostic that quantifies the total kinetic effort along each generation path of ODE-based samplers. Through comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that semantically richer samples require greater kinetic effort, and ({ii}) higher KPE inversely correlates with data density, with informative samples residing in sparse, low-density regions. Together, these findings reveal that semantically informative samples naturally reside on the sparse frontier of the data distribution, demanding greater generative effort. Our results suggest that trajectory-level analysis offers a physics-inspired and interpretable framework for understanding generation difficulty and sample characteristics.","authors":["Ziyun Li","Ben Dai","Huancheng Hu","Henrik Boström","Soon Hoe Lim"],"pdf_url":"","comment":"EurIPS 2025 Workshop on Principles of Generative Modeling (PriGM)"},{"id":"http://arxiv.org/abs/2509.10000v2","updated":"2025-11-24T13:26:06Z","published":"2025-09-12T06:49:19Z","title":"Neural Scaling Laws for Deep Regression","summary":"Neural scaling laws--power-law relationships between generalization errors and characteristics of deep learning models--are vital tools for developing reliable models while managing limited resources. Although the success of large language models highlights the importance of these laws, their application to deep regression models remains largely unexplored. Here, we empirically investigate neural scaling laws in deep regression using a parameter estimation model for twisted van der Waals magnets. We observe power-law relationships between the loss and both training dataset size and model capacity across a wide range of values, employing various architectures--including fully connected networks, residual networks, and vision transformers. Furthermore, the scaling exponents governing these relationships range from 1 to 2, with specific values depending on the regressed parameters and model details. The consistent scaling behaviors and their large scaling exponents suggest that the performance of deep regression models can improve substantially with increasing data size.","authors":["Tilen Cadez","Kyoung-Min Kim"],"pdf_url":"","comment":"Supplementary Information will be provided with the published manuscript"},{"id":"http://arxiv.org/abs/2504.20906v2","updated":"2025-11-24T13:25:33Z","published":"2025-04-29T16:24:11Z","title":"GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In Industrial Control Systems","summary":"The continuous monitoring of the interactions between cyber-physical components of any industrial control system (ICS) is required to secure automation of the system controls, and to guarantee plant processes are fail-safe and remain in an acceptably safe state. Safety is achieved by managing actuation (where electric signals are used to trigger physical movement), dependent on corresponding sensor readings; used as ground truth in decision making. Timely detection of anomalies (attacks, faults and unascertained states) in ICSs is crucial for the safe running of a plant, the safety of its personnel, and for the safe provision of any services provided. We propose an anomaly detection method that involves accurate linearization of the non-linear forms arising from sensor-actuator(s) relationships, primarily because solving linear models is easier and well understood. We accomplish this by using a well-known water treatment testbed as a use case. Our experiments show millisecond time response to detect anomalies, all of which are explainable and traceable; this simultaneous coupling of detection speed and explainability has not been achieved by other state of the art Artificial Intelligence (AI)/ Machine Learning (ML) models with eXplainable AI (XAI) used for the same purpose. Our methods explainability enables us to pin-point the sensor(s) and the actuation state(s) for which the anomaly was detected. The proposed algorithm showed an accuracy of 97.72% by flagging deviations within safe operation limits as non-anomalous; indicative that slower detectors with highest detection resolution is unnecessary, for systems whose safety boundaries provide leeway within safety limits.","authors":["Sarad Venugopalan","Sridhar Adepu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.02779v2","updated":"2025-11-24T13:14:48Z","published":"2025-10-03T07:22:36Z","title":"Optimal Rates for Generalization of Gradient Descent for Deep ReLU Classification","summary":"Recent advances have significantly improved our understanding of the generalization performance of gradient descent (GD) methods in deep neural networks. A natural and fundamental question is whether GD can achieve generalization rates comparable to the minimax optimal rates established in the kernel setting. Existing results either yield suboptimal rates of $O(1/\\sqrt{n})$, or focus on networks with smooth activation functions, incurring exponential dependence on network depth $L$. In this work, we establish optimal generalization rates for GD with deep ReLU networks by carefully trading off optimization and generalization errors, achieving only polynomial dependence on depth. Specifically, under the assumption that the data are NTK separable from the margin $γ$, we prove an excess risk rate of $\\widetilde{O}(L^4 (1 + γL^2) / (n γ^2))$, which aligns with the optimal SVM-type rate $\\widetilde{O}(1 / (n γ^2))$ up to depth-dependent factors. A key technical contribution is our novel control of activation patterns near a reference model, enabling a sharper Rademacher complexity bound for deep ReLU networks trained with gradient descent.","authors":["Yuanfan Li","Yunwen Lei","Zheng-Chu Guo","Yiming Ying"],"pdf_url":"","comment":"Published in NeurIPS 2025"},{"id":"http://arxiv.org/abs/2504.16941v3","updated":"2025-11-24T13:12:10Z","published":"2025-04-08T19:21:44Z","title":"Mathematical Insights into Protein Architecture: Persistent Homology and Machine Learning Applied to the Flagellar Motor","summary":"We present a machine learning approach that leverages persistent homology to classify bacterial flagellar motors into two functional states: rotated and stalled. By embedding protein structural data into a topological framework, we extract multiscale features from filtered simplicial complexes constructed over atomic coordinates. These topological invariants, specifically persistence diagrams and barcodes, capture critical geometric and connectivity patterns that correlate with motor function. The extracted features are vectorized and integrated into a machine learning pipeline that includes dimensionality reduction and supervised classification. Applied to a curated dataset of experimentally characterized flagellar motors from diverse bacterial species, our model demonstrates high classification accuracy and robustness to structural variation. This approach highlights the power of topological data analysis in revealing functionally relevant patterns beyond the reach of traditional geometric descriptors, offering a novel computational tool for protein function prediction.","authors":["Zakaria Lamine","Abdelatif Hafid","Mohamed Rahouti","My Ismail Mamouni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19075v1","updated":"2025-11-24T13:11:27Z","published":"2025-11-24T13:11:27Z","title":"Structured Matching via Cost-Regularized Unbalanced Optimal Transport","summary":"Unbalanced optimal transport (UOT) provides a flexible way to match or compare nonnegative finite Radon measures. However, UOT requires a predefined ground transport cost, which may misrepresent the data's underlying geometry. Choosing such a cost is particularly challenging when datasets live in heterogeneous spaces, often motivating practitioners to adopt Gromov-Wasserstein formulations. To address this challenge, we introduce cost-regularized unbalanced optimal transport (CR-UOT), a framework that allows the ground cost to vary while allowing mass creation and removal. We show that CR-UOT incorporates unbalanced Gromov-Wasserstein type problems through families of inner-product costs parameterized by linear transformations, enabling the matching of measures or point clouds across Euclidean spaces. We develop algorithms for such CR-UOT problems using entropic regularization and demonstrate that this approach improves the alignment of heterogeneous single-cell omics profiles, especially when many cells lack direct matches.","authors":["Emanuele Pardini","Katerina Papagiannouli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.19268v4","updated":"2025-11-24T13:11:18Z","published":"2025-06-24T02:59:14Z","title":"Health App Reviews for Privacy & Trust (HARPT): A Corpus for Analyzing Patient Privacy Concerns, Trust in Providers and Trust in Applications","summary":"Background: User reviews of Telehealth and Patient Portal mobile applications (apps) hereon referred to as electronic health (eHealth) apps are a rich source of unsolicited patient feedback, revealing critical insights into patient perceptions. However, the lack of large-scale, annotated datasets specific to privacy and trust has limited the ability of researchers to systematically analyze these concerns using natural language processing (NLP) techniques.\n  Objective: This study aims to develop and benchmark Health App Reviews for Privacy & Trust (HARPT), a large-scale annotated corpus of patient reviews from eHealth apps to advance research in patient privacy and trust.\n  Methods: We employed a multistage data construction strategy. This integrated keyword-based filtering, iterative manual labeling with review, targeted data augmentation, and weak supervision using transformer-based classifiers. A curated subset of 7,000 reviews was manually annotated to support machine learning model development and evaluation. The resulting dataset was used to benchmark a broad range of models.\n  Results: The HARPT corpus comprises 480,000 patient reviews annotated across seven categories capturing critical aspects of trust in the application (TA), trust in the provider (TP), and privacy concerns (PC). We provide comprehensive benchmark performance for a range of machine learning models on the manually annotated subset, establishing a baseline for future research.\n  Conclusions: The HARPT corpus is a significant resource for advancing the study of privacy and trust in the eHealth domain. By providing a large-scale, annotated dataset and initial benchmarks, this work supports reproducible research in usable privacy and trust within health informatics. HARPT is released under an open resource license.","authors":["Timoteo Kelly","Abdulkadir Korkmaz","Samuel Mallet","Connor Souders","Sadra Aliakbarpour","Praveen Rao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19067v1","updated":"2025-11-24T13:01:32Z","published":"2025-11-24T13:01:32Z","title":"DynaMix: Generalizable Person Re-identification via Dynamic Relabeling and Mixed Data Sampling","summary":"Generalizable person re-identification (Re-ID) aims to recognize individuals across unseen cameras and environments. While existing methods rely heavily on limited labeled multi-camera data, we propose DynaMix, a novel method that effectively combines manually labeled multi-camera and large-scale pseudo-labeled single-camera data. Unlike prior works, DynaMix dynamically adapts to the structure and noise of the training data through three core components: (1) a Relabeling Module that refines pseudo-labels of single-camera identities on-the-fly; (2) an Efficient Centroids Module that maintains robust identity representations under a large identity space; and (3) a Data Sampling Module that carefully composes mixed data mini-batches to balance learning complexity and intra-batch diversity. All components are specifically designed to operate efficiently at scale, enabling effective training on millions of images and hundreds of thousands of identities. Extensive experiments demonstrate that DynaMix consistently outperforms state-of-the-art methods in generalizable person Re-ID.","authors":["Timur Mamedov","Anton Konushin","Vadim Konushin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19066v1","updated":"2025-11-24T13:01:18Z","published":"2025-11-24T13:01:18Z","title":"Mitigating Participation Imbalance Bias in Asynchronous Federated Learning","summary":"In Asynchronous Federated Learning (AFL), the central server immediately updates the global model with each arriving client's contribution. As a result, clients perform their local training on different model versions, causing information staleness (delay). In federated environments with non-IID local data distributions, this asynchronous pattern amplifies the adverse effect of client heterogeneity (due to different data distribution, local objectives, etc.), as faster clients contribute more frequent updates, biasing the global model. We term this phenomenon heterogeneity amplification. Our work provides a theoretical analysis that maps AFL design choices to their resulting error sources when heterogeneity amplification occurs. Guided by our analysis, we propose ACE (All-Client Engagement AFL), which mitigates participation imbalance through immediate, non-buffered updates that use the latest information available from all clients. We also introduce a delay-aware variant, ACED, to balance client diversity against update staleness. Experiments on different models for different tasks across diverse heterogeneity and delay settings validate our analysis and demonstrate the robust performance of our approaches.","authors":["Xiangyu Chang","Manyi Yao","Srikanth V. Krishnamurthy","Christian R. Shelton","Anirban Chakraborty","Ananthram Swami","Samet Oymak","Amit Roy-Chowdhury"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19065v1","updated":"2025-11-24T12:59:27Z","published":"2025-11-24T12:59:27Z","title":"Understanding, Accelerating, and Improving MeanFlow Training","summary":"MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.","authors":["Jin-Young Kim","Hyojun Go","Lea Bogensperger","Julius Erbach","Nikolai Kalischek","Federico Tombari","Konrad Schindler","Dominik Narnhofer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11480v2","updated":"2025-11-24T12:53:25Z","published":"2025-11-14T16:58:04Z","title":"Inferring response times of perceptual decisions with Poisson variational autoencoders","summary":"Many properties of perceptual decision making are well-modeled by deep neural networks. However, such architectures typically treat decisions as instantaneous readouts, overlooking the temporal dynamics of the decision process. We present an image-computable model of perceptual decision making in which choices and response times arise from efficient sensory encoding and Bayesian decoding of neural spiking activity. We use a Poisson variational autoencoder to learn unsupervised representations of visual stimuli in a population of rate-coded neurons, modeled as independent homogeneous Poisson processes. A task-optimized decoder then continually infers an approximate posterior over actions conditioned on incoming spiking activity. Combining these components with an entropy-based stopping rule yields a principled and image-computable model of perceptual decisions capable of generating trial-by-trial patterns of choices and response times. Applied to MNIST digit classification, the model reproduces key empirical signatures of perceptual decision making, including stochastic variability, right-skewed response time distributions, logarithmic scaling of response times with the number of alternatives (Hick's law), and speed-accuracy trade-offs.","authors":["Hayden R. Johnson","Anastasia N. Krouglova","Hadi Vafaii","Jacob L. Yates","Pedro J. Gonçalves"],"pdf_url":"","comment":"To appear at the NeurIPS 2025 Workshop on Data on the Brain \\& Mind"},{"id":"http://arxiv.org/abs/2505.20192v2","updated":"2025-11-24T12:52:02Z","published":"2025-05-26T16:38:06Z","title":"FunReason: Enhancing Large Language Models' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement","summary":"The integration of large language models (LLMs) with function calling has emerged as a crucial capability for enhancing their practical utility in real-world applications. However, effectively combining reasoning processes with accurate function execution remains a significant challenge. Traditional training approaches often struggle to balance the detailed reasoning steps with the precision of function calls, leading to suboptimal performance. To address these limitations, we introduce FunReason, a novel framework that enhances LLMs' function calling capabilities through an automated data refinement strategy and a Self-Refinement Multiscale Loss (SRML) approach. FunReason leverages LLMs' natural reasoning abilities to generate high-quality training examples, focusing on query parseability, reasoning coherence, and function call precision. The SRML approach dynamically balances the contribution of reasoning processes and function call accuracy during training, addressing the inherent trade-off between these two critical aspects. FunReason achieves performance comparable to GPT-4o while effectively mitigating catastrophic forgetting during fine-tuning. FunReason provides a comprehensive solution for enhancing LLMs' function calling capabilities by introducing a balanced training methodology and a data refinement pipeline. For code and dataset, please refer to our repository at GitHub https://github.com/BingguangHao/FunReason","authors":["Bingguang Hao","Maolin Wang","Zengzhuang Xu","Cunyin Peng","Yicheng Chen","Xiangyu Zhao","Jinjie Gu","Chenyi Zhuang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.20153v2","updated":"2025-11-24T12:43:15Z","published":"2024-10-26T11:31:56Z","title":"The inexact power augmented Lagrangian method for constrained nonconvex optimization","summary":"This work introduces an unconventional inexact augmented Lagrangian method where the augmenting term is a Euclidean norm raised to a power between one and two. The proposed algorithm is applicable to a broad class of constrained nonconvex minimization problems that involve nonlinear equality constraints. In a first part of this work, we conduct a full complexity analysis of the method under a mild regularity condition, leveraging an accelerated first-order algorithm for solving the Hölder-smooth subproblems. Interestingly, this worst-case result indicates that using lower powers for the augmenting term leads to faster constraint satisfaction, albeit with a slower decrease of the dual residual. Notably, our analysis does not assume boundedness of the iterates. Thereafter, we present an inexact proximal point method for solving the weakly-convex and Hölder-smooth subproblems, and demonstrate that the combined scheme attains an improved rate that reduces to the best-known convergence rate whenever the augmenting term is a classical squared Euclidean norm. Different augmenting terms, involving a lower power, further improve the primal complexity at the cost of the dual complexity. Finally, numerical experiments validate the practical performance of unconventional augmenting terms.","authors":["Alexander Bodard","Konstantinos Oikonomidis","Emanuel Laude","Panagiotis Patrinos"],"pdf_url":"","comment":"Accepted for publication in Transactions on Machine Learning Research"},{"id":"http://arxiv.org/abs/2502.08542v3","updated":"2025-11-24T12:23:10Z","published":"2025-02-12T16:27:40Z","title":"Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making","summary":"Conventional automated decision-support systems often prioritize predictive accuracy, overlooking the complexities of real-world settings where stakeholders' preferences may diverge or conflict. This can lead to outcomes that disadvantage vulnerable groups and erode trust in algorithmic processes. Participatory AI approaches aim to address these issues but remain largely context-specific, limiting their broader applicability and scalability. To address these gaps, we propose a participatory framework that reframes decision-making as a multi-stakeholder learning and optimization problem. Our modular, model-agnostic approach builds on the standard machine learning training pipeline to fine-tune user-provided prediction models and evaluate decision strategies, including compromise functions that mediate stakeholder trade-offs. A synthetic scoring mechanism aggregates user-defined preferences across multiple metrics, ranking strategies and selecting an optimal decision-maker to generate actionable recommendations that jointly optimize performance, fairness, and domain-specific goals. Empirical validation on two high-stakes case studies demonstrates the versatility of the framework and its promise as a more accountable, context-aware alternative to prediction-centric pipelines for socially impactful deployments.","authors":["Vittoria Vineis","Giuseppe Perelli","Gabriele Tolomei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19037v1","updated":"2025-11-24T12:20:36Z","published":"2025-11-24T12:20:36Z","title":"Resolving Node Identifiability in Graph Neural Processes via Laplacian Spectral Encodings","summary":"Message passing graph neural networks are widely used for learning on graphs, yet their expressive power is limited by the one-dimensional Weisfeiler-Lehman test and can fail to distinguish structurally different nodes. We provide rigorous theory for a Laplacian positional encoding that is invariant to eigenvector sign flips and to basis rotations within eigenspaces. We prove that this encoding yields node identifiability from a constant number of observations and establishes a sample-complexity separation from architectures constrained by the Weisfeiler-Lehman test. The analysis combines a monotone link between shortest-path and diffusion distance, spectral trilateration with a constant set of anchors, and quantitative spectral injectivity with logarithmic embedding size. As an instantiation, pairing this encoding with a neural-process style decoder yields significant gains on a drug-drug interaction task on chemical graphs, improving both the area under the ROC curve and the F1 score and demonstrating the practical benefits of resolving theoretical expressiveness limitations with principled positional information.","authors":["Zimo Yan","Zheng Xie","Chang Liu","Yuan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.23822v2","updated":"2025-11-24T12:16:52Z","published":"2025-03-31T08:16:03Z","title":"Node Embeddings via Neighbor Embeddings","summary":"Node embeddings are a paradigm in non-parametric graph representation learning, where graph nodes are embedded into a given vector space to enable downstream processing. State-of-the-art node-embedding algorithms, such as DeepWalk and node2vec, are based on random-walk notions of node similarity and on contrastive learning. In this work, we introduce the graph neighbor-embedding (graph NE) framework that directly pulls together embedding vectors of adjacent nodes without relying on any random walks. We show that graph NE strongly outperforms state-of-the-art node-embedding algorithms in terms of local structure preservation. Furthermore, we apply graph NE to the 2D node-embedding problem, obtaining graph t-SNE layouts that also outperform existing graph-layout algorithms.","authors":["Jan Niklas Böhm","Marius Keute","Alica Guzmán","Sebastian Damrich","Andrew Draganov","Dmitry Kobak"],"pdf_url":"","comment":"Accepted to Transactions of Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2511.19023v1","updated":"2025-11-24T11:59:31Z","published":"2025-11-24T11:59:31Z","title":"OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs","summary":"Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.","authors":["Yuting Gao","Weihao Chen","Lan Wang","Ruihan Xu","Qingpei Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.14980v3","updated":"2025-11-24T11:54:06Z","published":"2024-09-23T12:57:42Z","title":"(De)-regularized Maximum Mean Discrepancy Gradient Flow","summary":"We introduce a (de)-regularization of the Maximum Mean Discrepancy (DrMMD) and its Wasserstein gradient flow. Existing gradient flows that transport samples from source distribution to target distribution with only target samples, either lack tractable numerical implementation ($f$-divergence flows) or require strong assumptions, and modifications such as noise injection, to ensure convergence (Maximum Mean Discrepancy flows). In contrast, DrMMD flow can simultaneously (i) guarantee near-global convergence for a broad class of targets in both continuous and discrete time, and (ii) be implemented in closed form using only samples. The former is achieved by leveraging the connection between the DrMMD and the $χ^2$-divergence, while the latter comes by treating DrMMD as MMD with a de-regularized kernel. Our numerical scheme uses an adaptive de-regularization schedule throughout the flow to optimally trade off between discretization errors and deviations from the $χ^2$ regime. The potential application of the DrMMD flow is demonstrated across several numerical experiments, including a large-scale setting of training student/teacher networks.","authors":["Zonghao Chen","Aratrika Mustafi","Pierre Glaser","Anna Korba","Arthur Gretton","Bharath K. Sriperumbudur"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04622v2","updated":"2025-11-24T11:53:20Z","published":"2025-10-06T09:32:10Z","title":"Forecasting-based Biomedical Time-series Data Synthesis for Open Data and Robust AI","summary":"The limited data availability due to strict privacy regulations and significant resource demands severely constrains biomedical time-series AI development, which creates a critical gap between data requirements and accessibility. Synthetic data generation presents a promising solution by producing artificial datasets that maintain the statistical properties of real biomedical time-series data without compromising patient confidentiality. While GANs, VAEs, and diffusion models capture global data distributions, forecasting models offer inductive biases tailored for sequential dynamics. We propose a framework for synthetic biomedical time-series data generation based on recent forecasting models that accurately replicates complex electrophysiological signals such as EEG and EMG with high fidelity. These synthetic datasets can be freely shared for open AI development and consistently improve downstream model performance. Numerical results on sleep-stage classification show up to a 3.71\\% performance gain with augmentation and a 91.00\\% synthetic-only accuracy that surpasses the real-data-only baseline.","authors":["Youngjoon Lee","Seongmin Cho","Yehhyun Jo","Jinu Gong","Hyunjoo Jenny Lee","Joonhyuk Kang"],"pdf_url":"","comment":"22 pages"},{"id":"http://arxiv.org/abs/2511.19019v1","updated":"2025-11-24T11:47:17Z","published":"2025-11-24T11:47:17Z","title":"3D Dynamic Radio Map Prediction Using Vision Transformers for Low-Altitude Wireless Networks","summary":"Low-altitude wireless networks (LAWN) are rapidly expanding with the growing deployment of unmanned aerial vehicles (UAVs) for logistics, surveillance, and emergency response. Reliable connectivity remains a critical yet challenging task due to three-dimensional (3D) mobility, time-varying user density, and limited power budgets. The transmit power of base stations (BSs) fluctuates dynamically according to user locations and traffic demands, leading to a highly non-stationary 3D radio environment. Radio maps (RMs) have emerged as an effective means to characterize spatial power distributions and support radio-aware network optimization. However, most existing works construct static or offline RMs, overlooking real-time power variations and spatio-temporal dependencies in multi-UAV networks. To overcome this limitation, we propose a {3D dynamic radio map (3D-DRM)} framework that learns and predicts the spatio-temporal evolution of received power. Specially, a Vision Transformer (ViT) encoder extracts high-dimensional spatial representations from 3D RMs, while a Transformer-based module models sequential dependencies to predict future power distributions. Experiments unveil that 3D-DRM accurately captures fast-varying power dynamics and substantially outperforms baseline models in both RM reconstruction and short-term prediction.","authors":["Nguyen Duc Minh Quang","Chang Liu","Huy-Trung Nguyen","Shuangyang Li","Derrick Wing Kwan Ng","Wei Xiang"],"pdf_url":"","comment":"7 pages, 4 figures, submitted to IEEE ICC 2026"},{"id":"http://arxiv.org/abs/2511.06852v4","updated":"2025-11-24T11:44:59Z","published":"2025-11-10T08:52:34Z","title":"Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment","summary":"Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.","authors":["Peng Zhang","Peijie Sun"],"pdf_url":"","comment":"AAAI-26-AIA"},{"id":"http://arxiv.org/abs/2511.18992v1","updated":"2025-11-24T11:18:59Z","published":"2025-11-24T11:18:59Z","title":"Classification EM-PCA for clustering and embedding","summary":"The mixture model is undoubtedly one of the greatest contributions to clustering. For continuous data, Gaussian models are often used and the Expectation-Maximization (EM) algorithm is particularly suitable for estimating parameters from which clustering is inferred. If these models are particularly popular in various domains including image clustering, they however suffer from the dimensionality and also from the slowness of convergence of the EM algorithm. However, the Classification EM (CEM) algorithm, a classifying version, offers a fast convergence solution while dimensionality reduction still remains a challenge. Thus we propose in this paper an algorithm combining simultaneously and non-sequentially the two tasks --Data embedding and Clustering-- relying on Principal Component Analysis (PCA) and CEM. We demonstrate the interest of such approach in terms of clustering and data embedding. We also establish different connections with other clustering approaches.","authors":["Zineddine Tighidet","Lazhar Labiod","Mohamed Nadif"],"pdf_url":"","comment":"Accepted at the IEEE conference on Big Data (Special Session on Machine Learning)"},{"id":"http://arxiv.org/abs/2503.04363v3","updated":"2025-11-24T11:18:03Z","published":"2025-03-06T12:06:54Z","title":"Causally Reliable Concept Bottleneck Models","summary":"Concept-based models are an emerging paradigm in deep learning that constrains the inference process to operate through human-interpretable variables, facilitating explainability and human interaction. However, these architectures, on par with popular opaque neural models, fail to account for the true causal mechanisms underlying the target phenomena represented in the data. This hampers their ability to support causal reasoning tasks, limits out-of-distribution generalization, and hinders the implementation of fairness constraints. To overcome these issues, we propose Causally reliable Concept Bottleneck Models (C$^2$BMs), a class of concept-based architectures that enforce reasoning through a bottleneck of concepts structured according to a model of the real-world causal mechanisms. We also introduce a pipeline to automatically learn this structure from observational data and unstructured background knowledge (e.g., scientific literature). Experimental evidence suggests that C$^2$BMs are more interpretable, causally reliable, and improve responsiveness to interventions w.r.t. standard opaque and concept-based models, while maintaining their accuracy.","authors":["Giovanni De Felice","Arianna Casanova Flores","Francesco De Santis","Silvia Santini","Johannes Schneider","Pietro Barbiero","Alberto Termine"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.18987v1","updated":"2025-11-24T11:00:32Z","published":"2025-11-24T11:00:32Z","title":"Dynamic Mixture of Experts Against Severe Distribution Shifts","summary":"The challenge of building neural networks that can continuously learn and adapt to evolving data streams is central to the fields of continual learning (CL) and reinforcement learning (RL). This lifelong learning problem is often framed in terms of the plasticity-stability dilemma, focusing on issues like loss of plasticity and catastrophic forgetting. Unlike neural networks, biological brains maintain plasticity through capacity growth, inspiring researchers to explore similar approaches in artificial networks, such as adding capacity dynamically. Prior solutions often lack parameter efficiency or depend on explicit task indices, but Mixture-of-Experts (MoE) architectures offer a promising alternative by specializing experts for distinct distributions. This paper aims to evaluate a DynamicMoE approach for continual and reinforcement learning environments and benchmark its effectiveness against existing network expansion methods.","authors":["Donghu Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18977v1","updated":"2025-11-24T10:47:55Z","published":"2025-11-24T10:47:55Z","title":"FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning","summary":"Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search's computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.","authors":["Xin Yuan","Siqi Li","Jiateng Wei","Chengrui Zhu","Yanming Wu","Qingpeng Li","Jiajun Lv","Xiaoke Lan","Jun Chen","Yong Liu"],"pdf_url":"","comment":"5 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2502.06761v3","updated":"2025-11-24T10:35:14Z","published":"2025-02-10T18:40:48Z","title":"When, Where and Why to Average Weights?","summary":"Averaging checkpoints along the training trajectory is a simple yet powerful approach to improve the generalization performance of Machine Learning models and reduce training time. Motivated by these potential gains, and in an effort to fairly and thoroughly benchmark this technique, we present an extensive evaluation of averaging techniques in modern Deep Learning, which we perform using AlgoPerf \\citep{dahl_benchmarking_2023}, a large-scale benchmark for optimization algorithms. We investigate whether weight averaging can reduce training time, improve generalization, and replace learning rate decay, as suggested by recent literature. Our evaluation across seven architectures and datasets reveals that averaging significantly accelerates training and yields considerable efficiency gains, at the price of a minimal implementation and memory cost, while mildly improving generalization across all considered workloads. Finally, we explore the relationship between averaging and learning rate annealing and show how to optimally combine the two to achieve the best performances.","authors":["Niccolò Ajroldi","Antonio Orvieto","Jonas Geiping"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18960v1","updated":"2025-11-24T10:22:28Z","published":"2025-11-24T10:22:28Z","title":"AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention","summary":"Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.","authors":["Lei Xiao","Jifeng Li","Juntao Gao","Feiyang Ye","Yan Jin","Jingjing Qian","Jing Zhang","Yong Wu","Xiaoyuan Yu"],"pdf_url":"","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.18958v1","updated":"2025-11-24T10:19:58Z","published":"2025-11-24T10:19:58Z","title":"Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation","summary":"As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.","authors":["Qisen Chai","Yansong Wang","Junjie Huang","Tao Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18950v1","updated":"2025-11-24T10:06:41Z","published":"2025-11-24T10:06:41Z","title":"Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation","summary":"Vision-Language-Action (VLA) models have emerged as a powerful paradigm in Embodied AI. However, the significant computational overhead of processing redundant visual tokens remains a critical bottleneck for real-time robotic deployment. While standard token pruning techniques can alleviate this, these task-agnostic methods struggle to preserve task-critical visual information. To address this challenge, simultaneously preserving both the holistic context and fine-grained details for precise action, we propose Compressor-VLA, a novel hybrid instruction-conditioned token compression framework designed for efficient, task-oriented compression of visual information in VLA models. The proposed Compressor-VLA framework consists of two token compression modules: a Semantic Task Compressor (STC) that distills holistic, task-relevant context, and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial details. This compression is dynamically modulated by the natural language instruction, allowing for the adaptive condensation of task-relevant visual information. Experimentally, extensive evaluations demonstrate that Compressor-VLA achieves a competitive success rate on the LIBERO benchmark while reducing FLOPs by 59% and the visual token count by over 3x compared to its baseline. The real-robot deployments on a dual-arm robot platform validate the model's sim-to-real transferability and practical applicability. Moreover, qualitative analyses reveal that our instruction guidance dynamically steers the model's perceptual focus toward task-relevant objects, thereby validating the effectiveness of our approach.","authors":["Juntao Gao","Feiyang Ye","Jing Zhang","Wenjing Qian"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.18945v1","updated":"2025-11-24T09:55:28Z","published":"2025-11-24T09:55:28Z","title":"MIST: Mutual Information Via Supervised Training","summary":"We propose a fully data-driven approach to designing mutual information (MI) estimators. Since any MI estimator is a function of the observed sample from two random variables, we parameterize this function with a neural network (MIST) and train it end-to-end to predict MI values. Training is performed on a large meta-dataset of 625,000 synthetic joint distributions with known ground-truth MI. To handle variable sample sizes and dimensions, we employ a two-dimensional attention scheme ensuring permutation invariance across input samples. To quantify uncertainty, we optimize a quantile regression loss, enabling the estimator to approximate the sampling distribution of MI rather than return a single point estimate. This research program departs from prior work by taking a fully empirical route, trading universal theoretical guarantees for flexibility and efficiency. Empirically, the learned estimators largely outperform classical baselines across sample sizes and dimensions, including on joint distributions unseen during training. The resulting quantile-based intervals are well-calibrated and more reliable than bootstrap-based confidence intervals, while inference is orders of magnitude faster than existing neural baselines. Beyond immediate empirical gains, this framework yields trainable, fully differentiable estimators that can be embedded into larger learning pipelines. Moreover, exploiting MI's invariance to invertible transformations, meta-datasets can be adapted to arbitrary data modalities via normalizing flows, enabling flexible training for diverse target meta-distributions.","authors":["German Gritsai","Megan Richards","Maxime Méloux","Kyunghyun Cho","Maxime Peyrard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13237v2","updated":"2025-11-24T09:47:20Z","published":"2025-11-17T11:00:43Z","title":"Counterfactual Explainable AI (XAI) Method for Deep Learning-Based Multivariate Time Series Classification","summary":"Recent advances in deep learning have improved multivariate time series (MTS) classification and regression by capturing complex patterns, but their lack of transparency hinders decision-making. Explainable AI (XAI) methods offer partial insights, yet often fall short of conveying the full decision space. Counterfactual Explanations (CE) provide a promising alternative, but current approaches typically prioritize either accuracy, proximity or sparsity -- rarely all -- limiting their practical value. To address this, we propose CONFETTI, a novel multi-objective CE method for MTS. CONFETTI identifies key MTS subsequences, locates a counterfactual target, and optimally modifies the time series to balance prediction confidence, proximity and sparsity. This method provides actionable insights with minimal changes, improving interpretability, and decision support. CONFETTI is evaluated on seven MTS datasets from the UEA archive, demonstrating its effectiveness in various domains. CONFETTI consistently outperforms state-of-the-art CE methods in its optimization objectives, and in six other metrics from the literature, achieving $\\geq10\\%$ higher confidence while improving sparsity in $\\geq40\\%$.","authors":["Alan G. Paredes Cetina","Kaouther Benguessoum","Raoni Lourenço","Sylvain Kubler"],"pdf_url":"","comment":"Accepted in AAAI 2026 Technical Main Track"},{"id":"http://arxiv.org/abs/2511.18940v1","updated":"2025-11-24T09:46:55Z","published":"2025-11-24T09:46:55Z","title":"Geometry-Aware Deep Congruence Networks for Manifold Learning in Cross-Subject Motor Imagery","summary":"Cross-subject motor-imagery decoding remains a major challenge in EEG-based brain-computer interfaces due to strong subject variability and the curved geometry of covariance matrices on the symmetric positive definite (SPD) manifold. We address the zero-shot cross-subject setting, where no target-subject labels or adaptation are allowed, by introducing novel geometry-aware preprocessing modules and deep congruence networks that operate directly on SPD covariance matrices. Our preprocessing modules, DCR and RiFU, extend Riemannian Alignment by improving action separation while reducing subject-specific distortions. We further propose two manifold classifiers, SPD-DCNet and RiFUNet, which use hierarchical congruence transforms to learn discriminative, subject-invariant covariance representations. On the BCI-IV 2a benchmark, our framework improves cross-subject accuracy by 3-4% over the strongest classical baselines, demonstrating the value of geometry-aware transformations for robust EEG decoding.","authors":["Sanjeev Manivannan","Chandrashekar Lakshminarayan"],"pdf_url":"","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.18936v1","updated":"2025-11-24T09:41:24Z","published":"2025-11-24T09:41:24Z","title":"SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression","summary":"Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.","authors":["Santhosh G S","Saurav Prakash","Balaraman Ravindran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.06567v2","updated":"2025-11-24T09:35:35Z","published":"2025-07-09T05:43:43Z","title":"SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference","summary":"Mixture-of-Experts (MoE) models improve the scalability of large language models (LLMs) by activating only a small subset of relevant experts per input. However, the sheer number of expert networks in an MoE model introduces a significant storage burden for an edge device. To address this challenge, we consider a scenario where experts are dispersed across an edge network for distributed inference. Based on the popular Top-$K$ expert selection strategy, we formulate a latency minimization problem by optimizing expert caching on edge servers under storage constraints. When $K=1$, the problem reduces to a monotone submodular maximization problem with knapsack constraints, for which we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee. For the general case where $K \\geq 1$, expert co-activation within the same MoE layer introduces non-submodularity, which renders greedy methods ineffective. To tackle this issue, we propose a successive greedy decomposition method to decompose the original problem into a series of subproblems, with each being solved by a dynamic programming approach. Furthermore, we design an accelerated algorithm based on the max-convolution technique to obtain the approximate solution with a provable guarantee in polynomial time. Simulation results on various MoE models demonstrate that our method significantly reduces inference latency compared to existing baselines.","authors":["Qian Chen","Xianhao Chen","Kaibin Huang"],"pdf_url":"","comment":"17 pages, 11 figures. This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2511.18930v1","updated":"2025-11-24T09:35:10Z","published":"2025-11-24T09:35:10Z","title":"Learning Solution Operators for Partial Differential Equations via Monte Carlo-Type Approximation","summary":"The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight architecture for learning solution operators for parametric PDEs by directly approximating the kernel integral using a Monte Carlo approach. Unlike Fourier Neural Operators, MCNO makes no spectral or translation-invariance assumptions. The kernel is represented as a learnable tensor over a fixed set of randomly sampled points. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with low computational cost, providing a simple and practical alternative to spectral and graph-based neural operators.","authors":["Salah Eddine Choutri","Prajwal Chauhan","Othmane Mazhar","Saif Eddin Jabari"],"pdf_url":"","comment":"NeurIPS 2025 Workshop on Machine Learning and the Physical Sciences"},{"id":"http://arxiv.org/abs/2503.15107v3","updated":"2025-11-24T09:33:15Z","published":"2025-03-19T11:04:53Z","title":"Interpretability of Graph Neural Networks to Assess Effects of Global Change Drivers on Ecological Networks","summary":"Pollinators play a crucial role for plant reproduction, either in natural ecosystem or in human-modified landscape. Global change drivers,including climate change or land use modifications, can alter the plant-pollinator interactions. To assess the potential influence of global change drivers on pollination, large-scale interactions, climate and land use data are required. While recent machine learning methods, such as graph neural networks (GNNs), allow the analysis of such datasets, interpreting their results can be challenging. We explore existing methods for interpreting GNNs in order to highlight the effects of various environmental covariates on pollination network connectivity. An extensive simulation study is performed to confirm whether these methods can detect the interactive effect between a covariate and a genus of plant on connectivity, and whether the application of debiasing techniques influences the estimation of these effects. An application on the Spipoll dataset, with and without accounting for sampling effects, highlights the potential impact of land use on network connectivity and shows that accounting for sampling effects partially alters the estimation of these effects.","authors":["Emre Anakok","Pierre Barbillon","Colin Fontaine","Elisa Thebault"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18903v1","updated":"2025-11-24T09:03:49Z","published":"2025-11-24T09:03:49Z","title":"How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining","summary":"Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.","authors":["Kairong Luo","Zhenbo Sun","Haodong Wen","Xinyu Shi","Jiarui Cui","Chenyi Dang","Kaifeng Lyu","Wenguang Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18902v1","updated":"2025-11-24T08:59:54Z","published":"2025-11-24T08:59:54Z","title":"VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL","summary":"Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \\emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \\textbf{VADE}, a \\textbf{V}ariance-\\textbf{A}ware \\textbf{D}ynamic sampling framework via online sample-level difficulty \\textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.","authors":["Zengjie Hu","Jiantao Qiu","Tianyi Bai","Haojin Yang","Binhang Yuan","Qi Jing","Conghui He","Wentao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18890v1","updated":"2025-11-24T08:46:36Z","published":"2025-11-24T08:46:36Z","title":"Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models","summary":"Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.","authors":["Yonggan Fu","Xin Dong","Shizhe Diao","Matthijs Van keirsbilck","Hanrong Ye","Wonmin Byeon","Yashaswi Karnati","Lucas Liebenwein","Hannah Zhang","Nikolaus Binder","Maksim Khadkevich","Alexander Keller","Jan Kautz","Yingyan Celine Lin","Pavlo Molchanov"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2508.00578v2","updated":"2025-11-24T08:44:20Z","published":"2025-08-01T12:21:49Z","title":"Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides","summary":"Hydrogen atom transfer (HAT) reactions are essential in many biological processes, such as radical migration in damaged proteins, but their mechanistic pathways remain incompletely understood. Simulating HAT is challenging due to the need for quantum chemical accuracy at biologically relevant scales; thus, neither classical force fields nor DFT-based molecular dynamics are applicable. Machine-learned potentials offer an alternative, able to learn potential energy surfaces (PESs) with near-quantum accuracy. However, training these models to generalize across diverse HAT configurations, especially at radical positions in proteins, requires tailored data generation and careful model selection. Here, we systematically generate HAT configurations in peptides to build large datasets using semiempirical methods and DFT. We benchmark three graph neural network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT PESs and indirectly predict reaction barriers from energy predictions. MACE consistently outperforms the others in energy, force, and barrier prediction, achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT barrier predictions. Using molecular dynamics, we show our MACE potential is stable, reactive, and generalizes beyond training data to model HAT barriers in collagen I. This accuracy enables integration of ML potentials into large-scale collagen simulations to compute reaction rates from predicted barriers, advancing mechanistic understanding of HAT and radical migration in peptides. We analyze scaling laws, model transferability, and cost-performance trade-offs, and outline strategies for improvement by combining ML potentials with transition state search algorithms and active learning. Our approach is generalizable to other biomolecular systems, enabling quantum-accurate simulations of chemical reactivity in complex environments.","authors":["Marlen Neubert","Patrick Reiser","Frauke Gräter","Pascal Friederich"],"pdf_url":"","comment":"20 pages, 12 figures, and 4 tables (references and SI included)"},{"id":"http://arxiv.org/abs/2511.18887v1","updated":"2025-11-24T08:42:40Z","published":"2025-11-24T08:42:40Z","title":"Hi-SAFE: Hierarchical Secure Aggregation for Lightweight Federated Learning","summary":"Federated learning (FL) faces challenges in ensuring both privacy and communication efficiency, particularly in resource-constrained environments such as Internet of Things (IoT) and edge networks. While sign-based methods, such as sign stochastic gradient descent with majority voting (SIGNSGD-MV), offer substantial bandwidth savings, they remain vulnerable to inference attacks due to exposure of gradient signs. Existing secure aggregation techniques are either incompatible with sign-based methods or incur prohibitive overhead. To address these limitations, we propose Hi-SAFE, a lightweight and cryptographically secure aggregation framework for sign-based FL. Our core contribution is the construction of efficient majority vote polynomials for SIGNSGD-MV, derived from Fermat's Little Theorem. This formulation represents the majority vote as a low-degree polynomial over a finite field, enabling secure evaluation that hides intermediate values and reveals only the final result. We further introduce a hierarchical subgrouping strategy that ensures constant multiplicative depth and bounded per-user complexity, independent of the number of users n.","authors":["Hyeong-Gun Joo","Songnam Hong","Seunghwan Lee","Dong-Joon Shin"],"pdf_url":"","comment":"currently submitted and awaiting review at the IEEE Internet of Things Journal"},{"id":"http://arxiv.org/abs/2501.11357v3","updated":"2025-11-24T08:40:40Z","published":"2025-01-20T09:38:30Z","title":"On the dimension of pullback attractors in recurrent neural networks","summary":"Recurrent Neural Networks (RNNs) are high-dimensional state space models capable of learning functions on sequence data. Recently, it has been conjectured that reservoir computers, a particular class of RNNs, trained on observations of a dynamical systems can be interpreted as embeddings. This result has been established for the case of linear reservoir systems. In this work, we use a nonautonomous dynamical systems approach to establish an upper bound for the fractal dimension of the subset of reservoir state space approximated during training and prediction phase. We prove that when the input sequences comes from an Nin-dimensional invertible dynamical system, the fractal dimension of this set is bounded above by Nin. The result obtained here are useful in dimensionality reduction of computation in RNNs as well as estimating fractal dimensions of dynamical systems from limited observations of their time series. It is also a step towards understanding embedding properties of reservoir computers.","authors":["Muhammed Fadera"],"pdf_url":"","comment":"Issues with clarity and notation"},{"id":"http://arxiv.org/abs/2511.18876v1","updated":"2025-11-24T08:31:02Z","published":"2025-11-24T08:31:02Z","title":"Fairness Meets Privacy: Integrating Differential Privacy and Demographic Parity in Multi-class Classification","summary":"The increasing use of machine learning in sensitive applications demands algorithms that simultaneously preserve data privacy and ensure fairness across potentially sensitive sub-populations. While privacy and fairness have each been extensively studied, their joint treatment remains poorly understood. Existing research often frames them as conflicting objectives, with multiple studies suggesting that strong privacy notions such as differential privacy inevitably compromise fairness. In this work, we challenge that perspective by showing that differential privacy can be integrated into a fairness-enhancing pipeline with minimal impact on fairness guarantees. We design a postprocessing algorithm, called DP2DP, that enforces both demographic parity and differential privacy. Our analysis reveals that our algorithm converges towards its demographic parity objective at essentially the same rate (up logarithmic factor) as the best non-private methods from the literature. Experiments on both synthetic and real datasets confirm our theoretical results, showing that the proposed algorithm achieves state-of-the-art accuracy/fairness/privacy trade-offs.","authors":["Lilian Say","Christophe Denis","Rafael Pinot"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.07456v2","updated":"2025-11-24T08:29:00Z","published":"2025-07-10T06:18:46Z","title":"General-Purpose Models for the Chemical Sciences: LLMs and Beyond","summary":"Data-driven techniques have a large potential to transform and accelerate the chemical sciences. However, chemical sciences also pose the unique challenge of very diverse, small, fuzzy datasets that are difficult to leverage in conventional machine learning approaches. A new class of models, which can be summarized under the term general-purpose models (GPMs) such as large language models, has shown the ability to solve tasks they have not been directly trained on, and to flexibly operate with low amounts of data in different formats. In this review, we discuss fundamental building principles of GPMs and review recent and emerging applications of those models in the chemical sciences across the entire scientific process. While many of these applications are still in the prototype phase, we expect that the increasing interest in GPMs will make many of them mature in the coming years.","authors":["Nawaf Alampara","Anagha Aneesh","Martiño Ríos-García","Adrian Mirza","Mara Schilling-Wilhelmi","Ali Asghar Aghajani","Meiling Sun","Gordan Prastalo","Kevin Maik Jablonka"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18874v1","updated":"2025-11-24T08:28:42Z","published":"2025-11-24T08:28:42Z","title":"GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction","summary":"Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.","authors":["Yuzhi Chen","Yuanchang Xie","Lei Zhao","Pan Liu","Yajie Zou","Chen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.06567v2","updated":"2025-11-24T08:27:31Z","published":"2025-03-09T11:50:39Z","title":"Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving","summary":"Large Language Models (LLMs) have demonstrated significant potential across various domains. However, they often struggle with integrating external knowledge and performing complex reasoning, leading to hallucinations and unreliable outputs. Retrieval Augmented Generation (RAG) has emerged as a promising paradigm to mitigate these issues by incorporating external knowledge. Yet, conventional RAG approaches, especially those based on vector similarity, fail to effectively capture relational dependencies and support multi-step reasoning. In this work, we propose CogGRAG, a human cognition-inspired, graph-based RAG framework designed for Knowledge Graph Question Answering (KGQA). CogGRAG models the reasoning process as a tree-structured mind map that decomposes the original problem into interrelated subproblems and explicitly encodes their semantic relationships. This structure not only provides a global view to guide subsequent retrieval and reasoning but also enables self-consistent verification across reasoning paths. The framework operates in three stages: (1) top-down problem decomposition via mind map construction, (2) structured retrieval of both local and global knowledge from external Knowledge Graphs (KGs), and (3) bottom-up reasoning with dual-process self-verification. Unlike previous tree-based decomposition methods such as MindMap or Graph-CoT, CogGRAG unifies problem decomposition, knowledge retrieval, and reasoning under a single graph-structured cognitive framework, allowing early integration of relational knowledge and adaptive verification. Extensive experiments demonstrate that CogGRAG achieves superior accuracy and reliability compared to existing methods.","authors":["Yao Cheng","Yibo Zhao","Jiapeng Zhu","Yao Liu","Xing Sun","Xiang Li"],"pdf_url":"","comment":"The paper has been accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.18871v1","updated":"2025-11-24T08:22:50Z","published":"2025-11-24T08:22:50Z","title":"Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning","summary":"Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.","authors":["Jian Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2111.03201v3","updated":"2025-11-24T08:17:47Z","published":"2021-11-05T00:16:06Z","title":"Compressing Sensor Data for Remote Assistance of Autonomous Vehicles using Deep Generative Models","summary":"In the foreseeable future, autonomous vehicles will require human assistance in situations they can not resolve on their own. In such scenarios, remote assistance from a human can provide the required input for the vehicle to continue its operation. Typical sensors used in autonomous vehicles include camera and lidar sensors. Due to the massive volume of sensor data that must be sent in real-time, highly efficient data compression is elementary to prevent an overload of network infrastructure. Sensor data compression using deep generative neural networks has been shown to outperform traditional compression approaches for both image and lidar data, regarding compression rate as well as reconstruction quality. However, there is a lack of research about the performance of generative-neural-network-based compression algorithms for remote assistance. In order to gain insights into the feasibility of deep generative models for usage in remote assistance, we evaluate state-of-the-art algorithms regarding their applicability and identify potential weaknesses. Further, we implement an online pipeline for processing sensor data and demonstrate its performance for remote assistance using the CARLA simulator.","authors":["Daniel Bogdoll","Johannes Jestram","Jonas Rauch","Christin Scheib","Moritz Wittig","J. Marius Zöllner"],"pdf_url":"","comment":"Daniel Bogdoll, Johannes Jestram, Jonas Rauch, Christin Scheib and Moritz Wittig contributed equally. Accepted for publication at NeurIPS 2021 ML4AD Workshop"},{"id":"http://arxiv.org/abs/2511.18868v1","updated":"2025-11-24T08:11:50Z","published":"2025-11-24T08:11:50Z","title":"KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit","summary":"High quality kernels are critical for reducing training and inference costs of Large Language Models (LLMs), yet they traditionally require significant expertise in hardware architecture and software optimization. While recent advances in LLM-based code generation show promise for complex optimization, existing methods struggle with the vast optimization space due to insufficient hardware domain knowledge, failing to effectively balance exploration and exploitation. We present KernelBand, a novel framework that formulates kernel optimization as a hierarchical multi-armed bandit problem, enabling LLM agents to strategically navigate the optimization space by treating kernel selection and optimization strategy application as sequential decision-making processes. Our approach leverages hardware profiling information to identify promising optimization strategies and employs runtime behavior clustering to reduce exploration overhead across kernel candidates. Extensive experiments on TritonBench demonstrate that KernelBand significantly outperforms state-of-the-art methods, achieving superior performance with fewer tokens while exhibiting consistent improvement without saturation as computational resources increase.","authors":["Dezhi Ran","Shuxiao Xie","Mingfang Ji","Ziyue Hua","Mengzhou Wu","Yuan Cao","Yuzhe Guo","Yu Hao","Linyi Li","Yitao Hu","Tao Xie"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2109.09607v4","updated":"2025-11-24T07:58:18Z","published":"2021-09-20T15:04:55Z","title":"Description of Corner Cases in Automated Driving: Goals and Challenges","summary":"Scaling the distribution of automated vehicles requires handling various unexpected and possibly dangerous situations, termed corner cases (CC). Since many modules of automated driving systems are based on machine learning (ML), CC are an essential part of the data for their development. However, there is only a limited amount of CC data in large-scale data collections, which makes them challenging in the context of ML. With a better understanding of CC, offline applications, e.g., dataset analysis, and online methods, e.g., improved performance of automated driving systems, can be improved. While there are knowledge-based descriptions and taxonomies for CC, there is little research on machine-interpretable descriptions. In this extended abstract, we will give a brief overview of the challenges and goals of such a description.","authors":["Daniel Bogdoll","Jasmin Breitenstein","Florian Heidecker","Maarten Bieshaar","Bernhard Sick","Tim Fingscheidt","J. Marius Zöllner"],"pdf_url":"","comment":"Daniel Bogdoll, Jasmin Breitenstein and Florian Heidecker contributed equally. Accepted for publication at ICCV 2021 ERCVAD Workshop"},{"id":"http://arxiv.org/abs/2511.18859v1","updated":"2025-11-24T07:57:37Z","published":"2025-11-24T07:57:37Z","title":"Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter Learning","summary":"Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable attention in adapting pre-trained GNN models for downstream graph learning tasks. One representative fine-tuning method is to exploit adapter (termed AdapterGNN) which aims to 'augment' the pre-trained model by inserting a lightweight module to make the 'augmented' model better adapt to the downstream tasks. However, graph data may contain various types of noise in downstream tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs are often prone to graph noise and exhibit limited generalizability. How to enhance the robustness and generalization ability of GNNs' fine tuning remains an open problem. In this paper, we show that the above problem can be well addressed by integrating uncertainty learning into the GNN adapter. We propose the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN models against noisy graph data in the fine-tuning process. Specifically, in contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic adapter to augment the pre-trained GNN model. In this way, when the graph contains various noises,our method can automatically absorb the effects of changes in the variances of the Gaussian distribution, thereby significantly enhancing the model's robustness. Also, UAdapterGNN can further improve the generalization ability of the model on the downstream tasks. Extensive experiments on several benchmarks demonstrate the effectiveness, robustness and high generalization ability of the proposed UAdapterGNN method.","authors":["Bo Jiang","Weijun Zhao","Beibei Wang","Xiao Wang","Jin Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18846v1","updated":"2025-11-24T07:33:35Z","published":"2025-11-24T07:33:35Z","title":"WaveTuner: Comprehensive Wavelet Subband Tuning for Time Series Forecasting","summary":"Due to the inherent complexity, temporal patterns in real-world time series often evolve across multiple intertwined scales, including long-term periodicity, short-term fluctuations, and abrupt regime shifts. While existing literature has designed many sophisticated decomposition approaches based on the time or frequency domain to partition trend-seasonality components and high-low frequency components, an alternative line of approaches based on the wavelet domain has been proposed to provide a unified multi-resolution representation with precise time-frequency localization. However, most wavelet-based methods suffer from a persistent bias toward recursively decomposing only low-frequency components, severely underutilizing subtle yet informative high-frequency components that are pivotal for precise time series forecasting. To address this problem, we propose WaveTuner, a Wavelet decomposition framework empowered by full-spectrum subband Tuning for time series forecasting. Concretely, WaveTuner comprises two key modules: (i) Adaptive Wavelet Refinement module, that transforms time series into time-frequency coefficients, utilizes an adaptive router to dynamically assign subband weights, and generates subband-specific embeddings to support refinement; and (ii) Multi-Branch Specialization module, that employs multiple functional branches, each instantiated as a flexible Kolmogorov-Arnold Network (KAN) with a distinct functional order to model a specific spectral subband. Equipped with these modules, WaveTuner comprehensively tunes global trends and local variations within a unified time-frequency framework. Extensive experiments on eight real-world datasets demonstrate WaveTuner achieves state-of-the-art forecasting performance in time series forecasting.","authors":["Yubo Wang","Hui He","Chaoxi Niu","Zhendong Niu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18843v1","updated":"2025-11-24T07:30:15Z","published":"2025-11-24T07:30:15Z","title":"A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis","summary":"Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a rigorous, reproducible computational framework for applying neural topic modeling to focus group transcripts, addressing fundamental methodological challenges: hyperparameter sensitivity, model stability, and validation of interpretability. Using BERTopic applied to ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076 utterances), we conducted systematic evaluation across 27 hyperparameter configurations, assessed stability through bootstrap resampling with 30 replicates per configuration, and validated interpretability through formal human evaluation by three domain experts. Our analysis demonstrates substantial sensitivity to hyperparameter choices and reveals that metric selection for stability assessment must align with analytical goals. A hierarchical merging strategy (extracting fine-grained topics for stability then consolidating for interpretability) effectively navigates the stability-coherence tradeoff, achieving coherence of 0.558 compared to 0.539 for direct extraction. Human validation confirmed topic quality with very good inter-rater reliability (ICC = 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical guidelines that researchers can adapt to their own qualitative research contexts. All code, data processing scripts, and evaluation protocols are publicly available to support reproduction and extension of this work.","authors":["Heger Arfaoui","Mohammed Iheb Hergli","Beya Benzina","Slimane BenMiled"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18841v1","updated":"2025-11-24T07:24:09Z","published":"2025-11-24T07:24:09Z","title":"Federated style aware transformer aggregation of representations","summary":"Personalized Federated Learning (PFL) faces persistent challenges, including domain heterogeneity from diverse client data, data imbalance due to skewed participation, and strict communication constraints. Traditional federated learning often lacks personalization, as a single global model cannot capture client-specific characteristics, leading to biased predictions and poor generalization, especially for clients with highly divergent data distributions.\n  To address these issues, we propose FedSTAR, a style-aware federated learning framework that disentangles client-specific style factors from shared content representations. FedSTAR aggregates class-wise prototypes using a Transformer-based attention mechanism, allowing the server to adaptively weight client contributions while preserving personalization.\n  Furthermore, by exchanging compact prototypes and style vectors instead of full model parameters, FedSTAR significantly reduces communication overhead. Experimental results demonstrate that combining content-style disentanglement with attention-driven prototype aggregation improves personalization and robustness in heterogeneous environments without increasing communication cost.","authors":["Mincheol Jeon","Euinam Huh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18839v1","updated":"2025-11-24T07:20:40Z","published":"2025-11-24T07:20:40Z","title":"Enhancing Multi-Label Thoracic Disease Diagnosis with Deep Ensemble-Based Uncertainty Quantification","summary":"The utility of deep learning models, such as CheXNet, in high stakes clinical settings is fundamentally constrained by their purely deterministic nature, failing to provide reliable measures of predictive confidence. This project addresses this critical gap by integrating robust Uncertainty Quantification (UQ) into a high performance diagnostic platform for 14 common thoracic diseases on the NIH ChestX-ray14 dataset. Initial architectural development failed to stabilize performance and calibration using Monte Carlo Dropout (MCD), yielding an unacceptable Expected Calibration Error (ECE) of 0.7588. This technical failure necessitated a rigorous architectural pivot to a high diversity, 9-member Deep Ensemble (DE). This resulting DE successfully stabilized performance and delivered superior reliability, achieving a State-of-the-Art (SOTA) average Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.8559 and an average F1 Score of 0.3857. Crucially, the DE demonstrated superior calibration (Mean ECE of 0.0728 and Negative Log-Likelihood (NLL) of 0.1916) and enabled the reliable decomposition of total uncertainty into its Aleatoric (irreducible data noise) and Epistemic (reducible model knowledge) components, with a mean Epistemic Uncertainty (EU) of 0.0240. These results establish the Deep Ensemble as a trustworthy and explainable platform, transforming the model from a probabilistic tool into a reliable clinical decision support system.","authors":["Yasiru Laksara","Uthayasanker Thayasivam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18835v1","updated":"2025-11-24T07:13:34Z","published":"2025-11-24T07:13:34Z","title":"Auto-ML Graph Neural Network Hypermodels for Outcome Prediction in Event-Sequence Data","summary":"This paper introduces HGNN(O), an AutoML GNN hypermodel framework for outcome prediction on event-sequence data. Building on our earlier work on graph convolutional network hypermodels, HGNN(O) extends four architectures-One Level, Two Level, Two Level Pseudo Embedding, and Two Level Embedding-across six canonical GNN operators. A self-tuning mechanism based on Bayesian optimization with pruning and early stopping enables efficient adaptation over architectures and hyperparameters without manual configuration. Empirical evaluation on both balanced and imbalanced event logs shows that HGNN(O) achieves accuracy exceeding 0.98 on the Traffic Fines dataset and weighted F1 scores up to 0.86 on the Patients dataset without explicit imbalance handling. These results demonstrate that the proposed AutoML-GNN approach provides a robust and generalizable benchmark for outcome prediction in complex event-sequence data.","authors":["Fang Wang","Lance Kosca","Adrienne Kosca","Marko Gacesa","Ernesto Damiani"],"pdf_url":"","comment":"6 pages"},{"id":"http://arxiv.org/abs/2410.13334v4","updated":"2025-11-24T07:12:09Z","published":"2024-10-17T08:46:09Z","title":"BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models","summary":"Although large language models (LLMs) demonstrate impressive proficiency in various tasks, they present potential safety risks, such as `jailbreaks', where malicious inputs can coerce LLMs into generating harmful content bypassing safety alignments. In this paper, we delve into the ethical biases in LLMs and examine how those biases could be exploited for jailbreaks. Notably, these biases result in a jailbreaking success rate in GPT-4o models that differs by 20\\% between non-binary and cisgender keywords and by 16\\% between white and black keywords, even when the other parts of the prompts are identical. We introduce the concept of BiasJailbreak, highlighting the inherent risks posed by these safety-induced biases. BiasJailbreak generates biased keywords automatically by asking the target LLM itself, and utilizes the keywords to generate harmful output. Additionally, we propose an efficient defense method BiasDefense, which prevents jailbreak attempts by injecting defense prompts prior to generation. BiasDefense stands as an appealing alternative to Guard Models, such as Llama-Guard, that require additional inference cost after text generation. Our findings emphasize that ethical biases in LLMs can actually lead to generating unsafe output, and suggest a method to make the LLMs more secure and unbiased. To enable further research and improvements, we open-source our code and artifacts of BiasJailbreak, providing the community with tools to better understand and mitigate safety-induced biases in LLMs.","authors":["Isack Lee","Haebin Seong"],"pdf_url":"","comment":"Accepted as a workshop paper at AAAI 2026"},{"id":"http://arxiv.org/abs/2511.18830v1","updated":"2025-11-24T07:06:08Z","published":"2025-11-24T07:06:08Z","title":"Leveraging Duration Pseudo-Embeddings in Multilevel LSTM and GCN Hypermodels for Outcome-Oriented PPM","summary":"Existing deep learning models for Predictive Process Monitoring (PPM) struggle with temporal irregularities, particularly stochastic event durations and overlapping timestamps, limiting their adaptability across heterogeneous datasets. We propose a dual input neural network strategy that separates event and sequence attributes, using a duration-aware pseudo-embedding matrix to transform temporal importance into compact, learnable representations. This design is implemented across two baseline families: B-LSTM and B-GCN, and their duration-aware variants D-LSTM and D-GCN. All models incorporate self-tuned hypermodels for adaptive architecture selection. Experiments on balanced and imbalanced outcome prediction tasks show that duration pseudo-embedding inputs consistently improve generalization, reduce model complexity, and enhance interpretability. Our results demonstrate the benefits of explicit temporal encoding and provide a flexible design for robust, real-world PPM applications.","authors":["Fang Wang","Paolo Ceravolo","Ernesto Damiani"],"pdf_url":"","comment":"12 pages"},{"id":"http://arxiv.org/abs/2511.18829v1","updated":"2025-11-24T07:06:06Z","published":"2025-11-24T07:06:06Z","title":"Towards Characterizing Knowledge Distillation of PPG Heart Rate Estimation Models","summary":"Heart rate estimation from photoplethysmography (PPG) signals generated by wearable devices such as smartwatches and fitness trackers has significant implications for the health and well-being of individuals. Although prior work has demonstrated deep learning models with strong performance in the heart rate estimation task, in order to deploy these models on wearable devices, these models must also adhere to strict memory and latency constraints. In this work, we explore and characterize how large pre-trained PPG models may be distilled to smaller models appropriate for real-time inference on the edge. We evaluate four distillation strategies through comprehensive sweeps of teacher and student model capacities: (1) hard distillation, (2) soft distillation, (3) decoupled knowledge distillation (DKD), and (4) feature distillation. We present a characterization of the resulting scaling laws describing the relationship between model size and performance. This early investigation lays the groundwork for practical and predictable methods for building edge-deployable models for physiological sensing.","authors":["Kanav Arora","Girish Narayanswamy","Shwetak Patel","Richard Li"],"pdf_url":"","comment":"To be published in: 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Learning from Time Series for Health"},{"id":"http://arxiv.org/abs/2304.13037v3","updated":"2025-11-24T07:05:54Z","published":"2023-04-25T07:32:16Z","title":"VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data","summary":"An end-to-end machine learning (ML) lifecycle consists of many iterative processes, from data preparation and ML model design to model training and then deploying the trained model for inference. When building an end-to-end lifecycle for an ML problem, many ML pipelines must be designed and executed that produce a huge number of lifecycle versions. Therefore, this paper introduces VeML, a Version management system dedicated to end-to-end ML Lifecycle. Our system tackles several crucial problems that other systems have not solved. First, we address the high cost of building an ML lifecycle, especially for large-scale and high-dimensional dataset. We solve this problem by proposing to transfer the lifecycle of similar datasets managed in our system to the new training data. We design an algorithm based on the core set to compute similarity for large-scale, high-dimensional data efficiently. Another critical issue is the model accuracy degradation by the difference between training data and testing data during the ML lifetime, which leads to lifecycle rebuild. Our system helps to detect this mismatch without getting labeled data from testing data and rebuild the ML lifecycle for a new data version. To demonstrate our contributions, we conduct experiments on real-world, large-scale datasets of driving images and spatiotemporal sensor data and show promising results.","authors":["Van-Duc Le","Tien-Cuong Bui","Wen-Syan Li"],"pdf_url":"","comment":"The updated version of this paper, titled \"Efficient ML Lifecycle Transferring for Large-scale and High-dimensional Data via Core Set-based Dataset Similarity,\" has been accepted for publication in IEEE Access"},{"id":"http://arxiv.org/abs/2511.18828v1","updated":"2025-11-24T07:03:56Z","published":"2025-11-24T07:03:56Z","title":"Solving a Research Problem in Mathematical Statistics with AI Assistance","summary":"Over the last few months, AI models including large language models have improved greatly. There are now several documented examples where they have helped professional mathematical scientists prove new results, sometimes even helping resolve known open problems. In this short note, we add another example to the list, by documenting how we were able to solve a previously unsolved research problem in robust mathematical statistics with crucial help from GPT-5. Our problem concerns robust density estimation, where the observations are perturbed by Wasserstein-bounded contaminations.In a previous preprint (Chao and Dobriban, 2023, arxiv:2308.01853v2), we have obtained upper and lower bounds on the minimax optimal estimation error; which were, however, not sharp.\n  Starting in October 2025, making significant use of GPT-5 Pro, we were able to derive the minimax optimal error rate (reported in version 3 of the above arxiv preprint). GPT-5 provided crucial help along the way, including by suggesting calculations that we did not think of, and techniques that were not familiar to us, such as the dynamic Benamou-Brenier formulation, for key steps in the analysis. Working with GPT-5 took a few weeks of effort, and we estimate that it could have taken several months to get the same results otherwise. At the same time, there are still areas where working with GPT-5 was challenging: it sometimes provided incorrect references, and glossed over details that sometimes took days of work to fill in. We outline our workflow and steps taken to mitigate issues. Overall, our work can serve as additional documentation for a new age of human-AI collaborative work in mathematical science.","authors":["Edgar Dobriban"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18826v1","updated":"2025-11-24T07:02:22Z","published":"2025-11-24T07:02:22Z","title":"Uncertainty-Aware Dual-Student Knowledge Distillation for Efficient Image Classification","summary":"Knowledge distillation has emerged as a powerful technique for model compression, enabling the transfer of knowledge from large teacher networks to compact student models. However, traditional knowledge distillation methods treat all teacher predictions equally, regardless of the teacher's confidence in those predictions. This paper proposes an uncertainty-aware dual-student knowledge distillation framework that leverages teacher prediction uncertainty to selectively guide student learning. We introduce a peer-learning mechanism where two heterogeneous student architectures, specifically ResNet-18 and MobileNetV2, learn collaboratively from both the teacher network and each other. Experimental results on ImageNet-100 demonstrate that our approach achieves superior performance compared to baseline knowledge distillation methods, with ResNet-18 achieving 83.84\\% top-1 accuracy and MobileNetV2 achieving 81.46\\% top-1 accuracy, representing improvements of 2.04\\% and 0.92\\% respectively over traditional single-student distillation approaches.","authors":["Aakash Gore","Anoushka Dey","Aryan Mishra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18820v1","updated":"2025-11-24T06:54:20Z","published":"2025-11-24T06:54:20Z","title":"Solution of Incompressible Flow Equations with Physics and Equality Constrained Artificial Neural Networks","summary":"We present a meshless method for the solution of incompressible Navier-Stokes equations in advection-dominated regimes using physics- and equality-constrained artificial neural networks combined with a conditionally adaptive augmented Lagrangian formulation. A single neural network parameterizes both the velocity and pressure fields, and is trained by minimizing the residual of a Poisson's equation for pressure, constrained by the momentum and continuity equations, together with boundary conditions on the velocity field. No boundary conditions are imposed on the pressure field aside from anchoring the pressure at a point to prevent its unbounded development. The training is performed from scratch without labeled data, relying solely on the governing equations and constraints. To enhance accuracy in advection-dominated flows, we employ a single Fourier feature mapping of the input coordinates. The proposed method is demonstrated for the canonical lid-driven cavity flow up to a Reynolds number of 7,500 and for laminar flow over a circular cylinder with inflow-outflow boundary conditions, achieving excellent agreement with benchmark solutions. We further compare the present formulation against alternative objective-function constructions based on different arrangements of the flow equations, thereby highlighting the algorithmic advantages of the proposed formulation centered around the Poisson's equation for pressure.","authors":["Qifeng Hu","Inanc Senocak"],"pdf_url":"","comment":"21 pages, 13 figures"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2511.19436v1","updated":"2025-11-24T18:59:56Z","published":"2025-11-24T18:59:56Z","title":"VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection","summary":"We present VDC-Agent, a self-evolving framework for Video Detailed Captioning that requires neither human annotations nor larger teacher models. The agent forms a closed loop of caption generation, principle-guided scoring (score and textual suggestions), and prompt refinement. When caption quality regresses, a self-reflection path leverages the previous chain-of-thought to amend the update. Running this process on unlabeled videos produces trajectories of (caption, score) pairs. We convert the trajectories into preference tuples and filter out samples with JSON parsing errors, resulting in VDC-Agent-19K, which contains 18,886 automatically constructed pairs. We then fine-tune the base MLLM on this dataset using an easy-to-hard curriculum direct preference optimization. Built on Qwen2.5-VL-7B-Instruct, our VDC-Agent-7B attains state-of-the-art performance on the VDC benchmark with 49.08% average accuracy and 2.50 score, surpassing specialized video captioners and improving over the base model by +5.13% accuracy and +0.27 score at similar inference cost.","authors":["Qiang Wang","Xinyuan Gao","SongLin Dong","Jizhou Han","Jiangyang Li","Yuhang He","Yihong Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19433v1","updated":"2025-11-24T18:59:51Z","published":"2025-11-24T18:59:51Z","title":"Mixture of Horizons in Action Chunking","summary":"Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\\textbf{action chunk length}$ used during training, termed $\\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $π_0$, $π_{0.5}$, and one-step regression policy $π_{\\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $π_{0.5}$ with MoH reaches a new state-of-the-art with 99$\\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons","authors":["Dong Jing","Gang Wang","Jiaqi Liu","Weiliang Tang","Zelong Sun","Yunchao Yao","Zhenyu Wei","Yunhui Liu","Zhiwu Lu","Mingyu Ding"],"pdf_url":"","comment":"15 pages, 14 figures"},{"id":"http://arxiv.org/abs/2511.16660v2","updated":"2025-11-24T18:59:30Z","published":"2025-11-20T18:59:00Z","title":"Cognitive Foundations for Reasoning and Their Manifestation in LLMs","summary":"Large language models (LLMs) solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. To understand this gap, we synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning reasoning invariants, meta-cognitive controls, representations for organizing reasoning & knowledge, and transformation operations. We introduce a fine-grained evaluation framework and conduct the first large-scale empirical analysis of 192K traces from 18 models across text, vision, and audio, complemented by 54 human think-aloud traces, which we make publicly available. We find that models under-utilize cognitive elements correlated with success, narrowing to rigid sequential processing on ill-structured problems where diverse representations and meta-cognitive monitoring are critical. Human traces show more abstraction and conceptual processing, while models default to surface-level enumeration. Meta-analysis of 1.6K LLM reasoning papers reveals the research community concentrates on easily quantifiable elements (sequential organization: 55%, decomposition: 60%) but neglecting meta-cognitive controls (self-awareness: 16%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 66.7% on complex problems. By establishing a shared vocabulary between cognitive science and LLM research, our framework enables systematic diagnosis of reasoning failures and principled development of models that reason through robust cognitive mechanisms rather than spurious shortcuts, while providing tools to test theories of human cognition at scale.","authors":["Priyanka Kargupta","Shuyue Stella Li","Haocheng Wang","Jinu Lee","Shan Chen","Orevaoghene Ahia","Dean Light","Thomas L. Griffiths","Max Kleiman-Weiner","Jiawei Han","Asli Celikyilmaz","Yulia Tsvetkov"],"pdf_url":"","comment":"40 pages, 4 tables, 6 figures"},{"id":"http://arxiv.org/abs/2511.19427v1","updated":"2025-11-24T18:58:22Z","published":"2025-11-24T18:58:22Z","title":"Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering","summary":"AI-Integrated programming is emerging as a foundational paradigm for building intelligent systems with large language models (LLMs). Recent approaches such as Meaning Typed Programming (MTP) automate prompt generation by leveraging the semantics already present in code. However, many real-world applications depend on contextual cues, developer intent, and domain-specific reasoning that extend beyond what static code semantics alone can express. To address this limitation, we introduce Semantic Engineering, a lightweight method for enriching program semantics so that LLM-based systems can more accurately reflect developer intent without requiring full manual prompt design. We present Semantic Context Annotations (SemTexts), a language-level mechanism that allows developers to embed natural-language context directly into program constructs. Integrated into the Jac programming language, Semantic Engineering extends MTP to incorporate these enriched semantics during prompt generation. We further introduce a benchmark suite designed to reflect realistic AI-Integrated application scenarios. Our evaluation shows that Semantic Engineering substantially improves prompt fidelity, achieving performance comparable to Prompt Engineering while requiring significantly less developer effort.","authors":["Jayanaka L. Dantanarayana","Savini Kashmira","Thakee Nathees","Zichen Zhang","Krisztian Flautner","Lingjia Tang","Jason Mars"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19423v1","updated":"2025-11-24T18:57:07Z","published":"2025-11-24T18:57:07Z","title":"Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design","summary":"We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design. Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates four capabilities -- literature-grounded reasoning through retrieval-augmented generation (RAG), structural parsing of Protein Data Bank files, electrostatic potential calculations, and machine-learning prediction of redox properties -- into a unified agentic workflow. By coupling natural-language reasoning with data-driven and physics-based computation, the system generates mechanistically interpretable, testable hypotheses linking sequence, structure, and function. In proof-of-concept demonstrations, Genie-CAT autonomously identifies residue-level modifications near [Fe--S] clusters that affect redox tuning, reproducing expert-derived hypotheses in a fraction of the time. The framework highlights how AI agents combining language models with domain-specific tools can bridge symbolic reasoning and numerical simulation, transforming LLMs from conversational assistants into partners for computational discovery.","authors":["Bruno Jacob","Khushbu Agarwal","Marcel Baer","Peter Rice","Simone Raugei"],"pdf_url":"","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.19422v1","updated":"2025-11-24T18:56:47Z","published":"2025-11-24T18:56:47Z","title":"SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning","summary":"Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.","authors":["David Jiahao Fu","Aryan Gupta","Aaron Councilman","David Grove","Yu-Xiong Wang","Vikram Adve"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19418v1","updated":"2025-11-24T18:55:19Z","published":"2025-11-24T18:55:19Z","title":"Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens","summary":"Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent representations that encode rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills knowledge from lightweight vision experts, capturing complementary properties such as 2D appearance, 3D geometry, spatial layout, and edge structure. During training, the VLM with COVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (e.g., depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than ten diverse perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL and LLaVA consistently improves performance by 3% to 16% and demonstrates that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.","authors":["Yiming Qin","Bomin Wei","Jiaxin Ge","Konstantinos Kallidromitis","Stephanie Fu","Trevor Darrell","Xudong Wang"],"pdf_url":"","comment":"Project page: https://wakalsprojectpage.github.io/comt-website/"},{"id":"http://arxiv.org/abs/2511.19417v1","updated":"2025-11-24T18:55:16Z","published":"2025-11-24T18:55:16Z","title":"Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.","authors":["James Y. Huang","Sheng Zhang","Qianchu Liu","Guanghui Qin","Tinghui Zhu","Tristan Naumann","Muhao Chen","Hoifung Poon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15846v3","updated":"2025-11-24T18:52:00Z","published":"2025-11-19T20:10:39Z","title":"The Loss of Control Playbook: Degrees, Dynamics, and Preparedness","summary":"This research report addresses the absence of an actionable definition for Loss of Control (LoC) in AI systems by developing a novel taxonomy and preparedness framework. Despite increasing policy and research attention, existing LoC definitions vary significantly in scope and timeline, hindering effective LoC assessment and mitigation. To address this issue, we draw from an extensive literature review and propose a graded LoC taxonomy, based on the metrics of severity and persistence, that distinguishes between Deviation, Bounded LoC, and Strict LoC. We model pathways toward a societal state of vulnerability in which sufficiently advanced AI systems have acquired or could acquire the means to cause Bounded or Strict LoC once a catalyst, either misalignment or pure malfunction, materializes. We argue that this state becomes increasingly likely over time, absent strategic intervention, and propose a strategy to avoid reaching a state of vulnerability. Rather than focusing solely on intervening on AI capabilities and propensities potentially relevant for LoC or on preventing potential catalysts, we introduce a complementary framework that emphasizes three extrinsic factors: Deployment context, Affordances, and Permissions (the DAP framework). Compared to work on intrinsic factors and catalysts, this framework has the unfair advantage of being actionable today. Finally, we put forward a plan to maintain preparedness and prevent the occurrence of LoC outcomes should a state of societal vulnerability be reached, focusing on governance measures (threat modeling, deployment policies, emergency response) and technical controls (pre-deployment testing, control measures, monitoring) that could maintain a condition of perennial suspension.","authors":["Charlotte Stix","Annika Hallensleben","Alejandro Ortega","Matteo Pistillo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19413v1","updated":"2025-11-24T18:50:01Z","published":"2025-11-24T18:50:01Z","title":"UniGame: Turning a Unified Multimodal Model Into Its Own Adversary","summary":"Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame","authors":["Zhaolong Su","Wang Lu","Hao Chen","Sharon Li","Jindong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19401v1","updated":"2025-11-24T18:38:45Z","published":"2025-11-24T18:38:45Z","title":"In-Video Instructions: Visual Signals as Generative Control","summary":"Large-scale video generative models have recently demonstrated strong visual capabilities, enabling the prediction of future frames that adhere to the logical and physical cues in the current observation. In this work, we investigate whether such capabilities can be harnessed for controllable image-to-video generation by interpreting visual signals embedded within the frames as instructions, a paradigm we term In-Video Instruction. In contrast to prompt-based control, which provides textual descriptions that are inherently global and coarse, In-Video Instruction encodes user guidance directly into the visual domain through elements such as overlaid text, arrows, or trajectories. This enables explicit, spatial-aware, and unambiguous correspondences between visual subjects and their intended actions by assigning distinct instructions to different objects. Extensive experiments on three state-of-the-art generators, including Veo 3.1, Kling 2.5, and Wan 2.2, show that video models can reliably interpret and execute such visually embedded instructions, particularly in complex multi-object scenarios.","authors":["Gongfan Fang","Xinyin Ma","Xinchao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19399v1","updated":"2025-11-24T18:35:54Z","published":"2025-11-24T18:35:54Z","title":"DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research","summary":"Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.","authors":["Rulin Shao","Akari Asai","Shannon Zejiang Shen","Hamish Ivison","Varsha Kishore","Jingming Zhuo","Xinran Zhao","Molly Park","Samuel G. Finlayson","David Sontag","Tyler Murray","Sewon Min","Pradeep Dasigi","Luca Soldaini","Faeze Brahman","Wen-tau Yih","Tongshuang Wu","Luke Zettlemoyer","Yoon Kim","Hannaneh Hajishirzi","Pang Wei Koh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19396v1","updated":"2025-11-24T18:33:50Z","published":"2025-11-24T18:33:50Z","title":"Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments","summary":"Advances in object tracking and acoustic beamforming are driving new capabilities in surveillance, human-computer interaction, and robotics. This work presents an embedded system that integrates deep learning-based tracking with beamforming to achieve precise sound source localization and directional audio capture in dynamic environments. The approach combines single-camera depth estimation and stereo vision to enable accurate 3D localization of moving objects. A planar concentric circular microphone array constructed with MEMS microphones provides a compact, energy-efficient platform supporting 2D beam steering across azimuth and elevation. Real-time tracking outputs continuously adapt the array's focus, synchronizing the acoustic response with the target's position. By uniting learned spatial awareness with dynamic steering, the system maintains robust performance in the presence of multiple or moving sources. Experimental evaluation demonstrates significant gains in signal-to-interference ratio, making the design well-suited for teleconferencing, smart home devices, and assistive technologies.","authors":["Jorge Ortigoso-Narro","Jose A. Belloch","Adrian Amor-Martin","Sandra Roger","Maximo Cobos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.02912v4","updated":"2025-11-24T18:31:13Z","published":"2025-08-04T21:29:07Z","title":"Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination with Embodied World Models","summary":"Robust coordination is critical for effective decision-making in multi-agent systems, especially under partial observability. A central question in Multi-Agent Reinforcement Learning (MARL) is whether to engineer communication protocols or learn them end-to-end. We investigate this dichotomy using embodied world models. We propose and compare two communication strategies for a cooperative task-allocation problem. The first, Learned Direct Communication (LDC), learns a protocol end-to-end. The second, Intention Communication, uses an engineered inductive bias: a compact, learned world model, the Imagined Trajectory Generation Module (ITGM), which uses the agent's own policy to simulate future states. A Message Generation Network (MGN) then compresses this plan into a message. We evaluate these approaches on goal-directed interaction in a grid world, a canonical abstraction for embodied AI problems, while scaling environmental complexity. Our experiments reveal that while emergent communication is viable in simple settings, the engineered, world model-based approach shows superior performance, sample efficiency, and scalability as complexity increases. These findings advocate for integrating structured, predictive models into MARL agents to enable active, goal-driven coordination.","authors":["Brennen A. Hill","Mant Koh En Wei","Thangavel Jishnuanandh"],"pdf_url":"","comment":"Published in the Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments for Agents (SEA). Additionally accepted for presentation in the NeurIPS 2025 Workshop: Embodied World Models for Decision Making (EWM) and the NeurIPS 2025 Workshop: Optimization for Machine Learning (OPT)"},{"id":"http://arxiv.org/abs/2511.19390v1","updated":"2025-11-24T18:30:04Z","published":"2025-11-24T18:30:04Z","title":"Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme","summary":"Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.","authors":["Rudy Morel","Francesco Pio Ramunno","Jeff Shen","Alberto Bietti","Kyunghyun Cho","Miles Cranmer","Siavash Golkar","Olexandr Gugnin","Geraud Krawezik","Tanya Marwah","Michael McCabe","Lucas Meyer","Payel Mukhopadhyay","Ruben Ohana","Liam Parker","Helen Qu","François Rozet","K. D. Leka","François Lanusse","David Fouhey","Shirley Ho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.10100v4","updated":"2025-11-24T18:17:51Z","published":"2025-01-17T10:39:09Z","title":"Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics","summary":"Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03469v2","updated":"2025-11-24T18:17:27Z","published":"2025-10-03T19:46:55Z","title":"Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification","summary":"We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model checking. We systematically evaluate this framework on a simplified version of the PlanBench plan verification dataset and report on metrics like Accuracy, Precision, Recall and F1 scores. Our experiments demonstrate that GPT-5 achieves excellent classification performance (F1 score of 96.3%) while almost always producing syntactically perfect formal representations that can act as guarantees. However, the synthesis of semantically perfect formal models remains an area for future exploration.","authors":["Keshav Ramani","Vali Tawosi","Salwa Alamir","Daniel Borrajo"],"pdf_url":"","comment":"Accepted to AgenticSE Workshop at ASE 2025"},{"id":"http://arxiv.org/abs/2510.03463v2","updated":"2025-11-24T18:11:57Z","published":"2025-10-03T19:35:23Z","title":"ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework","summary":"Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields. One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents. However, software development is a multifaceted environment that extends beyond just code. As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC). In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end. ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment. We showcase the progress towards ALMAS through our published works and a use case demonstrating the framework, where ALMAS is able to seamlessly generate an application and add a new feature.","authors":["Vali Tawosi","Keshav Ramani","Salwa Alamir","Xiaomo Liu"],"pdf_url":"","comment":"Accepted to MAS-GAIN Workshop at ASE 2025"},{"id":"http://arxiv.org/abs/2511.19367v1","updated":"2025-11-24T18:01:47Z","published":"2025-11-24T18:01:47Z","title":"An Anatomy Aware Hybrid Deep Learning Framework for Lung Cancer Tumor Stage Classification","summary":"Accurate lung cancer tumor staging is crucial for prognosis and treatment planning. However, it remains challenging for end-to-end deep learning approaches, as such approaches often overlook spatial and anatomical information that are central to the tumor-node-metastasis system. The tumor stage depends on multiple quantitative criteria, including the tumor size and its proximity to the nearest anatomical structures, and small variations can alter the staging outcome. We propose a medically grounded hybrid pipeline that performs staging by explicitly measuring the tumor's size and distance properties rather than treating it as a pure image classification task. Our method employs specialized encoder-decoder networks to precisely segment the lung and adjacent anatomy, including the lobes, tumor, mediastinum, and diaphragm. Subsequently, we extract the necessary tumor properties, i.e. measure the largest tumor dimension and calculate the distance between the tumor and neighboring anatomical structures by a quantitative analysis of the segmentation masks. Finally, we apply rule-based tumor staging aligned with the medical guidelines. This novel framework has been evaluated on the Lung-PET-CT-Dx dataset, demonstrating superior performance compared to traditional deep learning models, achieving an overall classification accuracy of 91.36%. We report the per-stage F1-scores of 0.93 (T1), 0.89 (T2), 0.96 (T3), and 0.90 (T4), a critical evaluation aspect often omitted in prior literature. To our knowledge, this is the first study that embeds explicit clinical context into tumor stage classification. Unlike standard convolutional neural networks that operate in an uninterpretable \"black box\" manner, our method offers both state-of-the-art performance and transparent decision support.","authors":["Saniah Kayenat Chowdhury","Rusab Sarmun","Muhammad E. H. Chowdhury","Sohaib Bassam Zoghoul","Israa Al-Hashimi","Adam Mushtak","Amith Khandakar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19365v1","updated":"2025-11-24T17:59:06Z","published":"2025-11-24T17:59:06Z","title":"DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation","summary":"Pixel diffusion aims to generate images directly in pixel space in an end-to-end fashion. This approach avoids the limitations of VAE in the two-stage latent diffusion, offering higher model capacity. Existing pixel diffusion models suffer from slow training and inference, as they usually model both high-frequency signals and low-frequency semantics within a single diffusion transformer (DiT). To pursue a more efficient pixel diffusion paradigm, we propose the frequency-DeCoupled pixel diffusion framework. With the intuition to decouple the generation of high and low frequency components, we leverage a lightweight pixel decoder to generate high-frequency details conditioned on semantic guidance from the DiT. This thus frees the DiT to specialize in modeling low-frequency semantics. In addition, we introduce a frequency-aware flow-matching loss that emphasizes visually salient frequencies while suppressing insignificant ones. Extensive experiments show that DeCo achieves superior performance among pixel diffusion models, attaining FID of 1.62 (256x256) and 2.22 (512x512) on ImageNet, closing the gap with latent diffusion methods. Furthermore, our pretrained text-to-image model achieves a leading overall score of 0.86 on GenEval in system-level comparison. Codes are publicly available at https://github.com/Zehong-Ma/DeCo.","authors":["Zehong Ma","Longhui Wei","Shuai Wang","Shiliang Zhang","Qi Tian"],"pdf_url":"","comment":"Project Page: https://zehong-ma.github.io/DeCo. Code Repository: https://github.com/Zehong-Ma/DeCo"},{"id":"http://arxiv.org/abs/2511.19355v1","updated":"2025-11-24T17:55:46Z","published":"2025-11-24T17:55:46Z","title":"Leveraging LLMs for reward function design in reinforcement learning control tasks","summary":"The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.","authors":["Franklin Cardenoso","Wouter Caarls"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00634v2","updated":"2025-11-24T17:55:01Z","published":"2025-11-01T17:26:56Z","title":"Node Preservation and its Effect on Crossover in Cartesian Genetic Programming","summary":"While crossover is a critical and often indispensable component in other forms of Genetic Programming, such as Linear- and Tree-based, it has consistently been claimed that it deteriorates search performance in CGP. As a result, a mutation-alone $(1+λ)$ evolutionary strategy has become the canonical approach for CGP. Although several operators have been developed that demonstrate an increased performance over the canonical method, a general solution to the problem is still lacking. In this paper, we compare basic crossover methods, namely one-point and uniform, to variants in which nodes are ``preserved,'' including the subgraph crossover developed by Roman Kalkreuth, the difference being that when ``node preservation'' is active, crossover is not allowed to break apart instructions. We also compare a node mutation operator to the traditional point mutation; the former simply replaces an entire node with a new one. We find that node preservation in both mutation and crossover improves search using symbolic regression benchmark problems, moving the field towards a general solution to CGP crossover.","authors":["Mark Kocherovsky","Illya Bakurov","Wolfgang Banzhaf"],"pdf_url":"","comment":"Draft to cite in another paper before both papers are peer-reviewed for the evo*2026 conference, 21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.19342v1","updated":"2025-11-24T17:41:04Z","published":"2025-11-24T17:41:04Z","title":"Explicit Tonal Tension Conditioning via Dual-Level Beam Search for Symbolic Music Generation","summary":"State-of-the-art symbolic music generation models have recently achieved remarkable output quality, yet explicit control over compositional features, such as tonal tension, remains challenging. We propose a novel approach that integrates a computational tonal tension model, based on tonal interval vector analysis, into a Transformer framework. Our method employs a two-level beam search strategy during inference. At the token level, generated candidates are re-ranked using model probability and diversity metrics to maintain overall quality. At the bar level, a tension-based re-ranking is applied to ensure that the generated music aligns with a desired tension curve. Objective evaluations indicate that our approach effectively modulates tonal tension, and subjective listening tests confirm that the system produces outputs that align with the target tension. These results demonstrate that explicit tension conditioning through a dual-level beam search provides a powerful and intuitive tool to guide AI-generated music. Furthermore, our experiments demonstrate that our method can generate multiple distinct musical interpretations under the same tension condition.","authors":["Maral Ebrahimzadeh","Gilberto Bernardes","Sebastian Stober"],"pdf_url":"","comment":"12 pages, 2 Figures, Accepted at the 17th International Symposium on Computer Music Multidisciplinary Research (CMMR) 2025"},{"id":"http://arxiv.org/abs/2511.19325v1","updated":"2025-11-24T17:18:25Z","published":"2025-11-24T17:18:25Z","title":"Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval","summary":"Query expansion is the reformulation of a user query by adding semantically related information, and is an essential component of monolingual and cross-lingual information retrieval used to ensure that relevant documents are not missed. Recently, multilingual large language models (mLLMs) have shifted query expansion from semantic augmentation with synonyms and related words to pseudo-document generation. Pseudo-documents both introduce additional relevant terms and bridge the gap between short queries and long documents, which is particularly beneficial in dense retrieval. This study evaluates recent mLLMs and fine-tuned variants across several generative expansion strategies to identify factors that drive cross-lingual retrieval performance. Results show that query length largely determines which prompting technique is effective, and that more elaborate prompts often do not yield further gains. Substantial linguistic disparities persist: cross-lingual query expansion can produce the largest improvements for languages with the weakest baselines, yet retrieval is especially poor between languages written in different scripts. Fine-tuning is found to lead to performance gains only when the training and test data are of similar format. These outcomes underline the need for more balanced multilingual and cross-lingual training and evaluation resources.","authors":["Olivia Macmillan-Scott","Roksana Goworek","Eda B. Özyiğit"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19324v1","updated":"2025-11-24T17:17:40Z","published":"2025-11-24T17:17:40Z","title":"What Drives Cross-lingual Ranking? Retrieval Approaches with Multilingual Language Models","summary":"Cross-lingual information retrieval (CLIR) enables access to multilingual knowledge but remains challenging due to disparities in resources, scripts, and weak cross-lingual semantic alignment in embedding models. Existing pipelines often rely on translation and monolingual retrieval heuristics, which add computational overhead and noise, degrading performance. This work systematically evaluates four intervention types, namely document translation, multilingual dense retrieval with pretrained encoders, contrastive learning at word, phrase, and query-document levels, and cross-encoder re-ranking, across three benchmark datasets. We find that dense retrieval models trained specifically for CLIR consistently outperform lexical matching methods and derive little benefit from document translation. Contrastive learning mitigates language biases and yields substantial improvements for encoders with weak initial alignment, and re-ranking can be effective, but depends on the quality of the cross-encoder training data. Although high-resource languages still dominate overall performance, gains over lexical and document-translated baselines are most pronounced for low-resource and cross-script pairs. These findings indicate that cross-lingual search systems should prioritise semantic multilingual embeddings and targeted learning-based alignment over translation-based pipelines, particularly for cross-script and under-resourced languages.","authors":["Roksana Goworek","Olivia Macmillan-Scott","Eda B. Özyiğit"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.13612v4","updated":"2025-11-24T17:16:26Z","published":"2025-04-18T10:35:19Z","title":"Entropic Time Schedulers for Generative Diffusion Models","summary":"The practical performance of generative diffusion models depends on the appropriate choice of the noise scheduling function, which can also be equivalently expressed as a time reparameterization. In this paper, we present a time scheduler that selects sampling points based on entropy rather than uniform time spacing, ensuring that each point contributes an equal amount of information to the final generation. We prove that this time reparameterization does not depend on the initial choice of time. Furthermore, we provide a tractable exact formula to estimate this \\emph{entropic time} for a trained model using the training loss without substantial overhead. Alongside the entropic time, inspired by the optimality results, we introduce a rescaled entropic time. In our experiments with mixtures of Gaussian distributions and ImageNet, we show that using the (rescaled) entropic times greatly improves the inference performance of trained models. In particular, we found that the image quality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can be substantially increased by the rescaled entropic time reparameterization without increasing the number of function evaluations, with greater improvements in the few NFEs regime. Code is available at https://github.com/DejanStancevic/Entropic-Time-Schedulers-for-Generative-Diffusion-Models.","authors":["Dejan Stancevic","Florian Handke","Luca Ambrogioni"],"pdf_url":"","comment":"31 pages"},{"id":"http://arxiv.org/abs/2508.02995v3","updated":"2025-11-24T17:11:32Z","published":"2025-08-05T01:52:42Z","title":"The Geometry of Cortical Computation: Manifold Disentanglement and Predictive Dynamics in VCNet","summary":"Despite their success, modern convolutional neural networks (CNNs) exhibit fundamental limitations, including data inefficiency, poor out-of-distribution generalization, and vulnerability to adversarial perturbations. These shortcomings can be traced to a lack of inductive biases that reflect the inherent geometric structure of the visual world. The primate visual system, in contrast, demonstrates superior efficiency and robustness, suggesting that its architectural and computational principles,which evolved to internalize these structures,may offer a blueprint for more capable artificial vision. This paper introduces Visual Cortex Network (VCNet), a novel neural network architecture whose design is informed by the macro-scale organization of the primate visual cortex. VCNet is framed as a geometric framework that emulates key biological mechanisms, including hierarchical processing across distinct cortical areas, dual-stream information segregation for learning disentangled representations, and top-down predictive feedback for representation refinement. We interpret these mechanisms through the lens of geometry and dynamical systems, positing that they guide the learning of structured, low-dimensional neural manifolds. We evaluate VCNet on two specialized benchmarks: the Spots-10 animal pattern dataset, which probes sensitivity to natural textures, and a light field image classification task, which requires processing higher-dimensional visual data. Our results show that VCNet achieves state-of-the-art accuracy of 92.1\\% on Spots-10 and 74.4\\% on the light field dataset, surpassing contemporary models of comparable size. This work demonstrates that integrating high-level neuroscientific principles, viewed through a geometric lens, can lead to more efficient and robust models, providing a promising direction for addressing long-standing challenges in machine learning.","authors":["Brennen A. Hill","Zhang Xinyu","Timothy Putra Prasetio"],"pdf_url":"","comment":"Published in the proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Symmetry and Geometry in Neural Representations (NeurReps). Additionally accepted for presentation in NeurIPS 2025 Workshop: Interpreting Cognition in Deep Learning Models (CogInterp)"},{"id":"http://arxiv.org/abs/2511.19316v1","updated":"2025-11-24T17:11:00Z","published":"2025-11-24T17:11:00Z","title":"Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach","summary":"Recent fine-tuning techniques for diffusion models enable them to reproduce specific image sets, such as particular faces or artistic styles, but also introduce copyright and security risks. Dataset watermarking has been proposed to ensure traceability by embedding imperceptible watermarks into training images, which remain detectable in outputs even after fine-tuning. However, current methods lack a unified evaluation framework. To address this, this paper establishes a general threat model and introduces a comprehensive evaluation framework encompassing Universality, Transmissibility, and Robustness. Experiments show that existing methods perform well in universality and transmissibility, and exhibit some robustness against common image processing operations, yet still fall short under real-world threat scenarios. To reveal these vulnerabilities, the paper further proposes a practical watermark removal method that fully eliminates dataset watermarks without affecting fine-tuning, highlighting a key challenge for future research.","authors":["Xincheng Wang","Hanchi Sun","Wenjun Sun","Kejun Xue","Wangqiu Zhou","Jianbo Zhang","Wei Sun","Dandan Zhu","Xiongkuo Min","Jun Jia","Zhijun Fang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21505v2","updated":"2025-11-24T17:10:38Z","published":"2025-05-27T17:59:52Z","title":"How does Alignment Enhance LLMs' Multilingual Capabilities? A Language Neurons Perspective","summary":"Multilingual Alignment is an effective and representative paradigm to enhance LLMs' multilingual capabilities, which transfers the capabilities from the high-resource languages to the low-resource languages. Meanwhile, some research on language-specific neurons provides a new perspective to analyze and understand LLMs' mechanisms. However, we find that there are many neurons that are shared by multiple but not all languages and cannot be correctly classified. In this work, we propose a ternary classification methodology that categorizes neurons into three types, including language-specific neurons, language-related neurons, and general neurons. And we propose a corresponding identification algorithm to distinguish these different types of neurons. Furthermore, based on the distributional characteristics of different types of neurons, we divide the LLMs' internal process for multilingual inference into four parts: (1) multilingual understanding, (2) shared semantic space reasoning, (3) multilingual output space transformation, and (4) vocabulary space outputting. Additionally, we systematically analyze the models before and after alignment with a focus on different types of neurons. We also analyze the phenomenon of ''Spontaneous Multilingual Alignment''. Overall, our work conducts a comprehensive investigation based on different types of neurons, providing empirical results and valuable insights to better understand multilingual alignment and multilingual capabilities of LLMs.","authors":["Shimao Zhang","Zhejian Lai","Xiang Liu","Shuaijie She","Xiao Liu","Yeyun Gong","Shujian Huang","Jiajun Chen"],"pdf_url":"","comment":"AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2511.19314v1","updated":"2025-11-24T17:09:43Z","published":"2025-11-24T17:09:43Z","title":"PRInTS: Reward Modeling for Long-Horizon Information Seeking","summary":"Information-seeking is a core capability for AI agents, requiring them to gather and reason over tool-generated information across long trajectories. However, such multi-step information-seeking tasks remain challenging for agents backed by language models. While process reward models (PRMs) can guide agents by ranking candidate steps at test-time, existing PRMs, designed for short reasoning with binary judgment, cannot capture richer dimensions of information-seeking steps, such as tool interactions and reasoning over tool outputs, nor handle the rapidly growing context in long-horizon tasks. To address these limitations, we introduce PRInTS, a generative PRM trained with dual capabilities: (1) dense scoring based on the PRM's reasoning across multiple step quality dimensions (e.g., interpretation of tool outputs, tool call informativeness) and (2) trajectory summarization that compresses the growing context while preserving essential information for step evaluation. Extensive evaluations across FRAMES, GAIA (levels 1-3), and WebWalkerQA (easy-hard) benchmarks on multiple models, along with ablations, reveal that best-of-n sampling with PRInTS enhances information-seeking abilities of open-source models as well as specialized agents, matching or surpassing the performance of frontier models with a much smaller backbone agent and outperforming other strong reward modeling baselines.","authors":["Jaewoo Lee","Archiki Prasad","Justin Chih-Yao Chen","Zaid Khan","Elias Stengel-Eskin","Mohit Bansal"],"pdf_url":"","comment":"18 pages, code: https://github.com/G-JWLee/PRInTS"},{"id":"http://arxiv.org/abs/2511.15622v2","updated":"2025-11-24T17:02:04Z","published":"2025-11-19T17:07:08Z","title":"The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification","summary":"Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at https://www.conservationxlabs.com/sa-fari.","authors":["Dante Francisco Wasmuht","Otto Brookes","Maximillian Schall","Pablo Palencia","Chris Beirne","Tilo Burghardt","Majid Mirmehdi","Hjalmar Kühl","Mimi Arandjelovic","Sam Pottie","Peter Bermant","Brandon Asheim","Yi Jin Toh","Adam Elzinga","Jason Holmberg","Andrew Whitworth","Eleanor Flatt","Laura Gustafson","Chaitanya Ryali","Yuan-Ting Hu","Baishan Guo","Andrew Westbury","Kate Saenko","Didac Suris"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19304v1","updated":"2025-11-24T16:54:23Z","published":"2025-11-24T16:54:23Z","title":"AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning","summary":"Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.","authors":["Jiayi Zhang","Yiran Peng","Fanqi Kong","Yang Cheng","Yifan Wu","Zhaoyang Yu","Jinyu Xiang","Jianhao Ruan","Jinlin Wang","Maojia Song","HongZhang Liu","Xiangru Tang","Bang Liu","Chenglin Wu","Yuyu Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.10750v2","updated":"2025-11-24T16:52:12Z","published":"2025-07-14T19:16:27Z","title":"AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition","summary":"Thanks to the availability of massive amounts of data, computing resources, and advanced algorithms, AI has entered nearly every sector. This has sparked significant investment and interest, particularly in building data centers with the necessary hardware and software to develop and operate AI models and AI-based workflows. In this technical review article, we present energy consumption scenarios of data centers and impact on GHG emissions, considering both near-term projections (up to 2030) and long-term outlook (2035 and beyond). We address the quintessential question of whether AI will have a net positive, neutral, or negative impact on CO2 emissions by 2035. Additionally, we discuss AI's potential to automate, create efficient and disruptive workflows across various fields related to energy production, supply and consumption. In the near-term scenario, the growing demand for AI will likely strain computing resources, lead to increase in electricity consumption and therefore associated CO2 emissions. This is due to the power-hungry nature of big data centers and the requirements for training and running of large and complex AI models, as well as the penetration of AI assistant search and applications for public use. However, the long-term outlook could be more promising. AI has the potential to be a game-changer in CO2 reduction. Its ability to further automate and optimize processes across industries, from energy production to logistics, could significantly decrease our carbon footprint. This positive impact is anticipated to outweigh the initial emissions bump, creating value for businesses and society in areas where traditional solutions have fallen short. In essence, AI might cause some initial growing pains for the environment, but it has the potential to support climate mitigation efforts.","authors":["Pandu Devarakota","Nicolas Tsesmetzis","Faruk O. Alpak","Apurva Gala","Detlef Hohl"],"pdf_url":"","comment":"Technical article to be submitted to Data Centric Engineering Journal"},{"id":"http://arxiv.org/abs/2511.19299v1","updated":"2025-11-24T16:46:44Z","published":"2025-11-24T16:46:44Z","title":"Open-weight genome language model safeguards: Assessing robustness via adversarial fine-tuning","summary":"Novel deep learning architectures are increasingly being applied to biological data, including genetic sequences. These models, referred to as genomic language mod- els (gLMs), have demonstrated impressive predictive and generative capabilities, raising concerns that such models may also enable misuse, for instance via the generation of genomes for human-infecting viruses. These concerns have catalyzed calls for risk mitigation measures. The de facto mitigation of choice is filtering of pretraining data (i.e., removing viral genomic sequences from training datasets) in order to limit gLM performance on virus-related tasks. However, it is not currently known how robust this approach is for securing open-source models that can be fine-tuned using sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and perform fine-tuning using sequences from 110 harmful human-infecting viruses to assess the rescue of misuse-relevant predictive capabilities. The fine- tuned model exhibited reduced perplexity on unseen viral sequences relative to 1) the pretrained model and 2) a version fine-tuned on bacteriophage sequences. The model fine-tuned on human-infecting viruses also identified immune escape variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo- sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that data exclusion might be circumvented by fine-tuning approaches that can, to some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need for safety frameworks for gLMs and outline further work needed on evaluations and mitigation measures to enable the safe deployment of gLMs.","authors":["James R. M. Black","Moritz S. Hanke","Aaron Maiwald","Tina Hernandez-Boussard","Oliver M. Crook","Jaspreet Pannu"],"pdf_url":"","comment":"39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI"},{"id":"http://arxiv.org/abs/2510.27280v2","updated":"2025-11-24T16:40:06Z","published":"2025-10-31T08:41:13Z","title":"FOCUS: Efficient Keyframe Selection for Long Video Understanding","summary":"Multimodal large language models (MLLMs) represent images and video frames as visual tokens. Scaling from single images to hour-long videos, however, inflates the token budget far beyond practical limits. Popular pipelines therefore either uniformly subsample or apply keyframe selection with retrieval-style scoring using smaller vision-language models. However, these keyframe selection methods still rely on pre-filtering before selection to reduce the inference cost and can miss the most informative moments. We propose FOCUS, Frame-Optimistic Confidence Upper-bound Selection, a training-free, model-agnostic keyframe selection module that selects query-relevant frames under a strict token budget. FOCUS formulates keyframe selection as a combinatorial pure-exploration (CPE) problem in multi-armed bandits: it treats short temporal clips as arms, and uses empirical means and Bernstein confidence radius to identify informative regions while preserving exploration of uncertain areas. The resulting two-stage exploration-exploitation procedure reduces from a sequential policy with theoretical guarantees, first identifying high-value temporal regions, then selecting top-scoring frames within each region. On two long-video question-answering benchmarks, FOCUS delivers substantial accuracy improvements while processing less than 2% of video frames. For videos longer than 20 minutes, it achieves an 11.9% gain in accuracy on LongVideoBench, demonstrating its effectiveness as a keyframe selection method and providing a simple and general solution for scalable long-video understanding with MLLMs. Code is available at https://github.com/NUS-HPC-AI-Lab/FOCUS.","authors":["Zirui Zhu","Hailun Xu","Yang Luo","Yong Liu","Kanchan Sarkar","Zhenheng Yang","Yang You"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01285v2","updated":"2025-11-24T16:36:29Z","published":"2025-08-02T09:32:52Z","title":"BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation","summary":"Identifying novel hypotheses is essential to scientific research, yet this process risks being overwhelmed by the sheer volume and complexity of available information. Existing automated methods often struggle to generate novel and evidence-grounded hypotheses, lack robust iterative refinement and rarely undergo rigorous temporal evaluation for future discovery potential. To address this, we propose BioDisco, a multi-agent framework that draws upon language model-based reasoning and a dual-mode evidence system (biomedical knowledge graphs and automated literature retrieval) for grounded novelty, integrates an internal scoring and feedback loop for iterative refinement, and validates performance through pioneering temporal and human evaluations and a Bradley-Terry paired comparison model to provide statistically-grounded assessment. Our evaluations demonstrate superior novelty and significance over ablated configurations and generalist biomedical agents. Designed for flexibility and modularity, BioDisco allows seamless integration of custom language models or knowledge graphs, and can be run with just a few lines of code.","authors":["Yujing Ke","Kevin George","Kathan Pandya","David Blumenthal","Maximilian Sprang","Gerrit Großmann","Sebastian Vollmer","David Antony Selby"],"pdf_url":"","comment":"12 pages main content, 31 including appendices. 8 figures"},{"id":"http://arxiv.org/abs/2503.10727v2","updated":"2025-11-24T16:34:25Z","published":"2025-03-13T11:41:25Z","title":"Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models","summary":"Ensuring transparency of data practices related to personal information is a core requirement of the General Data Protection Regulation (GDPR). However, large-scale compliance assessment remains challenging due to the complexity and diversity of privacy policy language. Manual audits are labour-intensive and inconsistent, while current automated methods often lack the granularity required to capture nuanced transparency disclosures.\n  In this paper, we present a modular large language model (LLM)-based pipeline for fine-grained word-level annotation of privacy policies with respect to GDPR transparency requirements. Our approach integrates LLM-driven annotation with passage-level classification, retrieval-augmented generation, and a self-correction mechanism to deliver scalable, context-aware annotations across 21 GDPR-derived transparency requirements. To support empirical evaluation, we compile a corpus of 703,791 English-language privacy policies and generate a ground-truth sample of 200 manually annotated policies based on a comprehensive, GDPR-aligned annotation scheme.\n  We propose a two-tiered evaluation methodology capturing both passage-level classification and span-level annotation quality and conduct a comparative analysis of seven state-of-the-art LLMs on two annotation schemes, including the widely used OPP-115 dataset. The results of our evaluation show that decomposing the annotation task and integrating targeted retrieval and classification components significantly improve annotation accuracy, particularly for well-structured requirements. Our work provides new empirical resources and methodological foundations for advancing automated transparency compliance assessment at scale.","authors":["Thomas Cory","Wolf Rieder","Julia Krämer","Philip Raschke","Patrick Herbke","Axel Küpper"],"pdf_url":"","comment":"Accepted to Proceedings on Privacy Enhancing Technologies (PoPETs) 1 (2026)"},{"id":"http://arxiv.org/abs/2511.19283v1","updated":"2025-11-24T16:31:50Z","published":"2025-11-24T16:31:50Z","title":"Data Flows and Colonial Regimes in Africa: A Critical Analysis of the Colonial Futurities Embedded in AI Ecosystems","summary":"This chapter seeks to frame the elemental and invisible problems of AI and big data in the African context by examining digital sites and infrastructure through the lens of power and interests. It will present reflections on how these sites are using AI recommendation algorithms to recreate new digital societies in the region, how they have the potential to propagate algorithmic colonialism and negative gender norms, and what this means for the regional sustainable development agenda. The chapter proposes adopting business models that embrace response-ability and consider the existence of alternative socio-material worlds of AI. These reflections will mainly come from ongoing discussions with Kenyan social media users in this authors' user space talks, personal experiences and six months of active participant observations done by the authors.","authors":["Ndaka. A","Avila-Acosta. F","Mbula-Ndaka. H","Amera. C","Chauke. S","Majiwa. E"],"pdf_url":"","comment":"12 pages"},{"id":"http://arxiv.org/abs/2506.10016v3","updated":"2025-11-24T16:26:13Z","published":"2025-05-29T12:29:39Z","title":"A Survey of Generative Categories and Techniques in Multimodal Generative Models","summary":"Multimodal Generative Models (MGMs) have rapidly evolved beyond text generation, now spanning diverse output modalities including images, music, video, human motion, and 3D objects, by integrating language with other sensory modalities under unified architectures. This survey categorises six primary generative modalities and examines how foundational techniques, namely Self-Supervised Learning (SSL), Mixture of Experts (MoE), Reinforcement Learning from Human Feedback (RLHF), and Chain-of-Thought (CoT) prompting, enable cross-modal capabilities. We analyze key models, architectural trends, and emergent cross-modal synergies, while highlighting transferable techniques and unresolved challenges. Building on a common taxonomy of models and training recipes, we propose a unified evaluation framework centred on faithfulness, compositionality, and robustness, and synthesise evidence from benchmarks and human studies across modalities. We further analyse trustworthiness, safety, and ethical risks, including multimodal bias, privacy leakage, and the misuse of high-fidelity media generation for deepfakes, disinformation, and copyright infringement in music and 3D assets, together with emerging mitigation strategies. Finally, we discuss how architectural trends, evaluation protocols, and governance mechanisms can be co-designed to close current capability and safety gaps, outlining critical paths toward more general-purpose, controllable, and accountable multimodal generative systems.","authors":["Longzhen Han","Awes Mubarak","Almas Baimagambetov","Nikolaos Polatidis","Thar Baker"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19275v1","updated":"2025-11-24T16:25:55Z","published":"2025-11-24T16:25:55Z","title":"Dynamic Multi-Species Bird Soundscape Generation with Acoustic Patterning and 3D Spatialization","summary":"Generation of dynamic, scalable multi-species bird soundscapes remains a significant challenge in computer music and algorithmic sound design. Birdsongs involve rapid frequency-modulated chirps, complex amplitude envelopes, distinctive acoustic patterns, overlapping calls, and dynamic inter-bird interactions, all of which require precise temporal and spatial control in 3D environments. Existing approaches, whether Digital Signal Processing (DSP)-based or data-driven, typically focus only on single species modeling, static call structures, or synthesis directly from recordings, and often suffer from noise, limited flexibility, or large data needs. To address these challenges, we present a novel, fully algorithm-driven framework that generates dynamic multi-species bird soundscapes using DSP-based chirp generation and 3D spatialization, without relying on recordings or training data. Our approach simulates multiple independently-moving birds per species along different moving 3D trajectories, supporting controllable chirp sequences, overlapping choruses, and realistic 3D motion in scalable soundscapes while preserving species-specific acoustic patterns. A visualization interface provides bird trajectories, spectrograms, activity timelines, and sound waves for analytical and creative purposes. Both visual and audio evaluations demonstrate the ability of the system to generate dense, immersive, and ecologically inspired soundscapes, highlighting its potential for computer music, interactive virtual environments, and computational bioacoustics research.","authors":["Ellie L. Zhang","Duoduo Liao","Callie C. Liao"],"pdf_url":"","comment":"Accepted by IEEE Big Data 2025"},{"id":"http://arxiv.org/abs/2506.06725v2","updated":"2025-11-24T16:18:31Z","published":"2025-06-07T09:13:34Z","title":"WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making","summary":"Large Language Models (LLMs) possess general world knowledge but often struggle to generate precise predictions in structured, domain-specific contexts such as simulations. These limitations arise from their inability to ground their broad, unstructured understanding in specific environments. To address this, we present WorldLLM, a framework that enhances LLM-based world modeling by combining Bayesian inference and autonomous active exploration with reinforcement learning. WorldLLM leverages the in-context learning abilities of LLMs to guide an LLM-based world model's predictions using natural language hypotheses given in its prompt. These hypotheses are iteratively refined through a Bayesian inference framework that leverages a second LLM as the proposal distribution given collected evidence. This evidence is collected using a curiosity-driven reinforcement learning policy that explores the environment to find transitions with a low log-likelihood under our LLM-based predictive model using the current hypotheses. By alternating between refining hypotheses and collecting new evidence, our framework autonomously drives continual improvement of the predictions. Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment that requires agents to manipulate and combine objects. The framework not only enhances predictive accuracy, but also generates human-interpretable theories of environment dynamics.","authors":["Guillaume Levy","Cedric Colas","Pierre-Yves Oudeyer","Thomas Carta","Clement Romac"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.01558v2","updated":"2025-11-24T16:17:57Z","published":"2024-12-02T14:45:53Z","title":"VideoLights: Feature Refinement and Cross-Task Alignment Transformer for Joint Video Highlight Detection and Moment Retrieval","summary":"Prevailing joint prediction transformers for Video Highlight Detection and Moment Retrieval (HD/MR) exhibit deficiencies in handling cross-task dynamics, achieving robust video-text alignment, and utilizing effective attention mechanisms, with the potential of Large Language/Vision-Language Models (LLMs/LVLMs) being largely untapped. This paper introduces VideoLights, a novel HD/MR framework addressing these limitations by incorporating: (i) Convolutional Projection and Feature Refinement modules with an alignment loss for enhanced video-text feature congruity; (ii) a Bi-Directional Cross-Modal Fusion network for strongly coupled query-aware representations; (iii) a Uni-directional joint-task feedback mechanism for synergistic task improvement; (iv) hard positive/negative losses for adaptive learning; and (v) the leveraging of LVLMs (e.g., BLIP-2) for superior multimodal feature integration and intelligent pre-training with synthetic data. Comprehensive evaluations on QVHighlights, TVSum, and Charades-STA benchmarks demonstrate that VideoLights significantly surpasses existing baselines, establishing new state-of-the-art performances. Codes and model checkpoints are available at https://github.com/dpaul06/VideoLights .","authors":["Dhiman Paul","Md Rizwan Parvez","Nabeel Mohammed","Shafin Rahman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19264v1","updated":"2025-11-24T16:16:18Z","published":"2025-11-24T16:16:18Z","title":"Interpreting GFlowNets for Drug Discovery: Extracting Actionable Insights for Medicinal Chemistry","summary":"Generative Flow Networks, or GFlowNets, offer a promising framework for molecular design, but their internal decision policies remain opaque. This limits adoption in drug discovery, where chemists require clear and interpretable rationales for proposed structures. We present an interpretability framework for SynFlowNet, a GFlowNet trained on documented chemical reactions and purchasable starting materials that generates both molecules and the synthetic routes that produce them. Our approach integrates three complementary components. Gradient based saliency combined with counterfactual perturbations identifies which atomic environments influence reward and how structural edits change molecular outcomes. Sparse autoencoders reveal axis aligned latent factors that correspond to physicochemical properties such as polarity, lipophilicity, and molecular size. Motif probes show that functional groups including aromatic rings and halogens are explicitly encoded and linearly decodable from the internal embeddings. Together, these results expose the chemical logic inside SynFlowNet and provide actionable and mechanistic insight that supports transparent and controllable molecular design.","authors":["Amirtha Varshini A S","Duminda S. Ranasinghe","Hok Hei Tam"],"pdf_url":"","comment":"13 pages, 7 figures. Accepted for presentation at NeurIPS 2025 WiML Workshop and Molecular Machine Learning Conference (MoML) 2025"},{"id":"http://arxiv.org/abs/2511.19263v1","updated":"2025-11-24T16:15:41Z","published":"2025-11-24T16:15:41Z","title":"Solar-GECO: Perovskite Solar Cell Property Prediction with Geometric-Aware Co-Attention","summary":"Perovskite solar cells are promising candidates for next-generation photovoltaics. However, their performance as multi-scale devices is determined by complex interactions between their constituent layers. This creates a vast combinatorial space of possible materials and device architectures, making the conventional experimental-based screening process slow and expensive. Machine learning models try to address this problem, but they only focus on individual material properties or neglect the important geometric information of the perovskite crystal. To address this problem, we propose to predict perovskite solar cell power conversion efficiency with a geometric-aware co-attention (Solar-GECO) model. Solar-GECO combines a geometric graph neural network (GNN) - that directly encodes the atomic structure of the perovskite absorber - with language model embeddings that process the textual strings representing the chemical compounds of the transport layers and other device components. Solar-GECO also integrates a co-attention module to capture intra-layer dependencies and inter-layer interactions, while a probabilistic regression head predicts both power conversion efficiency (PCE) and its associated uncertainty. Solar-GECO achieves state-of-the-art performance, significantly outperforming several baselines, reducing the mean absolute error (MAE) for PCE prediction from 3.066 to 2.936 compared to semantic GNN (the previous state-of-the-art model). Solar-GECO demonstrates that integrating geometric and textual information provides a more powerful and accurate framework for PCE prediction.","authors":["Lucas Li","Jean-Baptiste Puel","Florence Carton","Dounya Barrit","Jhony H. Giraldo"],"pdf_url":"","comment":"Accepted at the AI for Accelerated Materials Design (AI4Mat) Workshop at NeurIPS 2025. 14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.19262v1","updated":"2025-11-24T16:15:08Z","published":"2025-11-24T16:15:08Z","title":"Psychometric Tests for AI Agents and Their Moduli Space","summary":"We develop a moduli-theoretic view of psychometric test batteries for AI agents and connect it explicitly to the AAI score developed previously. First, we make precise the notion of an AAI functional on a battery and set out axioms that any reasonable autonomy/general intelligence score should satisfy. Second, we show that the composite index ('AAI-Index') defined previously is a special case of our AAI functional. Third, we introduce the notion of a cognitive core of an agent relative to a battery and define the associated AAI$_{\\textrm{core}}$ score as the restriction of an AAI functional to that core. Finally, we use these notions to describe invariants of batteries under evaluation-preserving symmetries and outline how moduli of equivalent batteries are organized.","authors":["Przemyslaw Chojecki"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19260v1","updated":"2025-11-24T16:12:03Z","published":"2025-11-24T16:12:03Z","title":"A Nutrition Multimodal Photoplethysmography Language Model","summary":"Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.","authors":["Kyle Verrier","Achille Nazaret","Joseph Futoma","Andrew C. Miller","Guillermo Sapiro"],"pdf_url":"","comment":"21 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.19257v1","updated":"2025-11-24T16:11:01Z","published":"2025-11-24T16:11:01Z","title":"Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation","summary":"With the rapid advancement of retrieval-augmented vision-language models, multimodal medical retrieval-augmented generation (MMed-RAG) systems are increasingly adopted in clinical decision support. These systems enhance medical applications by performing cross-modal retrieval to integrate relevant visual and textual evidence for tasks, e.g., report generation and disease diagnosis. However, their complex architecture also introduces underexplored adversarial vulnerabilities, particularly via visual input perturbations. In this paper, we propose Medusa, a novel framework for crafting cross-modal transferable adversarial attacks on MMed-RAG systems under a black-box setting. Specifically, Medusa formulates the attack as a perturbation optimization problem, leveraging a multi-positive InfoNCE loss (MPIL) to align adversarial visual embeddings with medically plausible but malicious textual targets, thereby hijacking the retrieval process. To enhance transferability, we adopt a surrogate model ensemble and design a dual-loop optimization strategy augmented with invariant risk minimization (IRM). Extensive experiments on two real-world medical tasks, including medical report generation and disease diagnosis, demonstrate that Medusa achieves over 90% average attack success rate across various generation models and retrievers under appropriate parameter configuration, while remaining robust against four mainstream defenses, outperforming state-of-the-art baselines. Our results reveal critical vulnerabilities in the MMed-RAG systems and highlight the necessity of robustness benchmarking in safety-critical medical applications. The code and data are available at https://anonymous.4open.science/r/MMed-RAG-Attack-F05A.","authors":["Yingjia Shang","Yi Liu","Huimin Wang","Furong Li","Wenfang Sun","Wu Chengyu","Yefeng Zheng"],"pdf_url":"","comment":"Accepted at KDD 2026 First Cycle (full version). Authors marked with * contributed equally. Yi Liu is the lead author"},{"id":"http://arxiv.org/abs/2511.19256v1","updated":"2025-11-24T16:09:55Z","published":"2025-11-24T16:09:55Z","title":"SimDiff: Simpler Yet Better Diffusion Model for Time Series Point Forecasting","summary":"Diffusion models have recently shown promise in time series forecasting, particularly for probabilistic predictions. However, they often fail to achieve state-of-the-art point estimation performance compared to regression-based methods. This limitation stems from difficulties in providing sufficient contextual bias to track distribution shifts and in balancing output diversity with the stability and precision required for point forecasts. Existing diffusion-based approaches mainly focus on full-distribution modeling under probabilistic frameworks, often with likelihood maximization objectives, while paying little attention to dedicated strategies for high-accuracy point estimation. Moreover, other existing point prediction diffusion methods frequently rely on pre-trained or jointly trained mature models for contextual bias, sacrificing the generative flexibility of diffusion models.\n  To address these challenges, we propose SimDiff, a single-stage, end-to-end framework. SimDiff employs a single unified Transformer network carefully tailored to serve as both denoiser and predictor, eliminating the need for external pre-trained or jointly trained regressors. It achieves state-of-the-art point estimation performance by leveraging intrinsic output diversity and improving mean squared error accuracy through multiple inference ensembling. Key innovations, including normalization independence and the median-of-means estimator, further enhance adaptability and stability. Extensive experiments demonstrate that SimDiff significantly outperforms existing methods in time series point forecasting.","authors":["Hang Ding","Xue Wang","Tian Zhou","Tao Yao"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.19254v1","updated":"2025-11-24T16:05:40Z","published":"2025-11-24T16:05:40Z","title":"Adversarial Patch Attacks on Vision-Based Cargo Occupancy Estimation via Differentiable 3D Simulation","summary":"Computer vision systems are increasingly adopted in modern logistics operations, including the estimation of trailer occupancy for planning, routing, and billing. Although effective, such systems may be vulnerable to physical adversarial attacks, particularly adversarial patches that can be printed and placed on interior surfaces. In this work, we study the feasibility of such attacks on a convolutional cargo-occupancy classifier using fully simulated 3D environments. Using Mitsuba 3 for differentiable rendering, we optimize patch textures across variations in geometry, lighting, and viewpoint, and compare their effectiveness to a 2D compositing baseline. Our experiments demonstrate that 3D-optimized patches achieve high attack success rates, especially in a denial-of-service scenario (empty to full), where success reaches 84.94 percent. Concealment attacks (full to empty) prove more challenging but still reach 30.32 percent. We analyze the factors influencing attack success, discuss implications for the security of automated logistics pipelines, and highlight directions for strengthening physical robustness. To our knowledge, this is the first study to investigate adversarial patch attacks for cargo-occupancy estimation in physically realistic, fully simulated 3D scenes.","authors":["Mohamed Rissal Hedna","Sesugh Samuel Nder"],"pdf_url":"","comment":"9 pages, 5 figures, 1 algorithm"},{"id":"http://arxiv.org/abs/2511.19253v1","updated":"2025-11-24T16:05:37Z","published":"2025-11-24T16:05:37Z","title":"MAESTRO: Multi-Agent Environment Shaping through Task and Reward Optimization","summary":"Cooperative Multi-Agent Reinforcement Learning (MARL) faces two major design bottlenecks: crafting dense reward functions and constructing curricula that avoid local optima in high-dimensional, non-stationary environments. Existing approaches rely on fixed heuristics or use Large Language Models (LLMs) directly in the control loop, which is costly and unsuitable for real-time systems. We propose MAESTRO (Multi-Agent Environment Shaping through Task and Reward Optimization), a framework that moves the LLM outside the execution loop and uses it as an offline training architect. MAESTRO introduces two generative components: (i) a semantic curriculum generator that creates diverse, performance-driven traffic scenarios, and (ii) an automated reward synthesizer that produces executable Python reward functions adapted to evolving curriculum difficulty. These components guide a standard MARL backbone (MADDPG) without increasing inference cost at deployment. We evaluate MAESTRO on large-scale traffic signal control (Hangzhou, 16 intersections) and conduct controlled ablations. Results show that combining LLM-generated curricula with LLM-generated reward shaping yields improved performance and stability. Across four seeds, the full system achieves +4.0% higher mean return (163.26 vs. 156.93) and 2.2% better risk-adjusted performance (Sharpe 1.53 vs. 0.70) over a strong curriculum baseline. These findings highlight LLMs as effective high-level designers for cooperative MARL training.","authors":["Boyuan Wu"],"pdf_url":"","comment":"Preprint. 16 pages, 6 figures. Preliminary version; extended experiments and analysis forthcoming"},{"id":"http://arxiv.org/abs/2511.13646v3","updated":"2025-11-24T15:55:51Z","published":"2025-11-17T17:58:18Z","title":"Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?","summary":"Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that LIVE-SWE-AGENT can achieve an impressive solve rate of 77.4% without test-time scaling, outperforming all existing software agents, including the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%.","authors":["Chunqiu Steven Xia","Zhe Wang","Yan Yang","Yuxiang Wei","Lingming Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19246v1","updated":"2025-11-24T15:55:44Z","published":"2025-11-24T15:55:44Z","title":"Neural Architecture Search for Quantum Autoencoders","summary":"In recent years, machine learning and deep learning have driven advances in domains such as image classification, speech recognition, and anomaly detection by leveraging multi-layer neural networks to model complex data. Simultaneously, quantum computing (QC) promises to address classically intractable problems via quantum parallelism, motivating research in quantum machine learning (QML). Among QML techniques, quantum autoencoders show promise for compressing high-dimensional quantum and classical data. However, designing effective quantum circuit architectures for quantum autoencoders remains challenging due to the complexity of selecting gates, arranging circuit layers, and tuning parameters.\n  This paper proposes a neural architecture search (NAS) framework that automates the design of quantum autoencoders using a genetic algorithm (GA). By systematically evolving variational quantum circuit (VQC) configurations, our method seeks to identify high-performing hybrid quantum-classical autoencoders for data reconstruction without becoming trapped in local minima. We demonstrate effectiveness on image datasets, highlighting the potential of quantum autoencoders for efficient feature extraction within a noise-prone, near-term quantum era. Our approach lays a foundation for broader application of genetic algorithms to quantum architecture search, aiming for a robust, automated method that can adapt to varied data and hardware constraints.","authors":["Hibah Agha","Samuel Yen-Chi Chen","Huan-Hsin Tseng","Shinjae Yoo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19241v1","updated":"2025-11-24T15:52:17Z","published":"2025-11-24T15:52:17Z","title":"Local Entropy Search over Descent Sequences for Bayesian Optimization","summary":"Searching large and complex design spaces for a global optimum can be infeasible and unnecessary. A practical alternative is to iteratively refine the neighborhood of an initial design using local optimization methods such as gradient descent. We propose local entropy search (LES), a Bayesian optimization paradigm that explicitly targets the solutions reachable by the descent sequences of iterative optimizers. The algorithm propagates the posterior belief over the objective through the optimizer, resulting in a probability distribution over descent sequences. It then selects the next evaluation by maximizing mutual information with that distribution, using a combination of analytic entropy calculations and Monte-Carlo sampling of descent sequences. Empirical results on high-complexity synthetic objectives and benchmark problems show that LES achieves strong sample efficiency compared to existing local and global Bayesian optimization methods.","authors":["David Stenger","Armin Lindicke","Alexander von Rohr","Sebastian Trimpe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19236v1","updated":"2025-11-24T15:48:59Z","published":"2025-11-24T15:48:59Z","title":"SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control","summary":"Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.","authors":["Yuxuan Wang","Haobin Jiang","Shiqing Yao","Ziluo Ding","Zongqing Lu"],"pdf_url":"","comment":"23 pages, 8 figures, 11 tables"},{"id":"http://arxiv.org/abs/2506.13292v2","updated":"2025-11-24T15:46:09Z","published":"2025-06-16T09:33:37Z","title":"Automatic Multi-View X-Ray/CT Registration Using Bone Substructure Contours","summary":"Purpose: Accurate intraoperative X-ray/CT registration is essential for surgical navigation in orthopedic procedures. However, existing methods struggle with consistently achieving sub-millimeter accuracy, robustness under broad initial pose estimates or need manual key-point annotations. This work aims to address these challenges by proposing a novel multi-view X-ray/CT registration method for intraoperative bone registration. Methods: The proposed registration method consists of a multi-view, contour-based iterative closest point (ICP) optimization. Unlike previous methods, which attempt to match bone contours across the entire silhouette in both imaging modalities, we focus on matching specific subcategories of contours corresponding to bone substructures. This leads to reduced ambiguity in the ICP matches, resulting in a more robust and accurate registration solution. This approach requires only two X-ray images and operates fully automatically. Additionally, we contribute a dataset of 5 cadaveric specimens, including real X-ray images, X-ray image poses and the corresponding CT scans. Results: The proposed registration method is evaluated on real X-ray images using mean reprojection error (mRPD). The method consistently achieves sub-millimeter accuracy with a mRPD 0.67mm compared to 5.35mm by a commercial solution requiring manual intervention. Furthermore, the method offers improved practical applicability, being fully automatic. Conclusion: Our method offers a practical, accurate, and efficient solution for multi-view X-ray/CT registration in orthopedic surgeries, which can be easily combined with tracking systems. By improving registration accuracy and minimizing manual intervention, it enhances intraoperative navigation, contributing to more accurate and effective surgical outcomes in computer-assisted surgery (CAS).","authors":["Roman Flepp","Leon Nissen","Bastian Sigrist","Arend Nieuwland","Nicola Cavalcanti","Philipp Fürnstahl","Thomas Dreher","Lilian Calvet"],"pdf_url":"","comment":"This paper was accepted to IPCAI 2025. The Project Webpage is: https://rflepp.github.io/BoneSubstructureContours2D3DRegistration/"},{"id":"http://arxiv.org/abs/2511.19232v1","updated":"2025-11-24T15:43:56Z","published":"2025-11-24T15:43:56Z","title":"In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations","summary":"How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.","authors":["Christos-Nikolaos Zacharopoulos","Revekka Kyriakoglou"],"pdf_url":"","comment":"Accepted at AICS2025"},{"id":"http://arxiv.org/abs/2511.19229v1","updated":"2025-11-24T15:42:23Z","published":"2025-11-24T15:42:23Z","title":"Learning Plug-and-play Memory for Guiding Video Diffusion Models","summary":"Diffusion Transformer(DiT) based video generation models have recently achieved impressive visual quality and temporal coherence, but they still frequently violate basic physical laws and commonsense dynamics, revealing a lack of explicit world knowledge. In this work, we explore how to equip them with a plug-and-play memory that injects useful world knowledge. Motivated by in-context memory in Transformer-based LLMs, we conduct empirical studies to show that DiT can be steered via interventions on its hidden states, and simple low-pass and high-pass filters in the embedding space naturally disentangle low-level appearance and high-level physical/semantic cues, enabling targeted guidance. Building on these observations, we propose a learnable memory encoder DiT-Mem, composed of stacked 3D CNNs, low-/high-pass filters, and self-attention layers. The encoder maps reference videos into a compact set of memory tokens, which are concatenated as the memory within the DiT self-attention layers. During training, we keep the diffusion backbone frozen, and only optimize the memory encoder. It yields a rather efficient training process on few training parameters (150M) and 10K data samples, and enables plug-and-play usage at inference time. Extensive experiments on state-of-the-art models demonstrate the effectiveness of our method in improving physical rule following and video fidelity. Our code and data are publicly released here: https://thrcle421.github.io/DiT-Mem-Web/.","authors":["Selena Song","Ziming Xu","Zijun Zhang","Kun Zhou","Jiaxian Guo","Lianhui Qin","Biwei Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19220v1","updated":"2025-11-24T15:26:58Z","published":"2025-11-24T15:26:58Z","title":"Are Large Vision Language Models Truly Grounded in Medical Images? Evidence from Italian Clinical Visual Question Answering","summary":"Large vision language models (VLMs) have achieved impressive performance on medical visual question answering benchmarks, yet their reliance on visual information remains unclear. We investigate whether frontier VLMs demonstrate genuine visual grounding when answering Italian medical questions by testing four state-of-the-art models: Claude Sonnet 4.5, GPT-4o, GPT-5-mini, and Gemini 2.0 flash exp. Using 60 questions from the EuropeMedQA Italian dataset that explicitly require image interpretation, we substitute correct medical images with blank placeholders to test whether models truly integrate visual and textual information. Our results reveal striking variability in visual dependency: GPT-4o shows the strongest visual grounding with a 27.9pp accuracy drop (83.2% [74.6%, 91.7%] to 55.3% [44.1%, 66.6%]), while GPT-5-mini, Gemini, and Claude maintain high accuracy with modest drops of 8.5pp, 2.4pp, and 5.6pp respectively. Analysis of model-generated reasoning reveals confident explanations for fabricated visual interpretations across all models, suggesting varying degrees of reliance on textual shortcuts versus genuine visual analysis. These findings highlight critical differences in model robustness and the need for rigorous evaluation before clinical deployment.","authors":["Federico Felizzi","Olivia Riccomi","Michele Ferramola","Francesco Andrea Causio","Manuel Del Medico","Vittorio De Vita","Lorenzo De Mori","Alessandra Piscitelli Pietro Eric Risuleo","Bianca Destro Castaniti","Antonio Cristiano Alessia Longo","Luigi De Angelis","Mariapia Vassalli","Marcello Di Pumpo"],"pdf_url":"","comment":"Accepted at the Workshop on Multimodal Representation Learning for Healthcare (MMRL4H), EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.19218v1","updated":"2025-11-24T15:23:41Z","published":"2025-11-24T15:23:41Z","title":"Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization","summary":"Large Language Models (LLMs) have developed rapidly in web services, delivering unprecedented capabilities while amplifying societal risks. Existing works tend to focus on either isolated jailbreak attacks or static defenses, neglecting the dynamic interplay between evolving threats and safeguards in real-world web contexts. To mitigate these challenges, we propose ACE-Safety (Adversarial Co-Evolution for LLM Safety), a novel framework that jointly optimize attack and defense models by seamlessly integrating two key innovative procedures: (1) Group-aware Strategy-guided Monte Carlo Tree Search (GS-MCTS), which efficiently explores jailbreak strategies to uncover vulnerabilities and generate diverse adversarial samples; (2) Adversarial Curriculum Tree-aware Group Policy Optimization (AC-TGPO), which jointly trains attack and defense LLMs with challenging samples via curriculum reinforcement learning, enabling robust mutual improvement. Evaluations across multiple benchmarks demonstrate that our method outperforms existing attack and defense approaches, and provides a feasible pathway for developing LLMs that can sustainably support responsible AI ecosystems.","authors":["Xurui Li","Kaisong Song","Rui Zhu","Pin-Yu Chen","Haixu Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.13223v3","updated":"2025-11-24T15:19:30Z","published":"2025-03-17T14:36:08Z","title":"Distributionally Robust Free Energy Principle for Decision-Making","summary":"Despite their groundbreaking performance, autonomous agents can misbehave when training and environmental conditions become inconsistent, with minor mismatches leading to undesirable behaviors or even catastrophic failures. Robustness towards these training-environment ambiguities is a core requirement for intelligent agents and its fulfillment is a long-standing challenge towards their real-world deployments. Here, we introduce a Distributionally Robust Free Energy model (DR-FREE) that instills this core property by design. Combining a robust extension of the free energy principle with a resolution engine, DR-FREE wires robustness into the agent decision-making mechanisms. Across benchmark experiments, DR-FREE enables the agents to complete the task even when, in contrast, state-of-the-art models fail. This milestone may inspire both deployments in multi-agent settings and, at a perhaps deeper level, the quest for an explanation of how natural agents -- with little or no training -- survive in capricious environments.","authors":["Allahkaram Shafiei","Hozefa Jesawada","Karl Friston","Giovanni Russo"],"pdf_url":"","comment":"Contains main text and supplementary information. Supplementary movie is at the paper repository"},{"id":"http://arxiv.org/abs/2511.19199v1","updated":"2025-11-24T15:09:07Z","published":"2025-11-24T15:09:07Z","title":"CLASH: A Benchmark for Cross-Modal Contradiction Detection","summary":"Contradictory multimodal inputs are common in real-world settings, yet existing benchmarks typically assume input consistency and fail to evaluate cross-modal contradiction detection - a fundamental capability for preventing hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark for multimodal contradiction detection, featuring COCO images paired with contradictory captions containing controlled object-level or attribute-level contradictions. The samples include targeted questions evaluated in both multiple-choice and open-ended formats. The benchmark provides an extensive fine-tuning set filtered through automated quality checks, alongside a smaller human-verified diagnostic set. Our analysis of state-of-the-art models reveals substantial limitations in recognizing cross-modal conflicts, exposing systematic modality biases and category-specific weaknesses. Furthermore, we empirically demonstrate that targeted fine-tuning on CLASH substantially enhances conflict detection capabilities.","authors":["Teodora Popordanoska","Jiameng Li","Matthew B. Blaschko"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2507.16356v2","updated":"2025-11-24T15:04:04Z","published":"2025-07-22T08:42:17Z","title":"Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health","summary":"Mobile health (mHealth) programs utilize automated voice messages to deliver health information, particularly targeting underserved communities, demonstrating the effectiveness of using mobile technology to disseminate crucial health information to these populations, improving health outcomes through increased awareness and behavioral change. India's Kilkari program delivers vital maternal health information via weekly voice calls to millions of mothers. However, the current random call scheduling often results in missed calls and reduced message delivery. This study presents a field trial of a collaborative bandit algorithm designed to optimize call timing by learning individual mothers' preferred call times. We deployed the algorithm with around $6500$ Kilkari participants as a pilot study, comparing its performance to the baseline random calling approach. Our results demonstrate a statistically significant improvement in call pick-up rates with the bandit algorithm, indicating its potential to enhance message delivery and impact millions of mothers across India. This research highlights the efficacy of personalized scheduling in mobile health interventions and underscores the potential of machine learning to improve maternal health outreach at scale.","authors":["Arpan Dasgupta","Mizhaan Maniyar","Awadhesh Srivastava","Sanat Kumar","Amrita Mahale","Aparna Hegde","Arun Suggala","Karthikeyan Shanmugam","Aparna Taneja","Milind Tambe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.01632v3","updated":"2025-11-24T14:54:55Z","published":"2025-04-02T11:37:39Z","title":"Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions","summary":"The robustness of deep neural networks is a crucial factor in safety-critical applications, particularly in complex and dynamic environments (e.g., medical or driving scenarios) where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remains underexplored. This paper fills this gap by introducing novel, region-aware metrics for benchmarking the spatial robustness of segmentation models, along with an evaluation framework to assess the impact of natural localized corruptions. Furthermore, it uncovers the inherent complexity of evaluating worst-case spatial robustness using only a single localized adversarial attack. To address this, the work proposes a region-aware multi-attack adversarial analysis to systematically assess model robustness across specific image regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones, and vice versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.","authors":["Giulia Marchiori Pietrosanti","Giulio Rossolini","Alessandro Biondi","Giorgio Buttazzo"],"pdf_url":"","comment":"Accepted for publication in Pattern Recognition"},{"id":"http://arxiv.org/abs/2511.19184v1","updated":"2025-11-24T14:51:29Z","published":"2025-11-24T14:51:29Z","title":"Torsion-Space Diffusion for Protein Backbone Generation with Geometric Refinement","summary":"Designing new protein structures is fundamental to computational biology, enabling advances in therapeutic molecule discovery and enzyme engineering. Existing diffusion-based generative models typically operate in Cartesian coordinate space, where adding noise disrupts strict geometric constraints such as fixed bond lengths and angles, often producing physically invalid structures. To address this limitation, we propose a Torsion-Space Diffusion Model that generates protein backbones by denoising torsion angles, ensuring perfect local geometry by construction. A differentiable forward-kinematics module reconstructs 3D coordinates with fixed 3.8 Angstrom backbone bond lengths while a constrained post-processing refinement optimizes global compactness via Radius of Gyration (Rg) correction, without violating bond constraints. Experiments on standard PDB proteins demonstrate 100% bond-length accuracy and significantly improved structural compactness, reducing Rg error from 70% to 18.6% compared to Cartesian diffusion baselines. Overall, this hybrid torsion-diffusion plus geometric-refinement framework generates physically valid and compact protein backbones, providing a promising path toward full-atom protein generation.","authors":["Lakshaditya Singh","Adwait Shelke","Divyansh Agrawal"],"pdf_url":"","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2510.01047v2","updated":"2025-11-24T14:42:41Z","published":"2025-10-01T15:51:10Z","title":"In-Situ Tweedie Discrete Diffusion Models","summary":"While diffusion models excel at generating continuous data such as images, adapting them to discrete tasks has relied on indirect approaches that either operate in continuous embedding spaces or use token masking mechanisms, both of which deviate from modeling the true discrete data distribution that can be theoretically guaranteed by Tweedie's formula. We propose in-situ Tweedie Discrete Diffusion (TDD), a framework that performs diffusion guaranteed by Tweedie's formula directly within the discrete one-hot space, hence \"in-situ.\" Unlike prior methods that diffuse continuous embeddings or mask tokens, TDD directly corrupts one-hot vectors with Gaussian noise and performs iterative denoising through a timestep-conditioned cross-entropy objective rather than mean-squared-error reconstruction. At each denoising step, the model predicts class probabilities, applies argmax to obtain discrete predictions, converts them to one-hot vectors, and feeds them into the next iteration with progressively reduced noise. This process naturally unifies discriminative classification and generative modeling under a single framework. Experiments demonstrate that TDD achieves strong performance on both image classification and text generation tasks, with extensive ablation studies confirming the effectiveness of each design component. Our work establishes a principled approach to discrete diffusion that preserves the core characteristics of diffusion models while operating natively in discrete space.","authors":["Xiao Li","Jiaqi Zhang","Shuxiang Zhang","Tianshui Chen","Liang Lin","Guangrun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19175v1","updated":"2025-11-24T14:36:11Z","published":"2025-11-24T14:36:11Z","title":"LLM-Based Agentic Negotiation for 6G: Addressing Uncertainty Neglect and Tail-Event Risk","summary":"A critical barrier to the trustworthiness of sixth-generation (6G) agentic autonomous networks is the uncertainty neglect bias; a cognitive tendency for large language model (LLM)-powered agents to make high-stakes decisions based on simple averages while ignoring the tail risk of extreme events. This paper proposes an unbiased, risk-aware framework for agentic negotiation, designed to ensure robust resource allocation in 6G network slicing. Specifically, agents leverage Digital Twins (DTs) to predict full latency distributions, which are then evaluated using a formal framework from extreme value theory, namely, Conditional Value-at-Risk (CVaR). This approach fundamentally shifts the agent's objective from reasoning over the mean to reasoning over the tail, thereby building a statistically-grounded buffer against worst-case outcomes. Furthermore, our framework ensures full uncertainty awareness by requiring agents to quantify epistemic uncertainty -- confidence in their own DTs predictions -- and propagate this meta-verification to make robust decisions, preventing them from acting on unreliable data. We validate this framework in a 6G inter-slice negotiation use-case between an eMBB and a URLLC agent. The results demonstrate the profound failure of the biased, mean-based baseline, which consistently fails its SLAs with a 25\\% rate. Our unbiased, CVaR-aware agent successfully mitigates this bias, eliminating SLA violations and reducing the URLLC and eMBB p99.999 latencies by around 11\\%. We show this reliability comes at the rational and quantifiable cost of slightly reduced energy savings to 17\\%, exposing the false economy of the biased approach. This work provides a concrete methodology for building the trustworthy autonomous systems required for 6G.","authors":["Hatim Chergui","Farhad Rezazadeh","Mehdi Bennis","Merouane Debbah"],"pdf_url":"","comment":"Link to open-source non-commercial code available"},{"id":"http://arxiv.org/abs/2506.07751v3","updated":"2025-11-24T14:29:20Z","published":"2025-06-09T13:34:50Z","title":"AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking","summary":"Recent studies have shown that large language models (LLMs), especially smaller ones, often lack robustness in grade school math (GSM) reasoning. In particular, they tend to experience performance drops when faced with distribution shifts, such as changes to numerical or nominal variables, or insertions of distracting clauses. A possible strategy to address this involves generating synthetic data to further \"instantiate\" reasoning problems on potential variations. In this work, we instead focuses on the strategy of \"abstracting\" reasoning problems. This not only helps counteract distribution shifts but also facilitates the connection to symbolic tools for deriving solutions. Focusing on GSM, we find that this abstraction process is better acquired through reinforcement learning (RL) than just supervised fine-tuning, which often fails to produce faithful abstractions. Our method, AbstRaL -- which promotes abstract reasoning in LLMs using RL on granular abstraction data -- significantly mitigates performance degradation on recent GSM perturbation benchmarks. Besides, improving GSM robustness via AbstRaL is shown to also implicitly benefit LLMs' capabilities on OOD mathematical and general reasoning tasks, indicating that abstract thinking broadly enables better generalizability.","authors":["Silin Gao","Antoine Bosselut","Samy Bengio","Emmanuel Abbe"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2511.19156v1","updated":"2025-11-24T14:24:08Z","published":"2025-11-24T14:24:08Z","title":"Information Physics of Intelligence: Unifying Logical Depth and Entropy under Thermodynamic Constraints","summary":"The rapid scaling of artificial intelligence models has revealed a fundamental tension between model capacity (storage) and inference efficiency (computation). While classical information theory focuses on transmission and storage limits, it lacks a unified physical framework to quantify the thermodynamic costs of generating information from compressed laws versus retrieving it from memory. In this paper, we propose a theoretical framework that treats information processing as an enabling mapping from ontological states to carrier states. We introduce a novel metric, Derivation Entropy, which quantifies the effective work required to compute a target state from a given logical depth. By analyzing the interplay between Shannon entropy (storage) and computational complexity (time/energy), we demonstrate the existence of a critical phase transition point. Below this threshold, memory retrieval is thermodynamically favorable; above it, generative computation becomes the optimal strategy. This \"Energy-Time-Space\" conservation law provides a physical explanation for the efficiency of generative models and offers a rigorous mathematical bound for designing next-generation, energy-efficient AI architectures. Our findings suggest that the minimization of Derivation Entropy is a governing principle for the evolution of both biological and artificial intelligence.","authors":["Jianfeng Xu","Zeyan Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19155v1","updated":"2025-11-24T14:23:42Z","published":"2025-11-24T14:23:42Z","title":"EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction","summary":"Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.","authors":["Xihe Qiu","Gengchen Ma","Haoyu Wang","Chen Zhan","Xiaoyu Tan","Shuo Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.16822v2","updated":"2025-11-24T14:18:04Z","published":"2025-10-19T13:18:44Z","title":"ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification","summary":"Coral reefs are rapidly declining due to anthropogenic pressures such as climate change, underscoring the urgent need for scalable, automated monitoring. We introduce ReefNet, a large public coral reef image dataset with point-label annotations mapped to the World Register of Marine Species (WoRMS). ReefNet aggregates imagery from 76 curated CoralNet sources and an additional site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level hard coral annotations with expert-verified labels. Unlike prior datasets, which are often limited by size, geography, or coarse labels and are not ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global scale to WoRMS. We propose two evaluation settings: (i) a within-source benchmark that partitions each source's images for localized evaluation, and (ii) a cross-source benchmark that withholds entire sources to test domain generalization. We analyze both supervised and zero-shot classification performance on ReefNet and find that while supervised within-source performance is promising, supervised performance drops sharply across domains, and performance is low across the board for zero-shot models, especially for rare and visually similar genera. This provides a challenging benchmark intended to catalyze advances in domain generalization and fine-grained coral classification. We will release our dataset, benchmarking code, and pretrained models to advance robust, domain-adaptive, global coral reef monitoring and conservation.","authors":["Yahia Battach","Abdulwahab Felemban","Faizan Farooq Khan","Yousef A. Radwan","Xiang Li","Fabio Marchese","Sara Beery","Burton H. Jones","Francesca Benzoni","Mohamed Elhoseiny"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19149v1","updated":"2025-11-24T14:13:57Z","published":"2025-11-24T14:13:57Z","title":"From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation","summary":"This paper introduces the retrieval-augmented framework for automatic fashion caption and hashtag generation, combining multi-garment detection, attribute reasoning, and Large Language Model (LLM) prompting. The system aims to produce visually grounded, descriptive, and stylistically interesting text for fashion imagery, overcoming the limitations of end-to-end captioners that have problems with attribute fidelity and domain generalization. The pipeline combines a YOLO-based detector for multi-garment localization, k-means clustering for dominant color extraction, and a CLIP-FAISS retrieval module for fabric and gender attribute inference based on a structured product index. These attributes, together with retrieved style examples, create a factual evidence pack that is used to guide an LLM to generate human-like captions and contextually rich hashtags. A fine-tuned BLIP model is used as a supervised baseline model for comparison. Experimental results show that the YOLO detector is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine categories of garments. The RAG-LLM pipeline generates expressive attribute-aligned captions and achieves mean attribute coverage of 0.80 with full coverage at the 50% threshold in hashtag generation, whereas BLIP gives higher lexical overlap and lower generalization. The retrieval-augmented approach exhibits better factual grounding, less hallucination, and great potential for scalable deployment in various clothing domains. These results demonstrate the use of retrieval-augmented generation as an effective and interpretable paradigm for automated and visually grounded fashion content generation.","authors":["Moazzam Umer Gondal","Hamad Ul Qudous","Daniya Siddiqui","Asma Ahmad Farhan"],"pdf_url":"","comment":"Submitted to Expert Systems with Applications"},{"id":"http://arxiv.org/abs/2505.07078v4","updated":"2025-11-24T14:03:22Z","published":"2025-05-11T18:02:21Z","title":"Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?","summary":"Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.","authors":["Weixian Waylon Li","Hyeonjun Kim","Mihai Cucuringu","Tiejun Ma"],"pdf_url":"","comment":"Accepted to KDD 2026, Datasets & Benchmarks Track"},{"id":"http://arxiv.org/abs/2511.19124v1","updated":"2025-11-24T13:53:31Z","published":"2025-11-24T13:53:31Z","title":"Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty","summary":"Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.","authors":["Krishang Sharma"],"pdf_url":"","comment":"10 pages, 2 figures, 3 tables. Submitted to arXiv"},{"id":"http://arxiv.org/abs/2511.19120v1","updated":"2025-11-24T13:49:31Z","published":"2025-11-24T13:49:31Z","title":"On the Optimality of Discrete Object Naming: a Kinship Case Study","summary":"The structure of naming systems in natural languages hinges on a trade-off between high informativeness and low complexity. Prior work capitalizes on information theory to formalize these notions; however, these studies generally rely on two simplifications: (i) optimal listeners, and (ii) universal communicative need across languages. Here, we address these limitations by introducing an information-theoretic framework for discrete object naming systems, and we use it to prove that an optimal trade-off is achievable if and only if the listener's decoder is equivalent to the Bayesian decoder of the speaker. Adopting a referential game setup from emergent communication, and focusing on the semantic domain of kinship, we show that our notion of optimality is not only theoretically achievable but also emerges empirically in learned communication systems.","authors":["Phong Le","Mees Lindeman","Raquel G. Alhama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19115v1","updated":"2025-11-24T13:48:02Z","published":"2025-11-24T13:48:02Z","title":"AI Consciousness and Existential Risk","summary":"In AI, the existential risk denotes the hypothetical threat posed by an artificial system that would possess both the capability and the objective, either directly or indirectly, to eradicate humanity. This issue is gaining prominence in scientific debate due to recent technical advancements and increased media coverage. In parallel, AI progress has sparked speculation and studies about the potential emergence of artificial consciousness. The two questions, AI consciousness and existential risk, are sometimes conflated, as if the former entailed the latter. Here, I explain that this view stems from a common confusion between consciousness and intelligence. Yet these two properties are empirically and theoretically distinct. Arguably, while intelligence is a direct predictor of an AI system's existential threat, consciousness is not. There are, however, certain incidental scenarios in which consciousness could influence existential risk, in either direction. Consciousness could be viewed as a means towards AI alignment, thereby lowering existential risk; or, it could be a precondition for reaching certain capabilities or levels of intelligence, and thus positively related to existential risk. Recognizing these distinctions can help AI safety researchers and public policymakers focus on the most pressing issues.","authors":["Rufin VanRullen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19114v1","updated":"2025-11-24T13:46:38Z","published":"2025-11-24T13:46:38Z","title":"Physics-informed Neural Operator Learning for Nonlinear Grad-Shafranov Equation","summary":"As artificial intelligence emerges as a transformative enabler for fusion energy commercialization, fast and accurate solvers become increasingly critical. In magnetic confinement nuclear fusion, rapid and accurate solution of the Grad-Shafranov equation (GSE) is essential for real-time plasma control and analysis. Traditional numerical solvers achieve high precision but are computationally prohibitive, while data-driven surrogates infer quickly but fail to enforce physical laws and generalize poorly beyond training distributions. To address this challenge, we present a Physics-Informed Neural Operator (PINO) that directly learns the GSE solution operator, mapping shape parameters of last closed flux surface to equilibrium solutions for realistic nonlinear current profiles. Comprehensive benchmarking of five neural architectures identifies the novel Transformer-KAN (Kolmogorov-Arnold Network) Neural Operator (TKNO) as achieving highest accuracy (0.25% mean L2 relative error) under supervised training (only data-driven). However, all data-driven models exhibit large physics residuals, indicating poor physical consistency. Our unsupervised training can reduce the residuals by nearly four orders of magnitude through embedding physics-based loss terms without labeled data. Critically, semi-supervised learning--integrating sparse labeled data (100 interior points) with physics constraints--achieves optimal balance: 0.48% interpolation error and the most robust extrapolation performance (4.76% error, 8.9x degradation factor vs 39.8x for supervised models). Accelerated by TensorRT optimization, our models enable millisecond-level inference, establishing PINO as a promising pathway for next-generation fusion control systems.","authors":["Siqi Ding","Zitong Zhang","Guoyang Shi","Xingyu Li","Xiang Gu","Yanan Xu","Huasheng Xie","Hanyue Zhao","Yuejiang Shi","Tianyuan Liu"],"pdf_url":"","comment":"42 pages, 17 figures, 8 tables,"},{"id":"http://arxiv.org/abs/2505.18670v3","updated":"2025-11-24T13:44:50Z","published":"2025-05-24T12:17:47Z","title":"MoveGPT: Scaling Mobility Foundation Models with Spatially-Aware Mixture of Experts","summary":"The success of foundation models in language has inspired a new wave of general-purpose models for human mobility. However, existing approaches struggle to scale effectively due to two fundamental limitations: a failure to use meaningful basic units to represent movement, and an inability to capture the vast diversity of patterns found in large-scale data. In this work, we develop MoveGPT, a large-scale foundation model specifically architected to overcome these barriers. MoveGPT is built upon two key innovations: (1) a unified location encoder that maps geographically disjoint locations into a shared semantic space, enabling pre-training on a global scale; and (2) a Spatially-Aware Mixture-of-Experts Transformer that develops specialized experts to efficiently capture diverse mobility patterns. Pre-trained on billion-scale datasets, MoveGPT establishes a new state-of-the-art across a wide range of downstream tasks, achieving performance gains of up to 35% on average. It also demonstrates strong generalization capabilities to unseen cities. Crucially, our work provides empirical evidence of scaling ability in human mobility, validating a clear path toward building increasingly capable foundation models in this domain.","authors":["Chonghua Han","Yuan Yuan","Jingtao Ding","Jie Feng","Fanjin Meng","Yong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19107v1","updated":"2025-11-24T13:42:43Z","published":"2025-11-24T13:42:43Z","title":"The Core in Max-Loss Non-Centroid Clustering Can Be Empty","summary":"We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\\geq 3$ there exist metric instances with $n\\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $α$-core for any $α<2^{\\frac{1}{5}}\\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.","authors":["Robert Bredereck","Eva Deltl","Leon Kellerhals","Jannik Peters"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19100v1","updated":"2025-11-24T13:36:45Z","published":"2025-11-24T13:36:45Z","title":"Extracting Robust Register Automata from Neural Networks over Data Sequences","summary":"Automata extraction is a method for synthesising interpretable surrogates for black-box neural models that can be analysed symbolically. Existing techniques assume a finite input alphabet, and thus are not directly applicable to data sequences drawn from continuous domains. We address this challenge with deterministic register automata (DRAs), which extend finite automata with registers that store and compare numeric values. Our main contribution is a framework for robust DRA extraction from black-box models: we develop a polynomial-time robustness checker for DRAs with a fixed number of registers, and combine it with passive and active automata learning algorithms. This combination yields surrogate DRAs with statistical robustness and equivalence guarantees. As a key application, we use the extracted automata to assess the robustness of neural networks: for a given sequence and distance metric, the DRA either certifies local robustness or produces a concrete counterexample. Experiments on recurrent neural networks and transformer architectures show that our framework reliably learns accurate automata and enables principled robustness evaluation. Overall, our results demonstrate that robust DRA extraction effectively bridges neural network interpretability and formal reasoning without requiring white-box access to the underlying network.","authors":["Chih-Duo Hong","Hongjian Jiang","Anthony W. Lin","Oliver Markgraf","Julian Parsert","Tony Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19087v1","updated":"2025-11-24T13:27:41Z","published":"2025-11-24T13:27:41Z","title":"EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching","summary":"Flow-based generative models synthesize data by integrating a learned velocity field from a reference distribution to the target data distribution. Prior work has focused on endpoint metrics (e.g., fidelity, likelihood, perceptual quality) while overlooking a deeper question: what do the sampling trajectories reveal? Motivated by classical mechanics, we introduce kinetic path energy (KPE), a simple yet powerful diagnostic that quantifies the total kinetic effort along each generation path of ODE-based samplers. Through comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that semantically richer samples require greater kinetic effort, and ({ii}) higher KPE inversely correlates with data density, with informative samples residing in sparse, low-density regions. Together, these findings reveal that semantically informative samples naturally reside on the sparse frontier of the data distribution, demanding greater generative effort. Our results suggest that trajectory-level analysis offers a physics-inspired and interpretable framework for understanding generation difficulty and sample characteristics.","authors":["Ziyun Li","Ben Dai","Huancheng Hu","Henrik Boström","Soon Hoe Lim"],"pdf_url":"","comment":"EurIPS 2025 Workshop on Principles of Generative Modeling (PriGM)"},{"id":"http://arxiv.org/abs/2511.19078v1","updated":"2025-11-24T13:18:21Z","published":"2025-11-24T13:18:21Z","title":"GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning","summary":"Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.","authors":["Yutong Li","Yitian Zhou","Xudong Wang"," GuoChen","Caiyan Qin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.10510v2","updated":"2025-11-24T13:08:12Z","published":"2025-07-14T17:34:49Z","title":"Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI","summary":"AI Video Chat emerges as a new paradigm for Real-time Communication (RTC), where one peer is not a human, but a Multimodal Large Language Model (MLLM). This makes interaction between humans and AI more intuitive, as if chatting face-to-face with a real person. However, this poses significant challenges to latency, because the MLLM inference takes up most of the response time, leaving very little time for video streaming. Due to network uncertainty, transmission latency becomes a critical bottleneck preventing AI from being like a real person. To address this, we call for AI-oriented RTC research, exploring the network requirement shift from \"humans watching video\" to \"AI understanding video\". We begin by recognizing the main differences between AI Video Chat and traditional RTC. Then, through prototype measurements, we identify that ultra-low bitrate is a key factor for low latency. To reduce bitrate dramatically while maintaining MLLM accuracy, we propose Context-Aware Video Streaming that recognizes the importance of each video region for chat and allocates bitrate almost exclusively to chat-important regions. To evaluate the impact of video streaming quality on MLLM accuracy, we build the first benchmark, named Degraded Video Understanding Benchmark (DeViBench). Finally, we discuss some open questions and ongoing solutions for AI Video Chat. DeViBench is open-sourced at: https://github.com/pku-netvideo/DeViBench.","authors":["Jiangkai Wu","Zhiyuan Ren","Liming Liu","Xinggong Zhang"],"pdf_url":"","comment":"9 pages, 10 figures, Proceedings of the 24th ACM Workshop on Hot Topics in Networks (HotNets 2025), College Park, Maryland, USA"},{"id":"http://arxiv.org/abs/2511.19067v1","updated":"2025-11-24T13:01:32Z","published":"2025-11-24T13:01:32Z","title":"DynaMix: Generalizable Person Re-identification via Dynamic Relabeling and Mixed Data Sampling","summary":"Generalizable person re-identification (Re-ID) aims to recognize individuals across unseen cameras and environments. While existing methods rely heavily on limited labeled multi-camera data, we propose DynaMix, a novel method that effectively combines manually labeled multi-camera and large-scale pseudo-labeled single-camera data. Unlike prior works, DynaMix dynamically adapts to the structure and noise of the training data through three core components: (1) a Relabeling Module that refines pseudo-labels of single-camera identities on-the-fly; (2) an Efficient Centroids Module that maintains robust identity representations under a large identity space; and (3) a Data Sampling Module that carefully composes mixed data mini-batches to balance learning complexity and intra-batch diversity. All components are specifically designed to operate efficiently at scale, enabling effective training on millions of images and hundreds of thousands of identities. Extensive experiments demonstrate that DynaMix consistently outperforms state-of-the-art methods in generalizable person Re-ID.","authors":["Timur Mamedov","Anton Konushin","Vadim Konushin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19066v1","updated":"2025-11-24T13:01:18Z","published":"2025-11-24T13:01:18Z","title":"Mitigating Participation Imbalance Bias in Asynchronous Federated Learning","summary":"In Asynchronous Federated Learning (AFL), the central server immediately updates the global model with each arriving client's contribution. As a result, clients perform their local training on different model versions, causing information staleness (delay). In federated environments with non-IID local data distributions, this asynchronous pattern amplifies the adverse effect of client heterogeneity (due to different data distribution, local objectives, etc.), as faster clients contribute more frequent updates, biasing the global model. We term this phenomenon heterogeneity amplification. Our work provides a theoretical analysis that maps AFL design choices to their resulting error sources when heterogeneity amplification occurs. Guided by our analysis, we propose ACE (All-Client Engagement AFL), which mitigates participation imbalance through immediate, non-buffered updates that use the latest information available from all clients. We also introduce a delay-aware variant, ACED, to balance client diversity against update staleness. Experiments on different models for different tasks across diverse heterogeneity and delay settings validate our analysis and demonstrate the robust performance of our approaches.","authors":["Xiangyu Chang","Manyi Yao","Srikanth V. Krishnamurthy","Christian R. Shelton","Anirban Chakraborty","Ananthram Swami","Samet Oymak","Amit Roy-Chowdhury"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19065v1","updated":"2025-11-24T12:59:27Z","published":"2025-11-24T12:59:27Z","title":"Understanding, Accelerating, and Improving MeanFlow Training","summary":"MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.","authors":["Jin-Young Kim","Hyojun Go","Lea Bogensperger","Julius Erbach","Nikolai Kalischek","Federico Tombari","Konrad Schindler","Dominik Narnhofer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11480v2","updated":"2025-11-24T12:53:25Z","published":"2025-11-14T16:58:04Z","title":"Inferring response times of perceptual decisions with Poisson variational autoencoders","summary":"Many properties of perceptual decision making are well-modeled by deep neural networks. However, such architectures typically treat decisions as instantaneous readouts, overlooking the temporal dynamics of the decision process. We present an image-computable model of perceptual decision making in which choices and response times arise from efficient sensory encoding and Bayesian decoding of neural spiking activity. We use a Poisson variational autoencoder to learn unsupervised representations of visual stimuli in a population of rate-coded neurons, modeled as independent homogeneous Poisson processes. A task-optimized decoder then continually infers an approximate posterior over actions conditioned on incoming spiking activity. Combining these components with an entropy-based stopping rule yields a principled and image-computable model of perceptual decisions capable of generating trial-by-trial patterns of choices and response times. Applied to MNIST digit classification, the model reproduces key empirical signatures of perceptual decision making, including stochastic variability, right-skewed response time distributions, logarithmic scaling of response times with the number of alternatives (Hick's law), and speed-accuracy trade-offs.","authors":["Hayden R. Johnson","Anastasia N. Krouglova","Hadi Vafaii","Jacob L. Yates","Pedro J. Gonçalves"],"pdf_url":"","comment":"To appear at the NeurIPS 2025 Workshop on Data on the Brain \\& Mind"},{"id":"http://arxiv.org/abs/2511.19055v1","updated":"2025-11-24T12:45:10Z","published":"2025-11-24T12:45:10Z","title":"Large Language Model-Assisted Planning of Electric Vehicle Charging Infrastructure with Real-World Case Study","summary":"The growing demand for electric vehicle (EV) charging infrastructure presents significant planning challenges, requiring efficient strategies for investment and operation to deliver cost-effective charging services. However, the potential benefits of EV charging assignment, particularly in response to varying spatial-temporal patterns of charging demand, remain under-explored in infrastructure planning. This paper proposes an integrated approach that jointly optimizes investment decisions and charging assignments while accounting for spatial-temporal demand dynamics and their interdependencies. To support efficient model development, we leverage a large language model (LLM) to assist in generating and refining the mathematical formulation from structured natural-language descriptions, significantly reducing the modeling burden. The resulting optimization model enables optimal joint decision-making for investment and operation. Additionally, we propose a distributed optimization algorithm based on the Alternating Direction Method of Multipliers (ADMM) to address computational complexity in high-dimensional scenarios, which can be executed on standard computing platforms. We validate our approach through a case study using 1.5 million real-world travel records from Chengdu, China, demonstrating a 30% reduction in total cost compared to a baseline without EV assignment.","authors":["Xinda Zheng","Canchen Jiang","Hao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19046v1","updated":"2025-11-24T12:34:38Z","published":"2025-11-24T12:34:38Z","title":"MedSAM3: Delving into Segment Anything with Medical Concepts","summary":"Medical image segmentation is fundamental for biomedical discovery. Existing methods lack generalizability and demand extensive, time-consuming manual annotation for new clinical application. Here, we propose MedSAM-3, a text promptable medical segmentation model for medical image and video segmentation. By fine-tuning the Segment Anything Model (SAM) 3 architecture on medical images paired with semantic conceptual labels, our MedSAM-3 enables medical Promptable Concept Segmentation (PCS), allowing precise targeting of anatomical structures via open-vocabulary text descriptions rather than solely geometric prompts. We further introduce the MedSAM-3 Agent, a framework that integrates Multimodal Large Language Models (MLLMs) to perform complex reasoning and iterative refinement in an agent-in-the-loop workflow. Comprehensive experiments across diverse medical imaging modalities, including X-ray, MRI, Ultrasound, CT, and video, demonstrate that our approach significantly outperforms existing specialist and foundation models. We will release our code and model at https://github.com/Joey-S-Liu/MedSAM3.","authors":["Anglin Liu","Rundong Xue","Xu R. Cao","Yifan Shen","Yi Lu","Xiang Li","Qianqian Chen","Jintai Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19035v1","updated":"2025-11-24T12:16:21Z","published":"2025-11-24T12:16:21Z","title":"CSD: Change Semantic Detection with only Semantic Change Masks for Damage Assessment in Conflict Zones","summary":"Accurately and swiftly assessing damage from conflicts is crucial for humanitarian aid and regional stability. In conflict zones, damaged zones often share similar architectural styles, with damage typically covering small areas and exhibiting blurred boundaries. These characteristics lead to limited data, annotation difficulties, and significant recognition challenges, including high intra-class similarity and ambiguous semantic changes. To address these issues, we introduce a pre-trained DINOv3 model and propose a multi-scale cross-attention difference siamese network (MC-DiSNet). The powerful visual representation capability of the DINOv3 backbone enables robust and rich feature extraction from bi-temporal remote sensing images. We also release a new Gaza-change dataset containing high-resolution satellite image pairs from 2023-2024 with pixel-level semantic change annotations. It is worth emphasizing that our annotations only include semantic pixels of changed areas. Unlike conventional semantic change detection (SCD), our approach eliminates the need for large-scale semantic annotations of bi-temporal images, instead focusing directly on the changed regions. We term this new task change semantic detection (CSD). The CSD task represents a direct extension of binary change detection (BCD). Due to the limited spatial extent of semantic regions, it presents greater challenges than traditional SCD tasks. We evaluated our method under the CSD framework on both the Gaza-Change and SECOND datasets. Experimental results demonstrate that our proposed approach effectively addresses the CSD task, and its outstanding performance paves the way for practical applications in rapid damage assessment across conflict zones.","authors":["Kai Zhenga","Zhenkai Wu","Fupeng Wei","Miaolan Zhou","Kai Lie","Haitao Guo","Lei Ding","Wei Zhang","Hang-Cheng Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19024v1","updated":"2025-11-24T11:59:55Z","published":"2025-11-24T11:59:55Z","title":"Life-IQA: Boosting Blind Image Quality Assessment through GCN-enhanced Layer Interaction and MoE-based Feature Decoupling","summary":"Blind image quality assessment (BIQA) plays a crucial role in evaluating and optimizing visual experience. Most existing BIQA approaches fuse shallow and deep features extracted from backbone networks, while overlooking the unequal contributions to quality prediction. Moreover, while various vision encoder backbones are widely adopted in BIQA, the effective quality decoding architectures remain underexplored. To address these limitations, this paper investigates the contributions of shallow and deep features to BIQA, and proposes a effective quality feature decoding framework via GCN-enhanced \\underline{l}ayer\\underline{i}nteraction and MoE-based \\underline{f}eature d\\underline{e}coupling, termed \\textbf{(Life-IQA)}. Specifically, the GCN-enhanced layer interaction module utilizes the GCN-enhanced deepest-layer features as query and the penultimate-layer features as key, value, then performs cross-attention to achieve feature interaction. Moreover, a MoE-based feature decoupling module is proposed to decouple fused representations though different experts specialized for specific distortion types or quality dimensions. Extensive experiments demonstrate that Life-IQA shows more favorable balance between accuracy and cost than a vanilla Transformer decoder and achieves state-of-the-art performance on multiple BIQA benchmarks.The code is available at: \\href{https://github.com/TANGLONG2/Life-IQA/tree/main}{\\texttt{Life-IQA}}.","authors":["Long Tang","Guoquan Zhen","Jie Hao","Jianbo Zhang","Huiyu Duan","Liang Yuan","Guangtao Zhai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19023v1","updated":"2025-11-24T11:59:31Z","published":"2025-11-24T11:59:31Z","title":"OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs","summary":"Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.","authors":["Yuting Gao","Weihao Chen","Lan Wang","Ruihan Xu","Qingpei Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06345v2","updated":"2025-11-24T11:46:50Z","published":"2025-11-09T12:01:43Z","title":"PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel Optimization","summary":"Designing high-performance kernels requires expert-level tuning and a deep understanding of hardware characteristics. Recent advances in large language models (LLMs) have enabled automated kernel generation, yet most existing systems rely solely on correctness or execution time feedback, lacking the ability to reason about low-level performance bottlenecks. In this paper, we introduce PRAGMA, a profile-guided AI kernel generation framework that integrates execution feedback and fine-grained hardware profiling into the reasoning loop. PRAGMA enables LLMs to identify performance bottlenecks, preserve historical best versions, and iteratively refine code quality. We evaluate PRAGMA on KernelBench, covering GPU and CPU backends. Results show that PRAGMA consistently outperforms baseline AIKG without profiling enabled and achieves 2.81$\\times$ and 2.30$\\times$ averaged speedups against Torch on CPU and GPU platforms, respectively.","authors":["Kelun Lei","Hailong Yang","Huaitao Zhang","Xin You","Kaige Zhang","Zhongzhi Luan","Yi Liu","Depei Qian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06852v4","updated":"2025-11-24T11:44:59Z","published":"2025-11-10T08:52:34Z","title":"Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment","summary":"Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.","authors":["Peng Zhang","Peijie Sun"],"pdf_url":"","comment":"AAAI-26-AIA"},{"id":"http://arxiv.org/abs/2511.19005v1","updated":"2025-11-24T11:32:24Z","published":"2025-11-24T11:32:24Z","title":"Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding","summary":"Spoken Language Understanding (SLU) consists of two sub-tasks: intent detection (ID) and slot filling (SF). Given its broad range of real-world applications, enhancing SLU for practical deployment is increasingly critical. Profile-based SLU addresses ambiguous user utterances by incorporating context awareness (CA), user profiles (UP), and knowledge graphs (KG) to support disambiguation, thereby advancing SLU research toward real-world applicability. However, existing SLU datasets still fall short in representing real-world scenarios. Specifically, (1) CA uses one-hot vectors for representation, which is overly idealized, and (2) models typically focuses solely on predicting intents and slot labels, neglecting the reasoning process that could enhance performance and interpretability. To overcome these limitations, we introduce VRSLU, a novel SLU dataset that integrates both Visual images and explicit Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate images reflecting users' environments and statuses, followed by human verification to ensure quality. For reasoning, GPT-4o is employed to generate explanations for predicted labels, which are then refined by human annotators to ensure accuracy and coherence. Additionally, we propose an instructional template, LR-Instruct, which first predicts labels and then generates corresponding reasoning. This two-step approach helps mitigate the influence of reasoning bias on label prediction. Experimental results confirm the effectiveness of incorporating visual information and highlight the promise of explicit reasoning in advancing SLU.","authors":["Di Wu","Liting Jiang","Ruiyu Fang"," Bianjing","Hongyan Xie","Haoxiang Su","Hao Huang","Zhongjiang He","Shuangyong Song","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18999v1","updated":"2025-11-24T11:25:30Z","published":"2025-11-24T11:25:30Z","title":"Enhancing low energy reconstruction and classification in KM3NeT/ORCA with transformers","summary":"The current KM3NeT/ORCA neutrino telescope, still under construction, has not yet reached its full potential in neutrino reconstruction capability. When training any deep learning model, no explicit information about the physics or the detector is provided, thus they remain unknown to the model. This study leverages the strengths of transformers by incorporating attention masks inspired by the physics and detector design, making the model understand both the telescope design and the neutrino physics measured on it. The study also shows the efficacy of transformers on retaining valuable information between detectors when doing fine-tuning from one configurations to another.","authors":["Iván Mozún Mateo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.18337v3","updated":"2025-11-24T11:19:05Z","published":"2025-08-25T13:07:03Z","title":"Warm Chat: Diffuse Emotion-aware Interactive Talking Head Avatar with Tree-Structured Guidance","summary":"Generative models have advanced rapidly, enabling impressive talking head generation that brings AI to life. However, most existing methods focus solely on one-way portrait animation. Even the few that support bidirectional conversational interactions lack precise emotion-adaptive capabilities, significantly limiting their practical applicability. In this paper, we propose Warm Chat, a novel emotion-aware talking head generation framework for dyadic interactions. Leveraging the dialogue generation capability of large language models (LLMs, e.g., GPT-4), our method produces temporally consistent virtual avatars with rich emotional variations that seamlessly transition between speaking and listening states. Specifically, we design a Transformer-based head mask generator that learns temporally consistent motion features in a latent mask space, capable of generating arbitrary-length, temporally consistent mask sequences to constrain head motions. Furthermore, we introduce an interactive talking tree structure to represent dialogue state transitions, where each tree node contains information such as child/parent/sibling nodes and the current character's emotional state. By performing reverse-level traversal, we extract rich historical emotional cues from the current node to guide expression synthesis. Extensive experiments demonstrate the superior performance and effectiveness of our method.","authors":["Haijie Yang","Zhenyu Zhang","Hao Tang","Jianjun Qian","Jian Yang"],"pdf_url":"","comment":"The submission is withdrawn at the request of the authors due to internal reasons within the research team"},{"id":"http://arxiv.org/abs/2511.18992v1","updated":"2025-11-24T11:18:59Z","published":"2025-11-24T11:18:59Z","title":"Classification EM-PCA for clustering and embedding","summary":"The mixture model is undoubtedly one of the greatest contributions to clustering. For continuous data, Gaussian models are often used and the Expectation-Maximization (EM) algorithm is particularly suitable for estimating parameters from which clustering is inferred. If these models are particularly popular in various domains including image clustering, they however suffer from the dimensionality and also from the slowness of convergence of the EM algorithm. However, the Classification EM (CEM) algorithm, a classifying version, offers a fast convergence solution while dimensionality reduction still remains a challenge. Thus we propose in this paper an algorithm combining simultaneously and non-sequentially the two tasks --Data embedding and Clustering-- relying on Principal Component Analysis (PCA) and CEM. We demonstrate the interest of such approach in terms of clustering and data embedding. We also establish different connections with other clustering approaches.","authors":["Zineddine Tighidet","Lazhar Labiod","Mohamed Nadif"],"pdf_url":"","comment":"Accepted at the IEEE conference on Big Data (Special Session on Machine Learning)"},{"id":"http://arxiv.org/abs/2503.04363v3","updated":"2025-11-24T11:18:03Z","published":"2025-03-06T12:06:54Z","title":"Causally Reliable Concept Bottleneck Models","summary":"Concept-based models are an emerging paradigm in deep learning that constrains the inference process to operate through human-interpretable variables, facilitating explainability and human interaction. However, these architectures, on par with popular opaque neural models, fail to account for the true causal mechanisms underlying the target phenomena represented in the data. This hampers their ability to support causal reasoning tasks, limits out-of-distribution generalization, and hinders the implementation of fairness constraints. To overcome these issues, we propose Causally reliable Concept Bottleneck Models (C$^2$BMs), a class of concept-based architectures that enforce reasoning through a bottleneck of concepts structured according to a model of the real-world causal mechanisms. We also introduce a pipeline to automatically learn this structure from observational data and unstructured background knowledge (e.g., scientific literature). Experimental evidence suggests that C$^2$BMs are more interpretable, causally reliable, and improve responsiveness to interventions w.r.t. standard opaque and concept-based models, while maintaining their accuracy.","authors":["Giovanni De Felice","Arianna Casanova Flores","Francesco De Santis","Silvia Santini","Johannes Schneider","Pietro Barbiero","Alberto Termine"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.18989v1","updated":"2025-11-24T11:08:01Z","published":"2025-11-24T11:08:01Z","title":"Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap with Vision Transformers and Zero-Shot Learning","summary":"Recent advances in deep learning have enabled significant progress in plant disease classification using leaf images. Much of the existing research in this field has relied on the PlantVillage dataset, which consists of well-centered plant images captured against uniform, uncluttered backgrounds. Although models trained on this dataset achieve high accuracy, they often fail to generalize to real-world field images, such as those submitted by farmers to plant diagnostic systems. This has created a significant gap between published studies and practical application requirements, highlighting the necessity of investigating and addressing this issue. In this study, we investigate whether attention-based architectures and zero-shot learning approaches can bridge the gap between curated academic datasets and real-world agricultural conditions in plant disease classification. We evaluate three model categories: Convolutional Neural Networks (CNNs), Vision Transformers, and Contrastive Language-Image Pre-training (CLIP)-based zero-shot models. While CNNs exhibit limited robustness under domain shift, Vision Transformers demonstrate stronger generalization by capturing global contextual features. Most notably, CLIP models classify diseases directly from natural language descriptions without any task-specific training, offering strong adaptability and interpretability. These findings highlight the potential of zero-shot learning as a practical and scalable domain adaptation strategy for plant health diagnosis in diverse field environments.","authors":["Wassim Benabbas","Mohammed Brahimi","Samir Akhrouf","Bilal Fortas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.12104v4","updated":"2025-11-24T11:06:07Z","published":"2025-01-21T12:55:04Z","title":"Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection","summary":"Visual anomaly detection is a highly challenging task, often categorized as a one-class classification and segmentation problem. Recent studies have demonstrated that the student-teacher (S-T) framework effectively addresses this challenge. However, most S-T frameworks rely solely on pre-trained teacher networks to guide student networks in learning multi-scale similar features, overlooking the potential of the student networks to enhance learning through multi-scale feature fusion. In this study, we propose a novel model named PFADSeg, which integrates a pre-trained teacher network, a denoising student network with multi-scale feature fusion, and a guided anomaly segmentation network into a unified framework. By adopting a unique teacher-encoder and student-decoder denoising mode, the model improves the student network's ability to learn from teacher network features. Furthermore, an adaptive feature fusion mechanism is introduced to train a self-supervised segmentation network that synthesizes anomaly masks autonomously, significantly increasing detection performance. Rigorous evaluations on the widely-used MVTec AD dataset demonstrate that PFADSeg exhibits excellent performance, achieving an image-level AUC of 98.9%, a pixel-level mean precision of 76.4%, and an instance-level mean precision of 78.7%.","authors":["Shixuan Song","Hao Chen","Shu Hu","Xin Wang","Jinrong Hu","Xi Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18987v1","updated":"2025-11-24T11:00:32Z","published":"2025-11-24T11:00:32Z","title":"Dynamic Mixture of Experts Against Severe Distribution Shifts","summary":"The challenge of building neural networks that can continuously learn and adapt to evolving data streams is central to the fields of continual learning (CL) and reinforcement learning (RL). This lifelong learning problem is often framed in terms of the plasticity-stability dilemma, focusing on issues like loss of plasticity and catastrophic forgetting. Unlike neural networks, biological brains maintain plasticity through capacity growth, inspiring researchers to explore similar approaches in artificial networks, such as adding capacity dynamically. Prior solutions often lack parameter efficiency or depend on explicit task indices, but Mixture-of-Experts (MoE) architectures offer a promising alternative by specializing experts for distinct distributions. This paper aims to evaluate a DynamicMoE approach for continual and reinforcement learning environments and benchmark its effectiveness against existing network expansion methods.","authors":["Donghu Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.09782v2","updated":"2025-11-24T10:55:38Z","published":"2025-06-11T14:21:38Z","title":"Q-SAM2: Accurate Quantization for Segment Anything Model 2","summary":"The Segment Anything Model 2 (SAM2) is a powerful foundation model for promptable segmentation. However, its high computational and memory costs are a major barrier to deployment on resource-constrained devices. In this paper, we present Q-SAM2, an accurate low-bit quantization method that achieves high compression and high fidelity. To address performance degradation arising from challenging weight and activation distributions during quantization, Q-SAM2 introduces two novel contributions: Variance-Reduced Calibration (VRC), an initialization method that reduces weight statistical variance by minimizing the Frobenius norm over a small calibration batch; and Learnable Statistical Clipping (LSC), a Quantization-Aware Training (QAT) method that learns momentum-stabilized clipping factors to manage outliers in weights and activations. Comprehensive experiments demonstrate that Q-SAM2 achieves highly accurate inference with substantial efficiency gains, significantly surpassing state-of-the-art general QAT schemes, particularly in the ultra-low 2-bit regime. Specifically, Q-SAM2 achieves an accuracy gain of up to 9.7 ppt in J&F on the video segmentation benchmark and 7.3 ppt in mIoU for instance segmentation over the best competing QAT model, all while achieving an 8x reduction in model size compared to the BF16 baseline.","authors":["Nicola Farronato","Florian Scheidegger","Mattia Rigotti","Cristiano Malossi","Michele Magno","Haotong Qin"],"pdf_url":"","comment":"22 pages"},{"id":"http://arxiv.org/abs/2511.18980v1","updated":"2025-11-24T10:54:19Z","published":"2025-11-24T10:54:19Z","title":"MOCLIP: A Foundation Model for Large-Scale Nanophotonic Inverse Design","summary":"Foundation models (FM) are transforming artificial intelligence by enabling generalizable, data-efficient solutions across different domains for a broad range of applications. However, the lack of large and diverse datasets limits the development of FM in nanophotonics. This work presents MOCLIP (Metasurface Optics Contrastive Learning Pretrained), a nanophotonic foundation model that integrates metasurface geometry and spectra within a shared latent space. MOCLIP employs contrastive learning to align geometry and spectral representations using an experimentally acquired dataset with a sample density comparable to ImageNet-1K. The study demonstrates MOCLIP inverse design capabilities for high-throughput zero-shot prediction at a rate of 0.2 million samples per second, enabling the design of a full 4-inch wafer populated with high-density metasurfaces in minutes. It also shows generative latent-space optimization reaching 97 percent accuracy. Finally, we introduce an optical information storage concept that uses MOCLIP to achieve a density of 0.1 Gbit per square millimeter at the resolution limit, exceeding commercial optical media by a factor of six. These results position MOCLIP as a scalable and versatile platform for next-generation photonic design and data-driven applications.","authors":["S. Rodionov","A. Burguete-Lopez","M. Makarenko","Q. Wang","F. Getman","A. Fratalocchi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.18662v2","updated":"2025-11-24T10:52:11Z","published":"2025-04-25T19:36:17Z","title":"M2R2: MultiModal Robotic Representation for Temporal Action Segmentation","summary":"Temporal action segmentation (TAS) has long been a key area of research in both robotics and computer vision. In robotics, algorithms have primarily focused on leveraging proprioceptive information to determine skill boundaries, with recent approaches in surgical robotics incorporating vision. In contrast, computer vision typically relies on exteroceptive sensors, such as cameras. Existing multimodal TAS models in robotics integrate feature fusion within the model, making it difficult to reuse learned features across different models. Meanwhile, pretrained vision-only feature extractors commonly used in computer vision struggle in scenarios with limited object visibility. In this work, we address these challenges by proposing M2R2, a multimodal feature extractor tailored for TAS, which combines information from both proprioceptive and exteroceptive sensors. We introduce a novel pretraining strategy that enables the reuse of learned features across multiple TAS models. Our method achieves state-of-the-art performance on the REASSEMBLE dataset, a challenging multimodal robotic assembly dataset, outperforming existing robotic action segmentation models by 46.6%. Additionally, we conduct an extensive ablation study to evaluate the contribution of different modalities in robotic TAS tasks.","authors":["Daniel Sliwowski","Dongheui Lee"],"pdf_url":"","comment":"8 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2511.18977v1","updated":"2025-11-24T10:47:55Z","published":"2025-11-24T10:47:55Z","title":"FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning","summary":"Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search's computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.","authors":["Xin Yuan","Siqi Li","Jiateng Wei","Chengrui Zhu","Yanming Wu","Qingpeng Li","Jiajun Lv","Xiaoke Lan","Jun Chen","Yong Liu"],"pdf_url":"","comment":"5 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.17421v2","updated":"2025-11-24T10:32:57Z","published":"2025-11-21T17:18:35Z","title":"Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers","summary":"Deep learning models are prone to learning shortcut solutions to problems using spuriously correlated yet irrelevant features of their training data. In high-risk applications such as medical image analysis, this phenomenon may prevent models from using clinically meaningful features when making predictions, potentially leading to poor robustness and harm to patients. We demonstrate that different types of shortcuts (those that are diffuse and spread throughout the image, as well as those that are localized to specific areas) manifest distinctly across network layers and can, therefore, be more effectively targeted through mitigation strategies that target the intermediate layers. We propose a novel knowledge distillation framework that leverages a teacher network fine-tuned on a small subset of task-relevant data to mitigate shortcut learning in a student network trained on a large dataset corrupted with a bias feature. Through extensive experiments on CheXpert, ISIC 2017, and SimBA datasets using various architectures (ResNet-18, AlexNet, DenseNet-121, and 3D CNNs), we demonstrate consistent improvements over traditional Empirical Risk Minimization, augmentation-based bias-mitigation, and group-based bias-mitigation approaches. In many cases, we achieve comparable performance with a baseline model trained on bias-free data, even on out-of-distribution test data. Our results demonstrate the practical applicability of our approach to real-world medical imaging scenarios where bias annotations are limited and shortcut features are difficult to identify a priori.","authors":["Christopher Boland","Sotirios Tsaftaris","Sonia Dahdouh"],"pdf_url":"","comment":"Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:020"},{"id":"http://arxiv.org/abs/2511.18966v1","updated":"2025-11-24T10:31:53Z","published":"2025-11-24T10:31:53Z","title":"LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models","summary":"The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.","authors":["Muhammad Usman Shahid","Chuadhry Mujeeb Ahmed","Rajiv Ranjan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18964v1","updated":"2025-11-24T10:30:33Z","published":"2025-11-24T10:30:33Z","title":"Synthesizing Visual Concepts as Vision-Language Programs","summary":"Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.","authors":["Antonia Wüst","Wolfgang Stammer","Hikaru Shindo","Lukas Helff","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18958v1","updated":"2025-11-24T10:19:58Z","published":"2025-11-24T10:19:58Z","title":"Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation","summary":"As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.","authors":["Qisen Chai","Yansong Wang","Junjie Huang","Tao Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18955v1","updated":"2025-11-24T10:14:09Z","published":"2025-11-24T10:14:09Z","title":"Active Inference is a Subtype of Variational Inference","summary":"Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.","authors":["Wouter W. L. Nuijten","Mykola Lukashchuk"],"pdf_url":"","comment":"Accepted to the EIML Workshop 2025 at EurIPS (non-archival)"},{"id":"http://arxiv.org/abs/2312.00326v21","updated":"2025-11-24T10:10:51Z","published":"2023-12-01T03:44:54Z","title":"Agent-OM: Leveraging LLM Agents for Ontology Matching","summary":"Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.","authors":["Zhangcheng Qiang","Weiqing Wang","Kerry Taylor"],"pdf_url":"","comment":"31 pages"},{"id":"http://arxiv.org/abs/2508.08227v2","updated":"2025-11-24T09:55:44Z","published":"2025-08-11T17:44:59Z","title":"OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution","summary":"Denoising Diffusion Probabilistic Models (DDPMs) show promising potential in one-step Real-World Image Super-Resolution (Real-ISR). Current one-step Real-ISR methods typically inject the low-quality (LQ) image latent representation at the start or end timestep of the DDPM scheduler. Recent studies have begun to note that the LQ image latent and the pre-trained noisy latent representations are intuitively closer at a mid-timestep. However, a quantitative analysis of these latent representations remains lacking. Considering these latent representations can be decomposed into signal and noise, we propose a method based on the Signal-to-Noise Ratio (SNR) to pre-compute an average optimal mid-timestep for injection. To better approximate the pre-trained noisy latent representation, we further introduce the Latent Representation Refinement (LRR) loss via a LoRA-enhanced VAE encoder. We also fine-tune the backbone of the DDPM-based generative model using LoRA to perform one-step denoising at the average optimal mid-timestep. Based on these components, we present OMGSR, a GAN-based Real-ISR framework that employs a DDPM-based generative model as the generator and a DINOv3-ConvNeXt model with multi-level discriminator heads as the discriminator. We also propose the DINOv3-ConvNeXt DISTS (Dv3CD) loss, which is enhanced for structural perception at varying resolutions. Within the OMGSR framework, we develop OMGSR-S based on SD2.1-base. An ablation study confirms that our pre-computation strategy and LRR loss significantly improve the baseline. Comparative studies demonstrate that OMGSR-S achieves state-of-the-art performance across multiple metrics. Code is available at \\hyperlink{Github}{https://github.com/wuer5/OMGSR}.","authors":["Zhiqiang Wu","Zhaomang Sun","Tong Zhou","Bingtao Fu","Ji Cong","Yitong Dong","Huaqi Zhang","Xuan Tang","Mingsong Chen","Xian Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.08641v2","updated":"2025-11-24T09:52:56Z","published":"2024-09-13T08:58:24Z","title":"Developing an Algorithm Selector for Green Configuration in Scheduling Problems","summary":"The Job Shop Scheduling Problem (JSP) is central to operations research, primarily optimizing energy efficiency due to its profound environmental and economic implications. Efficient scheduling enhances production metrics and mitigates energy consumption, thus effectively balancing productivity and sustainability objectives. Given the intricate and diverse nature of JSP instances, along with the array of algorithms developed to tackle these challenges, an intelligent algorithm selection tool becomes paramount. This paper introduces a framework designed to identify key problem features that characterize its complexity and guide the selection of suitable algorithms. Leveraging machine learning techniques, particularly XGBoost, the framework recommends optimal solvers such as GUROBI, CPLEX, and GECODE for efficient JSP scheduling. GUROBI excels with smaller instances, while GECODE demonstrates robust scalability for complex scenarios. The proposed algorithm selector achieves an accuracy of 84.51\\% in recommending the best algorithm for solving new JSP instances, highlighting its efficacy in algorithm selection. By refining feature extraction methodologies, the framework aims to broaden its applicability across diverse JSP scenarios, thereby advancing efficiency and sustainability in manufacturing logistics.","authors":["Carlos March","Christian Perez","Miguel A. Salido"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11043v2","updated":"2025-11-24T09:43:11Z","published":"2025-11-14T07:56:34Z","title":"Autonomous Vehicle Path Planning by Searching With Differentiable Simulation","summary":"Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.","authors":["Asen Nachkov","Jan-Nico Zaech","Danda Pani Paudel","Xi Wang","Luc Van Gool"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18936v1","updated":"2025-11-24T09:41:24Z","published":"2025-11-24T09:41:24Z","title":"SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression","summary":"Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.","authors":["Santhosh G S","Saurav Prakash","Balaraman Ravindran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18934v1","updated":"2025-11-24T09:39:03Z","published":"2025-11-24T09:39:03Z","title":"Skeletons Matter: Dynamic Data Augmentation for Text-to-Query","summary":"The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.","authors":["Yuchen Ji","Bo Xu","Jie Shi","Jiaqing Liang","Deqing Yang","Yu Mao","Hai Chen","Yanghua Xiao"],"pdf_url":"","comment":"Accepted at EMNLP 2025"},{"id":"http://arxiv.org/abs/2511.17443v2","updated":"2025-11-24T09:38:31Z","published":"2025-11-21T17:42:09Z","title":"GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity","summary":"Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing computational systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.","authors":["Joana Rovira Martins","Pedro Martins","Ana Boavida"],"pdf_url":"","comment":"20 pages, 16 figures"},{"id":"http://arxiv.org/abs/2511.18933v1","updated":"2025-11-24T09:38:11Z","published":"2025-11-24T09:38:11Z","title":"Defending Large Language Models Against Jailbreak Exploits with Responsible AI Considerations","summary":"Large Language Models (LLMs) remain susceptible to jailbreak exploits that bypass safety filters and induce harmful or unethical behavior. This work presents a systematic taxonomy of existing jailbreak defenses across prompt-level, model-level, and training-time interventions, followed by three proposed defense strategies. First, a Prompt-Level Defense Framework detects and neutralizes adversarial inputs through sanitization, paraphrasing, and adaptive system guarding. Second, a Logit-Based Steering Defense reinforces refusal behavior through inference-time vector steering in safety-sensitive layers. Third, a Domain-Specific Agent Defense employs the MetaGPT framework to enforce structured, role-based collaboration and domain adherence. Experiments on benchmark datasets show substantial reductions in attack success rate, achieving full mitigation under the agent-based defense. Overall, this study highlights how jailbreaks pose a significant security threat to LLMs and identifies key intervention points for prevention, while noting that defense strategies often involve trade-offs between safety, performance, and scalability. Code is available at: https://github.com/Kuro0911/CS5446-Project","authors":["Ryan Wong","Hosea David Yu Fei Ng","Dhananjai Sharma","Glenn Jun Jie Ng","Kavishvaran Srinivasan"],"pdf_url":"","comment":"20 pages including appendix; technical report; NeurIPS 2024 style"},{"id":"http://arxiv.org/abs/2511.18931v1","updated":"2025-11-24T09:37:43Z","published":"2025-11-24T09:37:43Z","title":"Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs","summary":"Modern large language models integrate web search to provide real-time answers, yet it remains unclear whether they are efficiently calibrated to use search when it is actually needed. We introduce a benchmark evaluating both the necessity and effectiveness of web access across commercial models with no access to internal states or parameters. The dataset includes a static split of 783 temporally anchored questions answerable from pre-cutoff knowledge, aimed at testing whether models invoke search based on low internal confidence, and a dynamic split of 288 post-cutoff queries designed to test whether models recognise when search is required and retrieve updated information. Web access substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5, though confidence calibration worsens. On dynamic queries, both models frequently invoke search yet remain below 70 percent accuracy due to weak query formulation. Costs per accuracy-improving call remain low, but returns diminish once initial retrieval fails. Selective invocation helps, but models become overconfident and inconsistent after search. Overall, built-in web search meaningfully improves factual accuracy and can be invoked selectively, yet models remain overconfident, skip retrieval when it is essential, and falter once initial search queries underperform. Taken together, internal web search works better as a good low-latency verification layer than a reliable analytical tool, with clear room for improvement.","authors":["Sahil Kale"],"pdf_url":"","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.18930v1","updated":"2025-11-24T09:35:10Z","published":"2025-11-24T09:35:10Z","title":"Learning Solution Operators for Partial Differential Equations via Monte Carlo-Type Approximation","summary":"The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight architecture for learning solution operators for parametric PDEs by directly approximating the kernel integral using a Monte Carlo approach. Unlike Fourier Neural Operators, MCNO makes no spectral or translation-invariance assumptions. The kernel is represented as a learnable tensor over a fixed set of randomly sampled points. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with low computational cost, providing a simple and practical alternative to spectral and graph-based neural operators.","authors":["Salah Eddine Choutri","Prajwal Chauhan","Othmane Mazhar","Saif Eddin Jabari"],"pdf_url":"","comment":"NeurIPS 2025 Workshop on Machine Learning and the Physical Sciences"},{"id":"http://arxiv.org/abs/2511.18926v1","updated":"2025-11-24T09:32:02Z","published":"2025-11-24T09:32:02Z","title":"MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship Dialogue Systems","summary":"With the rapid development of Large Language Models, dialogue systems are shifting from information tools to emotional companions, heralding the era of Emotional Companionship Dialogue Systems (ECDs) that provide personalized emotional support for users. However, the field lacks clear definitions and systematic evaluation standards for ECDs. To address this, we first propose a definition of ECDs with formal descriptions. Then, based on this theory and the design principle of \"Ability Layer-Task Layer (three level)-Data Layer-Method Layer\", we design and implement the first ECD evaluation benchmark - MoodBench 1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that MoodBench 1.0 has excellent discriminant validity and can effectively quantify the differences in emotional companionship abilities among models. Furthermore, the results reveal current models' shortcomings in deep emotional companionship, guiding future technological optimization and significantly aiding developers in enhancing ECDs' user experience.","authors":["Haifeng Jing","Yujie Hou","Junfei Liu","Rui Xie","alan Xu","Jinlong Ma","Qichun Deng"],"pdf_url":"","comment":"26 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.18924v1","updated":"2025-11-24T09:31:52Z","published":"2025-11-24T09:31:52Z","title":"LLM-Driven Kernel Evolution: Automating Driver Updates in Linux","summary":"Linux kernel evolution breaks drivers through API/ABI changes, semantic shifts, and security-hardening updates. We introduce DRIVEBENCH, an executable corpus of kernel$\\rightarrow$driver co-evolution cases, and AUTODRIVER, a closed-loop, LLM-driven system for automating driver maintenance. The system integrates prompt engineering, multi-agent collaboration, static analysis, and iterative validation to ensure that generated patches are not only syntactically correct but also functionally and semantically consistent with kernel conventions. The corpus spans v5.10-v6.10 with 235 validated cases drawn from 612 candidates. In evaluation across 55 cases, AUTODRIVER achieves 56.4% compilation success; QEMU-based boot verification indicates that compiled patches preserve driver initialization in most instances. By releasing DRIVEBENCH and tooling, we enable reproducible research and a practical route to continuous, safe co-evolution of drivers with the Linux kernel.","authors":["Arina Kharlamova","Jiawen Liu","Tianyi Zhang","Xinrui Yang","Humaid Alqasimi","Youcheng Sun","Chun Jason Xue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18919v1","updated":"2025-11-24T09:29:30Z","published":"2025-11-24T09:29:30Z","title":"Learning What to Trust: Bayesian Prior-Guided Optimization for Visual Generation","summary":"Group Relative Policy Optimization (GRPO) has emerged as an effective and lightweight framework for post-training visual generative models. However, its performance is fundamentally limited by the ambiguity of textual visual correspondence: a single prompt may validly describe diverse visual outputs, and a single image or video may support multiple equally correct interpretations. This many to many relationship leads reward models to generate uncertain and weakly discriminative signals, causing GRPO to underutilize reliable feedback and overfit noisy ones. We introduce Bayesian Prior-Guided Optimization (BPGO), a novel extension of GRPO that explicitly models reward uncertainty through a semantic prior anchor. BPGO adaptively modulates optimization trust at two levels: inter-group Bayesian trust allocation emphasizes updates from groups consistent with the prior while down-weighting ambiguous ones, and intra-group prior-anchored renormalization sharpens sample distinctions by expanding confident deviations and compressing uncertain scores. Across both image and video generation tasks, BPGO delivers consistently stronger semantic alignment, enhanced perceptual fidelity, and faster convergence than standard GRPO and recent variants.","authors":["Ruiying Liu","Yuanzhi Liang","Haibin Huang","Tianshu Yu","Chi Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16088v2","updated":"2025-11-24T09:21:12Z","published":"2025-11-20T06:26:01Z","title":"Future-Back Threat Modeling: A Foresight-Driven Security Framework","summary":"Traditional threat modeling remains reactive-focused on known TTPs and past incident data, while threat prediction and forecasting frameworks are often disconnected from operational or architectural artifacts. This creates a fundamental weakness: the most serious cyber threats often do not arise from what is known, but from what is assumed, overlooked, or not yet conceived, and frequently originate from the future, such as artificial intelligence, information warfare, and supply chain attacks, where adversaries continuously develop new exploits that can bypass defenses built on current knowledge. To address this mental gap, this paper introduces the theory and methodology of Future-Back Threat Modeling (FBTM). This predictive approach begins with envisioned future threat states and works backward to identify assumptions, gaps, blind spots, and vulnerabilities in the current defense architecture, providing a clearer and more accurate view of impending threats so that we can anticipate their emergence and shape the future we want through actions taken now. The proposed methodology further aims to reveal known unknowns and unknown unknowns, including tactics, techniques, and procedures that are emerging, anticipated, and plausible. This enhances the predictability of adversary behavior, particularly under future uncertainty, helping security leaders make informed decisions today that shape more resilient security postures for the future.","authors":["Vu Van Than"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18903v1","updated":"2025-11-24T09:03:49Z","published":"2025-11-24T09:03:49Z","title":"How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining","summary":"Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.","authors":["Kairong Luo","Zhenbo Sun","Haodong Wen","Xinyu Shi","Jiarui Cui","Chenyi Dang","Kaifeng Lyu","Wenguang Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18902v1","updated":"2025-11-24T08:59:54Z","published":"2025-11-24T08:59:54Z","title":"VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL","summary":"Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \\emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \\textbf{VADE}, a \\textbf{V}ariance-\\textbf{A}ware \\textbf{D}ynamic sampling framework via online sample-level difficulty \\textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.","authors":["Zengjie Hu","Jiantao Qiu","Tianyi Bai","Haojin Yang","Binhang Yuan","Qi Jing","Conghui He","Wentao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18894v1","updated":"2025-11-24T08:51:02Z","published":"2025-11-24T08:51:02Z","title":"MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting","summary":"Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy ground-truth labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg consistently outperforms existing state-of-the-art methods.","authors":["Chenyu Mu","Guihai Chen","Xun Yang","Erkun Yang","Cheng Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13590v2","updated":"2025-11-24T08:48:39Z","published":"2025-11-17T16:52:19Z","title":"Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation","summary":"Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for text-to-SQL classification based on dimensions including core intents, statement types, syntax structures, and key actions. Using this taxonomy, we evaluate widely used public text-to-SQL datasets (e.g., Spider and Bird) and reveal limitations in their coverage and diversity. We then introduce a taxonomy-guided dataset synthesis pipeline, yielding a new dataset named SQL-Synth. This approach combines the taxonomy with Large Language Models (LLMs) to ensure the dataset reflects the breadth and complexity of real-world text-to-SQL applications. Extensive analysis and experimental results validate the effectiveness of our taxonomy, as SQL-Synth exhibits greater diversity and coverage compared to existing benchmarks. Moreover, we uncover that existing LLMs typically fall short in adequately capturing the full range of scenarios, resulting in limited performance on SQL-Synth. However, fine-tuning can substantially improve their performance in these scenarios. The proposed taxonomy has significant potential impact, as it not only enables comprehensive analysis of datasets and the performance of different LLMs, but also guides the construction of training data for LLMs.","authors":["Hao Wang","Yuanfeng Song","Xiaoming Yin","Xing Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18890v1","updated":"2025-11-24T08:46:36Z","published":"2025-11-24T08:46:36Z","title":"Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models","summary":"Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.","authors":["Yonggan Fu","Xin Dong","Shizhe Diao","Matthijs Van keirsbilck","Hanrong Ye","Wonmin Byeon","Yashaswi Karnati","Lucas Liebenwein","Hannah Zhang","Nikolaus Binder","Maksim Khadkevich","Alexander Keller","Jan Kautz","Yingyan Celine Lin","Pavlo Molchanov"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.18889v1","updated":"2025-11-24T08:44:29Z","published":"2025-11-24T08:44:29Z","title":"CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation","summary":"Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \\textbf{CoreEval}, a \\textbf{Co}ntamination-\\textbf{re}silient \\textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.","authors":["Jingqian Zhao","Bingbing Wang","Geng Tu","Yice Zhang","Qianlong Wang","Bin Liang","Jing Li","Ruifeng Xu"],"pdf_url":"","comment":"ACL'25"},{"id":"http://arxiv.org/abs/2501.11357v3","updated":"2025-11-24T08:40:40Z","published":"2025-01-20T09:38:30Z","title":"On the dimension of pullback attractors in recurrent neural networks","summary":"Recurrent Neural Networks (RNNs) are high-dimensional state space models capable of learning functions on sequence data. Recently, it has been conjectured that reservoir computers, a particular class of RNNs, trained on observations of a dynamical systems can be interpreted as embeddings. This result has been established for the case of linear reservoir systems. In this work, we use a nonautonomous dynamical systems approach to establish an upper bound for the fractal dimension of the subset of reservoir state space approximated during training and prediction phase. We prove that when the input sequences comes from an Nin-dimensional invertible dynamical system, the fractal dimension of this set is bounded above by Nin. The result obtained here are useful in dimensionality reduction of computation in RNNs as well as estimating fractal dimensions of dynamical systems from limited observations of their time series. It is also a step towards understanding embedding properties of reservoir computers.","authors":["Muhammed Fadera"],"pdf_url":"","comment":"Issues with clarity and notation"},{"id":"http://arxiv.org/abs/2511.14299v2","updated":"2025-11-24T08:37:38Z","published":"2025-11-18T09:54:13Z","title":"DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning","summary":"In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.","authors":["Xiaochuan Liu","Yuanfeng Song","Xiaoming Yin","Xing Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18878v1","updated":"2025-11-24T08:33:47Z","published":"2025-11-24T08:33:47Z","title":"Accelerating Reinforcement Learning via Error-Related Human Brain Signals","summary":"In this work, we investigate how implicit neural feed back can accelerate reinforcement learning in complex robotic manipulation settings. While prior electroencephalogram (EEG) guided reinforcement learning studies have primarily focused on navigation or low-dimensional locomotion tasks, we aim to understand whether such neural evaluative signals can improve policy learning in high-dimensional manipulation tasks involving obstacles and precise end-effector control. We integrate error related potentials decoded from offline-trained EEG classifiers into reward shaping and systematically evaluate the impact of human-feedback weighting. Experiments on a 7-DoF manipulator in an obstacle-rich reaching environment show that neural feedback accelerates reinforcement learning and, depending on the human-feedback weighting, can yield task success rates that at times exceed those of sparse-reward baselines. Moreover, when applying the best-performing feedback weighting across all sub jects, we observe consistent acceleration of reinforcement learning relative to the sparse-reward setting. Furthermore, leave-one subject-out evaluations confirm that the proposed framework remains robust despite the intrinsic inter-individual variability in EEG decodability. Our findings demonstrate that EEG-based reinforcement learning can scale beyond locomotion tasks and provide a viable pathway for human-aligned manipulation skill acquisition.","authors":["Suzie Kim","Hye-Bin Shin","Hyo-Jeong Jang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18874v1","updated":"2025-11-24T08:28:42Z","published":"2025-11-24T08:28:42Z","title":"GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction","summary":"Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.","authors":["Yuzhi Chen","Yuanchang Xie","Lei Zhao","Pan Liu","Yajie Zou","Chen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.06567v2","updated":"2025-11-24T08:27:31Z","published":"2025-03-09T11:50:39Z","title":"Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving","summary":"Large Language Models (LLMs) have demonstrated significant potential across various domains. However, they often struggle with integrating external knowledge and performing complex reasoning, leading to hallucinations and unreliable outputs. Retrieval Augmented Generation (RAG) has emerged as a promising paradigm to mitigate these issues by incorporating external knowledge. Yet, conventional RAG approaches, especially those based on vector similarity, fail to effectively capture relational dependencies and support multi-step reasoning. In this work, we propose CogGRAG, a human cognition-inspired, graph-based RAG framework designed for Knowledge Graph Question Answering (KGQA). CogGRAG models the reasoning process as a tree-structured mind map that decomposes the original problem into interrelated subproblems and explicitly encodes their semantic relationships. This structure not only provides a global view to guide subsequent retrieval and reasoning but also enables self-consistent verification across reasoning paths. The framework operates in three stages: (1) top-down problem decomposition via mind map construction, (2) structured retrieval of both local and global knowledge from external Knowledge Graphs (KGs), and (3) bottom-up reasoning with dual-process self-verification. Unlike previous tree-based decomposition methods such as MindMap or Graph-CoT, CogGRAG unifies problem decomposition, knowledge retrieval, and reasoning under a single graph-structured cognitive framework, allowing early integration of relational knowledge and adaptive verification. Extensive experiments demonstrate that CogGRAG achieves superior accuracy and reliability compared to existing methods.","authors":["Yao Cheng","Yibo Zhao","Jiapeng Zhu","Yao Liu","Xing Sun","Xiang Li"],"pdf_url":"","comment":"The paper has been accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2507.11443v2","updated":"2025-11-24T08:27:03Z","published":"2025-07-15T16:07:07Z","title":"COLI: A Hierarchical Efficient Compressor for Large Images","summary":"The escalating adoption of high-resolution, large-field-of-view imagery amplifies the need for efficient compression methodologies. Conventional techniques frequently fail to preserve critical image details, while data-driven approaches exhibit limited generalizability. Implicit Neural Representations (INRs) present a promising alternative by learning continuous mappings from spatial coordinates to pixel intensities for individual images, thereby storing network weights rather than raw pixels and avoiding the generalization problem. However, INR-based compression of large images faces challenges including slow compression speed and suboptimal compression ratios. To address these limitations, we introduce COLI (Compressor for Large Images), a novel framework leveraging Neural Representations for Videos (NeRV). First, recognizing that INR-based compression constitutes a training process, we accelerate its convergence through a pretraining-finetuning paradigm, mixed-precision training, and reformulation of the sequential loss into a parallelizable objective. Second, capitalizing on INRs' transformation of image storage constraints into weight storage, we implement Hyper-Compression, a novel post-training technique to substantially enhance compression ratios while maintaining minimal output distortion. Evaluations across two medical imaging datasets demonstrate that COLI consistently achieves competitive or superior PSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while accelerating NeRV training by up to 4 times.","authors":["Haoran Wang","Hanyu Pei","Yang Lyu","Kai Zhang","Li Li","Feng-Lei Fan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.16123v2","updated":"2025-11-24T08:23:34Z","published":"2024-05-25T08:23:40Z","title":"Gradient Propagation in Retrosynthetic Space: An Efficient Framework for Synthesis Plan Generation","summary":"Retrosynthesis, which aims to identify viable synthetic pathways for target molecules by decomposing them into simpler precursors, is often treated as a search problem. However, its complexity arises from multi-branched tree-structured pathways rather than linear paths. Some algorithms have been successfully applied in this task, but they either overlook the uncertainties inherent in chemical space or face limitations in practical application scenarios. To address these challenges, this paper introduces a novel gradient-propagation-based algorithmic framework for retrosynthetic route exploration. The proposed framework obtains the contributions of different nodes to the target molecule's success probability through gradient propagation and then guides the algorithm to greedily select the node with the highest contribution for expansion, thereby conducting efficient search in the chemical space. Experimental validations demonstrate that our algorithm achieves broad applicability across diverse molecular targets and exhibits superior computational efficiency compared to existing methods.","authors":["Chengyang Tian","Yuhang Chang","Yangpeng Zhang","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18871v1","updated":"2025-11-24T08:22:50Z","published":"2025-11-24T08:22:50Z","title":"Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning","summary":"Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.","authors":["Jian Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.04645v3","updated":"2025-11-24T08:22:00Z","published":"2025-02-07T04:08:57Z","title":"Pathway to Relevance: How Cross-Encoders Implement a Semantic Variant of BM25","summary":"Mechanistic interpretation has greatly contributed to a more detailed understanding of generative language models, enabling significant progress in identifying structures that implement key behaviors through interactions between internal components. In contrast, interpretability in information retrieval (IR) remains relatively coarse-grained, and much is still unknown as to how IR models determine whether a document is relevant to a query. In this work, we address this gap by mechanistically analyzing how one commonly used model, a cross-encoder, estimates relevance. We find that the model extracts traditional relevance signals, such as term frequency and inverse document frequency, in early-to-middle layers. These concepts are then combined in later layers, similar to the well-known probabilistic ranking function, BM25. Overall, our analysis offers a more nuanced understanding of how IR models compute relevance. Isolating these components lays the groundwork for future interventions that could enhance transparency, mitigate safety risks, and improve scalability.","authors":["Meng Lu","Catherine Chen","Carsten Eickhoff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18869v1","updated":"2025-11-24T08:12:33Z","published":"2025-11-24T08:12:33Z","title":"Multidimensional Music Aesthetic Evaluation via Semantically Consistent C-Mixup Augmentation","summary":"Evaluating the aesthetic quality of generated songs is challenging due to the multi-dimensional nature of musical perception. We propose a robust music aesthetic evaluation framework that combines (1) multi-source multi-scale feature extraction to obtain complementary segment- and track-level representations, (2) a hierarchical audio augmentation strategy to enrich training data, and (3) a hybrid training objective that integrates regression and ranking losses for accurate scoring and reliable top-song identification. Experiments on the ICASSP 2026 SongEval benchmark demonstrate that our approach consistently outperforms baseline methods across correlation and top-tier metrics.","authors":["Shuyang Liu","Yuan Jin","Rui Lin","Shizhe Chen","Junyu Dai","Tao Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18868v1","updated":"2025-11-24T08:11:50Z","published":"2025-11-24T08:11:50Z","title":"KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit","summary":"High quality kernels are critical for reducing training and inference costs of Large Language Models (LLMs), yet they traditionally require significant expertise in hardware architecture and software optimization. While recent advances in LLM-based code generation show promise for complex optimization, existing methods struggle with the vast optimization space due to insufficient hardware domain knowledge, failing to effectively balance exploration and exploitation. We present KernelBand, a novel framework that formulates kernel optimization as a hierarchical multi-armed bandit problem, enabling LLM agents to strategically navigate the optimization space by treating kernel selection and optimization strategy application as sequential decision-making processes. Our approach leverages hardware profiling information to identify promising optimization strategies and employs runtime behavior clustering to reduce exploration overhead across kernel candidates. Extensive experiments on TritonBench demonstrate that KernelBand significantly outperforms state-of-the-art methods, achieving superior performance with fewer tokens while exhibiting consistent improvement without saturation as computational resources increase.","authors":["Dezhi Ran","Shuxiao Xie","Mingfang Ji","Ziyue Hua","Mengzhou Wu","Yuan Cao","Yuzhe Guo","Yu Hao","Linyi Li","Yitao Hu","Tao Xie"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2504.15668v2","updated":"2025-11-24T08:07:47Z","published":"2025-04-22T07:45:30Z","title":"Preprint: Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems","summary":"Explaining unsolvability of planning problems is of significant research interest in Explainable AI Planning. AI planning literature has reported several research efforts on generating explanations of solutions to planning problems. However, explaining the unsolvability of planning problems remains a largely open and understudied problem. A widely practiced approach to plan generation and automated problem solving, in general, is to decompose tasks into sub-problems that help progressively converge towards the goal. In this paper, we propose to adopt the same philosophy of sub-problem identification as a mechanism for analyzing and explaining unsolvability of planning problems in hybrid systems. In particular, for a given unsolvable planning problem, we propose to identify common waypoints, which are universal obstacles to plan existence; in other words, they appear on every plan from the source to the planning goal. This work envisions such waypoints as sub-problems of the planning problem and the unreachability of any of these waypoints as an explanation for the unsolvability of the original planning problem. We propose a novel method of waypoint identification by casting the problem as an instance of the longest common subsequence problem, a widely popular problem in computer science, typically considered as an illustrative example for the dynamic programming paradigm. Once the waypoints are identified, we perform symbolic reachability analysis on them to identify the earliest unreachable waypoint and report it as the explanation of unsolvability. We present experimental results on unsolvable planning problems in hybrid domains.","authors":["Mir Md Sajid Sarwar","Rajarshi Ray"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18860v1","updated":"2025-11-24T08:00:48Z","published":"2025-11-24T08:00:48Z","title":"Generating Reading Comprehension Exercises with Large Language Models for Educational Applications","summary":"With the rapid development of large language models (LLMs), the applications of LLMs have grown substantially. In the education domain, LLMs demonstrate significant potential, particularly in automatic text generation, which enables the creation of intelligent and adaptive learning content. This paper proposes a new LLMs framework, which is named as Reading Comprehension Exercise Generation (RCEG). It can generate high-quality and personalized English reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned LLMs to generate content candidates. Then, it uses a discriminator to select the best candidate. Finally, the quality of the generated content has been improved greatly. To evaluate the performance of RCEG, a dedicated dataset for English reading comprehension is constructed to perform the experiments, and comprehensive evaluation metrics are used to analyze the experimental results. These metrics include content diversity, factual accuracy, linguistic toxicity, and pedagogical alignment. Experimental results show that RCEG significantly improves the relevance and cognitive appropriateness of the generated exercises.","authors":["Xingyu Huang","Fei Jiang","Jianli Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16712v2","updated":"2025-11-24T07:58:20Z","published":"2025-11-20T08:56:46Z","title":"PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation","summary":"Personalized dual-person portrait customization has considerable potential applications, such as preserving emotional memories and facilitating wedding photography planning. However, the absence of a benchmark dataset hinders the pursuit of high-quality customization in dual-person portrait generation. In this paper, we propose the PairHuman dataset, which is the first large-scale benchmark dataset specifically designed for generating dual-person portraits that meet high photographic standards. The PairHuman dataset contains more than 100K images that capture a variety of scenes, attire, and dual-person interactions, along with rich metadata, including detailed image descriptions, person localization, human keypoints, and attribute tags. We also introduce DHumanDiff, which is a baseline specifically crafted for dual-person portrait generation that features enhanced facial consistency and simultaneously balances in personalized person generation and semantic-driven scene creation. Finally, the experimental results demonstrate that our dataset and method produce highly customized portraits with superior visual quality that are tailored to human preferences. Our dataset is publicly available at https://github.com/annaoooo/PairHuman.","authors":["Ting Pan","Ye Wang","Peiguang Jing","Rui Ma","Zili Yi","Yu Liu"],"pdf_url":"","comment":"46 pages, 31 figures"},{"id":"http://arxiv.org/abs/2506.21996v2","updated":"2025-11-24T07:52:48Z","published":"2025-06-27T08:07:17Z","title":"AlphaBeta is not as good as you think: a simple random games model for a better analysis of deterministic game-solving algorithms","summary":"Deterministic game-solving algorithms are conventionally analyzed in the light of their average-case complexity against a distribution of random game-trees, where leaf values are independently sampled from a fixed distribution. This simplified model enables uncluttered mathematical analysis, revealing two key properties: root value distributions asymptotically collapse to a single fixed value for finite-valued trees, and all reasonable algorithms achieve global optimality. However, these findings are artifacts of the model's design: its long criticized independence assumption strips games of structural complexity, producing trivial instances where no algorithm faces meaningful challenges. To address this limitation, we introduce a simple probabilistic model that incrementally constructs game-trees using a fixed level-wise conditional distribution. By enforcing ancestor dependencies, a critical structural feature of real-world games, our framework generates problems with adjustable difficulty while retaining some form of analytical tractability. For several algorithms, including AlphaBeta and Scout, we derive recursive formulas characterizing their average-case complexities under this model. These allow us to rigorously compare algorithms on deep game-trees, where Monte-Carlo simulations are no longer feasible. While asymptotically, all algorithms seem to converge to identical branching factor (a result analogous to that of independence-based models), deep finite trees reveal stark differences: AlphaBeta incurs a significantly larger constant multiplicative factor compared to algorithms like Scout, leading to a substantial practical slowdown. Our framework sheds new light on classical game-solving algorithms, offering rigorous evidence and analytical tools to advance the understanding of these methods under a richer, more challenging, and yet tractable model.","authors":["Raphaël Boige","Amine Boumaza","Bruno Scherrer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18856v1","updated":"2025-11-24T07:52:06Z","published":"2025-11-24T07:52:06Z","title":"Deep Hybrid Model for Region of Interest Detection in Omnidirectional Videos","summary":"The main goal of the project is to design a new model that predicts regions of interest in 360$^{\\circ}$ videos. The region of interest (ROI) plays an important role in 360$^{\\circ}$ video streaming. For example, ROIs are used to predict view-ports, intelligently cut the videos for live streaming, etc so that less bandwidth is used. Detecting view-ports in advance helps reduce the movement of the head while streaming and watching a video via the head-mounted device. Whereas, intelligent cuts of the videos help improve the efficiency of streaming the video to users and enhance the quality of their viewing experience. This report illustrates the secondary task to identify ROIs, in which, we design, train, and test a hybrid saliency model. In this work, we refer to saliency regions to represent the regions of interest. The method includes the processes as follows: preprocessing the video to obtain frames, developing a hybrid saliency model for predicting the region of interest, and finally post-processing the output predictions of the hybrid saliency model to obtain the output region of interest for each frame. Then, we compare the performance of the proposed method with the subjective annotations of the 360RAT dataset.","authors":["Sana Alamgeer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18854v1","updated":"2025-11-24T07:49:59Z","published":"2025-11-24T07:49:59Z","title":"Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect","summary":"We present a novel framework that integrates Large Language Models (LLMs) into the Git bisect process for semantic fault localization. Traditional bisect assumes deterministic predicates and binary failure states assumptions often violated in modern software development due to flaky tests, nonmonotonic regressions, and semantic divergence from upstream repositories. Our system augments bisect traversal with structured chain of thought reasoning, enabling commit by commit analysis under noisy conditions. We evaluate multiple open source and proprietary LLMs for their suitability and fine tune DeepSeekCoderV2 using QLoRA on a curated dataset of semantically labeled diffs. We adopt a weak supervision workflow to reduce annotation overhead, incorporating human in the loop corrections and self consistency filtering. Experiments across multiple open source projects show a 6.4 point absolute gain in success rate from 74.2 to 80.6 percent, leading to significantly fewer failed traversals and by experiment up to 2x reduction in average bisect time. We conclude with discussions on temporal reasoning, prompt design, and finetuning strategies tailored for commit level behavior analysis.","authors":["Yujing Wang","Weize Hong"],"pdf_url":"","comment":"submitted to Git Bisect SCALCOM 2025 Calgary (to be published)"},{"id":"http://arxiv.org/abs/2511.15065v2","updated":"2025-11-24T07:46:09Z","published":"2025-11-19T03:18:29Z","title":"Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks","summary":"Video Models have achieved remarkable success in high-fidelity video generation with coherent motion dynamics. Analogous to the development from text generation to text-based reasoning in language modeling, the development of video models motivates us to ask: Can video models reason via video generation? Compared with the discrete text corpus, video grounds reasoning in explicit spatial layouts and temporal continuity, which serves as an ideal substrate for spatial reasoning. In this work, we explore the reasoning via video paradigm and introduce VR-Bench -- a comprehensive benchmark designed to systematically evaluate video models' reasoning capabilities. Grounded in maze-solving tasks that inherently require spatial planning and multi-step reasoning, VR-Bench contains 7,920 procedurally generated videos across five maze types and diverse visual styles. Our empirical analysis demonstrates that SFT can efficiently elicit the reasoning ability of video model. Video models exhibit stronger spatial perception during reasoning, outperforming leading VLMs and generalizing well across diverse scenarios, tasks, and levels of complexity. We further discover a test-time scaling effect, where diverse sampling during inference improves reasoning reliability by 10--20%. These findings highlight the unique potential and scalability of reasoning via video for spatial reasoning tasks.","authors":["Cheng Yang","Haiyuan Wan","Yiran Peng","Xin Cheng","Zhaoyang Yu","Jiayi Zhang","Junchi Yu","Xinlei Yu","Xiawu Zheng","Dongzhan Zhou","Chenglin Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.08426v8","updated":"2025-11-24T07:43:14Z","published":"2024-06-12T17:13:17Z","title":"Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL","summary":"Generating accurate SQL from users' natural language questions (text-to-SQL) remains a long-standing challenge due to the complexities involved in user question understanding, database schema comprehension, and SQL generation. Traditional text-to-SQL systems, which combine human engineering and deep neural networks, have made significant progress. Subsequently, pre-trained language models (PLMs) have been developed for text-to-SQL tasks, achieving promising results. However, as modern databases and user questions grow more complex, PLMs with a limited parameter size often produce incorrect SQL. This necessitates more sophisticated and tailored optimization methods, which restricts the application of PLM-based systems. Recently, large language models (LLMs) have shown significant capabilities in natural language understanding as model scale increases. Thus, integrating LLM-based solutions can bring unique opportunities, improvements, and solutions to text-to-SQL research. In this survey, we provide a comprehensive review of existing LLM-based text-to-SQL studies. Specifically, we offer a brief overview of the technical challenges and evolutionary process of text-to-SQL. Next, we introduce the datasets and metrics designed to evaluate text-to-SQL systems. Subsequently, we present a systematic analysis of recent advances in LLM-based text-to-SQL. Finally, we make a summarization and discuss the remaining challenges in this field and suggest expectations for future research directions. All the related resources of LLM-based, including research papers, benchmarks, and open-source projects, are collected for the community in our repository: https://github.com/DEEP-PolyU/Awesome-LLM-based-Text2SQL.","authors":["Zijin Hong","Zheng Yuan","Qinggang Zhang","Hao Chen","Junnan Dong","Feiran Huang","Xiao Huang"],"pdf_url":"","comment":"Accepted to IEEE TKDE2025"},{"id":"http://arxiv.org/abs/2511.18849v1","updated":"2025-11-24T07:42:07Z","published":"2025-11-24T07:42:07Z","title":"Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming","summary":"Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% -> 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.","authors":["Mohammad Nour Al Awad","Sergey Ivanov","Olga Tikhonova"],"pdf_url":"","comment":"\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses"}]},"2025-11-23T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2506.19815v6","updated":"2025-11-23T21:37:13Z","published":"2025-06-24T17:28:43Z","title":"ReactEMG: Stable, Low-Latency Intent Detection from sEMG via Masked Modeling","summary":"Surface electromyography (sEMG) signals show promise for effective human-machine interfaces, particularly in rehabilitation and prosthetics. However, challenges remain in developing systems that respond quickly to user intent, produce stable flicker-free output suitable for device control, and work across different subjects without time-consuming calibration. In this work, we propose a framework for EMG-based intent detection that addresses these challenges. We cast intent detection as per-timestep segmentation of continuous sEMG streams, assigning labels as gestures unfold in real time. We introduce a masked modeling training strategy that aligns muscle activations with their corresponding user intents, enabling rapid onset detection and stable tracking of ongoing gestures. In evaluations against baseline methods, using metrics that capture accuracy, latency and stability for device control, our approach achieves state-of-the-art performance in zero-shot conditions. These results demonstrate its potential for wearable robotics and next-generation prosthetic systems. Our project website, video, code, and dataset are available at: https://reactemg.github.io/","authors":["Runsheng Wang","Xinyue Zhu","Ava Chen","Jingxi Xu","Lauren Winterbottom","Dawn M. Nilsen","Joel Stein","Matei Ciocarlie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18617v1","updated":"2025-11-23T21:21:10Z","published":"2025-11-23T21:21:10Z","title":"AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations","summary":"AutoFocus-IL is a simple yet effective method to improve data efficiency and generalization in visual imitation learning by guiding policies to attend to task-relevant features rather than distractors and spurious correlations. Although saliency regularization has emerged as a promising way to achieve this, existing approaches typically require costly supervision such as human gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages vision-language models (VLMs) to automatically identify and track key objects in demonstrations, generating temporal saliency maps that highlight causal visual signals while suppressing distractors. These maps are then used to regularize behavior cloning policies, yielding stronger alignment between visual attention and task-relevant cues. Experiments in both the CARLA simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not only outperforms standard behavior cloning but also surpasses state-of-the-art baselines that assume privileged access to human supervision, such as gaze data. Code, datasets, and trained policy videos are available at https://AutoFocus-IL.github.io/.","authors":["Litian Gong","Fatemeh Bahrani","Yutai Zhou","Amin Banayeeanzade","Jiachen Li","Erdem Biyik"],"pdf_url":"","comment":"8 pages, 6 figures. Code and datasets available at http://autofocus-il.github.io/"},{"id":"http://arxiv.org/abs/2511.14335v2","updated":"2025-11-23T20:36:38Z","published":"2025-11-18T10:42:36Z","title":"Simultaneous Localization and 3D-Semi Dense Mapping for Micro Drones Using Monocular Camera and Inertial Sensors","summary":"Monocular simultaneous localization and mapping (SLAM) algorithms estimate drone poses and build a 3D map using a single camera. Current algorithms include sparse methods that lack detailed geometry, while learning-driven approaches produce dense maps but are computationally intensive. Monocular SLAM also faces scale ambiguities, which affect its accuracy. To address these challenges, we propose an edge-aware lightweight monocular SLAM system combining sparse keypoint-based pose estimation with dense edge reconstruction. Our method employs deep learning-based depth prediction and edge detection, followed by optimization to refine keypoints and edges for geometric consistency, without relying on global loop closure or heavy neural computations. We fuse inertial data with vision by using an extended Kalman filter to resolve scale ambiguity and improve accuracy. The system operates in real time on low-power platforms, as demonstrated on a DJI Tello drone with a monocular camera and inertial sensors. In addition, we demonstrate robust autonomous navigation and obstacle avoidance in indoor corridors and on the TUM RGBD dataset. Our approach offers an effective, practical solution to real-time mapping and navigation in resource-constrained environments.","authors":["Jeryes Danial","Yosi Ben Asher","Itzik Klein"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18606v1","updated":"2025-11-23T20:15:28Z","published":"2025-11-23T20:15:28Z","title":"How to Train Your Latent Control Barrier Function: Smooth Safety Filtering Under Hard-to-Model Constraints","summary":"Latent safety filters extend Hamilton-Jacobi (HJ) reachability to operate on latent state representations and dynamics learned directly from high-dimensional observations, enabling safe visuomotor control under hard-to-model constraints. However, existing methods implement \"least-restrictive\" filtering that discretely switch between nominal and safety policies, potentially undermining the task performance that makes modern visuomotor policies valuable. While reachability value functions can, in principle, be adapted to be control barrier functions (CBFs) for smooth optimization-based filtering, we theoretically and empirically show that current latent-space learning methods produce fundamentally incompatible value functions. We identify two sources of incompatibility: First, in HJ reachability, failures are encoded via a \"margin function\" in latent space, whose sign indicates whether or not a latent is in the constraint set. However, representing the margin function as a classifier yields saturated value functions that exhibit discontinuous jumps. We prove that the value function's Lipschitz constant scales linearly with the margin function's Lipschitz constant, revealing that smooth CBFs require smooth margins. Second, reinforcement learning (RL) approximations trained solely on safety policy data yield inaccurate value estimates for nominal policy actions, precisely where CBF filtering needs them. We propose the LatentCBF, which addresses both challenges through gradient penalties that lead to smooth margin functions without additional labeling, and a value-training procedure that mixes data from both nominal and safety policy distributions. Experiments on simulated benchmarks and hardware with a vision-based manipulation policy demonstrate that LatentCBF enables smooth safety filtering while doubling the task-completion rate over prior switching methods.","authors":["Kensuke Nakamura","Arun L. Bishop","Steven Man","Aaron M. Johnson","Zachary Manchester","Andrea Bajcsy"],"pdf_url":"","comment":"3 figures, 10 tables, 22 pages"},{"id":"http://arxiv.org/abs/2511.18604v1","updated":"2025-11-23T20:11:47Z","published":"2025-11-23T20:11:47Z","title":"An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms","summary":"This study informs the design of future multi-agent pathfinding (MAPF) and multi-robot motion planning (MRMP) algorithms by guiding choices based on constraint classification for constraint-based search algorithms. We categorize constraints as conservative or aggressive and provide insights into their search behavior, focusing specifically on vanilla Conflict-Based Search (CBS) and Conflict-Based Search with Priorities (CBSw/P). Under a hybrid grid-roadmap representation with varying resolution, we observe that aggressive (priority constraint) formulations tend to solve more instances as agent count or resolution increases, whereas conservative (motion constraint) formulations yield stronger solution quality when both succeed. Findings are synthesized in a decision flowchart, aiding users in selecting suitable constraints. Recommendations extend to Multi-Robot Motion Planning (MRMP), emphasizing the importance of considering topological features alongside problem, solution, and representation features. A comprehensive exploration of the study, including raw data and map performance, is available in our public GitHub Repository: https://GitHub.com/hannahjmlee/constraint-mapf-analysis","authors":["Hannah Lee","James D. Motes","Marco Morales","Nancy M. Amato"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07387v2","updated":"2025-11-23T19:10:25Z","published":"2025-08-10T15:27:23Z","title":"MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control","summary":"Navigating unknown environments with a single RGB camera is challenging, as the lack of depth information prevents reliable collision-checking. While some methods use estimated depth to build collision maps, we found that depth estimates from vision foundation models are too noisy for zero-shot navigation in cluttered environments. We propose an alternative approach: instead of using noisy estimated depth for direct collision-checking, we use it as a rich context input to a learned collision model. This model predicts the distribution of minimum obstacle clearance that the robot can expect for a given control sequence. At inference, these predictions inform a risk-aware MPC planner that minimizes estimated collision risk. We proposed a joint learning pipeline that co-trains the collision model and risk metric using both safe and unsafe trajectories. Crucially, our joint-training ensures well calibrated uncertainty in our collision model that improves navigation in highly cluttered environments. Consequently, real-world experiments show reductions in collision-rate and improvements in goal reaching and speed over several strong baselines.","authors":["Basant Sharma","Prajyot Jadhav","Pranjal Paul","K. Madhava Krishna","Arun Kumar Singh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18579v1","updated":"2025-11-23T18:44:47Z","published":"2025-11-23T18:44:47Z","title":"Connectivity-Preserving Multi-Agent Area Coverage via Optimal-Transport-Based Density-Driven Optimal Control (D2OC)","summary":"Multi-agent systems play a central role in area coverage tasks across search-and-rescue, environmental monitoring, and precision agriculture. Achieving non-uniform coverage, where spatial priorities vary across the domain, requires coordinating agents while respecting dynamic and communication constraints. Density-driven approaches can distribute agents according to a prescribed reference density, but existing methods do not ensure connectivity. This limitation often leads to communication loss, reduced coordination, and degraded coverage performance.\n  This letter introduces a connectivity-preserving extension of the Density-Driven Optimal Control (D2OC) framework. The coverage objective, defined using the Wasserstein distance between the agent distribution and the reference density, admits a convex quadratic program formulation. Communication constraints are incorporated through a smooth connectivity penalty, which maintains strict convexity, supports distributed implementation, and preserves inter-agent communication without imposing rigid formations.\n  Simulation studies show that the proposed method consistently maintains connectivity, improves convergence speed, and enhances non-uniform coverage quality compared with density-driven schemes that do not incorporate explicit connectivity considerations.","authors":["Kooktae Lee","Ethan Brook"],"pdf_url":"","comment":"Under review in IEEE Control Systems Letters (LCSS). 6 pages"},{"id":"http://arxiv.org/abs/2511.18570v1","updated":"2025-11-23T18:29:20Z","published":"2025-11-23T18:29:20Z","title":"PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation","summary":"Understanding physical properties such as friction, stiffness, hardness, and material composition is essential for enabling robots to interact safely and effectively with their surroundings. However, existing 3D reconstruction methods focus on geometry and appearance and cannot infer these underlying physical properties. We present PhysGS, a Bayesian-inferred extension of 3D Gaussian Splatting that estimates dense, per-point physical properties from visual cues and vision--language priors. We formulate property estimation as Bayesian inference over Gaussian splats, where material and property beliefs are iteratively refined as new observations arrive. PhysGS also models aleatoric and epistemic uncertainties, enabling uncertainty-aware object and scene interpretation. Across object-scale (ABO-500), indoor, and outdoor real-world datasets, PhysGS improves accuracy of the mass estimation by up to 22.8%, reduces Shore hardness error by up to 61.2%, and lowers kinetic friction error by up to 18.1% compared to deterministic baselines. Our results demonstrate that PhysGS unifies 3D reconstruction, uncertainty modeling, and physical reasoning in a single, spatially continuous framework for dense physical property estimation. Additional results are available at https://samchopra2003.github.io/physgs.","authors":["Samarth Chopra","Jing Liang","Gershom Seneviratne","Dinesh Manocha"],"pdf_url":"","comment":"Submitted to CVPR 2026"},{"id":"http://arxiv.org/abs/2504.14135v2","updated":"2025-11-23T18:25:14Z","published":"2025-04-19T01:54:45Z","title":"Unreal Robotics Lab: A High-Fidelity Robotics Simulator with Advanced Physics and Rendering","summary":"High-fidelity simulation is essential for robotics research, enabling safe and efficient testing of perception, control, and navigation algorithms. However, achieving both photorealistic rendering and accurate physics modeling remains a challenge. This paper presents a novel simulation framework, the Unreal Robotics Lab (URL), that integrates the advanced rendering capabilities of the Unreal Engine with MuJoCo's high-precision physics simulation. Our approach enables realistic robotic perception while maintaining accurate physical interactions, facilitating benchmarking and dataset generation for vision-based robotics applications. The system supports complex environmental effects, such as smoke, fire, and water dynamics, which are critical to evaluating robotic performance under adverse conditions. We benchmark visual navigation and SLAM methods within our framework, demonstrating its utility for testing real-world robustness in controlled yet diverse scenarios. By bridging the gap between physics accuracy and photorealistic rendering, our framework provides a powerful tool for advancing robotics research and sim-to-real transfer. Our open-source framework is available at https://unrealroboticslab.github.io/.","authors":["Jonathan Embley-Riches","Jianwei Liu","Simon Julier","Dimitrios Kanoulas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18563v1","updated":"2025-11-23T18:18:49Z","published":"2025-11-23T18:18:49Z","title":"Object-centric Task Representation and Transfer using Diffused Orientation Fields","summary":"Curved objects pose a fundamental challenge for skill transfer in robotics: unlike planar surfaces, they do not admit a global reference frame. As a result, task-relevant directions such as \"toward\" or \"along\" the surface vary with position and geometry, making object-centric tasks difficult to transfer across shapes. To address this, we introduce an approach using Diffused Orientation Fields (DOF), a smooth representation of local reference frames, for transfer learning of tasks across curved objects. By expressing manipulation tasks in these smoothly varying local frames, we reduce the problem of transferring tasks across curved objects to establishing sparse keypoint correspondences. DOF is computed online from raw point cloud data using diffusion processes governed by partial differential equations, conditioned on keypoints. We evaluate DOF under geometric, topological, and localization perturbations, and demonstrate successful transfer of tasks requiring continuous physical interaction such as inspection, slicing, and peeling across varied objects. We provide our open-source codes at our website https://github.com/idiap/diffused_fields_robotics","authors":["Cem Bilaloglu","Tobias Löw","Sylvain Calinon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18525v1","updated":"2025-11-23T16:35:51Z","published":"2025-11-23T16:35:51Z","title":"Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation","summary":"We present Splatblox, a real-time system for autonomous navigation in outdoor environments with dense vegetation, irregular obstacles, and complex terrain. Our method fuses segmented RGB images and LiDAR point clouds using Gaussian Splatting to construct a traversability-aware Euclidean Signed Distance Field (ESDF) that jointly encodes geometry and semantics. Updated online, this field enables semantic reasoning to distinguish traversable vegetation (e.g., tall grass) from rigid obstacles (e.g., trees), while LiDAR ensures 360-degree geometric coverage for extended planning horizons. We validate Splatblox on a quadruped robot and demonstrate transfer to a wheeled platform. In field trials across vegetation-rich scenarios, it outperforms state-of-the-art methods with over 50% higher success rate, 40% fewer freezing incidents, 5% shorter paths, and up to 13% faster time to goal, while supporting long-range missions up to 100 meters. Experiment videos and more details can be found on our project page: https://splatblox.github.io","authors":["Samarth Chopra","Jing Liang","Gershom Seneviratne","Yonghan Lee","Jaehoon Choi","Jianyu An","Stephen Cheng","Dinesh Manocha"],"pdf_url":"","comment":"Submitted to ICRA 2026"},{"id":"http://arxiv.org/abs/2511.18509v1","updated":"2025-11-23T15:55:34Z","published":"2025-11-23T15:55:34Z","title":"SafeFall: Learning Protective Control for Humanoid Robots","summary":"Bipedal locomotion makes humanoid robots inherently prone to falls, causing catastrophic damage to the expensive sensors, actuators, and structural components of full-scale robots. To address this critical barrier to real-world deployment, we present \\method, a framework that learns to predict imminent, unavoidable falls and execute protective maneuvers to minimize hardware damage. SafeFall is designed to operate seamlessly alongside existing nominal controller, ensuring no interference during normal operation. It combines two synergistic components: a lightweight, GRU-based fall predictor that continuously monitors the robot's state, and a reinforcement learning policy for damage mitigation. The protective policy remains dormant until the predictor identifies a fall as unavoidable, at which point it activates to take control and execute a damage-minimizing response. This policy is trained with a novel, damage-aware reward function that incorporates the robot's specific structural vulnerabilities, learning to shield critical components like the head and hands while absorbing energy with more robust parts of its body. Validated on a full-scale Unitree G1 humanoid, SafeFall demonstrated significant performance improvements over unprotected falls. It reduced peak contact forces by 68.3\\%, peak joint torques by 78.4\\%, and eliminated 99.3\\% of collisions with vulnerable components. By enabling humanoids to fail safely, SafeFall provides a crucial safety net that allows for more aggressive experiments and accelerates the deployment of these robots in complex, real-world environments.","authors":["Ziyu Meng","Tengyu Liu","Le Ma","Yingying Wu","Ran Song","Wei Zhang","Siyuan Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18486v1","updated":"2025-11-23T15:14:39Z","published":"2025-11-23T15:14:39Z","title":"Expanding the Workspace of Electromagnetic Navigation Systems Using Dynamic Feedback for Single- and Multi-agent Control","summary":"Electromagnetic navigation systems (eMNS) enable a number of magnetically guided surgical procedures. A challenge in magnetically manipulating surgical tools is that the effective workspace of an eMNS is often severely constrained by power and thermal limits. We show that system-level control design significantly expands this workspace by reducing the currents needed to achieve a desired motion. We identified five key system approaches that enable this expansion: (i) motion-centric torque/force objectives, (ii) energy-optimal current allocation, (iii) real-time pose estimation, (iv) dynamic feedback, and (v) high-bandwidth eMNS components. As a result, we stabilize a 3D inverted pendulum on an eight-coil OctoMag eMNS with significantly lower currents (0.1-0.2 A vs. 8-14 A), by replacing a field-centric field-alignment strategy with a motion-centric torque/force-based approach. We generalize to multi-agent control by simultaneously stabilizing two inverted pendulums within a shared workspace, exploiting magnetic-field nonlinearity and coil redundancy for independent actuation. A structured analysis compares the electromagnetic workspaces of both paradigms and examines current-allocation strategies that map motion objectives to coil currents. Cross-platform evaluation of the clinically oriented Navion eMNS further demonstrates substantial workspace expansion by maintaining stable balancing at distances up to 50 cm from the coils. The results demonstrate that feedback is a practical path to scalable, efficient, and clinically relevant magnetic manipulation.","authors":["Jasan Zughaibi","Denis von Arx","Maurus Derungs","Florian Heemeyer","Luca A. Antonelli","Quentin Boehler","Michael Muehlebach","Bradley J. Nelson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2109.05265v4","updated":"2025-11-23T14:12:30Z","published":"2021-09-11T12:02:29Z","title":"Advancing Autonomous Driving: DepthSense with Radar and Spatial Attention","summary":"Depth perception is crucial for spatial understanding and has traditionally been achieved through stereoscopic imaging. However, the precision of depth estimation using stereoscopic methods depends on the accurate calibration of binocular vision sensors. Monocular cameras, while more accessible, often suffer from reduced accuracy, especially under challenging imaging conditions. Optical sensors, too, face limitations in adverse environments, leading researchers to explore radar technology as a reliable alternative. Although radar provides coarse but accurate signals, its integration with fine-grained monocular camera data remains underexplored. In this research, we propose DepthSense, a novel radar-assisted monocular depth enhancement approach. DepthSense employs an encoder-decoder architecture, a Radar Residual Network, feature fusion with a spatial attention mechanism, and an ordinal regression layer to deliver precise depth estimations. We conducted extensive experiments on the nuScenes dataset to validate the effectiveness of DepthSense. Our methodology not only surpasses existing approaches in quantitative performance but also reduces parameter complexity and inference times. Our findings demonstrate that DepthSense represents a significant advancement over traditional stereo methods, offering a robust and efficient solution for depth estimation in autonomous driving. By leveraging the complementary strengths of radar and monocular camera data, DepthSense sets a new benchmark in the field, paving the way for more reliable and accurate spatial perception systems.","authors":["Muhamamd Ishfaq Hussain","Zubia Naz","Muhammad Aasim Rafique","Moongu Jeon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18417v1","updated":"2025-11-23T12:07:45Z","published":"2025-11-23T12:07:45Z","title":"Categorical Equivariant Deep Learning: Category-Equivariant Neural Networks and Universal Approximation Theorems","summary":"We develop a theory of category-equivariant neural networks (CENNs) that unifies group/groupoid-equivariant networks, poset/lattice-equivariant networks, graph and sheaf neural networks. Equivariance is formulated as naturality in a topological category with Radon measures, formulating linear and nonlinear layers in the categorical setup. We prove the equivariant universal approximation theorem in the general setting: the class of finite-depth CENNs is dense in the space of continuous equivariant transformations. We instantiate the framework for groups/groupoids, posets/lattices, graphs and cellular sheaves, deriving universal approximation theorems for them in a systematic manner. Categorical equivariant deep learning thus allows us to expand the horizons of equivariant deep learning beyond group actions, encompassing not only geometric symmetries but also contextual and compositional symmetries.","authors":["Yoshihiro Maruyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18374v1","updated":"2025-11-23T09:48:41Z","published":"2025-11-23T09:48:41Z","title":"Explicit Bounds on the Hausdorff Distance for Truncated mRPI Sets via Norm-Dependent Contraction Rates","summary":"This paper establishes the first explicit and closed-form upper bound on the Hausdorff distance between the truncated minimal robust positively invariant (mRPI) set and its infinite-horizon limit. While existing mRPI approximations guarantee asymptotic convergence through geometric or norm-based arguments, none provides a computable expression that quantifies the truncation error for a given horizon. We show that the error satisfies \\( d_H(\\mathcal{E}_N,\\mathcal{E}_\\infty) \\le r_W\\,γ^{N+1}/(1-γ), \\) where $γ<1$ is the induced-norm contraction factor and $r_W$ depends only on the disturbance set. The bound is fully analytic, requires no iterative set computations, and directly characterizes the decay rate of the truncated Minkowski series. We further demonstrate that the choice of vector norm serves as a design parameter that accelerates convergence, enabling substantially tighter horizon selection for robust invariant-set computations and tube-based MPC. Numerical experiments validate the sharpness, scalability, and practical relevance of the proposed bound.","authors":["Jiaxun Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18353v1","updated":"2025-11-23T09:00:33Z","published":"2025-11-23T09:00:33Z","title":"Enhancing UAV Search under Occlusion using Next Best View Planning","summary":"Search and rescue missions are often critical following sudden natural disasters or in high-risk environmental situations. The most challenging search and rescue missions involve difficult-to-access terrains, such as dense forests with high occlusion. Deploying unmanned aerial vehicles for exploration can significantly enhance search effectiveness, facilitate access to challenging environments, and reduce search time. However, in dense forests, the effectiveness of unmanned aerial vehicles depends on their ability to capture clear views of the ground, necessitating a robust search strategy to optimize camera positioning and perspective. This work presents an optimized planning strategy and an efficient algorithm for the next best view problem in occluded environments. Two novel optimization heuristics, a geometry heuristic, and a visibility heuristic, are proposed to enhance search performance by selecting optimal camera viewpoints. Comparative evaluations in both simulated and real-world settings reveal that the visibility heuristic achieves greater performance, identifying over 90% of hidden objects in simulated forests and offering 10% better detection rates than the geometry heuristic. Additionally, real-world experiments demonstrate that the visibility heuristic provides better coverage under the canopy, highlighting its potential for improving search and rescue missions in occluded environments.","authors":["Sigrid Helene Strand","Thomas Wiedemann","Bram Burczek","Dmitriy Shutin"],"pdf_url":"","comment":"Submitted to IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing"},{"id":"http://arxiv.org/abs/2511.18322v1","updated":"2025-11-23T07:27:39Z","published":"2025-11-23T07:27:39Z","title":"Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video","summary":"Data-driven learning of soft continuum robot (SCR) dynamics from high-dimensional observations offers flexibility but often lacks physical interpretability, while model-based approaches require prior knowledge and can be computationally expensive. We bridge this gap by introducing (1) the Attention Broadcast Decoder (ABCD), a plug-and-play module for autoencoder-based latent dynamics learning that generates pixel-accurate attention maps localizing each latent dimension's contribution while filtering static backgrounds. (2) By coupling these attention maps to 2D oscillator networks, we enable direct on-image visualization of learned dynamics (masses, stiffness, and forces) without prior knowledge. We validate our approach on single- and double-segment SCRs, demonstrating that ABCD-based models significantly improve multi-step prediction accuracy: 5.7x error reduction for Koopman operators and 3.5x for oscillator networks on the two-segment robot. The learned oscillator network autonomously discovers a chain structure of oscillators. Unlike standard methods, ABCD models enable smooth latent space extrapolation beyond training data. This fully data-driven approach yields compact, physically interpretable models suitable for control applications.","authors":["Henrik Krauss","Johann Licher","Naoya Takeishi","Annika Raatz","Takehisa Yairi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18299v1","updated":"2025-11-23T05:40:16Z","published":"2025-11-23T05:40:16Z","title":"MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing","summary":"Robotic manipulation tasks are contact-rich, yet most imitation learning (IL) approaches rely primarily on vision, which struggles to capture stiffness, roughness, slip, and other fine interaction cues. Tactile signals can address this gap, but existing sensors often require expensive, delicate, or integration-heavy hardware. In this work, we introduce MicCheck, a plug-and-play acoustic sensing approach that repurposes an off-the-shelf Bluetooth pin microphone as a low-cost contact sensor. The microphone clips into a 3D-printed gripper insert and streams audio via a standard USB receiver, requiring no custom electronics or drivers. Despite its simplicity, the microphone provides signals informative enough for both perception and control. In material classification, it achieves 92.9% accuracy on a 10-class benchmark across four interaction types (tap, knock, slow press, drag). For manipulation, integrating pin microphone into an IL pipeline with open source hardware improves the success rate on picking and pouring task from 0.40 to 0.80 and enables reliable execution of contact-rich skills such as unplugging and sound-based sorting. Compared with high-resolution tactile sensors, pin microphones trade spatial detail for cost and ease of integration, offering a practical pathway for deploying acoustic contact sensing in low-cost robot setups.","authors":["Steven Oh","Tai Inui","Magdeline Kuan","Jia-Yeu Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18293v1","updated":"2025-11-23T05:20:40Z","published":"2025-11-23T05:20:40Z","title":"AIA-UltraNeRF:Acoustic-Impedance-Aware Neural Radiance Field with Hash Encodings for Robotic Ultrasound Reconstruction and Localization","summary":"Neural radiance field (NeRF) is a promising approach for reconstruction and new view synthesis. However, previous NeRF-based reconstruction methods overlook the critical role of acoustic impedance in ultrasound imaging. Localization methods face challenges related to local minima due to the selection of initial poses. In this study, we design a robotic ultrasound system (RUSS) with an acoustic-impedance-aware ultrasound NeRF (AIA-UltraNeRF) to decouple the scanning and diagnostic processes. Specifically, AIA-UltraNeRF models a continuous function of hash-encoded spatial coordinates for the 3D ultrasound map, allowing for the storage of acoustic impedance without dense sampling. This approach accelerates both reconstruction and inference speeds. We then propose a dual-supervised network that leverages teacher and student models to hash-encode the rendered ultrasound images from the reconstructed map. AIA-UltraNeRF retrieves the most similar hash values without the need to render images again, providing an offline initial image position for localization. Moreover, we develop a RUSS with a spherical remote center of motion mechanism to hold the probe, implementing operator-independent scanning modes that separate image acquisition from diagnostic workflows. Experimental results on a phantom and human subjects demonstrate the effectiveness of acoustic impedance in implicitly characterizing the color of ultrasound images. AIAUltraNeRF achieves both reconstruction and localization with inference speeds that are 9.9 faster than those of vanilla NeRF.","authors":["Shuai Zhang","Jingsong Mu","Cancan Zhao","Leiqi Tian","Zhijun Xing","Bo Ouyang","Xiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.08909v2","updated":"2025-11-23T05:14:33Z","published":"2024-12-12T03:45:07Z","title":"Continuous Gaussian Process Pre-Optimization for Asynchronous Event-Inertial Odometry","summary":"Event cameras, as bio-inspired sensors, are asynchronously triggered with high-temporal resolution compared to intensity cameras. Recent work has focused on fusing the event measurements with inertial measurements to enable ego-motion estimation in high-speed and HDR environments. However, existing methods predominantly rely on IMU preintegration designed mainly for synchronous sensors and discrete-time frameworks. In this paper, we propose a continuous-time preintegration method based on the Temporal Gaussian Process (TGP) called GPO. Concretely, we model the preintegration as a time-indexed motion trajectory and leverage an efficient two-step optimization to initialize the precision preintegration pseudo-measurements. Our method realizes a linear and constant time cost for initialization and query, respectively. To further validate the proposal, we leverage the GPO to design an asynchronous event-inertial odometry and compare with other asynchronous fusion schemes within the same odometry system. Experiments conducted on both public and own-collected datasets demonstrate that the proposed GPO offers significant advantages in terms of precision and efficiency, outperforming existing approaches in handling asynchronous sensor fusion.","authors":["Zhixiang Wang","Xudong Li","Yizhai Zhang","Fan Zhang","Panfeng Huang"],"pdf_url":"","comment":"8pages"},{"id":"http://arxiv.org/abs/2411.12175v2","updated":"2025-11-23T05:07:06Z","published":"2024-11-19T02:39:57Z","title":"AsynEIO: Asynchronous Monocular Event-Inertial Odometry Using Gaussian Process Regression","summary":"Event cameras, when combined with inertial sensors, show significant potential for motion estimation in challenging scenarios, such as high-speed maneuvers and low-light environments. There are many methods for producing such estimations, but most boil down to a synchronous discrete-time fusion problem. However, the asynchronous nature of event cameras and their unique fusion mechanism with inertial sensors remain underexplored. In this paper, we introduce a monocular event-inertial odometry method called AsynEIO, designed to fuse asynchronous event and inertial data within a unified Gaussian Process (GP) regression framework. Our approach incorporates an event-driven frontend that tracks feature trajectories directly from raw event streams at a high temporal resolution. These tracked feature trajectories, along with various inertial factors, are integrated into the same GP regression framework to enable asynchronous fusion. With deriving analytical residual Jacobians and noise models, our method constructs a factor graph that is iteratively optimized and pruned using a sliding-window optimizer. Comparative assessments highlight the performance of different inertial fusion strategies, suggesting optimal choices for varying conditions. Experimental results on both public datasets and our own event-inertial sequences indicate that AsynEIO outperforms existing methods, especially in high-speed and low-illumination scenarios.","authors":["Zhixiang Wang","Xudong Li","Yizhai Zhang","Fan Zhang","Panfeng Huang"],"pdf_url":"","comment":"20 pages, 20 figures"},{"id":"http://arxiv.org/abs/2511.18270v1","updated":"2025-11-23T03:40:37Z","published":"2025-11-23T03:40:37Z","title":"Skypilot: Fine-Tuning LLM with Physical Grounding for AAV Coverage Search","summary":"Autonomous aerial vehicles (AAVs) have played a pivotal role in coverage operations and search missions. Recent advances in large language models (LLMs) offer promising opportunities to augment AAV intelligence. These advances help address complex challenges like area coverage optimization, dynamic path planning, and adaptive decision-making. However, the absence of physical grounding in LLMs leads to hallucination and reproducibility problems in spatial reasoning and decision-making. To tackle these issues, we present Skypilot, an LLM-enhanced two-stage framework that grounds language models in physical reality by integrating monte carlo tree search (MCTS). In the first stage, we introduce a diversified action space that encompasses generate, regenerate, fine-tune, and evaluate operations, coupled with physics-informed reward functions to ensure trajectory feasibility. In the second stage, we fine-tune Qwen3-4B on 23,000 MCTS-generated samples, achieving substantial inference acceleration while maintaining solution quality. Extensive numerical simulations and real-world flight experiments validate the efficiency and superiority of our proposed approach. Detailed information and experimental results are accessible at https://sky-pilot.top.","authors":["Zhongkai Chen","Yihao Sun","Chao Yan","Han Zhou","Xiaojia Xiang","Jie Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.01119v2","updated":"2025-11-23T03:31:13Z","published":"2025-01-02T07:37:09Z","title":"Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction","summary":"Open-vocabulary panoptic reconstruction offers comprehensive scene understanding, enabling advances in embodied robotics and photorealistic simulation. In this paper, we propose PanopticRecon++, an end-to-end method that formulates panoptic reconstruction through a novel cross-attention perspective. This perspective models the relationship between 3D instances (as queries) and the scene's 3D embedding field (as keys) through their attention map. Unlike existing methods that separate the optimization of queries and keys or overlook spatial proximity, PanopticRecon++ introduces learnable 3D Gaussians as instance queries. This formulation injects 3D spatial priors to preserve proximity while maintaining end-to-end optimizability. Moreover, this query formulation facilitates the alignment of 2D open-vocabulary instance IDs across frames by leveraging optimal linear assignment with instance masks rendered from the queries. Additionally, we ensure semantic-instance segmentation consistency by fusing query-based instance segmentation probabilities with semantic probabilities in a novel panoptic head supervised by a panoptic loss. During training, the number of instance query tokens dynamically adapts to match the number of objects. PanopticRecon++ shows competitive performance in terms of 3D and 2D segmentation and reconstruction performance on both simulation and real-world datasets, and demonstrates a user case as a robot simulator. Our project website is at: https://yuxuan1206.github.io/panopticrecon_pp/","authors":["Xuan Yu","Yuxuan Xie","Yili Liu","Haojian Lu","Rong Xiong","Yiyi Liao","Yue Wang"],"pdf_url":"","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.18243v1","updated":"2025-11-23T01:29:44Z","published":"2025-11-23T01:29:44Z","title":"Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters","summary":"Current control algorithms for aerial robots struggle with robustness in dynamic environments and adverse conditions. Model-based reinforcement learning (RL) has shown strong potential in handling these challenges while remaining sample-efficient. Additionally, Dreamer has demonstrated that online model-based RL can be achieved using a recurrent world model trained on replay buffer data. However, applying Dreamer to aerial systems has been quite challenging due to its sample inefficiency and poor generalization of dynamics models. Our work explores a physics-informed approach to world model learning and improves policy performance. The world model treats the quadcopter as a free-body system and predicts the net forces and moments acting on it, which are then passed through a 6-DOF Runge-Kutta integrator (RK4) to predict future state rollouts. In this paper, we compare this physics-informed method to a standard RNN-based world model. Although both models perform well on the training data, we observed that they fail to generalize to new trajectories, leading to rapid divergence in state rollouts, preventing policy convergence.","authors":["Eashan Vytla","Bhavanishankar Kalavakolanu","Andrew Perrault","Matthew McCrink"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18236v1","updated":"2025-11-23T00:49:33Z","published":"2025-11-23T00:49:33Z","title":"APULSE: A Scalable Hybrid Algorithm for the RCSPP on Large-Scale Dense Graphs","summary":"The resource-constrained shortest path problem (RCSPP) is a fundamental NP-hard optimization challenge with broad applications, from network routing to autonomous navigation. This problem involves finding a path that minimizes a primary cost subject to a budget on a secondary resource. While various RCSPP solvers exist, they often face critical scalability limitations when applied to the large, dense graphs characteristic of complex, real-world scenarios, making them impractical for time-critical planning. This challenge is particularly acute in domains like mission planning for unmanned ground vehicles (UGVs), which demand solutions on large-scale terrain graphs. This paper introduces APULSE, a hybrid label-setting algorithm designed to efficiently solve the RCSPP on such challenging graphs. APULSE integrates a best-first search guided by an A* heuristic with aggressive, Pulse-style pruning mechanisms and a time-bucketing strategy for effective state-space reduction. A computational study, using a large-scale UGV planning scenario, benchmarks APULSE against state-of-the-art algorithms. The results demonstrate that APULSE consistently finds near-optimal solutions while being orders of magnitude faster and more robust, particularly on large problem instances where competing methods fail. This superior scalability establishes APULSE as an effective solution for RCSPP in complex, large-scale environments, enabling capabilities such as interactive decision support and dynamic replanning.","authors":["Nuno Soares","António Grilo"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2505.19574v2","updated":"2025-11-23T00:05:06Z","published":"2025-05-26T06:40:11Z","title":"Situationally-Aware Dynamics Learning","summary":"Autonomous robots operating in complex, unstructured environments face significant challenges due to latent, unobserved factors that obscure their understanding of both their internal state and the external world. Addressing this challenge would enable robots to develop a more profound grasp of their operational context. To tackle this, we propose a novel framework for online learning of hidden state representations, with which the robots can adapt in real-time to uncertain and dynamic conditions that would otherwise be ambiguous and result in suboptimal or erroneous behaviors. Our approach is formalized as a Generalized Hidden Parameter Markov Decision Process, which explicitly models the influence of unobserved parameters on both transition dynamics and reward structures. Our core innovation lies in learning online the joint distribution of state transitions, which serves as an expressive representation of latent ego- and environmental-factors. This probabilistic approach supports the identification and adaptation to different operational situations, improving robustness and safety. Through a multivariate extension of Bayesian Online Changepoint Detection, our method segments changes in the underlying data generating process governing the robot's dynamics. The robot's transition model is then informed with a symbolic representation of the current situation derived from the joint distribution of latest state transitions, enabling adaptive and context-aware decision-making. To showcase the real-world effectiveness, we validate our approach in the challenging task of unstructured terrain navigation, where unmodeled and unmeasured terrain characteristics can significantly impact the robot's motion. Extensive experiments in both simulation and real world reveal significant improvements in data efficiency, policy performance, and the emergence of safer, adaptive navigation strategies.","authors":["Alejandro Murillo-Gonzalez","Lantao Liu"],"pdf_url":"","comment":null}],"Systems and Control":[{"id":"http://arxiv.org/abs/2511.15238v2","updated":"2025-11-23T21:27:29Z","published":"2025-11-19T08:46:41Z","title":"Computing Sound and Accurate Upper and Lower Bounds on Hamilton-Jacobi Reachability Value Functions","summary":"Hamilton-Jacobi (HJ) reachability analysis is a fundamental tool for safety verification and control synthesis for nonlinear-control systems. Classical HJ reachability analysis methods discretize the continuous state space and solve the HJ partial differential equation over a grid, but these approaches do not account for discretization errors and can under-approximate backward reachable sets, which represent unsafe sets of states. We present a framework for computing sound upper and lower bounds on the HJ value functions via value iteration over grids. Additionally, we develop a refinement algorithm that splits cells that were not possible to classify as safe or unsafe given the computed bounds. This algorithm enables computing accurate over-approximations of backward reachable sets even when starting from coarse grids. Finally, we validate the effectiveness of our method in two case studies.","authors":["Ihab Tabbara","Eliya Badr","Hussein Sibai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18603v1","updated":"2025-11-23T20:09:31Z","published":"2025-11-23T20:09:31Z","title":"Bifurcation-Based Guidance Law for Powered Descent Landing","summary":"This paper develops a new guidance law for powered descent landing of a rocket-powered vehicle. The proposed law derives the acceleration command for a point mass model of the vehicle by expressing velocity as a dynamical system undergoing supercritical transcritical bifurcation with three bifurcation parameters. The parameters are designed such that the stable equilibrium points of the velocity dynamics correspond to the guided targeting state, that is, the landing point. Numerical simulations are performed to demonstrate the working of the proposed guidance law.","authors":["Neon Srinivasu","Amit Shivam","Nobin Paul"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18593v1","updated":"2025-11-23T19:27:13Z","published":"2025-11-23T19:27:13Z","title":"Generative Myopia: Why Diffusion Models Fail at Structure","summary":"Graph Diffusion Models (GDMs) optimize for statistical likelihood, implicitly acting as \\textbf{frequency filters} that favor abundant substructures over spectrally critical ones. We term this phenomenon \\textbf{Generative Myopia}. In combinatorial tasks like graph sparsification, this leads to the catastrophic removal of ``rare bridges,'' edges that are structurally mandatory ($R_{\\text{eff}} \\approx 1$) but statistically scarce. We prove theoretically and empirically that this failure is driven by \\textbf{Gradient Starvation}: the optimization landscape itself suppresses rare structural signals, rendering them unlearnable regardless of model capacity. To resolve this, we introduce \\textbf{Spectrally-Weighted Diffusion}, which re-aligns the variational objective using Effective Resistance. We demonstrate that spectral priors can be amortized into the training phase with zero inference overhead. Our method eliminates myopia, matching the performance of an optimal Spectral Oracle and achieving \\textbf{100\\% connectivity} on adversarial benchmarks where standard diffusion fails completely (0\\%).","authors":["Milad Siami"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18579v1","updated":"2025-11-23T18:44:47Z","published":"2025-11-23T18:44:47Z","title":"Connectivity-Preserving Multi-Agent Area Coverage via Optimal-Transport-Based Density-Driven Optimal Control (D2OC)","summary":"Multi-agent systems play a central role in area coverage tasks across search-and-rescue, environmental monitoring, and precision agriculture. Achieving non-uniform coverage, where spatial priorities vary across the domain, requires coordinating agents while respecting dynamic and communication constraints. Density-driven approaches can distribute agents according to a prescribed reference density, but existing methods do not ensure connectivity. This limitation often leads to communication loss, reduced coordination, and degraded coverage performance.\n  This letter introduces a connectivity-preserving extension of the Density-Driven Optimal Control (D2OC) framework. The coverage objective, defined using the Wasserstein distance between the agent distribution and the reference density, admits a convex quadratic program formulation. Communication constraints are incorporated through a smooth connectivity penalty, which maintains strict convexity, supports distributed implementation, and preserves inter-agent communication without imposing rigid formations.\n  Simulation studies show that the proposed method consistently maintains connectivity, improves convergence speed, and enhances non-uniform coverage quality compared with density-driven schemes that do not incorporate explicit connectivity considerations.","authors":["Kooktae Lee","Ethan Brook"],"pdf_url":"","comment":"Under review in IEEE Control Systems Letters (LCSS). 6 pages"},{"id":"http://arxiv.org/abs/2511.18573v1","updated":"2025-11-23T18:36:41Z","published":"2025-11-23T18:36:41Z","title":"Beyond the Expiry Date: Uncovering Hidden Value in Functional Drink Waste for a Circular Future","summary":"Expired functional drinks have great valorisation potential due to the high concentration of organic molecules present. However, detailed information of the resources in these expired functional drinks is limited, hindering the rational design of a recovery system. To address this gap, we present here a study that comprehensively characterises the chemical composition of functional drinks and discus their potential use as feedstocks for biomethane production. The example functional drinks were abundant in sugars, organic acids, and amino acids, and were especially rich in glucose, fructose, and alanine. Our studies revealed that functional drinks with high COD values that corresponded to high proportions of sugar and organic acid and low proportions of sorbitol and amino acids could realise profitable recovery through anaerobic digestion, with a minimum biomethane yield of 11.72 mL CH4 / mL drink. To assess utility further we also examined the dynamic composition of functional drinks up to 16 weeks (at 4 °C) after expiration to capture the shift in resources during deterioration. In doing so, we identified 4 distinct periods of carbon resource variation: 1) chemically stable period, 2) sorbitol degradation period, 3) sugar degradation period, and 4) acidification period. Based on the time-course biomethane production experiments for expired functional drinks, the optimal operating time window for biomethane production from drinks without ascorbic acid would be after sorbitol degradation period in terms of its economic performance through convenient natural deterioration. Therefore, this comprehensive study on dynamic chemical composition in expired functional drinks and their biomethane production potential could facilitate a rational design of resource recovery system for soft drink field.","authors":["Yiying He","Zhiqiang Zuo","Yianni Alissandratos","Penny Willson","Shameem Kazmi","Alex P. S. Brogan","Miao Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18554v1","updated":"2025-11-23T17:59:51Z","published":"2025-11-23T17:59:51Z","title":"Online Smoothed Demand Management","summary":"We introduce and study a class of online problems called online smoothed demand management $(\\texttt{OSDM})$, motivated by paradigm shifts in grid integration and energy storage for large energy consumers such as data centers. In $\\texttt{OSDM}$, an operator makes two decisions at each time step: an amount of energy to be purchased, and an amount of energy to be delivered (i.e., used for computation). The difference between these decisions charges (or discharges) the operator's energy storage (e.g., a battery). Two types of demand arrive online: base demand, which must be covered at the current time, and flexible demand, which can be satisfied at any time steps before a demand-specific deadline $Δ_t$. The operator's goal is to minimize a cost (subject to the constraints above) that combines a cost of purchasing energy, a cost for delivering energy (if applicable), and smoothness penalties on the purchasing and delivery rates to discourage fluctuations and encourage ``grid healthy'' decisions. $\\texttt{OSDM}$ generalizes several problems in the online algorithms literature while being the first to fully model applications of interest. We propose a competitive algorithm called $\\texttt{PAAD}$ (partitioned accounting \\& aggregated decisions) and show it achieves the optimal competitive ratio. To overcome the pessimism typical of worst-case analysis, we also propose a novel learning framework that provides guarantees on the worst-case competitive ratio (i.e., to provide robustness against nonstationarity) while allowing end-to-end differentiable learning of the best algorithm on historical instances of the problem. We evaluate our algorithms in a case study of a grid-integrated data center with battery storage, showing that $\\texttt{PAAD}$ effectively solves the problem and end-to-end learning achieves substantial performance improvements compared to $\\texttt{PAAD}$.","authors":["Adam Lechowicz","Nicolas Christianson","Mohammad Hajiesmaili","Adam Wierman","Prashant Shenoy"],"pdf_url":"","comment":"69 pages, 12 figures"},{"id":"http://arxiv.org/abs/2511.18551v1","updated":"2025-11-23T17:42:35Z","published":"2025-11-23T17:42:35Z","title":"Dissipativity and L2 Stability of Large-Scale Networks with Changing Interconnections","summary":"In this paper, the L2 stability of switched networks is studied based on the QSR-dissipativity of each agent. While the integration of dissipativity with switched systems has received considerable attention, most previous studies have focused on passivity, internal stability, or feedback networks involving only two agents. This work makes two contributions: first, the relationship between switched QSR-dissipativity and L2 stability is established based on the properties of dissipativity parameters of switched systems; and second, conditions for L2 stability of networks consisting of QSR-dissipative agents with switching interconnection topologies are derived. Crucially, this shows that a common storage function will exist across all modes, avoiding the need to find one, which becomes computationally taxing for large networks with many possible configurations. Numerical examples demonstrate how this can facilitate stability analysis for networked systems under arbitrary switching of swarm drones.","authors":["Ingyu Jang","Leila J. Bridgeman"],"pdf_url":"","comment":"Under review for IFAC 2026. 6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2511.18486v1","updated":"2025-11-23T15:14:39Z","published":"2025-11-23T15:14:39Z","title":"Expanding the Workspace of Electromagnetic Navigation Systems Using Dynamic Feedback for Single- and Multi-agent Control","summary":"Electromagnetic navigation systems (eMNS) enable a number of magnetically guided surgical procedures. A challenge in magnetically manipulating surgical tools is that the effective workspace of an eMNS is often severely constrained by power and thermal limits. We show that system-level control design significantly expands this workspace by reducing the currents needed to achieve a desired motion. We identified five key system approaches that enable this expansion: (i) motion-centric torque/force objectives, (ii) energy-optimal current allocation, (iii) real-time pose estimation, (iv) dynamic feedback, and (v) high-bandwidth eMNS components. As a result, we stabilize a 3D inverted pendulum on an eight-coil OctoMag eMNS with significantly lower currents (0.1-0.2 A vs. 8-14 A), by replacing a field-centric field-alignment strategy with a motion-centric torque/force-based approach. We generalize to multi-agent control by simultaneously stabilizing two inverted pendulums within a shared workspace, exploiting magnetic-field nonlinearity and coil redundancy for independent actuation. A structured analysis compares the electromagnetic workspaces of both paradigms and examines current-allocation strategies that map motion objectives to coil currents. Cross-platform evaluation of the clinically oriented Navion eMNS further demonstrates substantial workspace expansion by maintaining stable balancing at distances up to 50 cm from the coils. The results demonstrate that feedback is a practical path to scalable, efficient, and clinically relevant magnetic manipulation.","authors":["Jasan Zughaibi","Denis von Arx","Maurus Derungs","Florian Heemeyer","Luca A. Antonelli","Quentin Boehler","Michael Muehlebach","Bradley J. Nelson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18445v1","updated":"2025-11-23T13:36:12Z","published":"2025-11-23T13:36:12Z","title":"Speed Control Security System For safety of Driver and Surroundings","summary":"The speed control security system is best suited for the task of slowing the speed of a vehicle during rash driving as the Driver is over speeding the circuit captures the images of the lanes witch decides the speed of the road the car is currently on this input is further provided to the ESP-32 micro Prosser module in the car switch compiles this data with the data received for the RPM sensor of the car and decides whether the car is over speeding or not in case of over speeding a signal is send by the ESP to the Arduino witch actuates the dc motor used in the car to reduce the speed of the car by the use of a hydraulic brake system actuated by a DC motor.","authors":["Vishesh Vishal Ahire","Yash Badrinarayan Amle","Akshada Nanasaheb Waditke","Ojas Nitin Ahire","Amey Mahesh Warnekar","Ayush Ganesh Ahire","Prashant Anerao"],"pdf_url":"","comment":"9 Pages , 7 figures"},{"id":"http://arxiv.org/abs/2511.18428v1","updated":"2025-11-23T12:50:15Z","published":"2025-11-23T12:50:15Z","title":"Joint Optimization for Security and Reliability in Round-Trip Transmissions for URLLC services","summary":"Physical layer security (PLS) is a potential solution for secure and reliable transmissions in future Ultra-Reliable and Low-Latency Communications (URLLC). This work jointly optimizes redundant bits and blocklength allocation in practical round-trip transmission scenarios. To minimize the leakage-failure probability, a metric that jointly characterizes security and reliability in PLS, we formulate an optimization problem for allocating both redundant bits and blocklength. By deriving the boundaries of the feasible set, we obtain the globally optimal solution for this integer optimization problem. To achieve more computationally efficient solutions, we propose a block coordinate descent (BCD) method that exploits the partial convexity of the objective function. Subsequently, we develop a majorization-minimization (MM) algorithm through convex approximation of the objective function, which further improves computational efficiency. Finally, we validate the performance of the three proposed approaches through simulations, demonstrating their practical applicability for future URLLC services.","authors":["Xinyan Le","Yao Zhu","Yulin Hu","Bin Han"],"pdf_url":"","comment":"6 pages,4 figures"},{"id":"http://arxiv.org/abs/2509.00182v2","updated":"2025-11-23T12:38:01Z","published":"2025-08-29T18:30:54Z","title":"Newton-Flow Particle Filters based on Generalized Cramér Distance","summary":"We propose a recursive particle filter for high-dimensional problems that inherently never degenerates. The state estimate is represented by deterministic low-discrepancy particle sets. We focus on the measurement update step, where a likelihood function is used for representing the measurement and its uncertainty. This likelihood is progressively introduced into the filtering procedure by homotopy continuation over an artificial time. A generalized Cramér distance between particle sets is derived in closed form that is differentiable and invariant to particle order. A Newton flow then continually minimizes this distance over artificial time and thus smoothly moves particles from prior to posterior density. The new filter is surprisingly simple to implement and very efficient. It just requires a prior particle set and a likelihood function, never estimates densities from samples, and can be used as a plugin replacement for classic approaches.","authors":["Uwe D. Hanebeck"],"pdf_url":"","comment":"8 pages; typos corrected, small changes"},{"id":"http://arxiv.org/abs/2511.18418v1","updated":"2025-11-23T12:12:55Z","published":"2025-11-23T12:12:55Z","title":"Aspiration-based Perturbed Learning Automata in Games with Noisy Utility Measurements. Part B: Stochastic Stability in Weakly Acyclic Games","summary":"Reinforcement-based learning dynamics may exhibit several limitations when applied in a distributed setup. In (repeatedly-played) multi-player/action strategic-form games, and when each player applies an independent copy of the learning dynamics, convergence to (usually desirable) pure Nash equilibria cannot be guaranteed. Prior work has only focused on a small class of games, namely potential and coordination games. Furthermore, strong convergence guarantees (i.e., almost sure convergence or weak convergence) are mostly restricted to two-player games. To address this main limitation of reinforcement-based learning in repeatedly-played strategic-form games, this paper introduces a novel payoff-based learning scheme for distributed optimization in multi-player/action strategic-form games. We present an extension of perturbed learning automata (PLA), namely aspiration-based perturbed learning automata (APLA), in which each player's probability distribution for selecting actions is reinforced both by repeated selection and an aspiration factor that captures the player's satisfaction level. We provide a stochastic stability analysis of APLA in multi-player positive-utility games under the presence of noisy observations. This paper is the second part of this study that analyzes stochastic stability in multi-player/action weakly-acyclic games in the presence of noisy observations. We provide conditions under which convergence is attained (in weak sense) to the set of pure Nash equilibria and payoff-dominant equilibria. To the best of our knowledge, this is the first reinforcement-based learning scheme that addresses convergence in weakly-acyclic games. Lastly, we provide a specialization of the results to the classical Stag-Hunt game, supported by a simulation study.","authors":["Georgios C. Chasparis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18390v1","updated":"2025-11-23T10:28:26Z","published":"2025-11-23T10:28:26Z","title":"On Linear Convergence of Distributed Stochastic Bilevel Optimization over Undirected Networks via Gradient Aggregation","summary":"Many large-scale constrained optimization problems can be formulated as bilevel distributed optimization tasks over undirected networks, where agents collaborate to minimize a global cost function while adhering to constraints, relying only on local communication and computation. In this work, we propose a distributed stochastic gradient aggregation scheme and establish its linear convergence under the weak assumption of global strong convexity, which relaxes the common requirement of local function convexity on the objective and constraint functions. Specifically, we prove that the algorithm converges at a linear rate when the global objective function (and not each local objective function) satisfies strong-convexity. Our results significantly extend existing theoretical guarantees for distributed bilevel optimization. Additionally, we demonstrate the effectiveness of our approach through numerical experiments on distributed sensor network problems and distributed linear regression with rank-deficient data.","authors":["Ajay Tak","Mayank Baranwal"],"pdf_url":"","comment":"8 pages, submitted to ACC"},{"id":"http://arxiv.org/abs/2511.18374v1","updated":"2025-11-23T09:48:41Z","published":"2025-11-23T09:48:41Z","title":"Explicit Bounds on the Hausdorff Distance for Truncated mRPI Sets via Norm-Dependent Contraction Rates","summary":"This paper establishes the first explicit and closed-form upper bound on the Hausdorff distance between the truncated minimal robust positively invariant (mRPI) set and its infinite-horizon limit. While existing mRPI approximations guarantee asymptotic convergence through geometric or norm-based arguments, none provides a computable expression that quantifies the truncation error for a given horizon. We show that the error satisfies \\( d_H(\\mathcal{E}_N,\\mathcal{E}_\\infty) \\le r_W\\,γ^{N+1}/(1-γ), \\) where $γ<1$ is the induced-norm contraction factor and $r_W$ depends only on the disturbance set. The bound is fully analytic, requires no iterative set computations, and directly characterizes the decay rate of the truncated Minkowski series. We further demonstrate that the choice of vector norm serves as a design parameter that accelerates convergence, enabling substantially tighter horizon selection for robust invariant-set computations and tube-based MPC. Numerical experiments validate the sharpness, scalability, and practical relevance of the proposed bound.","authors":["Jiaxun Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.07953v7","updated":"2025-11-23T09:14:07Z","published":"2025-07-10T17:38:52Z","title":"Incremental Collision Laws Based on the Bouc-Wen Model: Improved Collision Models and Further Results","summary":"In the article titled \"The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies\" and published in the Journal of Computational and Nonlinear Dynamics (Volume 20, Issue 6, June 2025), the authors studied mathematical models of binary direct collinear collisions of convex viscoplastic bodies that employed two incremental collision laws based on the Bouc-Wen differential model of hysteresis. It was shown that the models possess favorable analytical properties, and several model parameter identification studies were conducted, demonstrating that the models can accurately capture the nature of a variety of collision phenomena. In this article, the aforementioned models are augmented by modeling the effects of external forces as time-dependent inputs. Furthermore, the range of the parameters under which the models possess favorable analytical properties is extended to several corner cases that were not considered in the prior publication. Finally, the previously conducted model parameter identification studies are extended, and an additional model parameter identification study is provided in an attempt to validate the ability of the augmented models to represent the effects of external forces.","authors":["Mihails Milehins","Dan B. Marghitu"],"pdf_url":"","comment":"14 pages, 9 figures, see https://gitlab.com/user9716869/EBWCM ; (v2-v7) various minor amendments; (v5) replaced the parameter identification study of Quinn (2004) with Villegas et al (2021) due to incompatibility of the proposed collision models with the experimental setup in Quinn (2004); (v7) added ODEs for COM and an application example; arXiv admin note: text overlap with arXiv:2410.08147"},{"id":"http://arxiv.org/abs/2509.20788v3","updated":"2025-11-23T09:03:11Z","published":"2025-09-25T06:14:26Z","title":"Revealing Chaotic Dependence and Degree-Structure Mechanisms in Optimal Pinning Control of Complex Networks","summary":"Identifying an optimal set of driver nodes to achieve synchronization via pinning control is a fundamental challenge in complex network science, limited by computational intractability and the lack of general theory. Here, leveraging a degree-based mean-field (annealed) approximation from statistical physics, we analytically reveal how the structural degree distribution systematically governs synchronization performance, and derive an analytic characterization of the globally optimal pinning set and constructive algorithms with linear complexity (dominated by degree sorting, O(N+M). The optimal configuration exhibits a chaotic dependence--a discontinuous sensitivity--on its cardinality, whereby adding a single node can trigger abrupt changes in node composition and control effectiveness. This structural transition fundamentally challenges traditional heuristics that assume monotonic performance gains with budget. Systematic experiments on synthetic and empirical networks confirm that the proposed approach consistently outperforms degree-, betweenness-, and other centrality-based baselines. Furthermore, we quantify how key degree-distribution features--low-degree saturation, high-degree cutoff, and the power-law exponent--govern achievable synchronizability and shape the form of optimal sets. These results offer a systematic understanding of how degree heterogeneity shapes the network controllability. Our work establishes a unified link between degree heterogeneity and spectral controllability, offering both mechanistic insights and practical design rules for optimal driver-node selection in diverse complex systems.","authors":["Qingyang Liu","Tianlong Fan","Liming Pan","Linyuan Lü"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2510.20152v3","updated":"2025-11-23T08:25:36Z","published":"2025-10-23T03:00:04Z","title":"Soft Switching Expert Policies for Controlling Systems with Uncertain Parameters","summary":"This paper proposes a simulation-based reinforcement learning algorithm for controlling systems with uncertain and varying system parameters. While simulators are useful to safely synthesize control policies for physical systems using reinforcement learning, mitigating the reality gap remains a major challenge. To address the challenge, we propose a two-stage algorithm. In the first stage, multiple control policies are learned for systems with different parameters in a simulator. In the second stage, for a real system, the control policies learned in the first stage are smoothly switched using an online convex optimization algorithm based on observations. Our proposed algorithm is demonstrated through numerical experiments.","authors":["Junya Ikemoto"],"pdf_url":"","comment":"7 pages, 8 figures. Submitted to an International Conference"},{"id":"http://arxiv.org/abs/2511.18319v1","updated":"2025-11-23T07:18:28Z","published":"2025-11-23T07:18:28Z","title":"Weakly-supervised Latent Models for Task-specific Visual-Language Control","summary":"Autonomous inspection in hazardous environments requires AI agents that can interpret high-level goals and execute precise control. A key capability for such agents is spatial grounding, for example when a drone must center a detected object in its camera view to enable reliable inspection. While large language models provide a natural interface for specifying goals, using them directly for visual control achieves only 58\\% success in this task. We envision that equipping agents with a world model as a tool would allow them to roll out candidate actions and perform better in spatially grounded settings, but conventional world models are data and compute intensive. To address this, we propose a task-specific latent dynamics model that learns state-specific action-induced shifts in a shared latent space using only goal-state supervision. The model leverages global action embeddings and complementary training losses to stabilize learning. In experiments, our approach achieves 71\\% success and generalizes to unseen images and instructions, highlighting the potential of compact, domain-specific latent dynamics models for spatial alignment in autonomous inspection.","authors":["Xian Yeow Lee","Lasitha Vidyaratne","Gregory Sin","Ahmed Farahat","Chetan Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.12535v3","updated":"2025-11-23T06:06:14Z","published":"2024-05-21T06:58:00Z","title":"PhiBE: A PDE-based Bellman Equation for Continuous Time Policy Evaluation","summary":"In this paper, we study policy evaluation in continuous-time reinforcement learning, where the state follows an unknown stochastic differential equation (SDE) but only discrete-time data are available. We first highlight that the discrete-time Bellman equation (BE) is not always a reliable approximation to the true value function because it ignores the underlying continuous-time structure. We then introduce a new bellman equation, PhiBE, which integrates the discrete-time information into a continuous-time PDE formulation. By leveraging the smooth SDE structure of the underlying dynamics, PhiBE provides a provably more accurate approximation to the true value function, especially in scenarios where the underlying dynamics change slowly or the reward oscillates. Moreover, we extend PhiBE to higher orders, providing increasingly accurate approximations. We further develop a model-free algorithm for PhiBE under linear function approximation and establish its convergence under model misspecification. In contrast to existing RL analyses that diverges as the sampling interval shrinks, the approximation error of PhiBE remains remains well-conditioned and independent of the discretization step by exploiting the smoothness of the underlying dynamics. Numerical experiments are provided to validate the theoretical guarantees we propose.","authors":["Yuhua Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.08909v2","updated":"2025-11-23T05:14:33Z","published":"2024-12-12T03:45:07Z","title":"Continuous Gaussian Process Pre-Optimization for Asynchronous Event-Inertial Odometry","summary":"Event cameras, as bio-inspired sensors, are asynchronously triggered with high-temporal resolution compared to intensity cameras. Recent work has focused on fusing the event measurements with inertial measurements to enable ego-motion estimation in high-speed and HDR environments. However, existing methods predominantly rely on IMU preintegration designed mainly for synchronous sensors and discrete-time frameworks. In this paper, we propose a continuous-time preintegration method based on the Temporal Gaussian Process (TGP) called GPO. Concretely, we model the preintegration as a time-indexed motion trajectory and leverage an efficient two-step optimization to initialize the precision preintegration pseudo-measurements. Our method realizes a linear and constant time cost for initialization and query, respectively. To further validate the proposal, we leverage the GPO to design an asynchronous event-inertial odometry and compare with other asynchronous fusion schemes within the same odometry system. Experiments conducted on both public and own-collected datasets demonstrate that the proposed GPO offers significant advantages in terms of precision and efficiency, outperforming existing approaches in handling asynchronous sensor fusion.","authors":["Zhixiang Wang","Xudong Li","Yizhai Zhang","Fan Zhang","Panfeng Huang"],"pdf_url":"","comment":"8pages"},{"id":"http://arxiv.org/abs/2511.18267v1","updated":"2025-11-23T03:33:08Z","published":"2025-11-23T03:33:08Z","title":"Laboratory and field testing of a residential heat pump retrofit for a DC solar nanogrid","summary":"Residential buildings are increasingly integrating large devices that run natively on direct current (DC), such as solar photovoltaics, electric vehicles, stationary batteries, and DC motors that drive heat pumps and other major appliances. Today, these natively-DC devices typically connect within buildings through alternating current (AC) distribution systems, entailing significant energy losses due to conversions between AC and DC. This paper investigates the alternative of connecting DC devices through DC distribution. Specifically, this paper shows through laboratory and field experiments that an off-the-shelf residential heat pump designed for conventional AC systems can be powered directly on DC with few hardware modifications and little change in performance. Supporting simulations of a DC nanogrid including historical heat pump and rest-of-house load measurements, a solar photovoltaic array, and a stationary battery suggest that connecting these devices through DC distribution could decrease annual electricity bills by 12.5% with an after-market AC-to-DC heat pump retrofit and by 16.7% with a heat pump designed to run on DC.","authors":["Aaron H. P. Farha","Jonathan P. Ore","Elias N. Pergantis","Davide Ziviani","Eckhard A. Groll","Kevin J. Kircher"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2202.02419v3","updated":"2025-11-23T01:17:08Z","published":"2022-02-04T22:39:03Z","title":"Learning to Admit Optimally in an $M/M/k/k+N$ Queueing System with Unknown Service Rate","summary":"Motivated by applications of the Erlang-B blocking model and the extended $M/M/k/k+N$ model that allows for some queueing, beyond communication networks to sizing and pricing in production, messaging, and app-based parking systems, we study admission control for such systems with unknown service rate. In our model, a dispatcher either admits every arrival into the system (when there is room) or blocks it. Every served job yields a fixed reward but incurs a per unit time holding cost which includes the waiting time in the queue to get service if there is any. We aim to design a dispatching policy that maximizes the long-term average reward by observing arrival times and system state at arrivals, a realistic decision-event driven sampling of such systems. The dispatcher observes neither service times nor departure epochs, which excludes the use of reward-based reinforcement learning approaches. We develop our learning-based dispatch scheme as a parametric learning problem a'la self-tuning adaptive control. In our problem, certainty equivalent control switches between always admit if room (explore infinitely often), and never admit (terminate learning), so at judiciously chosen times we avoid the never admit recommendation. We prove that our proposed policy asymptotically converges to the optimal policy and present finite-time regret guarantees. The extreme contrast in the control policies shows up in our regret bounds for different parameter regimes: constant in one versus logarithmic in another.","authors":["Saghar Adler","Mehrdad Moharrami","Vijay Subramanian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18236v1","updated":"2025-11-23T00:49:33Z","published":"2025-11-23T00:49:33Z","title":"APULSE: A Scalable Hybrid Algorithm for the RCSPP on Large-Scale Dense Graphs","summary":"The resource-constrained shortest path problem (RCSPP) is a fundamental NP-hard optimization challenge with broad applications, from network routing to autonomous navigation. This problem involves finding a path that minimizes a primary cost subject to a budget on a secondary resource. While various RCSPP solvers exist, they often face critical scalability limitations when applied to the large, dense graphs characteristic of complex, real-world scenarios, making them impractical for time-critical planning. This challenge is particularly acute in domains like mission planning for unmanned ground vehicles (UGVs), which demand solutions on large-scale terrain graphs. This paper introduces APULSE, a hybrid label-setting algorithm designed to efficiently solve the RCSPP on such challenging graphs. APULSE integrates a best-first search guided by an A* heuristic with aggressive, Pulse-style pruning mechanisms and a time-bucketing strategy for effective state-space reduction. A computational study, using a large-scale UGV planning scenario, benchmarks APULSE against state-of-the-art algorithms. The results demonstrate that APULSE consistently finds near-optimal solutions while being orders of magnitude faster and more robust, particularly on large problem instances where competing methods fail. This superior scalability establishes APULSE as an effective solution for RCSPP in complex, large-scale environments, enabling capabilities such as interactive decision support and dynamic replanning.","authors":["Nuno Soares","António Grilo"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2511.19505v1","updated":"2025-11-23T22:00:54Z","published":"2025-11-23T22:00:54Z","title":"Sequential Convex Programming for Multimode Spacecraft Trajectory Optimization","summary":"Spacecraft equipped with multiple propulsion modes or systems can offer enhanced performance and mission flexibility compared with traditional configurations. Despite these benefits, the trajectory optimization of spacecraft utilizing such configurations remains a complex challenge. This paper presents a sequential convex programming (SCP) approach for the optimal design of multi-mode and multi-propulsion spacecraft trajectories. The method extends the dynamical linearization within SCP using sparse automatic differentiation, enabling efficient inclusion of multiple propulsion modes or systems without complex manual reformulation while maintaining comparable computational efficiency. New constraint formulations are introduced to ensure selection of a single propulsion mode at each time step and limit the total number of modes used. The approach is demonstrated for (i) a low-thrust Earth-67P rendezvous using the SPT-140 thruster with 20 discrete modes, and (ii) an Earth-Mars transfer employing both a low-thrust engine and a solar sail. Results confirm that the proposed method can efficiently compute optimal trajectories for these scenarios.","authors":["Jack Yarndley"],"pdf_url":"","comment":"12 pages, 5 figures, presented at the ORSNZ Annual Conference 2025"}]},"2025-11-22T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2511.18215v1","updated":"2025-11-22T23:14:30Z","published":"2025-11-22T23:14:30Z","title":"AFT: Appearance-Based Feature Tracking for Markerless and Training-Free Shape Reconstruction of Soft Robots","summary":"Accurate shape reconstruction is essential for precise control and reliable operation of soft robots. Compared to sensor-based approaches, vision-based methods offer advantages in cost, simplicity, and ease of deployment. However, existing vision-based methods often rely on complex camera setups, specific backgrounds, or large-scale training datasets, limiting their practicality in real-world scenarios. In this work, we propose a vision-based, markerless, and training-free framework for soft robot shape reconstruction that directly leverages the robot's natural surface appearance. These surface features act as implicit visual markers, enabling a hierarchical matching strategy that decouples local partition alignment from global kinematic optimization. Requiring only an initial 3D reconstruction and kinematic alignment, our method achieves real-time shape tracking across diverse environments while maintaining robustness to occlusions and variations in camera viewpoints. Experimental validation on a continuum soft robot demonstrates an average tip error of 2.6% during real-time operation, as well as stable performance in practical closed-loop control tasks. These results highlight the potential of the proposed approach for reliable, low-cost deployment in dynamic real-world settings.","authors":["Shangyuan Yuan","Preston Fairchild","Yu Mei","Xinyu Zhou","Xiaobo Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02162v4","updated":"2025-11-22T22:47:57Z","published":"2025-11-04T01:02:21Z","title":"Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models","summary":"Advances in 3D generative AI have enabled the creation of physical objects from text prompts, but challenges remain in creating objects involving multiple component types. We present a pipeline that integrates 3D generative AI with vision-language models (VLMs) to enable the robotic assembly of multi-component objects from natural language. Our method leverages VLMs for zero-shot, multi-modal reasoning about geometry and functionality to decompose AI-generated meshes into multi-component 3D models using predefined structural and panel components. We demonstrate that a VLM is capable of determining which mesh regions need panel components in addition to structural components, based on the object's geometry and functionality. Evaluation across test objects shows that users preferred the VLM-generated assignments 90.6% of the time, compared to 59.4% for rule-based and 2.5% for random assignment. Lastly, the system allows users to refine component assignments through conversational feedback, enabling greater human control and agency in making physical objects with generative AI and robotics.","authors":["Alexander Htet Kyaw","Richa Gupta","Dhruv Shah","Anoop Sinha","Kory Mathewson","Stefanie Pender","Sachin Chitta","Yotto Koga","Faez Ahmed","Lawrence Sass","Randall Davis"],"pdf_url":"","comment":"Accepted to NeurIPS 2025, Conference on Neural Information Processing Systems, Creative AI Track"},{"id":"http://arxiv.org/abs/2511.18203v1","updated":"2025-11-22T22:25:11Z","published":"2025-11-22T22:25:11Z","title":"SkillWrapper: Generative Predicate Invention for Skill Abstraction","summary":"Generalizing from individual skill executions to solving long-horizon tasks remains a core challenge in building autonomous agents. A promising direction is learning high-level, symbolic abstractions of the low-level skills of the agents, enabling reasoning and planning independent of the low-level state space. Among possible high-level representations, object-centric skill abstraction with symbolic predicates has been proven to be efficient because of its compatibility with domain-independent planners. Recent advances in foundation models have made it possible to generate symbolic predicates that operate on raw sensory inputs, a process we call generative predicate invention, to facilitate downstream abstraction learning. However, it remains unclear which formal properties the learned representations must satisfy, and how they can be learned to guarantee these properties. In this paper, we address both questions by presenting a formal theory of generative predicate invention for skill abstraction, resulting in symbolic operators that can be used for provably sound and complete planning. Within this framework, we propose SkillWrapper, a method that leverages foundation models to actively collect robot data and learn human-interpretable, plannable representations of black-box skills, using only RGB image observations. Our extensive empirical evaluation in simulation and on real robots shows that SkillWrapper learns abstract representations that enable solving unseen, long-horizon tasks in the real world with black-box skills.","authors":["Ziyi Yang","Benned Hedegaard","Ahmed Jaafar","Yichen Wei","Skye Thompson","Shreyas S. Raman","Haotian Fu","Stefanie Tellex","George Konidaris","David Paulius","Naman Shah"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10936v2","updated":"2025-11-22T22:09:54Z","published":"2025-08-12T19:50:34Z","title":"Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction","summary":"Collaborative perception enables connected vehicles to share information, overcoming occlusions and extending the limited sensing range inherent in single-agent (non-collaborative) systems. Existing vision-only methods for 3D semantic occupancy prediction commonly rely on dense 3D voxels, which incur high communication costs, or 2D planar features, which require accurate depth estimation or additional supervision, limiting their applicability to collaborative scenarios. To address these challenges, we propose the first approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D semantic occupancy prediction. By sharing and fusing intermediate Gaussian primitives, our method provides three benefits: a neighborhood-based cross-agent fusion that removes duplicates and suppresses noisy or inconsistent Gaussians; a joint encoding of geometry and semantics in each primitive, which reduces reliance on depth supervision and allows simple rigid alignment; and sparse, object-centric messages that preserve structural information while reducing communication volume. Extensive experiments demonstrate that our approach outperforms single-agent perception and baseline collaborative methods by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU, respectively. When further reducing the number of transmitted Gaussians, our method still achieves a +1.9 improvement in mIoU, using only 34.6% communication volume, highlighting robust performance under limited communication budgets.","authors":["Cheng Chen","Hao Huang","Saurabh Bagchi"],"pdf_url":"","comment":"Accepted by AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2508.01192v2","updated":"2025-11-22T21:47:46Z","published":"2025-08-02T04:42:34Z","title":"Unified Generation-Refinement Planning: Bridging Guided Flow Matching and Sampling-Based MPC for Social Navigation","summary":"Planning safe and effective robot behavior in dynamic, human-centric environments remains a core challenge due to the need to handle multimodal uncertainty, adapt in real-time, and ensure safety. Optimization-based planners offer explicit constraint handling but performance relies on initialization quality. Learning-based planners better capture multimodal possible solutions but struggle to enforce constraints such as safety. In this paper, we introduce a unified generation-refinement framework bridging learning and optimization with a novel reward-guided conditional flow matching (CFM) model and model predictive path integral (MPPI) control. Our key innovation is in the incorporation of a bidirectional information exchange: samples from a reward-guided CFM model provide informed priors for MPPI refinement, while the optimal trajectory from MPPI warm-starts the next CFM generation. Using autonomous social navigation as a motivating application, we demonstrate that our approach can flexibly adapt to dynamic environments to satisfy safety requirements in real-time.","authors":["Kazuki Mizuta","Karen Leung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18183v1","updated":"2025-11-22T20:39:31Z","published":"2025-11-22T20:39:31Z","title":"Off-Road Navigation via Implicit Neural Representation of Terrain Traversability","summary":"Autonomous off-road navigation requires robots to estimate terrain traversability from onboard sensors and plan accordingly. Conventional approaches typically rely on sampling-based planners such as MPPI to generate short-term control actions that aim to minimize traversal time and risk measures derived from the traversability estimates. These planners can react quickly but optimize only over a short look-ahead window, limiting their ability to reason about the full path geometry, which is important for navigating in challenging off-road environments. Moreover, they lack the ability to adjust speed based on the terrain bumpiness, which is important for smooth navigation on challenging terrains. In this paper, we introduce TRAIL (Traversability with an Implicit Learned Representation), an off-road navigation framework that leverages an implicit neural representation to continuously parameterize terrain properties. This representation yields spatial gradients that enable integration with a novel gradient-based trajectory optimization method that adapts the path geometry and speed profile based on terrain traversability.","authors":["Yixuan Jia","Qingyuan Li","Jonathan P. How"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2511.18170v1","updated":"2025-11-22T19:51:10Z","published":"2025-11-22T19:51:10Z","title":"Time-aware Motion Planning in Dynamic Environments with Conformal Prediction","summary":"Safe navigation in dynamic environments remains challenging due to uncertain obstacle behaviors and the lack of formal prediction guarantees. We propose two motion planning frameworks that leverage conformal prediction (CP): a global planner that integrates Safe Interval Path Planning (SIPP) for uncertainty-aware trajectory generation, and a local planner that performs online reactive planning. The global planner offers distribution-free safety guarantees for long-horizon navigation, while the local planner mitigates inaccuracies in obstacle trajectory predictions through adaptive CP, enabling robust and responsive motion in dynamic environments. To further enhance trajectory feasibility, we introduce an adaptive quantile mechanism in the CP-based uncertainty quantification. Instead of using a fixed confidence level, the quantile is automatically tuned to the optimal value that preserves trajectory feasibility, allowing the planner to adaptively tighten safety margins in regions with higher uncertainty. We validate the proposed framework through numerical experiments conducted in dynamic and cluttered environments. The project page is available at https://time-aware-planning.github.io","authors":["Kaier Liang","Licheng Luo","Yixuan Wang","Mingyu Cai","Cristian Ioan Vasile"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18157v1","updated":"2025-11-22T18:52:34Z","published":"2025-11-22T18:52:34Z","title":"scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python","summary":"Three-dimensional rigid-body transforms, i.e. rotations and translations, are central to modern differentiable machine learning pipelines in robotics, vision, and simulation. However, numerically robust and mathematically correct implementations, particularly on SO(3), are error-prone due to issues such as axis conventions, normalizations, composition consistency and subtle errors that only appear in edge cases. SciPy's spatial.transform module is a rigorously tested Python implementation. However, it historically only supported NumPy, limiting adoption in GPU-accelerated and autodiff-based workflows. We present a complete overhaul of SciPy's spatial.transform functionality that makes it compatible with any array library implementing the Python array API, including JAX, PyTorch, and CuPy. The revised implementation preserves the established SciPy interface while enabling GPU/TPU execution, JIT compilation, vectorized batching, and differentiation via native autodiff of the chosen backend. We demonstrate how this foundation supports differentiable scientific computing through two case studies: (i) scalability of 3D transforms and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation for accurate integration of rotational dynamics. Our contributions have been merged into SciPy main and will ship in the next release, providing a framework-agnostic, production-grade basis for 3D spatial math in differentiable systems and ML.","authors":["Martin Schuck","Alexander von Rohr","Angela P. Schoellig"],"pdf_url":"","comment":"Accepted as oral at the 1st Workshop on Differentiable Systems and Scientific Machine Learning @ EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.18153v1","updated":"2025-11-22T18:50:35Z","published":"2025-11-22T18:50:35Z","title":"A Coordinated Dual-Arm Framework for Delicate Snap-Fit Assemblies","summary":"Delicate snap-fit assemblies, such as inserting a lens into an eye-wear frame or during electronics assembly, demand timely engagement detection and rapid force attenuation to prevent overshoot-induced component damage or assembly failure. We address these challenges with two key contributions. First, we introduce SnapNet, a lightweight neural network that detects snap-fit engagement from joint-velocity transients in real-time, showing that reliable detection can be achieved using proprioceptive signals without external sensors. Second, we present a dynamical-systems-based dual-arm coordination framework that integrates SnapNet driven detection with an event-triggered impedance modulation, enabling accurate alignment and compliant insertion during delicate snap-fit assemblies. Experiments across diverse geometries on a heterogeneous bimanual platform demonstrate high detection accuracy (over 96% recall) and up to a 30% reduction in peak impact forces compared to standard impedance control.","authors":["Shreyas Kumar","Barat S","Debojit Das","Yug Desai","Siddhi Jain","Rajesh Kumar","Harish J. Palanthandalam-Madapusi"],"pdf_url":"","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.18140v1","updated":"2025-11-22T17:53:16Z","published":"2025-11-22T17:53:16Z","title":"Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting","summary":"We propose Observer Actor (ObAct), a novel framework for active vision imitation learning in which the observer moves to optimal visual observations for the actor. We study ObAct on a dual-arm robotic system equipped with wrist-mounted cameras. At test time, ObAct dynamically assigns observer and actor roles: the observer arm constructs a 3D Gaussian Splatting (3DGS) representation from three images, virtually explores this to find an optimal camera pose, then moves to this pose; the actor arm then executes a policy using the observer's observations. This formulation enhances the clarity and visibility of both the object and the gripper in the policy's observations. As a result, we enable the training of ambidextrous policies on observations that remain closer to the occlusion-free training distribution, leading to more robust policies. We study this formulation with two existing imitation learning methods -- trajectory transfer and behavior cloning -- and experiments show that ObAct significantly outperforms static-camera setups: trajectory transfer improves by 145% without occlusion and 233% with occlusion, while behavior cloning improves by 75% and 143%, respectively. Videos are available at https://obact.github.io.","authors":["Yilong Wang","Cheng Qian","Ruomeng Fan","Edward Johns"],"pdf_url":"","comment":"Videos are available on our project webpage at https://obact.github.io"},{"id":"http://arxiv.org/abs/2503.02387v3","updated":"2025-11-22T17:12:13Z","published":"2025-03-04T08:23:01Z","title":"RGBSQGrasp: Inferring Local Superquadric Primitives from Single RGB Image for Graspability-Aware Bin Picking","summary":"Bin picking is a challenging robotic task due to occlusions and physical constraints that limit visual information for object recognition and grasping. Existing approaches often rely on known CAD models or prior object geometries, restricting generalization to novel or unknown objects. Other methods directly regress grasp poses from RGB-D data without object priors, but the inherent noise in depth sensing and the lack of object understanding make grasp synthesis and evaluation more difficult. Superquadrics (SQ) offer a compact, interpretable shape representation that captures the physical and graspability understanding of objects. However, recovering them from limited viewpoints is challenging, as existing methods rely on multiple perspectives for near-complete point cloud reconstruction, limiting their effectiveness in bin-picking. To address these challenges, we propose \\textbf{RGBSQGrasp}, a grasping framework that leverages superquadric shape primitives and foundation metric depth estimation models to infer grasp poses from a monocular RGB camera -- eliminating the need for depth sensors. Our framework integrates a universal, cross-platform dataset generation pipeline, a foundation model-based object point cloud estimation module, a global-local superquadric fitting network, and an SQ-guided grasp pose sampling module. By integrating these components, RGBSQGrasp reliably infers grasp poses through geometric reasoning, enhancing grasp stability and adaptability to unseen objects. Real-world robotic experiments demonstrate a 92% grasp success rate, highlighting the effectiveness of RGBSQGrasp in packed bin-picking environments.","authors":["Yifeng Xu","Fan Zhu","Ye Li","Sebastian Ren","Xiaonan Huang","Yuhao Chen"],"pdf_url":"","comment":"8 pages, 6 figures, IROS2025 RGMCW Best Workshop Paper"},{"id":"http://arxiv.org/abs/2511.18112v1","updated":"2025-11-22T16:30:55Z","published":"2025-11-22T16:30:55Z","title":"EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation","summary":"Recent progress in Vision-Language-Action (VLA) models has enabled embodied agents to interpret multimodal instructions and perform complex tasks. However, existing VLAs are mostly confined to short-horizon, table-top manipulation, lacking the memory and reasoning capability required for long-horizon mobile manipulation, where agents must coordinate navigation and manipulation under changing spatial contexts. In this work, we present EchoVLA, a memory-aware VLA model for long-horizon mobile manipulation. EchoVLA incorporates a synergistic declarative memory inspired by the human brain, consisting of a scene memory that maintains a collection of spatial-semantic maps and an episodic memory that stores task-level experiences with multimodal contextual features. During both training and inference, the two memories are individually stored, updated, and retrieved based on current observations, task history, and instructions, and their retrieved representations are fused via coarse- and fine-grained attention to guide mobile-arm diffusion policies. To support large-scale training and evaluation, we further introduce MoMani, an automated benchmark that generates expert-level long-horizon trajectories through multimodal large language model (MLLM)-guided planning and feedback-driven refinement, supplemented with real-robot demonstrations. Experiments in simulated and real-world settings show that EchoVLA improves long-horizon performance, reaching 0.52 SR on manipulation/navigation and 0.31 on mobile manipulation, exceeding $π_{0.5}$ by +0.08 and +0.11.","authors":["Min Lin","Xiwen Liang","Bingqian Lin","Liu Jingzhi","Zijian Jiao","Kehan Li","Yuhan Ma","Yuecheng Liu","Shen Zhao","Yuzheng Zhuang","Xiaodan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18088v1","updated":"2025-11-22T15:05:44Z","published":"2025-11-22T15:05:44Z","title":"A Unified Multi-Dynamics Framework for Perception-Oriented Modeling in Tendon-Driven Continuum Robots","summary":"Tendon-driven continuum robots offer intrinsically safe and contact-rich interactions owing to their kinematic redundancy and structural compliance. However, their perception often depends on external sensors, which increase hardware complexity and limit scalability. This work introduces a unified multi-dynamics modeling framework for tendon-driven continuum robotic systems, exemplified by a spiral-inspired robot named Spirob. The framework integrates motor electrical dynamics, motor-winch dynamics, and continuum robot dynamics into a coherent system model. Within this framework, motor signals such as current and angular displacement are modeled to expose the electromechanical signatures of external interactions, enabling perception grounded in intrinsic dynamics. The model captures and validates key physical behaviors of the real system, including actuation hysteresis and self-contact at motion limits. Building on this foundation, the framework is applied to environmental interaction: first for passive contact detection, verified experimentally against simulation data; then for active contact sensing, where control and perception strategies from simulation are successfully applied to the real robot; and finally for object size estimation, where a policy learned in simulation is directly deployed on hardware. The results demonstrate that the proposed framework provides a physically grounded way to interpret interaction signatures from intrinsic motor signals in tendon-driven continuum robots.","authors":["Ibrahim Alsarraj","Yuhao Wang","Abdalla Swikir","Cesare Stefanini","Dezhen Song","Zhanchi Wang","Ke Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18086v1","updated":"2025-11-22T15:00:19Z","published":"2025-11-22T15:00:19Z","title":"Anti-Jamming based on Null-Steering Antennas and Intelligent UAV Swarm Behavior","summary":"Unmanned Aerial Vehicle (UAV) swarms represent a key advancement in autonomous systems, enabling coordinated missions through inter-UAV communication. However, their reliance on wireless links makes them vulnerable to jamming, which can disrupt coordination and mission success. This work investigates whether a UAV swarm can effectively overcome jamming while maintaining communication and mission efficiency.\n  To address this, a unified optimization framework combining Genetic Algorithms (GA), Supervised Learning (SL), and Reinforcement Learning (RL) is proposed. The mission model, structured into epochs and timeslots, allows dynamic path planning, antenna orientation, and swarm formation while progressively enforcing collision rules. Null-steering antennas enhance resilience by directing antenna nulls toward interference sources.\n  Results show that the GA achieved stable, collision-free trajectories but with high computational cost. SL models replicated GA-based configurations but struggled to generalize under dynamic or constrained settings. RL, trained via Proximal Policy Optimization (PPO), demonstrated adaptability and real-time decision-making with consistent communication and lower computational demand. Additionally, the Adaptive Movement Model generalized UAV motion to arbitrary directions through a rotation-based mechanism, validating the scalability of the proposed system.\n  Overall, UAV swarms equipped with null-steering antennas and guided by intelligent optimization algorithms effectively mitigate jamming while maintaining communication stability, formation cohesion, and collision safety. The proposed framework establishes a unified, flexible, and reproducible basis for future research on resilient swarm communication systems.","authors":["Miguel Lourenço","António Grilo"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2511.18085v1","updated":"2025-11-22T15:00:08Z","published":"2025-11-22T15:00:08Z","title":"Continually Evolving Skill Knowledge in Vision Language Action Model","summary":"Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models leverage massive pretraining data to support diverse manipulation tasks, but they still depend heavily on task-specific fine-tuning, revealing a lack of continual learning capability. Existing continual learning methods are also resource-intensive to scale to VLA models. We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, modeling task-centric knowledge space, and TS-Stellar, capturing hierarchical task-skill structure. Stellar VLA enables self-supervised knowledge evolution through joint learning of task latent representation and the knowledge space, reducing annotation needs. Knowledge-guided expert routing provide task specialization without extra network parameters, lowering training overhead.Experiments on the LIBERO benchmark and real-world tasks show over 50 percentage average improvement in final success rates relative to baselines. TS-Stellar further excels in complex action inference, and in-depth analyses verify effective knowledge retention and discovery. Our code will be released soon.","authors":["Yuxuan Wu","Guangming Wang","Zhiheng Yang","Maoqing Yao","Brian Sheil","Hesheng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18082v1","updated":"2025-11-22T14:44:03Z","published":"2025-11-22T14:44:03Z","title":"ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models","summary":"Recent Vision-Language-Action (VLA) models have shown impressive flexibility and generalization, yet their deployment in robotic manipulation remains limited by heavy computational overhead and inference latency. In this work, we present ActDistill, a general action-guided self-derived distillation framework that transfers the action prediction capability of any existing VLA model to a lightweight counterpart. Unlike previous efficiency strategies that primarily emphasize vision-language correlations, ActDistill leverages action priors to guide knowledge transfer and model compression, achieving action-oriented efficiency for VLA models. Specifically, we employ a well-trained VLA model as the teacher and introduce a graph-structured encapsulation strategy to explicitly model the hierarchical evolution of action prediction. The student model, derived from the graph-encapsulated teacher, is further equipped with a dynamic router that adaptively selects computation paths based on action prediction demands, guided by hierarchical graph-informed supervision to ensure smooth and efficient evolution. During inference, graph-related auxiliary components are removed, allowing the student to execute only dynamically routed layers and predict high-precision actions with minimal computation and latency. Experiments on embodied benchmarks demonstrate that ActDistill achieves comparable or superior performance to full-scale VLA models while reducing computation by over 50% with up to 1.67 times speedup, thereby establishing a general paradigm toward efficient embodied intelligence.","authors":["Wencheng Ye","Tianshi Wang","Lei Zhu","Fengling Li","Guoli Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.08562v2","updated":"2025-11-22T12:57:50Z","published":"2025-10-09T17:59:36Z","title":"ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving","summary":"End-to-end autonomous driving (E2EAD) systems, which learn to predict future trajectories directly from sensor data, are fundamentally challenged by the inherent spatio-temporal imbalance of trajectory data. This imbalance creates a significant optimization burden, causing models to learn spurious correlations instead of robust driving logic, while also prioritizing uncertain, distant predictions, thereby compromising immediate safety. To address these issues, we propose ResAD, a novel Normalized Residual Trajectory Modeling framework. Instead of predicting the future trajectory directly, our approach reframes and simplifies the learning task by predicting the residual deviation from a deterministic inertial reference. This inertial reference serves as a strong physical prior, compelling the model to move beyond simple pattern-matching and instead focus its capacity on learning the necessary, context-driven deviations (e.g., traffic rules, obstacles) from this default, inertially-guided path. To mitigate the optimization imbalance caused by uncertain, long-term horizons, ResAD further incorporates Point-wise Normalization of the predicted residual. This technique re-weights the optimization objective, preventing large-magnitude errors associated with distant, uncertain waypoints from dominating the learning signal. On the NAVSIM v1 and v2 benchmarks, ResAD achieves state-of-the-art results of 88.8 PDMS and 85.5 EPDMS with only two denoising steps, demonstrating that ResAD significantly simplifies the learning task and improves planning performance. The code will be released to facilitate further research.","authors":["Zhiyu Zheng","Shaoyu Chen","Haoran Yin","Xinbang Zhang","Jialv Zou","Xinggang Wang","Qian Zhang","Lefei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17992v1","updated":"2025-11-22T09:19:08Z","published":"2025-11-22T09:19:08Z","title":"Unobservable Subspace Evolution and Alignment for Consistent Visual-Inertial Navigation","summary":"The inconsistency issue in the Visual-Inertial Navigation System (VINS) is a long-standing and fundamental challenge. While existing studies primarily attribute the inconsistency to observability mismatch, these analyses are often based on simplified theoretical formulations that consider only prediction and SLAM correction. Such formulations fail to cover the non-standard estimation steps, such as MSCKF correction and delayed initialization, which are critical for practical VINS estimators. Furthermore, the lack of a comprehensive understanding of how inconsistency dynamically emerges across estimation steps has hindered the development of precise and efficient solutions. As a result, current approaches often face a trade-off between estimator accuracy, consistency, and implementation complexity. To address these limitations, this paper proposes a novel analysis framework termed Unobservable Subspace Evolution (USE), which systematically characterizes how the unobservable subspace evolves throughout the entire estimation pipeline by explicitly tracking changes in its evaluation points. This perspective sheds new light on how individual estimation steps contribute to inconsistency. Our analysis reveals that observability misalignment induced by certain steps is the antecedent of observability mismatch. Guided by this insight, we propose a simple yet effective solution paradigm, Unobservable Subspace Alignment (USA), which eliminates inconsistency by selectively intervening only in those estimation steps that induce misalignment. We design two USA methods: transformation-based and re-evaluation-based, both offering accurate and computationally lightweight solutions. Extensive simulations and real-world experiments validate the effectiveness of the proposed methods.","authors":["Chungeng Tian","Fenghua He","Ning Hao"],"pdf_url":"","comment":"20 pages, 16 figures"},{"id":"http://arxiv.org/abs/2511.17961v1","updated":"2025-11-22T07:51:46Z","published":"2025-11-22T07:51:46Z","title":"RoboArmGS: High-Quality Robotic Arm Splatting via Bézier Curve Refinement","summary":"Building high-quality digital assets of robotic arms is crucial yet challenging for the Real2Sim2Real pipeline. Current approaches naively bind static 3D Gaussians according to URDF links, forcing them to follow an URDF-rigged motion passively. However, real-world arm motion is noisy, and the idealized URDF-rigged motion cannot accurately model it, leading to severe rendering artifacts in 3D Gaussians. To address these challenges, we propose RoboArmGS, a novel hybrid representation that refines the URDF-rigged motion with learnable Bézier curves, enabling more accurate real-world motion modeling. To be more specific, we present a learnable Bézier Curve motion refiner that corrects per-joint residuals to address mismatches between real-world motion and URDF-rigged motion. RoboArmGS enables the learning of more accurate real-world motion while achieving a coherent binding of 3D Gaussians across arm parts. To support future research, we contribute a carefully collected dataset named RoboArm4D, which comprises several widely used robotic arms for evaluating the quality of building high-quality digital assets. We evaluate our approach on RoboArm4D, and RoboArmGS achieves state-of-the-art performance in real-world motion modeling and rendering quality. The code and dataset will be released.","authors":["Hao Wang","Xiaobao Wei","Ying Li","Qingpo Wuwu","Dongli Wu","Jiajun Cao","Ming Lu","Wenzhao Zheng","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.23771v3","updated":"2025-11-22T06:43:10Z","published":"2025-06-30T12:17:42Z","title":"Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving","summary":"Reinforcement Learning (RL) is increasingly used in autonomous driving (AD) and shows clear advantages. However, most RL-based AD methods overlook policy structure design. An RL policy that only outputs short-timescale vehicle control commands results in fluctuating driving behavior due to fluctuations in network outputs, while one that only outputs long-timescale driving goals cannot achieve unified optimality of driving behavior and control. Therefore, we propose a multi-timescale hierarchical reinforcement learning approach. Our approach adopts a hierarchical policy structure, where high- and low-level RL policies are unified-trained to produce long-timescale motion guidance and short-timescale control commands, respectively. Therein, motion guidance is explicitly represented by hybrid actions to capture multimodal driving behaviors on structured road and support incremental low-level extend-state updates. Additionally, a hierarchical safety mechanism is designed to ensure multi-timescale safety. Evaluation in simulator-based and HighD dataset-based highway multi-lane scenarios demonstrates that our approach significantly improves AD performance, effectively increasing driving efficiency, action consistency and safety.","authors":["Guizhe Jin","Zhuoren Li","Bo Leng","Ran Yu","Lu Xiong","Chen Sun"],"pdf_url":"","comment":"8 pages, accepted for publication in IEEE Robotics and Automation Letters (RAL)"},{"id":"http://arxiv.org/abs/2511.17925v1","updated":"2025-11-22T05:40:52Z","published":"2025-11-22T05:40:52Z","title":"Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game","summary":"Recent advances in whole-body robot control have enabled humanoid and legged robots to perform increasingly agile and coordinated motions. However, standardized benchmarks for evaluating these capabilities in real-world settings, and in direct comparison to humans, remain scarce. Existing evaluations often rely on pre-collected human motion datasets or simulation-based experiments, which limit reproducibility, overlook hardware factors, and hinder fair human-robot comparisons. We present Switch-JustDance, a low-cost and reproducible benchmarking pipeline that leverages motion-sensing console games, Just Dance on the Nintendo Switch, to evaluate robot whole-body control. Using Just Dance on the Nintendo Switch as a representative platform, Switch-JustDance converts in-game choreography into robot-executable motions through streaming, motion reconstruction, and motion retargeting modules and enables users to evaluate controller performance through the game's built-in scoring system. We first validate the evaluation properties of Just Dance, analyzing its reliability, validity, sensitivity, and potential sources of bias. Our results show that the platform provides consistent and interpretable performance measures, making it a suitable tool for benchmarking embodied AI. Building on this foundation, we benchmark three state-of-the-art humanoid whole-body controllers on hardware and provide insights into their relative strengths and limitations.","authors":["Jeonghwan Kim","Wontaek Kim","Yidan Lu","Jin Cheng","Fatemeh Zargarbashi","Zicheng Zeng","Zekun Qi","Zhiyang Dou","Nitish Sontakke","Donghoon Baek","Sehoon Ha","Tianyu Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17904v1","updated":"2025-11-22T03:42:49Z","published":"2025-11-22T03:42:49Z","title":"CUS-GS: A Compact Unified Structured Gaussian Splatting Framework for Multimodal Scene Representation","summary":"Recent advances in Gaussian Splatting based 3D scene representation have shown two major trends: semantics-oriented approaches that focus on high-level understanding but lack explicit 3D geometry modeling, and structure-oriented approaches that capture spatial structures yet provide limited semantic abstraction. To bridge this gap, we present CUS-GS, a compact unified structured Gaussian Splatting representation, which connects multimodal semantic features with structured 3D geometry. Specifically, we design a voxelized anchor structure that constructs a spatial scaffold, while extracting multimodal semantic features from a set of foundation models (e.g., CLIP, DINOv2, SEEM). Moreover, we introduce a multimodal latent feature allocation mechanism to unify appearance, geometry, and semantics across heterogeneous feature spaces, ensuring a consistent representation across multiple foundation models. Finally, we propose a feature-aware significance evaluation strategy to dynamically guide anchor growing and pruning, effectively removing redundant or invalid anchors while maintaining semantic integrity. Extensive experiments show that CUS-GS achieves competitive performance compared to state-of-the-art methods using as few as 6M parameters - an order of magnitude smaller than the closest rival at 35M - highlighting the excellent trade off between performance and model efficiency of the proposed framework.","authors":["Yuhang Ming","Chenxin Fang","Xingyuan Yu","Fan Zhang","Weichen Dai","Wanzeng Kong","Guofeng Zhang"],"pdf_url":"","comment":"15 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.17898v1","updated":"2025-11-22T03:11:18Z","published":"2025-11-22T03:11:18Z","title":"L1 Sample Flow for Efficient Visuomotor Learning","summary":"Denoising-based models, such as diffusion and flow matching, have been a critical component of robotic manipulation for their strong distribution-fitting and scaling capacity. Concurrently, several works have demonstrated that simple learning objectives, such as L1 regression, can achieve performance comparable to denoising-based methods on certain tasks, while offering faster convergence and inference. In this paper, we focus on how to combine the advantages of these two paradigms: retaining the ability of denoising models to capture multi-modal distributions and avoid mode collapse while achieving the efficiency of the L1 regression objective. To achieve this vision, we reformulate the original v-prediction flow matching and transform it into sample-prediction with the L1 training objective. We empirically show that the multi-modality can be expressed via a single ODE step. Thus, we propose \\textbf{L1 Flow}, a two-step sampling schedule that generates a suboptimal action sequence via a single integration step and then reconstructs the precise action sequence through a single prediction. The proposed method largely retains the advantages of flow matching while reducing the iterative neural function evaluations to merely two and mitigating the potential performance degradation associated with direct sample regression. We evaluate our method with varying baselines and benchmarks, including 8 tasks in MimicGen, 5 tasks in RoboMimic \\& PushT Bench, and one task in the real-world scenario. The results show the advantages of the proposed method with regard to training efficiency, inference speed, and overall performance. \\href{https://song-wx.github.io/l1flow.github.io/}{Project Website.}","authors":["Weixi Song","Zhetao Chen","Tao Xu","Xianchao Zeng","Xinyu Zhou","Lixin Yang","Donglin Wang","Cewu Lu","Yong-Lu Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17889v1","updated":"2025-11-22T02:34:10Z","published":"2025-11-22T02:34:10Z","title":"MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots","summary":"Grounding natural-language instructions into continuous control for quadruped robots remains a fundamental challenge in vision language action. Existing methods struggle to bridge high-level semantic reasoning and low-level actuation, leading to unstable grounding and weak generalization in the real world. To address these issues, we present MobileVLA-R1, a unified vision-language-action framework that enables explicit reasoning and continuous control for quadruped robots. We construct MobileVLA-CoT, a large-scale dataset of multi-granularity chain-of-thought (CoT) for embodied trajectories, providing structured reasoning supervision for alignment. Built upon this foundation, we introduce a two-stage training paradigm that combines supervised CoT alignment with GRPO reinforcement learning to enhance reasoning consistency, control stability, and long-horizon execution. Extensive evaluations on VLN and VLA tasks demonstrate superior performance over strong baselines, with approximately a 5% improvement. Real-world deployment on a quadruped robot validates robust performance in complex environments. Code: https://github.com/AIGeeksGroup/MobileVLA-R1. Website: https://aigeeksgroup.github.io/MobileVLA-R1.","authors":["Ting Huang","Dongjian Li","Rui Yang","Zeyu Zhang","Zida Yang","Hao Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.06359v2","updated":"2025-11-22T02:29:28Z","published":"2025-02-10T11:20:14Z","title":"Occlusion-Aware Contingency Safety-Critical Planning for Autonomous Driving","summary":"Ensuring safe driving while maintaining travel efficiency for autonomous vehicles in dynamic and occluded environments is a critical challenge. This paper proposes an occlusion-aware contingency safety-critical planning approach for real-time autonomous driving. Leveraging reachability analysis for risk assessment, forward reachable sets of phantom vehicles are used to derive risk-aware dynamic velocity boundaries. These velocity boundaries are incorporated into a biconvex nonlinear programming (NLP) formulation that formally enforces safety using spatiotemporal barrier constraints, while simultaneously optimizing exploration and fallback trajectories within a receding horizon planning framework. To enable real-time computation and coordination between trajectories, we employ the consensus alternating direction method of multipliers (ADMM) to decompose the biconvex NLP problem into low-dimensional convex subproblems. The effectiveness of the proposed approach is validated through simulations and real-world experiments in occluded intersections. Experimental results demonstrate enhanced safety and improved travel efficiency, enabling real-time safe trajectory generation in dynamic occluded intersections under varying obstacle conditions. The project page is available at https://zack4417.github.io/oacp-website/.","authors":["Lei Zheng","Rui Yang","Minzhe Zheng","Zengqi Peng","Michael Yu Wang","Jun Ma"],"pdf_url":"","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.17883v1","updated":"2025-11-22T02:19:53Z","published":"2025-11-22T02:19:53Z","title":"ArticFlow: Generative Simulation of Articulated Mechanisms","summary":"Recent advances in generative models have produced strong results for static 3D shapes, whereas articulated 3D generation remains challenging due to action-dependent deformations and limited datasets. We introduce ArticFlow, a two-stage flow matching framework that learns a controllable velocity field from noise to target point sets under explicit action control. ArticFlow couples (i) a latent flow that transports noise to a shape-prior code and (ii) a point flow that transports points conditioned on the action and the shape prior, enabling a single model to represent diverse articulated categories and generalize across actions. On MuJoCo Menagerie, ArticFlow functions both as a generative model and as a neural simulator: it predicts action-conditioned kinematics from a compact prior and synthesizes novel morphologies via latent interpolation. Compared with object-specific simulators and an action-conditioned variant of static point-cloud generators, ArticFlow achieves higher kinematic accuracy and better shape quality. Results show that action-conditioned flow matching is a practical route to controllable and high-quality articulated mechanism generation.","authors":["Jiong Lin","Jinchen Ruan","Hod Lipson"],"pdf_url":"","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.17855v1","updated":"2025-11-22T00:45:33Z","published":"2025-11-22T00:45:33Z","title":"QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents","summary":"Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.","authors":["Jordan Abi Nader","David Lee","Nathaniel Dennler","Andreea Bobu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04602v2","updated":"2025-11-22T00:44:33Z","published":"2025-07-07T01:40:52Z","title":"DragonFly: Single mmWave Radar 3D Localization of Highly Dynamic Tags in GPS-Denied Environments","summary":"The accurate localization and tracking of dynamic targets, such as equipment, people, vehicles, drones, robots, and the assets that they interact with in GPS-denied indoor environments is critical to enabling safe and efficient operations in the next generation of spatially aware industrial facilities. This paper presents DragonFly , a 3D localization system of highly dynamic backscatter tags using a single MIMO mmWave radar. The system delivers the first demonstration of a mmWave backscatter system capable of exploiting the capabilities of MIMO radars for the 3D localization of mmID tags moving at high speeds and accelerations at long ranges by introducing a critical Doppler disambiguation algorithm and a fully integrated cross-polarized dielectric lens-based mmID tag consuming a mere 68 uW. DragonFly was extensively evaluated in static and dynamic configurations, including on a flying quadcopter, and benchmarked against multiple baselines, demonstrating its ability to track the positions of multiple tags with a median 3D accuracy of 12 cm at speeds and acceleration on the order of 10 m/s and 4 m/s^2 and at ranges of up to 50m.","authors":["Skanda Harisha","Jimmy G. D. Hester","Aline Eid"],"pdf_url":"","comment":"Accepted in ACM Mobicom'25"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2511.18184v1","updated":"2025-11-22T20:39:35Z","published":"2025-11-22T20:39:35Z","title":"Energy Control Strategy to Enhance AC Fault Ride-Through in Offshore Wind MMC-HVDC Systems","summary":"Modular Multilevel Converter-based High Voltage Direct Current (MMC-HVDC) system is a promising technology for integration of offshore wind farms (OWFs). However, onshore AC faults on MMC-HVDC reduce the power transfer capability of onshore converter station, leading to surplus power accumulation in HVDC link. This surplus power causes a rapid rise in DC-link voltage and may hinder safe operation of OWFs. To address such a situation, this paper presents an AC fault ride-through scheme that combines the storage of surplus power in MMC submodule (SM) capacitors and dissipation of residual power in an energy dissipation device (EDD). The proposed energy control facilitates use of half-bridge MMC SMs with low-capacitance, with their storage capacity leveraged to share the surplus power during faults, with a lower-rated EDD. The proposed scheme is tested on a 640kV/420MW MMC-HVDC system. The results show that proposed control scheme effectively maintains DC link voltages, ensuring connection of OWFs.","authors":["Dileep Kumar","Wajiha Shireen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18154v1","updated":"2025-11-22T18:51:36Z","published":"2025-11-22T18:51:36Z","title":"Optimizing the Driving Profile for Vehicle Mass Estimation","summary":"Accurate mass estimation is essential for the safe and efficient operation of autonomous heavy-duty vehicles, particularly during transportation missions in unstructured environments such as mining sites, where vehicle mass can vary significantly due to loading and unloading. While prior work has recognized the importance of acceleration profiles for estimation accuracy, the systematic design of driving profiles during transport has not been thoroughly investigated. This paper presents a framework for designing driving profiles to support accurate mass estimation. Based on application-oriented input design, it aims to meet a user-defined accuracy constraint under three optimization objectives: minimum-time, minimum-distance, and maximum accuracy (within a fixed time). It allows time- and distance-dependent bounds on acceleration and velocity, and is based on a Newtonian vehicle dynamics model with actuator dynamics. The optimal profiles are obtained by solving concave optimization problems using a branch-and-bound method, with alternative rank-constrained and semi-definite relaxations also discussed. Theoretical analysis provides insights into the optimal profiles, including feasibility conditions, key ratios between velocity and acceleration bounds, and trade-offs between time- and distance-optimal solutions. The framework is validated through simulations and real-world experiments on a Scania truck with different payloads. Results show that the designed profiles are feasible and effective, enabling accurate mass estimation as part of normal transportation operations without requiring dedicated calibration runs. An additional contribution is a non-causal Wiener filter, with parameters estimated via the Empirical Bayes method, used to filter the accelerometer signal with no phase-lag.","authors":["Le Wang","Jessica Ye","Michael Refors","Oscar Flärdh","Håkan Hjalmarsson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18148v1","updated":"2025-11-22T18:17:24Z","published":"2025-11-22T18:17:24Z","title":"Real-Time Lane-Level Crash Detection on Freeways Using Sparse Telematics Data","summary":"Real-time traffic crash detection is critical in intelligent transportation systems because traditional crash notifications often suffer delays and lack specific, lane-level location information, which can lead to safety risks and economic losses. This paper proposes a real-time, lane-level crash detection approach for freeways that only leverages sparse telematics trajectory data. In the offline stage, the historical trajectories are discretized into spatial cells using vector cross-product techniques, and then used to estimate a vehicle intention distribution and select an alert threshold by maximizing the F1-score based on official crash reports. In the online stage, incoming telematics records are mapped to these cells and scored for three modules: transition anomalies, speed deviations, and lateral maneuver risks, with scores accumulated into a cell-specific risk map. When any cell's risk exceeds the alert threshold, the system issues a prompt warning. Relying solely on telematics data, this real-time and low-cost solution is evaluated on a Wisconsin dataset and validated against official crash reports, achieving a 75% crash identification rate with accurate lane-level localization, an overall accuracy of 96%, an F1-score of 0.84, and a non-crash-to-crash misclassification rate of only 0.6%, while also detecting 13% of crashes more than 3 minutes before the recorded crash time.","authors":["Shixiao Liang","Chengyuan Ma","Pei Li","Haotian Shi","Jiaxi Liu","Hang Zhou","Keke Long","Bofeng Cao","Todd Szymkowski","Xiaopeng Li"],"pdf_url":"","comment":"15 pages,6 figures"},{"id":"http://arxiv.org/abs/2503.02387v3","updated":"2025-11-22T17:12:13Z","published":"2025-03-04T08:23:01Z","title":"RGBSQGrasp: Inferring Local Superquadric Primitives from Single RGB Image for Graspability-Aware Bin Picking","summary":"Bin picking is a challenging robotic task due to occlusions and physical constraints that limit visual information for object recognition and grasping. Existing approaches often rely on known CAD models or prior object geometries, restricting generalization to novel or unknown objects. Other methods directly regress grasp poses from RGB-D data without object priors, but the inherent noise in depth sensing and the lack of object understanding make grasp synthesis and evaluation more difficult. Superquadrics (SQ) offer a compact, interpretable shape representation that captures the physical and graspability understanding of objects. However, recovering them from limited viewpoints is challenging, as existing methods rely on multiple perspectives for near-complete point cloud reconstruction, limiting their effectiveness in bin-picking. To address these challenges, we propose \\textbf{RGBSQGrasp}, a grasping framework that leverages superquadric shape primitives and foundation metric depth estimation models to infer grasp poses from a monocular RGB camera -- eliminating the need for depth sensors. Our framework integrates a universal, cross-platform dataset generation pipeline, a foundation model-based object point cloud estimation module, a global-local superquadric fitting network, and an SQ-guided grasp pose sampling module. By integrating these components, RGBSQGrasp reliably infers grasp poses through geometric reasoning, enhancing grasp stability and adaptability to unseen objects. Real-world robotic experiments demonstrate a 92% grasp success rate, highlighting the effectiveness of RGBSQGrasp in packed bin-picking environments.","authors":["Yifeng Xu","Fan Zhu","Ye Li","Sebastian Ren","Xiaonan Huang","Yuhao Chen"],"pdf_url":"","comment":"8 pages, 6 figures, IROS2025 RGMCW Best Workshop Paper"},{"id":"http://arxiv.org/abs/2410.02000v3","updated":"2025-11-22T15:36:25Z","published":"2024-10-02T20:04:27Z","title":"Barycentric rational approximation for learning the index of a dynamical system from limited data","summary":"We consider the task of data-driven identification of dynamical systems, specifically for systems whose behavior at large frequencies is non-standard, as encoded by a non-trivial relative degree of the transfer function or, alternatively, a non-trivial index of a corresponding realization as a descriptor system. We develop novel surrogate modeling strategies that allow state-of-the-art rational approximation algorithms (e.g., AAA and vector fitting) to better handle data coming from such systems with non-trivial relative degree. Our contribution is twofold. On one hand, we describe a strategy to build rational surrogate models with prescribed relative degree, with the objective of mirroring the high-frequency behavior of the high-fidelity problem, when known. The surrogate model's desired degree is achieved through constraints on its barycentric coefficients, rather than through ad-hoc modifications of the rational form. On the other hand, we present a degree-identification routine that allows one to estimate the unknown relative degree of a system from low-frequency data. By identifying the degree of the system that generated the data, we can build a surrogate model that, in addition to matching the data well (at low frequencies), has enhanced extrapolation capabilities (at high frequencies). We showcase the effectiveness and robustness of the newly proposed method through a suite of numerical tests.","authors":["Davide Pradovera","Ion Victor Gosea","Jan Heiland"],"pdf_url":"","comment":"22 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.18086v1","updated":"2025-11-22T15:00:19Z","published":"2025-11-22T15:00:19Z","title":"Anti-Jamming based on Null-Steering Antennas and Intelligent UAV Swarm Behavior","summary":"Unmanned Aerial Vehicle (UAV) swarms represent a key advancement in autonomous systems, enabling coordinated missions through inter-UAV communication. However, their reliance on wireless links makes them vulnerable to jamming, which can disrupt coordination and mission success. This work investigates whether a UAV swarm can effectively overcome jamming while maintaining communication and mission efficiency.\n  To address this, a unified optimization framework combining Genetic Algorithms (GA), Supervised Learning (SL), and Reinforcement Learning (RL) is proposed. The mission model, structured into epochs and timeslots, allows dynamic path planning, antenna orientation, and swarm formation while progressively enforcing collision rules. Null-steering antennas enhance resilience by directing antenna nulls toward interference sources.\n  Results show that the GA achieved stable, collision-free trajectories but with high computational cost. SL models replicated GA-based configurations but struggled to generalize under dynamic or constrained settings. RL, trained via Proximal Policy Optimization (PPO), demonstrated adaptability and real-time decision-making with consistent communication and lower computational demand. Additionally, the Adaptive Movement Model generalized UAV motion to arbitrary directions through a rotation-based mechanism, validating the scalability of the proposed system.\n  Overall, UAV swarms equipped with null-steering antennas and guided by intelligent optimization algorithms effectively mitigate jamming while maintaining communication stability, formation cohesion, and collision safety. The proposed framework establishes a unified, flexible, and reproducible basis for future research on resilient swarm communication systems.","authors":["Miguel Lourenço","António Grilo"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2511.18081v1","updated":"2025-11-22T14:28:26Z","published":"2025-11-22T14:28:26Z","title":"Sparse Broad Learning System via Sequential Threshold Least-Squares for Nonlinear System Identification under Noise","summary":"The Broad Learning System (BLS) has gained significant attention for its computational efficiency and less network parameters compared to deep learning structures. However, the standard BLS relies on the pseudoinverse solution, which minimizes the mean square error with $L_2$-norm but lacks robustness against sensor noise and outliers common in industrial environments. To address this limitation, this paper proposes a novel Sparse Broad Learning System (S-BLS) framework. Instead of the traditional ridge regression, we incorporate the Sequential Threshold Least-Squares (STLS) algorithm -- originally utilized in the sparse identification of nonlinear dynamics (SINDy) -- into the output weight learning process of BLS. By iteratively thresholding small coefficients, the proposed method promotes sparsity in the output weights, effectively filtering out noise components while maintaining modeling accuracy. This approach falls under the category of sparse regression and is particularly suitable for noisy environments. Experimental results on a numerical nonlinear system and a noisy Continuous Stirred Tank Reactor (CSTR) benchmark demonstrate that the proposed method is effective and achieves superior robustness compared to standard BLS.","authors":["Zijing Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18051v1","updated":"2025-11-22T13:07:56Z","published":"2025-11-22T13:07:56Z","title":"Sparse Kalman Identification for Partially Observable Systems via Adaptive Bayesian Learning","summary":"Sparse dynamics identification is an essential tool for discovering interpretable physical models and enabling efficient control in engineering systems. However, existing methods rely on batch learning with full historical data, limiting their applicability to real-time scenarios involving sequential and partially observable data. To overcome this limitation, this paper proposes an online Sparse Kalman Identification (SKI) method by integrating the Augmented Kalman Filter (AKF) and Automatic Relevance Determination (ARD). The main contributions are: (1) a theoretically grounded Bayesian sparsification scheme that is seamlessly integrated into the AKF framework and adapted to sequentially collected data in online scenarios; (2) an update mechanism that adapts the Kalman posterior to reflect the updated selection of the basis functions that define the model structure; (3) an explicit gradient-descent formulation that enhances computational efficiency. Consequently, the SKI method achieves accurate model structure selection with millisecond-level efficiency and higher identification accuracy, as demonstrated by extensive simulations and real-world experiments (showing an 84.21\\% improvement in accuracy over the baseline AKF).","authors":["Jilan Mei","Tengjie Zheng","Lin Cheng","Shengping Gong","Xu Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14390v2","updated":"2025-11-22T12:17:05Z","published":"2025-11-18T11:51:01Z","title":"Accelerating Automatic Differentiation of Direct Form Digital Filters","summary":"We introduce a general formulation for automatic differentiation through direct form filters, yielding a closed-form backpropagation that includes initial condition gradients. The result is a single expression that can represent both the filter and its gradients computation while supporting parallelism. C++/CUDA implementations in PyTorch achieve at least 1000x speedup over naive Python implementations and consistently run fastest on the GPU. For the low-order filters commonly used in practice, exact time-domain filtering with analytical gradients outperforms the frequency-domain method in terms of speed. The source code is available at https://github.com/yoyolicoris/philtorch.","authors":["Chin-Yun Yu","György Fazekas"],"pdf_url":"","comment":"Accepted at the 1st Workshop on Differentiable Systems and Scientific Machine Learning @ EurIPS 2025"},{"id":"http://arxiv.org/abs/2505.10438v6","updated":"2025-11-22T12:04:14Z","published":"2025-05-15T15:55:13Z","title":"Koopman Eigenfunction-Based Identification and Optimal Nonlinear Control of Turbojet Engine","summary":"Gas turbine engines are complex and highly nonlinear dynamical systems. Deriving their physics-based models can be challenging because it requires performance characteristics that are not always available, often leading to many simplifying assumptions. This paper discusses the limitations of conventional experimental methods used to derive component-level and locally linear parameter-varying models, and addresses these issues by employing identification techniques based on data collected from standard engine operation under closed-loop control. The rotor dynamics are estimated using the sparse identification of nonlinear dynamics. Subsequently, the autonomous part of the dynamics is mapped into an optimally constructed Koopman eigenfunction space. This process involves eigenvalue optimization using metaheuristic algorithms and temporal projection, followed by gradient-based eigenfunction identification. The resulting Koopman model is validated against an in-house reference component-level model. A globally optimal nonlinear feedback controller and a Kalman estimator are then designed within the eigenfunction space and compared to traditional and gain-scheduled proportional-integral controllers, as well as a proposed internal model control approach. The eigenmode structure enables targeting individual modes during optimization, leading to improved performance tuning. Results demonstrate that the Koopman-based controller surpasses other benchmark controllers in both reference tracking and disturbance rejection under sea-level and varying flight conditions, due to its global nature.","authors":["David Grasev"],"pdf_url":"","comment":"35 pages, 29 figures Accepted for publication in Springer Nonlinear Dynamics"},{"id":"http://arxiv.org/abs/2312.14049v2","updated":"2025-11-22T12:02:06Z","published":"2023-12-21T17:18:45Z","title":"MHE under parametric uncertainty -- Robust state estimation without informative data","summary":"In this paper, we study joint state and parameter estimation for general nonlinear systems with uncertain parameters and persistent process and measurement noise. In particular, we are interested in stability properties of the resulting state estimate in the absence of persistency of excitation (PE). With a simple academic example, we show that existing moving horizon estimation (MHE) approaches for joint state and parameter estimation as well as classical adaptive observers can result in diverging state estimates in the absence of PE, even if the noise is small. We propose an MHE formulation involving a regularization based on a constant prior estimate of the unknown system parameters. Only assuming the existence of a stable state estimator, we prove that the proposed MHE approach results in practically robustly stable state estimates irrespective of PE. We discuss the relation of the proposed MHE formulation to state-of-the-art results from MHE and adaptive estimation. The properties of the proposed MHE approach are illustrated with a numerical example of a car with unknown tire friction parameters.","authors":["Simon Muntwiler","Johannes Köhler","Melanie N. Zeilinger"],"pdf_url":"","comment":"Version accepted for publication in IEEE Transactions on Automatic Control"},{"id":"http://arxiv.org/abs/2511.18015v1","updated":"2025-11-22T10:30:42Z","published":"2025-11-22T10:30:42Z","title":"On the stability of event-based control with neuronal dynamics","summary":"Event-based control, unlike analogue control, poses significant analytical challenges due to its hybrid dynamics. This work investigates the stability and inter-event time properties of a control-affine system under event-based impulsive control. The controller consists of multiple neuronal units with leaky integrate-and-fire dynamics acting on a time-invariant, multiple-input multiple-output plant in closed loop. Both the plant state and the neuronal units exhibit discontinuities that cancel if combined linearly, enabling a direct correspondence between the event-based impulsive controller and a corresponding analogue controller. Leveraging this observation, we prove global practical stability of the event-based impulsive control system. In the general nonlinear case, we show that the event-based impulsive controller ensures global practical asymptotic stability if the analogue system is input-to-state stable (ISS) with respect to specific disturbances. In the linear case, we further show global practical exponential stability if the analogue system is stable. We illustrate our results with numerical simulations. The findings reveal a fundamental link between analogue and event-based impulsive control, providing new insights for the design of neuromorphic controllers.","authors":["Luke Eilers","Jonas Stapmanns","Catarina Dias","Jean-Pascal Pfister"],"pdf_url":"","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.18479v2","updated":"2025-11-22T07:17:34Z","published":"2025-03-24T09:24:57Z","title":"Differentiable Simulator for Electrically Reconfigurable Electromagnetic Structures","summary":"This paper introduces a novel CUDA-enabled PyTorch-based framework designed for the gradient-based optimization of such reconfigurable electromagnetic structures with electrically tunable parameters. Traditional optimization techniques for these structures often rely on non-gradient-based methods, limiting efficiency and flexibility. Our framework leverages automatic differentiation, facilitating the application of gradient-based optimization methods. This approach is particularly advantageous for embedding within deep learning frameworks, enabling sophisticated optimization strategies.\n  We demonstrate the framework's effectiveness through comprehensive simulations involving resonant structures with tunable parameters. Key contributions include the efficient solution of the inverse problem. The framework's performance is validated using three different resonant structures: a single-loop copper wire (Unit-Cell) as well as an 8x1 and an 8x8 array of resonant unit cells with multiple inductively coupled unit cells (1d and 2d Metasurfaces). Results show precise in-silico control over the magnetic field's component normal to the surface of each resonant structure, achieving desired field strengths with minimal error. The proposed framework is compatible with existing simulation software.\n  This PyTorch-based framework sets the stage for advanced electromagnetic control strategies for resonant structures with application in e.g. MRI, providing a robust platform for further exploration and innovation in the design and optimization of resonant electromagnetic structures.","authors":["Johannes Müller","Dennis Philipp","Matthias Günther"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.20392v2","updated":"2025-11-22T03:40:38Z","published":"2025-09-23T03:57:03Z","title":"The First Open-Source Framework for Learning Stability Certificates from Data","summary":"Before 2025, no open-source system existed that could learn Lyapunov stability certificates directly from noisy, real-world flight data. This work addresses that gap by proposing a data-driven approach that learns Lyapunov functions from trajectory data under realistic, noise-corrupted conditions. Unlike statistical anomaly detectors that only flag deviations, the proposed method assesses whether the system can still be certified as stable. Applied to public data from the 2024 SAS severe turbulence incident, this framework revealed that, within 60 seconds of the aircraft's descent becoming abnormal, no Lyapunov function could be constructed to certify system stability. To the best of our knowledge, this is also the first application of a data-driven Lyapunov-based stability verification method to real civil aviation data, achieved without any access to proprietary controller logic. The proposed framework is open-sourced and available at: https://github.com/HansOersted/stability","authors":["Zhe Shen"],"pdf_url":"","comment":"Accepted by IEEE Aerospace Conference"},{"id":"http://arxiv.org/abs/2511.17894v1","updated":"2025-11-22T02:56:21Z","published":"2025-11-22T02:56:21Z","title":"Machine Learning-based Online Stability Lobe Diagram Estimation and Chatter Suppression Control in Milling Process","summary":"Chatter is a self-excited vibration in milling that degrades surface quality and accelerates tool wear. This paper presents an adaptive process controller that suppresses chatter by leveraging machine learning-based online estimation of the Stability Lobe Diagram (SLD) and surface roughness in the process. Stability analysis is conducted using the semi-discretization method for milling dynamics modeled by delay differential equations. An integrated machine learning framework estimates the SLD from sensor data and predicts surface roughness for chatter detection in real time. These estimates are integrated into an optimal controller that adaptively adjusts spindle speed to maintain process stability and improve surface finish. Simulations and experiments are performed to demonstrate the superior performance compared to the existing approaches.","authors":["Yi Huang","Feng Han","Wenyi Liu","Jingang Yi","Yuebin Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17865v1","updated":"2025-11-22T01:22:53Z","published":"2025-11-22T01:22:53Z","title":"Generative Model Predictive Control in Manufacturing Processes: A Review","summary":"Manufacturing processes are inherently dynamic and uncertain, with varying parameters and nonlinear behaviors, making robust control essential for maintaining quality and reliability. Traditional control methods often fail under these conditions due to their reactive nature. Model Predictive Control (MPC) has emerged as a more advanced framework, leveraging process models to predict future states and optimize control actions. However, MPC relies on simplified models that often fail to capture complex dynamics, and it struggles with accurate state estimation and handling the propagation of uncertainty in manufacturing environments. Machine learning (ML) has been introduced to enhance MPC by modeling nonlinear dynamics and learning latent representations that support predictive modeling, state estimation, and optimization. Yet existing ML-driven MPC approaches remain deterministic and correlation-focused, motivating the exploration of generative. Generative ML offers new opportunities by learning data distributions, capturing hidden patterns, and inherently managing uncertainty, thereby complementing MPC. This review highlights five representative methods and examines how each has been integrated into MPC components, including predictive modeling, state estimation, and optimization. By synthesizing these cases, we outline the common ways generative ML can systematically enhance MPC and provide a framework for understanding its potential in diverse manufacturing processes. We identify key research gaps, propose future directions, and use a representative case to illustrate how generative ML-driven MPC can extend broadly across manufacturing. Taken together, this review positions generative ML not as an incremental add-on but as a transformative approach to reshape predictive control for next-generation manufacturing systems.","authors":["Suk Ki Lee","Ronnie F. P. Stone","Max Gao","Wenlong Zhang","Zhenghui Sha","Hyunwoong Ko"],"pdf_url":"","comment":"24 pages, 5 figures, Review article"}]},"2025-11-25T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2511.20633v1","updated":"2025-11-25T18:52:56Z","published":"2025-11-25T18:52:56Z","title":"Reinforcing Action Policies by Prophesying","summary":"Vision-Language-Action (VLA) policies excel in aligning language, perception, and robot control. However, most VLAs are trained purely by imitation, which overfits to demonstrations, and is brittle under distribution shift. Reinforcement learning (RL) directly optimizes task reward and thus addresses this misalignment, but real-robot interaction is expensive and conventional simulators are hard to engineer and transfer. We address both data efficiency and optimization stability in VLA post-training via a learned world model and an RL procedure tailored to flow-based action heads. Specifically, we introduce Prophet, a unified action-to-video robot actuation pretrained across large-scale, heterogeneous robot data to learn reusable action-outcome dynamics. It is able to few-shot adapt to new robots, objects, and environments, yielding a rollout-ready simulator. Upon Prophet, we reinforce action policies with Flow-action-GRPO (FA-GRPO), which adapts Flow-GRPO to operate on VLA actions, and with FlowScale, a stepwise reweighting that rescales per-step gradients in the flow head. Together, Prophet, FA-GRPO, and FlowScale constitute ProphRL, a practical, data- and compute-efficient path to VLA post-training. Experiments show 5-17% success gains on public benchmarks and 24-30% gains on real robots across different VLA variants.","authors":["Jiahui Zhang","Ze Huang","Chun Gu","Zipei Ma","Li Zhang"],"pdf_url":"","comment":"https://LogosRoboticsGroup.github.io/ProphRL"},{"id":"http://arxiv.org/abs/2511.20620v1","updated":"2025-11-25T18:43:55Z","published":"2025-11-25T18:43:55Z","title":"Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI","summary":"Reproducible closed-loop evaluation remains a major bottleneck in Embodied AI such as visual navigation. A promising path forward is high-fidelity simulation that combines photorealistic sensor rendering with geometrically grounded interaction in complex, open-world urban environments. Although recent video-3DGS methods ease open-world scene capturing, they are still unsuitable for benchmarking due to large visual and geometric sim-to-real gaps. To address these challenges, we introduce Wanderland, a real-to-sim framework that features multi-sensor capture, reliable reconstruction, accurate geometry, and robust view synthesis. Using this pipeline, we curate a diverse dataset of indoor-outdoor urban scenes and systematically demonstrate how image-only pipelines scale poorly, how geometry quality impacts novel view synthesis, and how all of these adversely affect navigation policy learning and evaluation reliability. Beyond serving as a trusted testbed for embodied navigation, Wanderland's rich raw sensor data further allows benchmarking of 3D reconstruction and novel view synthesis models. Our work establishes a new foundation for reproducible research in open-world embodied AI. Project website is at https://ai4ce.github.io/wanderland/.","authors":["Xinhao Liu","Jiaqi Li","Youming Deng","Ruxin Chen","Yingjia Zhang","Yifei Ma","Li Guo","Yiming Li","Jing Zhang","Chen Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20593v1","updated":"2025-11-25T18:24:11Z","published":"2025-11-25T18:24:11Z","title":"Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning","summary":"Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.","authors":["Allen Emmanuel Binny","Mahathi Anand","Hugo T. M. Kussaba","Lingyun Chen","Shreenabh Agrawal","Fares J. Abu-Dakka","Abdalla Swikir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20570v1","updated":"2025-11-25T18:05:05Z","published":"2025-11-25T18:05:05Z","title":"Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics","summary":"Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.","authors":["Tasha Kim","Oiwi Parker Jones"],"pdf_url":"","comment":"Embodied and Safe-Assured Robotic Systems workshop at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.18617v2","updated":"2025-11-25T17:43:27Z","published":"2025-11-23T21:21:10Z","title":"AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations","summary":"AutoFocus-IL is a simple yet effective method to improve data efficiency and generalization in visual imitation learning by guiding policies to attend to task-relevant features rather than distractors and spurious correlations. Although saliency regularization has emerged as a promising way to achieve this, existing approaches typically require costly supervision such as human gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages vision-language models (VLMs) to automatically identify and track key objects in demonstrations, generating temporal saliency maps that highlight causal visual signals while suppressing distractors. These maps are then used to regularize behavior cloning policies, yielding stronger alignment between visual attention and task-relevant cues. Experiments in both the CARLA simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not only outperforms standard behavior cloning but also surpasses state-of-the-art baselines that assume privileged access to human supervision, such as gaze data. Code, datasets, and trained policy videos are available at https://AutoFocus-IL.github.io/.","authors":["Litian Gong","Fatemeh Bahrani","Yutai Zhou","Amin Banayeeanzade","Jiachen Li","Erdem Bıyık"],"pdf_url":"","comment":"8 pages, 6 figures. Code and datasets available at http://autofocus-il.github.io/"},{"id":"http://arxiv.org/abs/2511.20532v1","updated":"2025-11-25T17:34:38Z","published":"2025-11-25T17:34:38Z","title":"MIMIC-MJX: Neuromechanical Emulation of Animal Behavior","summary":"The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.","authors":["Charles Y. Zhang","Yuanjia Yang","Aidan Sirbu","Elliott T. T. Abe","Emil Wärnberg","Eric J. Leonardis","Diego E. Aldarondo","Adam Lee","Aaditya Prasad","Jason Foat","Kaiwen Bian","Joshua Park","Rusham Bhatt","Hutton Saunders","Akira Nagamori","Ayesha R. Thanawalla","Kee Wui Huang","Fabian Plum","Hendrik K. Beck","Steven W. Flavell","David Labonte","Blake A. Richards","Bingni W. Brunton","Eiman Azim","Bence P. Ölveczky","Talmo D. Pereira"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20496v1","updated":"2025-11-25T17:03:11Z","published":"2025-11-25T17:03:11Z","title":"Metric, inertially aligned monocular state estimation via kinetodynamic priors","summary":"Accurate state estimation for flexible robotic systems poses significant challenges, particular for platforms with dynamically deforming structures that invalidate rigid-body assumptions. This paper tackles this problem and allows to extend existing rigid-body pose estimation methods to non-rigid systems. Our approach hinges on two core assumptions: first, the elastic properties are captured by an injective deformation-force model, efficiently learned via a Multi-Layer Perceptron; second, we solve the platform's inherently smooth motion using continuous-time B-spline kinematic models. By continuously applying Newton's Second Law, our method establishes a physical link between visually-derived trajectory acceleration and predicted deformation-induced acceleration. We demonstrate that our approach not only enables robust and accurate pose estimation on non-rigid platforms, but that the properly modeled platform physics instigate inertial sensing properties. We demonstrate this feasibility on a simple spring-camera system, and show how it robustly resolves the typically ill-posed problem of metric scale and gravity recovery in monocular visual odometry.","authors":["Jiaxin Liu","Min Li","Wanting Xu","Liang Li","Jiaqi Yang","Laurent Kneip"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20492v1","updated":"2025-11-25T16:59:29Z","published":"2025-11-25T16:59:29Z","title":"Kleinkram: Open Robotic Data Management","summary":"We introduce Kleinkram, a free and open-source system designed to solve the challenge of managing massive, unstructured robotic datasets. Designed as a modular, on-premises cloud solution, Kleinkram enables scalable storage, indexing, and sharing of datasets, ranging from individual experiments to large-scale research collections. Kleinkram natively integrates with standard formats such as ROS bags and MCAP and utilises S3-compatible storage for flexibility. Beyond storage, Kleinkram features an integrated \"Action Runner\" that executes customizable Docker-based workflows for data validation, curation, and benchmarking. Kleinkram has successfully managed over 30 TB of data from diverse robotic systems, streamlining the research lifecycle through a modern web interface and a robust Command Line Interface (CLI).","authors":["Cyrill Püntener","Johann Schwabe","Dominique Garmier","Jonas Frey","Marco Hutter"],"pdf_url":"","comment":"for associated source code, see https://github.com/leggedrobotics/kleinkram"},{"id":"http://arxiv.org/abs/2511.20467v1","updated":"2025-11-25T16:31:43Z","published":"2025-11-25T16:31:43Z","title":"Power-Efficient Autonomous Mobile Robots","summary":"This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.","authors":["Liangkai Liu","Weisong Shi","Kang G. Shin"],"pdf_url":"","comment":"13 pages, 16 figures"},{"id":"http://arxiv.org/abs/2511.20431v1","updated":"2025-11-25T16:03:38Z","published":"2025-11-25T16:03:38Z","title":"BRIC: Bridging Kinematic Plans and Physical Control at Test Time","summary":"We propose BRIC, a novel test-time adaptation (TTA) framework that enables long-term human motion generation by resolving execution discrepancies between diffusion-based kinematic motion planners and reinforcement learning-based physics controllers. While diffusion models can generate diverse and expressive motions conditioned on text and scene context, they often produce physically implausible outputs, leading to execution drift during simulation. To address this, BRIC dynamically adapts the physics controller to noisy motion plans at test time, while preserving pre-trained skills via a loss function that mitigates catastrophic forgetting. In addition, BRIC introduces a lightweight test-time guidance mechanism that steers the diffusion model in the signal space without updating its parameters. By combining both adaptation strategies, BRIC ensures consistent and physically plausible long-term executions across diverse environments in an effective and efficient manner. We validate the effectiveness of BRIC on a variety of long-term tasks, including motion composition, obstacle avoidance, and human-scene interaction, achieving state-of-the-art performance across all tasks.","authors":["Dohun Lim","Minji Kim","Jaewoon Lim","Sungchan Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20422v1","updated":"2025-11-25T15:48:49Z","published":"2025-11-25T15:48:49Z","title":"VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning","summary":"Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.","authors":["Bo Pang","Chenxi Xu","Jierui Ren","Guoping Wang","Sheng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26536v2","updated":"2025-11-25T15:21:05Z","published":"2025-09-30T17:09:32Z","title":"OceanGym: A Benchmark Environment for Underwater Embodied Agents","summary":"We introduce OceanGym, the first comprehensive benchmark for ocean underwater embodied agents, designed to advance AI in one of the most demanding real-world environments. Unlike terrestrial or aerial domains, underwater settings present extreme perceptual and decision-making challenges, including low visibility, dynamic ocean currents, making effective agent deployment exceptionally difficult. OceanGym encompasses eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), which integrates perception, memory, and sequential decision-making. Agents are required to comprehend optical and sonar data, autonomously explore complex environments, and accomplish long-horizon objectives under these harsh conditions. Extensive experiments reveal substantial gaps between state-of-the-art MLLM-driven agents and human experts, highlighting the persistent difficulty of perception, planning, and adaptability in ocean underwater environments. By providing a high-fidelity, rigorously designed platform, OceanGym establishes a testbed for developing robust embodied AI and transferring these capabilities to real-world autonomous ocean underwater vehicles, marking a decisive step toward intelligent agents capable of operating in one of Earth's last unexplored frontiers. The code and data are available at https://github.com/OceanGPT/OceanGym.","authors":["Yida Xue","Mingjun Mao","Xiangyuan Ru","Yuqi Zhu","Baochang Ren","Shuofei Qiao","Mengru Wang","Shumin Deng","Xinyu An","Ningyu Zhang","Ying Chen","Huajun Chen"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2511.20394v1","updated":"2025-11-25T15:19:45Z","published":"2025-11-25T15:19:45Z","title":"Improved adaptive wind driven optimization algorithm for real-time path planning","summary":"Recently, path planning has achieved remarkable progress in enhancing global search capability and convergence accuracy through heuristic and learning-inspired optimization frameworks. However, real-time adaptability in dynamic environments remains a critical challenge for autonomous navigation, particularly when robots must generate collision-free, smooth, and efficient trajectories under complex constraints. By analyzing the difficulties in dynamic path planning, the Wind Driven Optimization (WDO) algorithm emerges as a promising framework owing to its physically interpretable search dynamics. Motivated by these observations, this work revisits the WDO principle and proposes a variant formulation, Multi-hierarchical adaptive wind driven optimization(MAWDO), that improves adaptability and robustness in time-varying environments. To mitigate instability and premature convergence, a hierarchical-guidance mechanism divides the population into multiple groups guided by individual, regional, and global leaders to balance exploration and exploitation. Extensive evaluations on sixteen benchmark functions show that MAWDO achieves superior optimization accuracy, convergence stability, and adaptability over state-of-the art metaheuristics. In dynamic path planning, MAWDO shortens the path length to 469.28 pixels, improving over Multi-strategy ensemble wind driven optimization(MEWDO), Adaptive wind driven optimization(AWDO) and WDO by 3.51\\%, 11.63\\% and 14.93\\%, and achieves the smallest optimality gap (1.01) with smoothness 0.71 versus 13.50 and 15.67 for AWDO and WDO, leading to smoother, shorter, and collision-free trajectories that confirm its effectiveness for real-time path planning in complex environments.","authors":["Shiqian Liu","Azlan Mohd Zain","Le-le Mao"],"pdf_url":"","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.09178v2","updated":"2025-11-25T14:39:55Z","published":"2024-06-13T14:40:43Z","title":"A Physics-informed Demonstration-guided Learning Framework for Granular Material Manipulation","summary":"Due to the complex physical properties of granular materials, research on robot learning for manipulating such materials predominantly either disregards the consideration of their physical characteristics or uses surrogate models to approximate their physical properties. Learning to manipulate granular materials based on physical information obtained through precise modelling remains an unsolved problem. In this paper, we propose to address this challenge by constructing a differentiable physics-based simulator for granular materials using the Taichi programming language and developing a learning framework accelerated by demonstrations generated through gradient-based optimisation on non-granular materials within our simulator, eliminating the costly data collection and model training of prior methods. Experimental results show that our method, with its flexible design, trains robust policies that are capable of executing the task of transporting granular materials in both simulated and real-world environments, beyond the capabilities of standard reinforcement learning, imitation learning, and prior task-specific granular manipulation methods.","authors":["Minglun Wei","Xintong Yang","Yu-Kun Lai","Seyed Amir Tafrishi","Ze Ji"],"pdf_url":"","comment":"Accepted as a regular paper by IEEE Transactions on Neural Networks and Learning Systems (TNNLS)"},{"id":"http://arxiv.org/abs/2511.20353v1","updated":"2025-11-25T14:31:12Z","published":"2025-11-25T14:31:12Z","title":"Quality-guided UAV Surface Exploration for 3D Reconstruction","summary":"Reasons for mapping an unknown environment with autonomous robots are wide-ranging, but in practice, they are often overlooked when developing planning strategies. Rapid information gathering and comprehensive structural assessment of buildings have different requirements and therefore necessitate distinct methodologies. In this paper, we propose a novel modular Next-Best-View (NBV) planning framework for aerial robots that explicitly uses a reconstruction quality objective to guide the exploration planning. In particular, our approach introduces new and efficient methods for view generation and selection of viewpoint candidates that are adaptive to the user-defined quality requirements, fully exploiting the uncertainty encoded in a Truncated Signed Distance field (TSDF) representation of the environment. This results in informed and efficient exploration decisions tailored towards the predetermined objective. Finally, we validate our method via extensive simulations in realistic environments. We demonstrate that it successfully adjusts its behavior to the user goal while consistently outperforming conventional NBV strategies in terms of coverage, quality of the final 3D map and path efficiency.","authors":["Benjamin Sportich","Kenza Boubakri","Olivier Simonin","Alessandro Renzaglia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20348v1","updated":"2025-11-25T14:25:19Z","published":"2025-11-25T14:25:19Z","title":"Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin","summary":"3D reconstruction for Digital Twins often relies on LiDAR-based methods, which provide accurate geometry but lack the semantics and textures naturally captured by cameras. Traditional LiDAR-camera fusion approaches require complex calibration and still struggle with certain materials like glass, which are visible in images but poorly represented in point clouds. We propose a camera-only pipeline that reconstructs scenes using 3D Gaussian Splatting from multi-view images, extracts semantic material masks via vision models, converts Gaussian representations to mesh surfaces with projected material labels, and assigns physics-based material properties for accurate sensor simulation in modern graphics engines and simulators. This approach combines photorealistic reconstruction with physics-based material assignment, providing sensor simulation fidelity comparable to LiDAR-camera fusion while eliminating hardware complexity and calibration requirements. We validate our camera-only method using an internal dataset from an instrumented test vehicle, leveraging LiDAR as ground truth for reflectivity validation alongside image similarity metrics.","authors":["João Malheiro Silva","Andy Huynh","Tong Duy Son","Holger Caesar"],"pdf_url":"","comment":"8 pages, 5 figures. Submitted to IEEE Intelligent Vehicles Symposium (IV) 2026 for possible publication"},{"id":"http://arxiv.org/abs/2511.20330v1","updated":"2025-11-25T14:07:17Z","published":"2025-11-25T14:07:17Z","title":"ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation","summary":"Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.","authors":["Yuhan Wu","Tiantian Wei","Shuo Wang","ZhiChao Wang","Yanyong Zhang","Daniel Cremers","Yan Xia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20299v1","updated":"2025-11-25T13:38:04Z","published":"2025-11-25T13:38:04Z","title":"How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks","summary":"Recent advancements in robotics have increased the possibilities for integrating robotic systems into human-involved workplaces, highlighting the need to examine and optimize human-robot coordination in collaborative settings. This study explores human-robot interactions during handover tasks using Virtual Reality (VR) to investigate differences in human motor performance across various task dynamics and robot kinematics. A VR-based robot handover simulation afforded safe and controlled assessments of human-robot interactions. In separate experiments, four potential influences on human performance were examined (1) control over task initiation and robot movement synchrony (temporal and spatiotemporal); (2) partner appearance (human versus robotic); (3) robot velocity profiles (minimum jerk, constant velocity, constant acceleration, and biphasic); and (4) the timing of rotational object motion. Findings across experiments emphasize humans benefit from robots providing early and salient visual information about task-relevant object motion, and advantages of human-like smooth robot trajectories. To varying degrees, these manipulations improved predictive accuracy and synchronization during interaction. This suggests that human-robot interactions should be designed to allow humans to leverage their natural capabilities for detecting biological motion, which conversely may reduce the need for costly robotic computations or added cognitive adaptation on the human side.","authors":["Róisín Keenan","Joost C. Dessing"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20292v1","updated":"2025-11-25T13:21:27Z","published":"2025-11-25T13:21:27Z","title":"Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes","summary":"Reliable odometry in highly dynamic environments remains challenging when it relies on ICP-based registration: ICP assumes near-static scenes and degrades in repetitive or low-texture geometry. We introduce Dynamic-ICP, a Doppler-aware registration framework. The method (i) estimates ego motion from per-point Doppler velocity via robust regression and builds a velocity filter, (ii) clusters dynamic objects and reconstructs object-wise translational velocities from ego-compensated radial measurements, (iii) predicts dynamic points with a constant-velocity model, and (iv) aligns scans using a compact objective that combines point-to-plane geometry residual with a translation-invariant, rotation-only Doppler residual. The approach requires no external sensors or sensor-vehicle calibration and operates directly on FMCW LiDAR range and Doppler velocities. We evaluate Dynamic-ICP on three datasets-HeRCULES, HeLiPR, AevaScenes-focusing on highly dynamic scenes. Dynamic-ICP consistently improves rotational stability and translation accuracy over the state-of-the-art methods. Our approach is also simple to integrate into existing pipelines, runs in real time, and provides a lightweight solution for robust registration in dynamic environments. To encourage further research, the code is available at: https://github.com/JMUWRobotics/Dynamic-ICP.","authors":["Dong Wang","Daniel Casado Herraez","Stefan May","Andreas Nüchter"],"pdf_url":"","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.20275v1","updated":"2025-11-25T13:02:17Z","published":"2025-11-25T13:02:17Z","title":"HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments","summary":"Reinforcement learning controllers have made impressive progress in humanoid locomotion and light load manipulation. However, achieving robust and precise motion with strong force interaction remains a significant challenge. Based on the above limitations, this paper proposes HAFO, a dual-agent reinforcement learning control framework that simultaneously optimizes both a robust locomotion strategy and a precise upper-body manipulation strategy through coupled training under external force interaction environments. Simultaneously, we explicitly model the external pulling disturbances through a spring-damper system and achieve fine-grained force control by manipulating the virtual spring. During this process, the reinforcement-learning policy spontaneously generates disturbance-rejection response by exploiting environmental feedback. Moreover, HAFO employs an asymmetric Actor-Critic framework in which the Critic-network access to privileged spring-damping forces guides the actor-network to learn a generalizable, robust policy for resisting external disturbances. The experimental results demonstrate that HAFO achieves stable control of humanoid robot under various strong force interactions, showing remarkable performance in load tasks and ensuring stable robot operation under rope tension disturbances. Project website: hafo-robot.github.io.","authors":["Chenhui Dong","Haozhe Xu","Wenhao Feng","Zhipeng Wang","Yanmin Zhou","Yifei Zhao","Bin He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.17773v3","updated":"2025-11-25T12:29:22Z","published":"2025-01-29T17:09:28Z","title":"SafePR: Unified Approach for Safe Parallel Robots by Contact Detection and Reaction with Redundancy Resolution","summary":"Fast and safe motion is crucial for the successful deployment of physically interactive robots. Parallel robots (PRs) offer the potential for higher speeds while maintaining the same energy limits due to their low moving masses. However, they require methods for contact detection and reaction while avoiding singularities and self-collisions. We address this issue and present SafePR - a unified approach for the detection and localization, including the distinction between collision and clamping to perform a reaction that is safe for humans and feasible for PRs. Our approach uses information from the encoders and motor currents to estimate forces via a generalized-momentum observer. Neural networks and particle filters classify and localize the contacts. We introduce reactions with redundancy resolution to avoid self-collisions and type-II singularities. Our approach detected and terminated 72 real-world collision and clamping contacts with end-effector speeds of up to 1.5 m/s, each within 25-275 ms. The forces were below the thresholds from ISO/TS 15066. By using built-in sensors, SafePR enables safe interaction with already assembled PRs without the need for new hardware components.","authors":["Aran Mohammad","Tim-Lukas Habich","Thomas Seel","Moritz Schappler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20226v1","updated":"2025-11-25T11:55:53Z","published":"2025-11-25T11:55:53Z","title":"Toward generic control for soft robotic systems","summary":"Soft robotics has advanced rapidly, yet its control methods remain fragmented: different morphologies and actuation schemes still require task-specific controllers, hindering theoretical integration and large-scale deployment. A generic control framework is therefore essential, and a key obstacle lies in the persistent use of rigid-body control logic, which relies on precise models and strict low-level execution. Such a paradigm is effective for rigid robots but fails for soft robots, where the ability to tolerate and exploit approximate action representations, i.e., control compliance, is the basis of robustness and adaptability rather than a disturbance to be eliminated. Control should thus shift from suppressing compliance to explicitly exploiting it. Human motor control exemplifies this principle: instead of computing exact dynamics or issuing detailed muscle-level commands, it expresses intention through high-level movement tendencies, while reflexes and biomechanical mechanisms autonomously resolve local details. This architecture enables robustness, flexibility, and cross-task generalization. Motivated by this insight, we propose a generic soft-robot control framework grounded in control compliance and validate it across robots with diverse morphologies and actuation mechanisms. The results demonstrate stable, safe, and cross-platform transferable behavior, indicating that embracing control compliance, rather than resisting it, may provide a widely applicable foundation for unified soft-robot control.","authors":["Yu Sun","Yaosheng Deng","Wenjie Mei","Xiaogang Xiong","Yang Bai","Masaki Ogura","Zeyu Zhou","Mir Feroskhan","Michael Yu Wang","Qiyang Zuo","Yao Li","Yunjiang Lou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20216v1","updated":"2025-11-25T11:42:28Z","published":"2025-11-25T11:42:28Z","title":"CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents","summary":"Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.","authors":["Haebin Seong","Sungmin Kim","Minchan Kim","Yongjun Cho","Myunchul Joe","Suhwan Choi","Jaeyoon Jung","Jiyong Youn","Yoonshik Kim","Samwoo Seong","Yubeen Park","Youngjae Yu","Yunsung Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20180v1","updated":"2025-11-25T11:02:34Z","published":"2025-11-25T11:02:34Z","title":"Hibikino-Musashi@Home 2025 Team Description Paper","summary":"This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator. The large-language-model-powered task planner selects appropriate primitive skills to perform the task requested by the user. Moreover, the team has focused on research involving brain-inspired memory models for adaptation to individual home environments. This approach aims to provide intuitive and personalized assistance. Additionally, the team contributed to the reusability of the navigation system developed by Pumas in RoboCup2024. The team aimed to design a home service robot to assist humans in their homes and continuously attend competitions to evaluate and improve the developed system.","authors":["Ryohei Kobayashi","Kosei Isomoto","Kosei Yamao","Soma Fumoto","Koshun Arimura","Naoki Yamaguchi","Akinobu Mizutani","Tomoya Shiba","Kouki Kimizuka","Yuta Ohno","Ryo Terashima","Hiromasa Yamaguchi","Tomoaki Fujino","Ryoga Maruno","Wataru Yoshimura","Kazuhito Mine","Tang Phu Thien Nhan","Yuga Yano","Yuichiro Tanaka","Takeshi Nishida","Takashi Morie","Hakaru Tamukoh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20156v1","updated":"2025-11-25T10:30:26Z","published":"2025-11-25T10:30:26Z","title":"Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving","summary":"Motion planning for autonomous driving must handle multiple plausible futures while remaining computationally efficient. Recent end-to-end systems and world-model-based planners predict rich multi-modal trajectories, but typically rely on handcrafted anchors or reinforcement learning to select a single best mode for training and control. This selection discards information about alternative futures and complicates optimization. We propose MAP-World, a prior-free multi-modal planning framework that couples masked action planning with a path-weighted world model. The Masked Action Planning (MAP) module treats future ego motion as masked sequence completion: past waypoints are encoded as visible tokens, future waypoints are represented as mask tokens, and a driving-intent path provides a coarse scaffold. A compact latent planning state is expanded into multiple trajectory queries with injected noise, yielding diverse, temporally consistent modes without anchor libraries or teacher policies. A lightweight world model then rolls out future BEV semantics conditioned on each candidate trajectory. During training, semantic losses are computed as an expectation over modes, using trajectory probabilities as discrete path weights, so the planner learns from the full distribution of plausible futures instead of a single selected path. On NAVSIM, our method matches anchor-based approaches and achieves state-of-the-art performance among world-model-based methods, while avoiding reinforcement learning and maintaining real-time inference latency.","authors":["Bin Hu","Zijian Lu","Haicheng Liao","Chengran Yuan","Bin Rao","Yongkang Li","Guofa Li","Zhiyong Cui","Cheng-zhong Xu","Zhenning Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.13733v3","updated":"2025-11-25T09:17:23Z","published":"2025-09-17T06:36:41Z","title":"FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph","summary":"Visual-Language Navigation (VLN) is a fundamental challenge in robotic systems, with broad applications for the deployment of embodied agents in real-world environments. Despite recent advances, existing approaches are limited in long-range spatial reasoning, often exhibiting low success rates and high inference latency, particularly in long-range navigation tasks. To address these limitations, we propose FSR-VLN, a vision-language navigation system that combines a Hierarchical Multi-modal Scene Graph (HMSG) with Fast-to-Slow Navigation Reasoning (FSR). The HMSG provides a multi-modal map representation supporting progressive retrieval, from coarse room-level localization to fine-grained goal view and object identification. Building on HMSG, FSR first performs fast matching to efficiently select candidate rooms, views, and objects, then applies VLM-driven refinement for final goal selection. We evaluated FSR-VLN across four comprehensive indoor datasets collected by humanoid robots, utilizing 87 instructions that encompass a diverse range of object categories. FSR-VLN achieves state-of-the-art (SOTA) performance in all datasets, measured by the retrieval success rate (RSR), while reducing the response time by 82% compared to VLM-based methods on tour videos by activating slow reasoning only when fast intuition fails. Furthermore, we integrate FSR-VLN with speech interaction, planning, and control modules on a Unitree-G1 humanoid robot, enabling natural language interaction and real-time navigation.","authors":["Xiaolin Zhou","Tingyang Xiao","Liu Liu","Yucheng Wang","Maiyue Chen","Xinrui Meng","Xinjie Wang","Wei Feng","Wei Sui","Zhizhong Su"],"pdf_url":"","comment":"Demo video are available at https://horizonrobotics.github.io/robot_lab/fsr-vln/"},{"id":"http://arxiv.org/abs/2511.18910v2","updated":"2025-11-25T08:45:39Z","published":"2025-11-24T09:15:54Z","title":"An Efficient Closed-Form Solution to Full Visual-Inertial State Initialization","summary":"In this letter, we present a closed-form initialization method that recovers the full visual-inertial state without nonlinear optimization. Unlike previous approaches that rely on iterative solvers, our formulation yields analytical, easy-to-implement, and numerically stable solutions for reliable start-up. Our method builds on small-rotation and constant-velocity approximations, which keep the formulation compact while preserving the essential coupling between motion and inertial measurements. We further propose an observability-driven, two-stage initialization scheme that balances accuracy with initialization latency. Extensive experiments on the EuRoC dataset validate our assumptions: our method achieves 10-20% lower initialization error than optimization-based approaches, while using 4x shorter initialization windows and reducing computational cost by 5x.","authors":["Samuel Cerezo","Seong Hun Lee","Javier Civera"],"pdf_url":"","comment":"8 pages, 2 figures, 10 tables. Submitted to RA-L"},{"id":"http://arxiv.org/abs/2511.20050v1","updated":"2025-11-25T08:17:32Z","published":"2025-11-25T08:17:32Z","title":"Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification","summary":"In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.","authors":["Yan Li","Yingzhao Li","Gim Hee Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.05718v3","updated":"2025-11-25T07:32:45Z","published":"2024-12-07T18:31:16Z","title":"RLZero: Direct Policy Inference from Language Without In-Domain Supervision","summary":"The reward hypothesis states that all goals and purposes can be understood as the maximization of a received scalar reward signal. However, in practice, defining such a reward signal is notoriously difficult, as humans are often unable to predict the optimal behavior corresponding to a reward function. Natural language offers an intuitive alternative for instructing reinforcement learning (RL) agents, yet previous language-conditioned approaches either require costly supervision or test-time training given a language instruction. In this work, we present a new approach that uses a pretrained RL agent trained using only unlabeled, offline interactions--without task-specific supervision or labeled trajectories--to get zero-shot test-time policy inference from arbitrary natural language instructions. We introduce a framework comprising three steps: imagine, project, and imitate. First, the agent imagines a sequence of observations corresponding to the provided language description using video generative models. Next, these imagined observations are projected into the target environment domain. Finally, an agent pretrained in the target environment with unsupervised RL instantly imitates the projected observation sequence through a closed-form solution. To the best of our knowledge, our method, RLZero, is the first approach to show direct language-to-behavior generation abilities on a variety of tasks and environments without any in-domain supervision. We further show that components of RLZero can be used to generate policies zero-shot from cross-embodied videos, such as those available on YouTube, even for complex embodiments like humanoids.","authors":["Harshit Sikchi","Siddhant Agarwal","Pranaya Jajoo","Samyak Parajuli","Caleb Chuck","Max Rudolph","Peter Stone","Amy Zhang","Scott Niekum"],"pdf_url":"","comment":"NeurIPS 2025, 26 pages"},{"id":"http://arxiv.org/abs/2412.15447v3","updated":"2025-11-25T06:55:58Z","published":"2024-12-19T22:59:55Z","title":"LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene Reconstruction","summary":"Photorealistic 3D scene reconstruction plays an important role in autonomous driving, enabling the generation of novel data from existing datasets to simulate safety-critical scenarios and expand training data without additional acquisition costs. Gaussian Splatting (GS) facilitates real-time, photorealistic rendering with an explicit 3D Gaussian representation of the scene, providing faster processing and more intuitive scene editing than the implicit Neural Radiance Fields (NeRFs). While extensive GS research has yielded promising advancements in autonomous driving applications, they overlook two critical aspects: First, existing methods mainly focus on low-speed and feature-rich urban scenes and ignore the fact that highway scenarios play a significant role in autonomous driving. Second, while LiDARs are commonplace in autonomous driving platforms, existing methods learn primarily from images and use LiDAR only for initial estimates or without precise sensor modeling, thus missing out on leveraging the rich depth information LiDAR offers and limiting the ability to synthesize LiDAR data. In this paper, we propose a novel GS method for dynamic scene synthesis and editing with improved scene reconstruction through LiDAR supervision and support for LiDAR rendering. Unlike prior works that are tested mostly on urban datasets, to the best of our knowledge, we are the first to focus on the more challenging and highly relevant highway scenes for autonomous driving, with sparse sensor views and monotone backgrounds. Visit our project page at: https://umautobots.github.io/lihi_gs","authors":["Pou-Chun Kung","Xianling Zhang","Katherine A. Skinner","Nikita Jaipuria"],"pdf_url":"","comment":"RA-L 2025"},{"id":"http://arxiv.org/abs/2511.05900v2","updated":"2025-11-25T06:39:10Z","published":"2025-11-08T07:50:53Z","title":"Disentangled Control of Multi-Agent Systems","summary":"This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments.","authors":["Ruoyu Lin","Gennaro Notomista","Magnus Egerstedt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01014v3","updated":"2025-11-25T06:20:26Z","published":"2025-08-01T18:27:23Z","title":"Hestia: Voxel-Face-Aware Hierarchical Next-Best-View Acquisition for Efficient 3D Reconstruction","summary":"Advances in 3D reconstruction and novel view synthesis have enabled efficient and photorealistic rendering. However, images for reconstruction are still either largely manual or constrained by simple preplanned trajectories. To address this issue, recent works propose generalizable next-best-view planners that do not require online learning. Nevertheless, robustness and performance remain limited across various shapes. Hence, this study introduces Voxel-Face-Aware Hierarchical Next-Best-View Acquisition for Efficient 3D Reconstruction (Hestia), which addresses the shortcomings of the reinforcement learning-based generalizable approaches for five-degree-of-freedom viewpoint prediction. Hestia systematically improves the planners through four components: a more diverse dataset to promote robustness, a hierarchical structure to manage the high-dimensional continuous action search space, a close-greedy strategy to mitigate spurious correlations, and a face-aware design to avoid overlooking geometry. Experimental results show that Hestia achieves non-marginal improvements, with at least a 4% gain in coverage ratio, while reducing Chamfer Distance by 50% and maintaining real-time inference. In addition, Hestia outperforms prior methods by at least 12% in coverage ratio with a 5-image budget and remains robust to object placement variations. Finally, we demonstrate that Hestia, as a next-best-view planner, is feasible for the real-world application. Our project page is https://johnnylu305.github.io/hestia web.","authors":["Cheng-You Lu","Zhuoli Zhuang","Nguyen Thanh Trung Le","Da Xiao","Yu-Cheng Chang","Thomas Do","Srinath Sridhar","Chin-teng Lin"],"pdf_url":"","comment":"Accepted to the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026"},{"id":"http://arxiv.org/abs/2511.19955v1","updated":"2025-11-25T06:01:04Z","published":"2025-11-25T06:01:04Z","title":"ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation","summary":"Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six- axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.","authors":["Jinxuan Zhu","Zihao Yan","Yangyu Xiao","Jingxiang Guo","Chenrui Tie","Xinyi Cao","Yuhang Zheng","Lin Shao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19932v1","updated":"2025-11-25T05:18:51Z","published":"2025-11-25T05:18:51Z","title":"Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine","summary":"The 3D bin packing problem, with its diverse industrial applications, has garnered significant research attention in recent years. Existing approaches typically model it as a discrete and static process, while real-world applications involve continuous gravity-driven interactions. This idealized simplification leads to infeasible deployments (e.g., unstable packing) in practice. Simulations with physical engine offer an opportunity to emulate continuous gravity effects, enabling the training of reinforcement learning (RL) agents to address such limitations and improve packing stability. However, a simulation-to-reality gap persists due to dynamic variations in physical properties of real-world objects, such as various friction coefficients, elasticity, and non-uniform weight distributions. To bridge this gap, we propose a hybrid RL framework that collaborates with physical simulation with real-world data feedback. Firstly, domain randomization is applied during simulation to expose agents to a spectrum of physical parameters, enhancing their generalization capability. Secondly, the RL agent is fine-tuned with real-world deployment feedback, further reducing collapse rates. Extensive experiments demonstrate that our method achieves lower collapse rates in both simulated and real-world scenarios. Large-scale deployments in logistics systems validate the practical effectiveness, with a 35\\% reduction in packing collapse compared to baseline methods.","authors":["Lidi Zhang","Han Wu","Liyu Zhang","Ruofeng Liu","Haotian Wang","Chao Li","Desheng Zhang","Yunhuai Liu","Tian He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.19430v2","updated":"2025-11-25T05:15:42Z","published":"2025-10-22T09:57:13Z","title":"GigaBrain-0: A World Model-Powered Vision-Language-Action Model","summary":"Training Vision-Language-Action (VLA) models for generalist robots typically requires large-scale real-world robot data, which is expensive and time-consuming to collect. The inefficiency of physical data collection severely limits the scalability, and generalization capacity of current VLA systems. To address this challenge, we introduce GigaBrain-0, a novel VLA foundation model empowered by world model-generated data (e.g., video generation, real2real transfer, human transfer, view transfer, sim2real transfer data). By leveraging world models to generate diverse data at scale, GigaBrain-0 significantly reduces reliance on real robot data while improving cross-task generalization. Our approach further improves policy robustness through RGBD input modeling and embodied Chain-of-Thought (CoT) supervision, enabling the model to reason about spatial geometry, object states, and long-horizon dependencies during task execution. This leads to substantial gains in real-world performance on dexterous, long-horizon, and mobile manipulation tasks. Extensive experiments demonstrate that GigaBrain-0 achieves superior generalization across variations in appearances (e.g., textures, colors), object placements, and camera viewpoints. Additionally, we present GigaBrain-0-Small, an optimized lightweight variant designed to run efficiently on devices such as the NVIDIA Jetson AGX Orin.","authors":[" GigaBrain Team","Angen Ye","Boyuan Wang","Chaojun Ni","Guan Huang","Guosheng Zhao","Haoyun Li","Jie Li","Jiagang Zhu","Lv Feng","Peng Li","Qiuping Deng","Runqi Ouyang","Wenkang Qin","Xinze Chen","Xiaofeng Wang","Yang Wang","Yifan Li","Yilong Li","Yiran Ding","Yuan Xu","Yun Ye","Yukun Zhou","Zhehao Dong","Zhenan Wang","Zhichao Liu","Zheng Zhu"],"pdf_url":"","comment":"https://gigabrain0.github.io/"},{"id":"http://arxiv.org/abs/2511.19914v1","updated":"2025-11-25T04:46:30Z","published":"2025-11-25T04:46:30Z","title":"CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model","summary":"Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.","authors":["Dapeng Zhang","Fei Shen","Rui Zhao","Yinda Chen","Peng Zhi","Chenyang Li","Rui Zhou","Qingguo Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19912v1","updated":"2025-11-25T04:40:11Z","published":"2025-11-25T04:40:11Z","title":"Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving","summary":"Vision-Language-Action (VLA) models have recently shown strong decision-making capabilities in autonomous driving. However, existing VLAs often struggle with achieving efficient inference and generalizing to novel autonomous vehicle configurations and driving scenarios. In this paper, we propose Reasoning-VLA, a general and fast action-generation VLA framework. The proposed model employs a set of learnable action queries, initialized via Gaussian sampling from ground-truth trajectories within the training corpus. These learnable queries interact with reasoning-enhanced vision-language features to generate continuous action trajectories in parallel. To promote robust generalization, we consolidate eight publicly available autonomous driving datasets into a standardized, Chain-of-Thought reasoning-based, and easy-to-use data format for model training. Leveraging both supervised learning and reinforcement learning fine-tuning, extensive empirical evaluations across multiple benchmarks demonstrate that Reasoning-VLA achieves state-of-the-art performance, superior generalization capability, and the excellent inference speed reported to date.","authors":["Dapeng Zhang","Zhenlong Yuan","Zhangquan Chen","Chih-Ting Liao","Yinda Chen","Fei Shen","Qingguo Zhou","Tat-Seng Chua"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19880v1","updated":"2025-11-25T03:40:11Z","published":"2025-11-25T03:40:11Z","title":"Improved Linear-Time Construction of Minimal Dominating Set via Mobile Agents","summary":"Mobile agents have emerged as a powerful framework for solving fundamental graph problems in distributed settings in recent times. These agents, modelled as autonomous physical or software entities, possess local computation power, finite memory and have the ability to traverse a graph, offering efficient solutions to a range of classical problems. In this work, we focus on the problem of computing a \\emph{minimal dominating set} (mDS) in anonymous graphs using mobile agents. Building on the recently proposed optimal dispersion algorithm on the synchronous mobile agent model, we design two new algorithms that achieve a \\emph{linear-time} solution for this problem in the synchronous setting. Specifically, given a connected $n$-node graph with $n$ agents initially placed in either rooted or arbitrary configurations, we show that an mDS can be computed in $O(n)$ rounds using only $O(\\log n)$ bits of memory per agent, without using any prior knowledge of any global parameters. This improves upon the best-known complexity results in the literature over the same model. In addition, as natural by-products of our methodology, our algorithms also construct a spanning tree and elect a unique leader in $O(n)$ rounds, which are also important results of independent interest in the mobile-agent framework.","authors":["Prabhat Kumar Chand","Anisur Rahaman Molla"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19878v1","updated":"2025-11-25T03:39:37Z","published":"2025-11-25T03:39:37Z","title":"MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization","summary":"Vision-Language-Action (VLA) models inherit strong priors from pretrained Vision-Language Models (VLMs), but naive fine-tuning often disrupts these representations and harms generalization. Existing fixes -- freezing modules or applying uniform regularization -- either overconstrain adaptation or ignore the differing roles of VLA components. We present MAPS (Module-Wise Proximity Scheduling), the first robust fine-tuning framework for VLAs. Through systematic analysis, we uncover an empirical order in which proximity constraints should be relaxed to balance stability and flexibility. MAPS linearly schedules this relaxation, enabling visual encoders to stay close to their pretrained priors while action-oriented language layers adapt more freely. MAPS introduces no additional parameters or data, and can be seamlessly integrated into existing VLAs. Across MiniVLA-VQ, MiniVLA-OFT, OpenVLA-OFT, and challenging benchmarks such as SimplerEnv, CALVIN, LIBERO, as well as real-world evaluations on the Franka Emika Panda platform, MAPS consistently boosts both in-distribution and out-of-distribution performance (up to +30%). Our findings highlight empirically guided proximity to pretrained VLMs as a simple yet powerful principle for preserving broad generalization in VLM-to-VLA transfer.","authors":["Chengyue Huang","Mellon M. Zhang","Robert Azarcon","Glen Chou","Zsolt Kira"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.19654v2","updated":"2025-11-25T03:37:38Z","published":"2025-10-22T14:57:51Z","title":"From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction","summary":"Despite remarkable progress in driving world models, their potential for autonomous systems remains largely untapped: the world models are mostly learned for world simulation and decoupled from trajectory planning. While recent efforts aim to unify world modeling and planning in a single framework, the synergistic facilitation mechanism of world modeling for planning still requires further exploration. In this work, we introduce a new driving paradigm named Policy World Model (PWM), which not only integrates world modeling and trajectory planning within a unified architecture, but is also able to benefit planning using the learned world knowledge through the proposed action-free future state forecasting scheme. Through collaborative state-action prediction, PWM can mimic the human-like anticipatory perception, yielding more reliable planning performance. To facilitate the efficiency of video forecasting, we further introduce a dynamically enhanced parallel token generation mechanism, equipped with a context-guided tokenizer and an adaptive dynamic focal loss. Despite utilizing only front camera input, our method matches or exceeds state-of-the-art approaches that rely on multi-view and multi-modal inputs. Code and model weights will be released at https://github.com/6550Zhao/Policy-World-Model.","authors":["Zhida Zhao","Talas Fu","Yifan Wang","Lijun Wang","Huchuan Lu"],"pdf_url":"","comment":"Accepted by NuerIPS 2025 (Poster)"},{"id":"http://arxiv.org/abs/2502.18549v3","updated":"2025-11-25T03:25:11Z","published":"2025-02-25T16:05:33Z","title":"ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for Cooperative Multi-USV Target Defense","summary":"The target defense problem (TDP) for unmanned surface vehicles (USVs) concerns intercepting an adversarial USV before it breaches a designated target region, using one or more defending USVs. A particularly challenging scenario arises when the attacker exhibits superior maneuverability compared to the defenders, significantly complicating effective interception. To tackle this challenge, this letter introduces ARBoids, a novel adaptive residual reinforcement learning framework that integrates deep reinforcement learning (DRL) with the biologically inspired, force-based Boids model. Within this framework, the Boids model serves as a computationally efficient baseline policy for multi-agent coordination, while DRL learns a residual policy to adaptively refine and optimize the defenders' actions. The proposed approach is validated in a high-fidelity Gazebo simulation environment, demonstrating superior performance over traditional interception strategies, including pure force-based approaches and vanilla DRL policies. Furthermore, the learned policy exhibits strong adaptability to attackers with diverse maneuverability profiles, highlighting its robustness and generalization capability. The code of ARBoids will be released upon acceptance of this letter.","authors":["Jiyue Tao","Tongsheng Shen","Dexin Zhao","Feitian Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19869v1","updated":"2025-11-25T03:22:59Z","published":"2025-11-25T03:22:59Z","title":"Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function","summary":"Haptic shared control (HSC) is effective in teleoperation when full autonomy is limited by uncertainty or sensing constraints. However, autonomous control performance achieved by maximizing HSC strength is limited because the dynamics of the joystick and human arm affect the robot's behavior. We propose a cooperative framework coupling a joystick-independent autonomous controller with HSC. A control barrier function ignores joystick inputs within a safe region determined by the human operator in real-time, while HSC is engaged otherwise. A pilot experiment on simulated tasks with tele-operated underwater robot in virtual environment demonstrated improved accuracy and reduced required time over conventional HSC.","authors":["Eito Sato","Takahiro Wada"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14977v2","updated":"2025-11-25T03:09:09Z","published":"2025-11-18T23:45:30Z","title":"SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification","summary":"As more autonomous vehicles operate on public roads, understanding real-world behavior of autonomous vehicles is critical to analyzing traffic safety, making policies, and public acceptance. This paper proposes SVBRD-LLM, a framework that automatically discovers, verifies, and applies interpretable behavioral rules from real traffic videos through zero-shot prompt engineering. The framework extracts vehicle trajectories using YOLOv8 and ByteTrack, computes kinematic features, and employs GPT-5 zero-shot prompting to compare autonomous and human-driven vehicles, generating 35 structured behavioral rule hypotheses. These rules are tested on a validation set, iteratively refined based on failure cases to filter spurious correlations, and compiled into a high-confidence rule library. The framework is evaluated on an independent test set for speed change prediction, lane change prediction, and autonomous vehicle identification tasks. Experiments on over 1500 hours of real traffic videos show that the framework achieves 90.0% accuracy and 93.3% F1-score in autonomous vehicle identification. The discovered rules clearly reveal distinctive characteristics of autonomous vehicles in speed control smoothness, lane change conservativeness, and acceleration stability, with each rule accompanied by semantic description, applicable context, and validation confidence.","authors":["Xiangyu Li","Zhaomiao Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19861v1","updated":"2025-11-25T03:00:42Z","published":"2025-11-25T03:00:42Z","title":"GigaWorld-0: World Models as Data Engine to Empower Embodied AI","summary":"World models are emerging as a foundational paradigm for scalable, data-efficient embodied AI. In this work, we present GigaWorld-0, a unified world model framework designed explicitly as a data engine for Vision-Language-Action (VLA) learning. GigaWorld-0 integrates two synergistic components: GigaWorld-0-Video, which leverages large-scale video generation to produce diverse, texture-rich, and temporally coherent embodied sequences under fine-grained control of appearance, camera viewpoint, and action semantics; and GigaWorld-0-3D, which combines 3D generative modeling, 3D Gaussian Splatting reconstruction, physically differentiable system identification, and executable motion planning to ensure geometric consistency and physical realism. Their joint optimization enables the scalable synthesis of embodied interaction data that is visually compelling, spatially coherent, physically plausible, and instruction-aligned. Training at scale is made feasible through our efficient GigaTrain framework, which exploits FP8-precision and sparse attention to drastically reduce memory and compute requirements. We conduct comprehensive evaluations showing that GigaWorld-0 generates high-quality, diverse, and controllable data across multiple dimensions. Critically, VLA model (e.g., GigaBrain-0) trained on GigaWorld-0-generated data achieve strong real-world performance, significantly improving generalization and task success on physical robots without any real-world interaction during training.","authors":[" GigaWorld Team","Angen Ye","Boyuan Wang","Chaojun Ni","Guan Huang","Guosheng Zhao","Haoyun Li","Jiagang Zhu","Kerui Li","Mengyuan Xu","Qiuping Deng","Siting Wang","Wenkang Qin","Xinze Chen","Xiaofeng Wang","Yankai Wang","Yu Cao","Yifan Chang","Yuan Xu","Yun Ye","Yang Wang","Yukun Zhou","Zhengyuan Zhang","Zhehao Dong","Zheng Zhu"],"pdf_url":"","comment":"Project Page: https://gigaworld0.github.io/"},{"id":"http://arxiv.org/abs/2511.19859v1","updated":"2025-11-25T02:43:20Z","published":"2025-11-25T02:43:20Z","title":"Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation","summary":"Vision-Language-Action (VLA) models built upon Chain-of-Thought (CoT) have achieved remarkable success in advancing general-purpose robotic agents, owing to its significant perceptual comprehension. Recently, since text-only CoT struggles to adequately capture scene details in complex spatial environments, a highly promising strategy involves leveraging visual priors to guide robotic action generation. Nevertheless, these strategies face two inherent challenges: (i) a modality gap between visual observations and low-level actions, and (ii) unstable training due to competing objectives between visual prediction and action generation. To address these challenges, we propose a Vision-Integrated Trajectory Alignment (VITA) framework that learns a shared discrete latent space for vision and action, enabling joint modeling of perception and motor control. VITA introduces a implicit visual CoT: autoregressively generated tokens is simultaneously decoded into future frames predictions and robot actions, thereby internalizing visual dynamics as an inductive bias for motion planning. Extensive experiments on simulated and real-world environments demonstrate state-of-the-art performance. VITA improves 14.5\\%, 9.6\\% and 12.1\\% over existing baselines on CALVIN, LIBERO and SimplerEnv. Furthermore, VITA attains an average success rate of 80.5\\% across six real-world tasks, demonstrating its potential as a generalist robotic manipulation model.","authors":["Xiangkai Ma","Lekai Xing","Han Zhang","Wenzhong Li","Sanglu Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.04323v3","updated":"2025-11-25T02:31:45Z","published":"2024-12-05T16:39:01Z","title":"GRAM: Generalization in Deep RL with a Robust Adaptation Module","summary":"The reliable deployment of deep reinforcement learning in real-world settings requires the ability to generalize across a variety of conditions, including both in-distribution scenarios seen during training as well as novel out-of-distribution scenarios. In this work, we present a framework for dynamics generalization in deep reinforcement learning that unifies these two distinct types of generalization within a single architecture. We introduce a robust adaptation module that provides a mechanism for identifying and reacting to both in-distribution and out-of-distribution environment dynamics, along with a joint training pipeline that combines the goals of in-distribution adaptation and out-of-distribution robustness. Our algorithm GRAM achieves strong generalization performance across in-distribution and out-of-distribution scenarios upon deployment, which we demonstrate through extensive simulation and hardware locomotion experiments on a quadruped robot.","authors":["James Queeney","Xiaoyi Cai","Alexander Schperberg","Radu Corcodel","Mouhacine Benosman","Jonathan P. How"],"pdf_url":"","comment":"Accepted for publication in IEEE Robotics and Automation Letters (RA-L)"},{"id":"http://arxiv.org/abs/2511.18085v2","updated":"2025-11-25T02:25:13Z","published":"2025-11-22T15:00:08Z","title":"Continually Evolving Skill Knowledge in Vision Language Action Model","summary":"Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models leverage massive pretraining data to support diverse manipulation tasks, but they still depend heavily on task-specific fine-tuning, revealing a lack of continual learning capability. Existing continual learning methods are also resource-intensive to scale to VLA models. We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, modeling task-centric knowledge space, and TS-Stellar, capturing hierarchical task-skill structure. Stellar VLA enables self-supervised knowledge evolution through joint learning of task latent representation and the knowledge space, reducing annotation needs. Knowledge-guided expert routing provide task specialization without extra network parameters, lowering training overhead. Experiments on the LIBERO benchmark and real-world tasks show over 50 percentage average improvement in final success rates relative to baselines. TS-Stellar further excels in complex action inference, and in-depth analyses verify effective knowledge retention and discovery. Our code will be released soon.","authors":["Yuxuan Wu","Guangming Wang","Zhiheng Yang","Maoqing Yao","Brian Sheil","Hesheng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13100v2","updated":"2025-11-25T02:17:53Z","published":"2025-11-17T07:53:16Z","title":"Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing","summary":"As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \\sysname. \\sysname features two components: \\textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \\textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \\sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\\%. Additionally, \\sysname infers drone flight commands with 96.5\\% precision and improves drone tracking accuracy by over 22\\% when combined with other sensing modalities. \\textit{ Demo: {\\color{blue}https://eventpro25.github.io/EventPro/.} }","authors":["Xuecheng Chen","Jingao Xu","Wenhua Ding","Haoyang Wang","Xinyu Luo","Ruiyang Duan","Jialong Chen","Xueqian Wang","Yunhao Liu","Xinlei Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20906v1","updated":"2025-11-25T22:46:42Z","published":"2025-11-25T22:46:42Z","title":"Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy","summary":"Diffusion- and flow-based policies deliver state-of-the-art performance on long-horizon robotic manipulation and imitation learning tasks. However, these controllers employ a fixed inference budget at every control step, regardless of task complexity, leading to computational inefficiency for simple subtasks while potentially underperforming on challenging ones. To address these issues, we introduce Difficulty-Aware Stochastic Interpolant Policy (DA-SIP), a framework that enables robotic controllers to adaptively adjust their integration horizon in real time based on task difficulty. Our approach employs a difficulty classifier that analyzes observations to dynamically select the step budget, the optimal solver variant, and ODE/SDE integration at each control cycle. DA-SIP builds upon the stochastic interpolant formulation to provide a unified framework that unlocks diverse training and inference configurations for diffusion- and flow-based policies. Through comprehensive benchmarks across diverse manipulation tasks, DA-SIP achieves 2.6-4.4x reduction in total computation time while maintaining task success rates comparable to fixed maximum-computation baselines. By implementing adaptive computation within this framework, DA-SIP transforms generative robot controllers into efficient, task-aware systems that intelligently allocate inference resources where they provide the greatest benefit.","authors":["Inkook Chun","Seungjae Lee","Michael S. Albergo","Saining Xie","Eric Vanden-Eijnden"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20894v1","updated":"2025-11-25T22:21:27Z","published":"2025-11-25T22:21:27Z","title":"Efficient Greedy Algorithms for Feature Selection in Robot Visual Localization","summary":"Robot localization is a fundamental component of autonomous navigation in unknown environments. Among various sensing modalities, visual input from cameras plays a central role, enabling robots to estimate their position by tracking point features across image frames. However, image frames often contain a large number of features, many of which are redundant or uninformative for localization. Processing all features can introduce significant computational latency and inefficiency. This motivates the need for intelligent feature selection, identifying a subset of features that are most informative for localization over a prediction horizon. In this work, we propose two fast and memory-efficient feature selection algorithms that enable robots to actively evaluate the utility of visual features in real time. Unlike existing approaches with high computational and memory demands, the proposed methods are explicitly designed to reduce both time and memory complexity while achieving a favorable trade-off between computational efficiency and localization accuracy.","authors":["Vivek Pandey","Amirhossein Mollaei","Nader Motee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20887v1","updated":"2025-11-25T22:07:21Z","published":"2025-11-25T22:07:21Z","title":"ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation","summary":"Teleoperation systems are essential for efficiently collecting diverse and high-quality robot demonstration data, especially for complex, contact-rich tasks. However, current teleoperation platforms typically lack integrated force feedback, cross-embodiment generalization, and portable, user-friendly designs, limiting their practical deployment. To address these limitations, we introduce ACE-F, a cross embodiment foldable teleoperation system with integrated force feedback. Our approach leverages inverse kinematics (IK) combined with a carefully designed human-robot interface (HRI), enabling users to capture precise and high-quality demonstrations effortlessly. We further propose a generalized soft-controller pipeline integrating PD control and inverse dynamics to ensure robot safety and precise motion control across diverse robotic embodiments. Critically, to achieve cross-embodiment generalization of force feedback without additional sensors, we innovatively interpret end-effector positional deviations as virtual force signals, which enhance data collection and enable applications in imitation learning. Extensive teleoperation experiments confirm that ACE-F significantly simplifies the control of various robot embodiments, making dexterous manipulation tasks as intuitive as operating a computer mouse. The system is open-sourced at: https://acefoldable.github.io/","authors":["Rui Yan","Jiajian Fu","Shiqi Yang","Lars Paulsen","Xuxin Cheng","Xiaolong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20848v1","updated":"2025-11-25T20:56:27Z","published":"2025-11-25T20:56:27Z","title":"NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities","summary":"Neural Signal Operated Intelligent Robots (NOIR) system is a versatile brain-robot interface that allows humans to control robots for daily tasks using their brain signals. This interface utilizes electroencephalography (EEG) to translate human intentions regarding specific objects and desired actions directly into commands that robots can execute. We present NOIR 2.0, an enhanced version of NOIR. NOIR 2.0 includes faster and more accurate brain decoding algorithms, which reduce task completion time by 46%. NOIR 2.0 uses few-shot robot learning algorithms to adapt to individual users and predict their intentions. The new learning algorithms leverage foundation models for more sample-efficient learning and adaptation (15 demos vs. a single demo), significantly reducing overall human time by 65%.","authors":["Tasha Kim","Yingke Wang","Hanvit Cho","Alex Hodges"],"pdf_url":"","comment":"Conference on Robot Learning (CoRL 2024), CoRoboLearn"},{"id":"http://arxiv.org/abs/2511.20841v1","updated":"2025-11-25T20:46:31Z","published":"2025-11-25T20:46:31Z","title":"OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping","summary":"To manipulate objects in novel, unstructured environments, robots need task-oriented grasps that target object parts based on the given task. Geometry-based methods often struggle with visually defined parts, occlusions, and unseen objects. We introduce OVAL-Grasp, a zero-shot open-vocabulary approach to task-oriented, affordance based grasping that uses large-language models and vision-language models to allow a robot to grasp objects at the correct part according to a given task. Given an RGB image and a task, OVAL-Grasp identifies parts to grasp or avoid with an LLM, segments them with a VLM, and generates a 2D heatmap of actionable regions on the object. During our evaluations, we found that our method outperformed two task oriented grasping baselines on experiments with 20 household objects with 3 unique tasks for each. OVAL-Grasp successfully identifies and segments the correct object part 95% of the time and grasps the correct actionable area 78.3% of the time in real-world experiments with the Fetch mobile manipulator. Additionally, OVAL-Grasp finds correct object parts under partial occlusions, demonstrating a part selection success rate of 80% in cluttered scenes. We also demonstrate OVAL-Grasp's efficacy in scenarios that rely on visual features for part selection, and show the benefit of a modular design through our ablation experiments. Our project webpage is available at https://ekjt.github.io/OVAL-Grasp/","authors":["Edmond Tong","Advaith Balaji","Anthony Opipari","Stanley Lewis","Zhen Zeng","Odest Chadwicke Jenkins"],"pdf_url":"","comment":"10 pages, 7 figures, 3 tables. Presented at the 2025 International Symposium on Experimental Robotics (ISER)"},{"id":"http://arxiv.org/abs/2511.20720v1","updated":"2025-11-25T07:00:26Z","published":"2025-11-25T07:00:26Z","title":"DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving","summary":"Vision-Language Action (VLA) models unify perception, reasoning, and trajectory generation for autonomous driving, but suffer from significant inference latency due to deep transformer stacks. We present DeeAD, a training-free, action-guided early-exit framework that accelerates VLA planning by evaluating the physical feasibility of intermediate trajectories. Instead of relying on confidence scores, DeeAD terminates inference when predicted trajectories align with lightweight planning priors (e.g., Navigation or Low-precision Planning) within a tolerable deviation (<2m). To improve efficiency, we introduce a multi-hop controller that adaptively skips redundant layers based on the change rate of scores. DeeAD integrates into existing VLA models, such as ORION, without requiring retraining. Experiments on the Bench2Drive benchmark demonstrate up to 28% transformer-layer sparsity and 29% latency reduction, while preserving planning quality and safety.","authors":["Haibo HU","Lianming Huang","Nan Guan","Chun Jason Xue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19955v1","updated":"2025-11-25T06:01:04Z","published":"2025-11-25T06:01:04Z","title":"ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation","summary":"Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six-axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.","authors":["Jinxuan Zhu","Zihao Yan","Yangyu Xiao","Jingxiang Guo","Chenrui Tie","Xinyi Cao","Yuhang Zheng","Lin Shao"],"pdf_url":"","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2511.20651v1","updated":"2025-11-25T18:59:55Z","published":"2025-11-25T18:59:55Z","title":"RubricRL: Simple Generalizable Rewards for Text-to-Image Generation","summary":"Reinforcement learning (RL) has recently emerged as a promising approach for aligning text-to-image generative models with human preferences. A key challenge, however, lies in designing effective and interpretable rewards. Existing methods often rely on either composite metrics (e.g., CLIP, OCR, and realism scores) with fixed weights or a single scalar reward distilled from human preference models, which can limit interpretability and flexibility. We propose RubricRL, a simple and general framework for rubric-based reward design that offers greater interpretability, composability, and user control. Instead of using a black-box scalar signal, RubricRL dynamically constructs a structured rubric for each prompt--a decomposable checklist of fine-grained visual criteria such as object correctness, attribute accuracy, OCR fidelity, and realism--tailored to the input text. Each criterion is independently evaluated by a multimodal judge (e.g., o4-mini), and a prompt-adaptive weighting mechanism emphasizes the most relevant dimensions. This design not only produces interpretable and modular supervision signals for policy optimization (e.g., GRPO or PPO), but also enables users to directly adjust which aspects to reward or penalize. Experiments with an autoregressive text-to-image model demonstrate that RubricRL improves prompt faithfulness, visual detail, and generalizability, while offering a flexible and extensible foundation for interpretable RL alignment across text-to-image architectures.","authors":["Xuelu Feng","Yunsheng Li","Ziyu Wan","Zixuan Gao","Junsong Yuan","Dongdong Chen","Chunming Qiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20650v1","updated":"2025-11-25T18:59:53Z","published":"2025-11-25T18:59:53Z","title":"MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities","summary":"Traditional object detection models in medical imaging operate within a closed-set paradigm, limiting their ability to detect objects of novel labels. Open-vocabulary object detection (OVOD) addresses this limitation but remains underexplored in medical imaging due to dataset scarcity and weak text-image alignment. To bridge this gap, we introduce MedROV, the first Real-time Open Vocabulary detection model for medical imaging. To enable open-vocabulary learning, we curate a large-scale dataset, Omnis, with 600K detection samples across nine imaging modalities and introduce a pseudo-labeling strategy to handle missing annotations from multi-source datasets. Additionally, we enhance generalization by incorporating knowledge from a large pre-trained foundation model. By leveraging contrastive learning and cross-modal representations, MedROV effectively detects both known and novel structures. Experimental results demonstrate that MedROV outperforms the previous state-of-the-art foundation model for medical image detection with an average absolute improvement of 40 mAP50, and surpasses closed-set detectors by more than 3 mAP50, while running at 70 FPS, setting a new benchmark in medical detection. Our source code, dataset, and trained model are available at https://github.com/toobatehreem/MedROV.","authors":["Tooba Tehreem Sheikh","Jean Lahoud","Rao Muhammad Anwer","Fahad Shahbaz Khan","Salman Khan","Hisham Cholakkal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20649v1","updated":"2025-11-25T18:59:46Z","published":"2025-11-25T18:59:46Z","title":"Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges From Autoregressive Self-Rollout","summary":"Current autoregressive video diffusion models are constrained by three core bottlenecks: (i) the finite temporal horizon imposed by the base model's 3D Rotary Positional Embedding (3D-RoPE), (ii) slow prompt responsiveness in maintaining fine-grained action control during long-form rollouts, and (iii) the inability to realize discontinuous cinematic transitions within a single generation stream. We introduce $\\infty$-RoPE, a unified inference-time framework that addresses all three limitations through three interconnected components: Block-Relativistic RoPE, KV Flush, and RoPE Cut. Block-Relativistic RoPE reformulates temporal encoding as a moving local reference frame, where each newly generated latent block is rotated relative to the base model's maximum frame horizon while earlier blocks are rotated backward to preserve relative temporal geometry. This relativistic formulation eliminates fixed temporal positions, enabling continuous video generation far beyond the base positional limits. To obtain fine-grained action control without re-encoding, KV Flush renews the KV cache by retaining only two latent frames, the global sink and the last generated latent frame, thereby ensuring immediate prompt responsiveness. Finally, RoPE Cut introduces controlled discontinuities in temporal RoPE coordinates, enabling multi-cut scene transitions within a single continuous rollout. Together, these components establish $\\infty$-RoPE as a training-free foundation for infinite-horizon, controllable, and cinematic video diffusion. Comprehensive experiments show that $\\infty$-RoPE consistently surpasses previous autoregressive models in overall VBench scores.","authors":["Hidir Yesiltepe","Tuna Han Salih Meral","Adil Kaan Akan","Kaan Oktay","Pinar Yanardag"],"pdf_url":"","comment":"Project Page: https://infinity-rope.github.io/"},{"id":"http://arxiv.org/abs/2511.19431v2","updated":"2025-11-25T18:59:46Z","published":"2025-11-24T18:59:37Z","title":"Cloud4D: Estimating Cloud Properties at a High Spatial and Temporal Resolution","summary":"There has been great progress in improving numerical weather prediction and climate models using machine learning. However, most global models act at a kilometer-scale, making it challenging to model individual clouds and factors such as extreme precipitation, wind gusts, turbulence, and surface irradiance. Therefore, there is a need to move towards higher-resolution models, which in turn require high-resolution real-world observations that current instruments struggle to obtain. We present Cloud4D, the first learning-based framework that reconstructs a physically consistent, four-dimensional cloud state using only synchronized ground-based cameras. Leveraging a homography-guided 2D-to-3D transformer, Cloud4D infers the full 3D distribution of liquid water content at 25 m spatial and 5 s temporal resolution. By tracking the 3D liquid water content retrievals over time, Cloud4D additionally estimates horizontal wind vectors. Across a two-month deployment comprising six skyward cameras, our system delivers an order-of-magnitude improvement in space-time resolution relative to state-of-the-art satellite measurements, while retaining single-digit relative error ($<10\\%$) against collocated radar measurements. Code and data are available on our project page https://cloud4d.jacob-lin.com/.","authors":["Jacob Lin","Edward Gryspeerdt","Ronald Clark"],"pdf_url":"","comment":"NeurIPS 2025 Spotlight, project page: https://cloud4d.jacob-lin.com/"},{"id":"http://arxiv.org/abs/2511.20647v1","updated":"2025-11-25T18:59:45Z","published":"2025-11-25T18:59:45Z","title":"Diverse Video Generation with Determinantal Point Process-Guided Policy Optimization","summary":"While recent text-to-video (T2V) diffusion models have achieved impressive quality and prompt alignment, they often produce low-diversity outputs when sampling multiple videos from a single text prompt. We tackle this challenge by formulating it as a set-level policy optimization problem, with the goal of training a policy that can cover the diverse range of plausible outcomes for a given prompt. To address this, we introduce DPP-GRPO, a novel framework for diverse video generation that combines Determinantal Point Processes (DPPs) and Group Relative Policy Optimization (GRPO) theories to enforce explicit reward on diverse generations. Our objective turns diversity into an explicit signal by imposing diminishing returns on redundant samples (via DPP) while supplies groupwise feedback over candidate sets (via GRPO). Our framework is plug-and-play and model-agnostic, and encourages diverse generations across visual appearance, camera motions, and scene structure without sacrificing prompt fidelity or perceptual quality. We implement our method on WAN and CogVideoX, and show that our method consistently improves video diversity on state-of-the-art benchmarks such as VBench, VideoScore, and human preference studies. Moreover, we release our code and a new benchmark dataset of 30,000 diverse prompts to support future research.","authors":["Tahira Kazimi","Connor Dunlop","Pinar Yanardag"],"pdf_url":"","comment":"Project webpage: https://diverse-video.github.io/"},{"id":"http://arxiv.org/abs/2511.20648v1","updated":"2025-11-25T18:59:45Z","published":"2025-11-25T18:59:45Z","title":"LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight","summary":"To act in the world, a model must name what it sees and know where it is in 3D. Today's vision-language models (VLMs) excel at open-ended 2D description and grounding, yet multi-object 3D detection remains largely missing from the VLM toolbox. We present LocateAnything3D, a VLM-native recipe that casts 3D detection as a next-token prediction problem. The key is a short, explicit Chain-of-Sight (CoS) sequence that mirrors how human reason from images: find an object in 2D, then infer its distance, size, and pose. The decoder first emits 2D detections as a visual chain-of-thought, then predicts 3D boxes under an easy-to-hard curriculum: across objects, a near-to-far order reduces early ambiguity and matches ego-centric utility; within each object, a center-from-camera, dimensions, and rotation factorization ranks information by stability and learnability. This VLM-native interface preserves open-vocabulary and visual-prompting capability without specialized heads. On the challenging Omni3D benchmark, our model achieves state-of-the-art results, with 49.89 AP_3D, surpassing the previous best by +15.51 absolute improvement even when the baseline is given ground-truth 2D boxes. It also generalizes zero-shot to held-out categories with strong robustness. By turning 3D detection into a disciplined next-token problem, LocateAnything3D offers a practical foundation for models to perceive in 3D.","authors":["Yunze Man","Shihao Wang","Guowen Zhang","Johan Bjorck","Zhiqi Li","Liang-Yan Gui","Jim Fan","Jan Kautz","Yu-Xiong Wang","Zhiding Yu"],"pdf_url":"","comment":"Tech report. Project page: https://nvlabs.github.io/LocateAnything3D/"},{"id":"http://arxiv.org/abs/2511.20646v1","updated":"2025-11-25T18:59:34Z","published":"2025-11-25T18:59:34Z","title":"3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding","summary":"This paper addresses the challenge of training a single network to jointly perform multiple dense prediction tasks, such as segmentation and depth estimation, i.e., multi-task learning (MTL). Current approaches mainly capture cross-task relations in the 2D image space, often leading to unstructured features lacking 3D-awareness. We argue that 3D-awareness is vital for modeling cross-task correlations essential for comprehensive scene understanding. We propose to address this problem by integrating correlations across views, i.e., cost volume, as geometric consistency in the MTL network. Specifically, we introduce a lightweight Cross-view Module (CvM), shared across tasks, to exchange information across views and capture cross-view correlations, integrated with a feature from MTL encoder for multi-task predictions. This module is architecture-agnostic and can be applied to both single and multi-view data. Extensive results on NYUv2 and PASCAL-Context demonstrate that our method effectively injects geometric consistency into existing MTL methods to improve performance.","authors":["Xiaoye Wang","Chen Tang","Xiangyu Yue","Wei-Hong Li"],"pdf_url":"","comment":"3D-aware Multi-task Learning, Cross-view Correlations, Code will be available at https://github.com/WeiHongLee/CrossView3DMTL"},{"id":"http://arxiv.org/abs/2511.20645v1","updated":"2025-11-25T18:59:25Z","published":"2025-11-25T18:59:25Z","title":"PixelDiT: Pixel Diffusion Transformers for Image Generation","summary":"Latent-space modeling has been the standard for Diffusion Transformers (DiTs). However, it relies on a two-stage pipeline where the pretrained autoencoder introduces lossy reconstruction, leading to error accumulation while hindering joint optimization. To address these issues, we propose PixelDiT, a single-stage, end-to-end model that eliminates the need for the autoencoder and learns the diffusion process directly in the pixel space. PixelDiT adopts a fully transformer-based architecture shaped by a dual-level design: a patch-level DiT that captures global semantics and a pixel-level DiT that refines texture details, enabling efficient training of a pixel-space diffusion model while preserving fine details. Our analysis reveals that effective pixel-level token modeling is essential to the success of pixel diffusion. PixelDiT achieves 1.61 FID on ImageNet 256x256, surpassing existing pixel generative models by a large margin. We further extend PixelDiT to text-to-image generation and pretrain it at the 1024x1024 resolution in pixel space. It achieves 0.74 on GenEval and 83.5 on DPG-bench, approaching the best latent diffusion models.","authors":["Yongsheng Yu","Wei Xiong","Weili Nie","Yichen Sheng","Shiqiu Liu","Jiebo Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20644v1","updated":"2025-11-25T18:59:02Z","published":"2025-11-25T18:59:02Z","title":"Vision-Language Memory for Spatial Reasoning","summary":"Spatial reasoning is a critical capability for intelligent robots, yet current vision-language models (VLMs) still fall short of human-level performance in video-based spatial reasoning. This gap mainly stems from two challenges: a semantic-geometric misalignment that prevents consistent 3D understanding, and the absence of persistent memory to retain 3D representation and understanding over time. To address these limitations, we present VLM$^2$, a Vision-Language Model with persistent Memory for spatial reasoning with a view-consistent, 3D-aware representation purely from 2D video. Specifically, to enhance long-horizon reasoning, we incorporate a dual-memory module, consisting of a working memory that operates as a sliding window to focus on immediate context, and an episodic memory that consolidates and stores critical long-term information. This design enables efficient and long-horizon spatial reasoning with a fixed computational cost. Extensive experiments on multiple benchmarks show that VLM$^2$ achieves state-of-the-art performance among video-only models, significantly advancing the frontier of visual-spatial intelligence.","authors":["Zuntao Liu","Yi Du","Taimeng Fu","Shaoshu Su","Cherie Ho","Chen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20643v1","updated":"2025-11-25T18:58:07Z","published":"2025-11-25T18:58:07Z","title":"Concept-Aware Batch Sampling Improves Language-Image Pretraining","summary":"What data should a vision-language model be trained on? To answer this question, many data curation efforts center on the quality of a dataset. However, most of these existing methods are (i) offline, i.e. they produce a static dataset from a set of predetermined filtering criteria, and (ii) concept-agnostic, i.e. they use model-based filters which induce additional data biases. In this work, we go beyond such offline, concept-agnostic methods and advocate for more flexible, task-adaptive online concept-based curation. Our first contribution is DataConcept, a collection of 128M web-crawled image-text pairs annotated with fine-grained details about their concept composition. Building on DataConcept, we introduce Concept-Aware Batch Sampling (CABS), a simple yet effective batch sampling framework that flexibly constructs batches on-the-fly based on specific target distributions. We propose two variants: (i) Diversity Maximization (CABS-DM) to curate batches with a broad coverage of available concepts, and (ii) Frequency Maximization (CABS-FM) to curate batches with high object multiplicity. Through extensive evaluations across 28 benchmarks, we demonstrate that our CABS method significantly benefits CLIP/SigLIP model classes and yields highly performant models. Overall, CABS represents a strong open-source alternative to proprietary online data curation algorithms, enabling practitioners to define custom concept distributions that optimize for specific downstream tasks.","authors":["Adhiraj Ghosh","Vishaal Udandarao","Thao Nguyen","Matteo Farina","Mehdi Cherti","Jenia Jitsev","Sewoong Oh","Elisa Ricci","Ludwig Schmidt","Matthias Bethge"],"pdf_url":"","comment":"Tech Report"},{"id":"http://arxiv.org/abs/2209.15402v3","updated":"2025-11-25T18:57:28Z","published":"2022-09-30T12:00:54Z","title":"Rethinking the Learning Paradigm for Facial Expression Recognition","summary":"Due to the subjective crowdsourcing annotations and the inherent inter-class similarity of facial expressions, the real-world Facial Expression Recognition (FER) datasets usually exhibit ambiguous annotation. To simplify the learning paradigm, most previous methods convert ambiguous annotation results into precise one-hot annotations and train FER models in an end-to-end supervised manner. In this paper, we rethink the existing training paradigm and propose that it is better to use weakly supervised strategies to train FER models with original ambiguous annotation.","authors":["Weijie Wang","Nicu Sebe","Bruno Lepri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20641v1","updated":"2025-11-25T18:57:28Z","published":"2025-11-25T18:57:28Z","title":"Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition","summary":"Long-tailed multi-label visual recognition poses a significant challenge, as images typically contain multiple labels with highly imbalanced class distributions, leading to biased models that favor head classes while underperforming on tail classes. Recent efforts have leveraged pre-trained vision-language models, such as CLIP, alongside long-tailed learning techniques to exploit rich visual-textual priors for improved performance. However, existing methods often derive semantic inter-class relationships directly from imbalanced datasets, resulting in unreliable correlations for tail classes due to data scarcity. Moreover, CLIP's zero-shot paradigm is optimized for single-label image-text matching, making it suboptimal for multi-label tasks. To address these issues, we propose the correlation adaptation prompt network (CAPNET), a novel end-to-end framework that explicitly models label correlations from CLIP's textual encoder. The framework incorporates a graph convolutional network for label-aware propagation and learnable soft prompts for refined embeddings. It utilizes a distribution-balanced Focal loss with class-aware re-weighting for optimized training under imbalance. Moreover, it improves generalization through test-time ensembling and realigns visual-textual modalities using parameter-efficient fine-tuning to avert overfitting on tail classes without compromising head class performance. Extensive experiments and ablation studies on benchmarks including VOC-LT, COCO-LT, and NUS-WIDE demonstrate that CAPNET achieves substantial improvements over state-of-the-art methods, validating its effectiveness for real-world long-tailed multi-label visual recognition.","authors":["Wei Tang","Zuo-Zheng Wang","Kun Zhang","Tong Wei","Min-Ling Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20640v1","updated":"2025-11-25T18:57:25Z","published":"2025-11-25T18:57:25Z","title":"MotionV2V: Editing Motion in a Video","summary":"While generative video models have achieved remarkable fidelity and consistency, applying these capabilities to video editing remains a complex challenge. Recent research has explored motion controllability as a means to enhance text-to-video generation or image animation; however, we identify precise motion control as a promising yet under-explored paradigm for editing existing videos. In this work, we propose modifying video motion by directly editing sparse trajectories extracted from the input. We term the deviation between input and output trajectories a \"motion edit\" and demonstrate that this representation, when coupled with a generative backbone, enables powerful video editing capabilities. To achieve this, we introduce a pipeline for generating \"motion counterfactuals\", video pairs that share identical content but distinct motion, and we fine-tune a motion-conditioned video diffusion architecture on this dataset. Our approach allows for edits that start at any timestamp and propagate naturally. In a four-way head-to-head user study, our model achieves over 65 percent preference against prior work. Please see our project page: https://ryanndagreat.github.io/MotionV2V","authors":["Ryan Burgert","Charles Herrmann","Forrester Cole","Michael S Ryoo","Neal Wadhwa","Andrey Voynov","Nataniel Ruiz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20635v1","updated":"2025-11-25T18:54:16Z","published":"2025-11-25T18:54:16Z","title":"iMontage: Unified, Versatile, Highly Dynamic Many-to-many Image Generation","summary":"Pre-trained video models learn powerful priors for generating high-quality, temporally coherent content. While these models excel at temporal coherence, their dynamics are often constrained by the continuous nature of their training data. We hypothesize that by injecting the rich and unconstrained content diversity from image data into this coherent temporal framework, we can generate image sets that feature both natural transitions and a far more expansive dynamic range. To this end, we introduce iMontage, a unified framework designed to repurpose a powerful video model into an all-in-one image generator. The framework consumes and produces variable-length image sets, unifying a wide array of image generation and editing tasks. To achieve this, we propose an elegant and minimally invasive adaptation strategy, complemented by a tailored data curation process and training paradigm. This approach allows the model to acquire broad image manipulation capabilities without corrupting its invaluable original motion priors. iMontage excels across several mainstream many-in-many-out tasks, not only maintaining strong cross-image contextual consistency but also generating scenes with extraordinary dynamics that surpass conventional scopes. Find our homepage at: https://kr1sjfu.github.io/iMontage-web/.","authors":["Zhoujie Fu","Xianfang Zeng","Jinghong Lan","Xinyao Liao","Cheng Chen","Junyi Chen","Jiacheng Wei","Wei Cheng","Shiyu Liu","Yunuo Chen","Gang Yu","Guosheng Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20629v1","updated":"2025-11-25T18:49:21Z","published":"2025-11-25T18:49:21Z","title":"MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models","summary":"Reinforcement learning from human feedback (RLHF) with reward models has advanced alignment of generative models to human aesthetic and perceptual preferences. However, jointly optimizing multiple rewards often incurs an alignment tax, improving one dimension while degrading others. To address this, we introduce two complementary methods: MapReduce LoRA and Reward-aware Token Embedding (RaTE). MapReduce LoRA trains preference-specific LoRA experts in parallel and iteratively merges them to refine a shared base model; RaTE learns reward-specific token embeddings that compose at inference for flexible preference control. Experiments on Text-to-Image generation (Stable Diffusion 3.5 Medium and FLUX.1-dev) show improvements of 36.1%, 4.6%, and 55.7%, and 32.7%, 4.3%, and 67.1% on GenEval, PickScore, and OCR, respectively. On Text-to-Video generation (HunyuanVideo), visual and motion quality improve by 48.1% and 90.0%, respectively. On the language task, Helpful Assistant, with Llama-2 7B, helpful and harmless improve by 43.4% and 136.7%, respectively. Our framework sets a new state-of-the-art multi-preference alignment recipe across modalities.","authors":["Chieh-Yun Chen","Zhonghao Wang","Qi Chen","Zhifan Ye","Min Shi","Yue Zhao","Yinan Zhao","Hui Qu","Wei-An Lin","Yiru Shen","Ajinkya Kale","Irfan Essa","Humphrey Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20624v1","updated":"2025-11-25T18:47:27Z","published":"2025-11-25T18:47:27Z","title":"ShapeGen: Towards High-Quality 3D Shape Synthesis","summary":"Inspired by generative paradigms in image and video, 3D shape generation has made notable progress, enabling the rapid synthesis of high-fidelity 3D assets from a single image. However, current methods still face challenges, including the lack of intricate details, overly smoothed surfaces, and fragmented thin-shell structures. These limitations leave the generated 3D assets still one step short of meeting the standards favored by artists. In this paper, we present ShapeGen, which achieves high-quality image-to-3D shape generation through 3D representation and supervision improvements, resolution scaling up, and the advantages of linear transformers. These advancements allow the generated assets to be seamlessly integrated into 3D pipelines, facilitating their widespread adoption across various applications. Through extensive experiments, we validate the impact of these improvements on overall performance. Ultimately, thanks to the synergistic effects of these enhancements, ShapeGen achieves a significant leap in image-to-3D generation, establishing a new state-of-the-art performance.","authors":["Yangguang Li","Xianglong He","Zi-Xin Zou","Zexiang Liu","Wanli Ouyang","Ding Liang","Yan-Pei Cao"],"pdf_url":"","comment":"Accepted to SIGGRAPH Asia 2025"},{"id":"http://arxiv.org/abs/2511.20620v1","updated":"2025-11-25T18:43:55Z","published":"2025-11-25T18:43:55Z","title":"Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI","summary":"Reproducible closed-loop evaluation remains a major bottleneck in Embodied AI such as visual navigation. A promising path forward is high-fidelity simulation that combines photorealistic sensor rendering with geometrically grounded interaction in complex, open-world urban environments. Although recent video-3DGS methods ease open-world scene capturing, they are still unsuitable for benchmarking due to large visual and geometric sim-to-real gaps. To address these challenges, we introduce Wanderland, a real-to-sim framework that features multi-sensor capture, reliable reconstruction, accurate geometry, and robust view synthesis. Using this pipeline, we curate a diverse dataset of indoor-outdoor urban scenes and systematically demonstrate how image-only pipelines scale poorly, how geometry quality impacts novel view synthesis, and how all of these adversely affect navigation policy learning and evaluation reliability. Beyond serving as a trusted testbed for embodied navigation, Wanderland's rich raw sensor data further allows benchmarking of 3D reconstruction and novel view synthesis models. Our work establishes a new foundation for reproducible research in open-world embodied AI. Project website is at https://ai4ce.github.io/wanderland/.","authors":["Xinhao Liu","Jiaqi Li","Youming Deng","Ruxin Chen","Yingjia Zhang","Yifei Ma","Li Guo","Yiming Li","Jing Zhang","Chen Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.14993v3","updated":"2025-11-25T18:43:50Z","published":"2024-09-23T13:16:09Z","title":"Multi-modal Generative AI: Multi-modal LLMs, Diffusions, and the Unification","summary":"Multi-modal generative AI (Artificial Intelligence) has attracted increasing attention from both academia and industry. Particularly, two dominant families of techniques have emerged: i) Multi-modal large language models (LLMs) demonstrate impressive ability for multi-modal understanding; and ii) Diffusion models exhibit remarkable multi-modal powers in terms of multi-modal generation. Therefore, this paper provides a comprehensive overview of multi-modal generative AI, including multi-modal LLMs, diffusions, and the unification for understanding and generation. To lay a solid foundation for unified models, we first provide a detailed review of both multi-modal LLMs and diffusion models respectively, including their probabilistic modeling procedure, multi-modal architecture design, and advanced applications to image/video LLMs as well as text-to-image/video generation. Furthermore, we explore the emerging efforts toward unified models for understanding and generation. To achieve the unification of understanding and generation, we investigate key designs including autoregressive-based and diffusion-based modeling, as well as dense and Mixture-of-Experts (MoE) architectures. We then introduce several strategies for unified models, analyzing their potential advantages and disadvantages. In addition, we summarize the common datasets widely used for multi-modal generative AI pretraining. Last but not least, we present several challenging future research directions which may contribute to the ongoing advancement of multi-modal generative AI.","authors":["Xin Wang","Yuwei Zhou","Bin Huang","Hong Chen","Wenwu Zhu"],"pdf_url":"","comment":"21 pages, 10 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.20615v1","updated":"2025-11-25T18:40:48Z","published":"2025-11-25T18:40:48Z","title":"Evaluating the Performance of Deep Learning Models in Whole-body Dynamic 3D Posture Prediction During Load-reaching Activities","summary":"This study aimed to explore the application of deep neural networks for whole-body human posture prediction during dynamic load-reaching activities. Two time-series models were trained using bidirectional long short-term memory (BLSTM) and transformer architectures. The dataset consisted of 3D full-body plug-in gait dynamic coordinates from 20 normal-weight healthy male individuals each performing 204 load-reaching tasks from different load positions while adapting various lifting and handling techniques. The model inputs consisted of the 3D position of the hand-load position, lifting (stoop, full-squat and semi-squat) and handling (one- and two-handed) techniques, body weight and height, and the 3D coordinate data of the body posture from the first 25% of the task duration. These inputs were used by the models to predict body coordinates during the remaining 75% of the task period. Moreover, a novel method was proposed to improve the accuracy of the previous and present posture prediction networks by enforcing constant body segment lengths through the optimization of a new cost function. The results indicated that the new cost function decreased the prediction error of the models by approximately 8% and 21% for the arm and leg models, respectively. We indicated that utilizing the transformer architecture, with a root-mean-square-error of 47.0 mm, exhibited ~58% more accurate long-term performance than the BLSTM-based model. This study merits the use of neural networks that capture time series dependencies in 3D motion frames, providing a unique approach for understanding and predict motion dynamics during manual material handling activities.","authors":["Seyede Niloofar Hosseini","Ali Mojibi","Mahdi Mohseni","Navid Arjmand","Alireza Taheri"],"pdf_url":"","comment":"10 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2511.20614v1","updated":"2025-11-25T18:40:25Z","published":"2025-11-25T18:40:25Z","title":"The Consistency Critic: Correcting Inconsistencies in Generated Images via Reference-Guided Attentive Alignment","summary":"Previous works have explored various customized generation tasks given a reference image, but they still face limitations in generating consistent fine-grained details. In this paper, our aim is to solve the inconsistency problem of generated images by applying a reference-guided post-editing approach and present our ImageCritic. We first construct a dataset of reference-degraded-target triplets obtained via VLM-based selection and explicit degradation, which effectively simulates the common inaccuracies or inconsistencies observed in existing generation models. Furthermore, building on a thorough examination of the model's attention mechanisms and intrinsic representations, we accordingly devise an attention alignment loss and a detail encoder to precisely rectify inconsistencies. ImageCritic can be integrated into an agent framework to automatically detect inconsistencies and correct them with multi-round and local editing in complex scenarios. Extensive experiments demonstrate that ImageCritic can effectively resolve detail-related issues in various customized generation scenarios, providing significant improvements over existing methods.","authors":["Ziheng Ouyang","Yiren Song","Yaoli Liu","Shihao Zhu","Qibin Hou","Ming-Ming Cheng","Mike Zheng Shou"],"pdf_url":"","comment":"Project page: https://ouyangziheng.github.io/ImageCritic-Page/"},{"id":"http://arxiv.org/abs/2511.20607v1","updated":"2025-11-25T18:35:14Z","published":"2025-11-25T18:35:14Z","title":"Optimization of Sums of Bivariate Functions: An Introduction to Relaxation-Based Methods for the Case of Finite Domains","summary":"We study the optimization of functions with $n>2$ arguments that have a representation as a sum of several functions that have only $2$ of the $n$ arguments each, termed sums of bivariates, on finite domains. The complexity of optimizing sums of bivariates is shown to be NP-equivalent and it is shown that there exists free lunch in the optimization of sums of bivariates. Based on measure-valued extensions of the objective function, so-called relaxations, $\\ell^2$-approximation, and entropy-regularization, we derive several tractable problem formulations solvable with linear programming, coordinate ascent as well as with closed-form solutions. The limits of applying tractable versions of such relaxations to sums of bivariates are investigated using general results for reconstructing measures from their bivariate marginals. Experiments in which the derived algorithms are applied to random functions, vertex coloring, and signal reconstruction problems provide insights into qualitatively different function classes that can be modeled as sums of bivariates.","authors":["Nils Müller"],"pdf_url":"","comment":"59 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.20592v1","updated":"2025-11-25T18:21:33Z","published":"2025-11-25T18:21:33Z","title":"Latent Diffusion Inversion Requires Understanding the Latent Space","summary":"The recovery of training data from generative models (``model inversion'') has been extensively studied for diffusion models in the data domain. The encoder/decoder pair and corresponding latent codes have largely been ignored by inversion techniques applied to latent space generative models, e.g., Latent Diffusion models (LDMs). In this work we describe two key findings: (1) The diffusion model exhibits non-uniform memorization across latent codes, tending to overfit samples located in high-distortion regions of the decoder pullback metric. (2) Even within a single latent code, different dimensions contribute unequally to memorization. We introduce a principled method to rank latent dimensions by their per-dimensional contribution to the decoder pullback metric, identifying those most responsible for memorization. Empirically, removing less-memorizing dimensions when computing attack statistics for score-based membership inference attacker significantly improves performance, with average AUROC gains of 2.7\\% and substantial increases in TPR@1\\%FPR (6.42\\%) across diverse datasets including CIFAR-10, CelebA, ImageNet-1K, Pokémon, MS-COCO, and Flickr. This indicates stronger confidence in identifying members under extremely low false-positive tolerance. Our results highlight the overlooked influence of the auto-encoder geometry on LDM memorization and provide a new perspective for analyzing privacy risks in diffusion-based generative models.","authors":["Mingxing Rao","Bowen Qu","Daniel Moyer"],"pdf_url":"","comment":"14 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.20573v1","updated":"2025-11-25T18:06:22Z","published":"2025-11-25T18:06:22Z","title":"VQ-VA World: Towards High-Quality Visual Question-Visual Answering","summary":"This paper studies Visual Question-Visual Answering (VQ-VA): generating an image, rather than text, in response to a visual question -- an ability that has recently emerged in proprietary systems such as NanoBanana and GPT-Image. To also bring this capability to open-source models, we introduce VQ-VA World, a data-centric framework built around an agentic pipeline for large-scale, targeted data construction. Leveraging web-scale deployment, this pipeline crawls a massive amount of ~1.8M high-quality, interleaved image-text samples for model training. For evaluation, we further release IntelligentBench, a human-curated benchmark that systematically assesses VQ-VA along the aspects of world knowledge, design knowledge, and reasoning. Training with VQ-VA World data yields strong empirical gains: it helps LightFusion attain 53.06 on IntelligentBench, substantially surpassing the best prior open-source baselines (i.e., 7.78 from vanilla LightFusion; 1.94 from UniWorld-V1), and significantly narrowing the gap toward leading proprietary systems (e.g., 81.67 from NanoBanana; 82.64 from GPT-Image). By releasing the full suite of model weights, datasets, and pipelines, we hope to stimulate future research on VQ-VA.","authors":["Chenhui Gou","Zilong Chen","Zeyu Wang","Feng Li","Deyao Zhu","Zicheng Duan","Kunchang Li","Chaorui Deng","Hongyi Yuan","Haoqi Fan","Cihang Xie","Jianfei Cai","Hamid Rezatofighi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18832v2","updated":"2025-11-25T18:04:41Z","published":"2025-05-24T19:02:20Z","title":"Localizing Knowledge in Diffusion Transformers","summary":"Understanding how knowledge is distributed across the layers of generative models is crucial for improving interpretability, controllability, and adaptation. While prior work has explored knowledge localization in UNet-based architectures, Diffusion Transformer (DiT)-based models remain underexplored in this context. In this paper, we propose a model- and knowledge-agnostic method to localize where specific types of knowledge are encoded within the DiT blocks. We evaluate our method on state-of-the-art DiT-based models, including PixArt-alpha, FLUX, and SANA, across six diverse knowledge categories. We show that the identified blocks are both interpretable and causally linked to the expression of knowledge in generated outputs. Building on these insights, we apply our localization framework to two key applications: model personalization and knowledge unlearning. In both settings, our localized fine-tuning approach enables efficient and targeted updates, reducing computational cost, improving task-specific performance, and better preserving general model behavior with minimal interference to unrelated or surrounding content. Overall, our findings offer new insights into the internal structure of DiTs and introduce a practical pathway for more interpretable, efficient, and controllable model editing.","authors":["Arman Zarei","Samyadeep Basu","Keivan Rezaei","Zihao Lin","Sayan Nag","Soheil Feizi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20565v1","updated":"2025-11-25T18:00:00Z","published":"2025-11-25T18:00:00Z","title":"DINO-Tok: Adapting DINO for Visual Tokenizers","summary":"Recent advances in visual generation have highlighted the rise of Latent Generative Models (LGMs), which rely on effective visual tokenizers to bridge pixels and semantics. However, existing tokenizers are typically trained from scratch and struggle to balance semantic representation and reconstruction fidelity, particularly in high-dimensional latent spaces. In this work, we introduce DINO-Tok, a DINO-based visual tokenizer that unifies hierarchical representations into an information-complete latent space. By integrating shallow features that retain fine-grained details with deep features encoding global semantics, DINO-Tok effectively bridges pretrained representations and visual generation. We further analyze the challenges of vector quantization (VQ) in this high-dimensional space, where key information is often lost and codebook collapse occurs. We thus propose a global PCA reweighting mechanism to stabilize VQ and preserve essential information across dimensions. On ImageNet 256$\\times$256, DINO-Tok achieves state-of-the-art reconstruction performance, reaching 28.54 PSNR for autoencoding and 23.98 PSNR for VQ-based modeling, significantly outperforming prior tokenizers and comparable to billion-level data trained models (such as Hunyuan and Wan). These results demonstrate that adapting powerful pretrained vision models like DINO for tokenization enables semantically aligned and high-fidelity latent representations, enabling next-generation visual generative models. Code will be publicly available at https://github.com/MKJia/DINO-Tok.","authors":["Mingkai Jia","Mingxiao Li","Liaoyuan Fan","Tianxing Shi","Jiaxin Guo","Zeming Li","Xiaoyang Guo","Xiao-Xiao Long","Qian Zhang","Ping Tan","Wei Yin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20563v1","updated":"2025-11-25T17:59:07Z","published":"2025-11-25T17:59:07Z","title":"A Reason-then-Describe Instruction Interpreter for Controllable Video Generation","summary":"Diffusion Transformers have significantly improved video fidelity and temporal coherence, however, practical controllability remains limited. Concise, ambiguous, and compositionally complex user inputs contrast with the detailed prompts used in training, yielding an intent-output mismatch. We propose ReaDe, a universal, model-agnostic interpreter that converts raw instructions into precise, actionable specifications for downstream video generators. ReaDe follows a reason-then-describe paradigm: it first analyzes the user request to identify core requirements and resolve ambiguities, then produces detailed guidance that enables faithful, controllable generation. We train ReaDe via a two-stage optimization: (i) reasoning-augmented supervision imparts analytic parsing with stepwise traces and dense captions, and (ii) a multi-dimensional reward assigner enables stable, feedback-driven refinement for natural-style captions. Experiments across single- and multi-condition scenarios show consistent gains in instruction fidelity, caption accuracy, and downstream video quality, with strong generalization to reasoning-intensive and unseen inputs. ReaDe offers a practical route to aligning controllable video generation with accurately interpreted user intent. Project Page: https://sqwu.top/ReaDe/.","authors":["Shengqiong Wu","Weicai Ye","Yuanxing Zhang","Jiahao Wang","Quande Liu","Xintao Wang","Pengfei Wan","Kun Gai","Hao Fei","Tat-Seng Chua"],"pdf_url":"","comment":"27 pages, 13 figures, 13 tables, Project Page: https://sqwu.top/ReaDe/"},{"id":"http://arxiv.org/abs/2511.20562v1","updated":"2025-11-25T17:59:04Z","published":"2025-11-25T17:59:04Z","title":"PhysChoreo: Physics-Controllable Video Generation with Part-Aware Semantic Grounding","summary":"While recent video generation models have achieved significant visual fidelity, they often suffer from the lack of explicit physical controllability and plausibility. To address this, some recent studies attempted to guide the video generation with physics-based rendering. However, these methods face inherent challenges in accurately modeling complex physical properties and effectively control ling the resulting physical behavior over extended temporal sequences. In this work, we introduce PhysChoreo, a novel framework that can generate videos with diverse controllability and physical realism from a single image. Our method consists of two stages: first, it estimates the static initial physical properties of all objects in the image through part-aware physical property reconstruction. Then, through temporally instructed and physically editable simulation, it synthesizes high-quality videos with rich dynamic behaviors and physical realism. Experimental results show that PhysChoreo can generate videos with rich behaviors and physical realism, outperforming state-of-the-art methods on multiple evaluation metrics.","authors":["Haoze Zhang","Tianyu Huang","Zichen Wan","Xiaowei Jin","Hongzhi Zhang","Hui Li","Wangmeng Zuo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20561v1","updated":"2025-11-25T17:58:48Z","published":"2025-11-25T17:58:48Z","title":"Does Understanding Inform Generation in Unified Multimodal Models? From Analysis to Path Forward","summary":"Recent years have witnessed significant progress in Unified Multimodal Models, yet a fundamental question remains: Does understanding truly inform generation? To investigate this, we introduce UniSandbox, a decoupled evaluation framework paired with controlled, synthetic datasets to avoid data leakage and enable detailed analysis. Our findings reveal a significant understanding-generation gap, which is mainly reflected in two key dimensions: reasoning generation and knowledge transfer. Specifically, for reasoning generation tasks, we observe that explicit Chain-of-Thought (CoT) in the understanding module effectively bridges the gap, and further demonstrate that a self-training approach can successfully internalize this ability, enabling implicit reasoning during generation. Additionally, for knowledge transfer tasks, we find that CoT assists the generative process by helping retrieve newly learned knowledge, and also discover that query-based architectures inherently exhibit latent CoT-like properties that affect this transfer. UniSandbox provides preliminary insights for designing future unified architectures and training strategies that truly bridge the gap between understanding and generation. Code and data are available at https://github.com/PKU-YuanGroup/UniSandBox","authors":["Yuwei Niu","Weiyang Jin","Jiaqi Liao","Chaoran Feng","Peng Jin","Bin Lin","Zongjian Li","Bin Zhu","Weihao Yu","Li Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.17177v3","updated":"2025-11-25T17:49:27Z","published":"2025-09-21T17:53:30Z","title":"FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions","summary":"We conduct a moderate-scale contamination-free (to some extent) evaluation of current large reasoning models (LRMs) with some preliminary findings. We also release ROME, our evaluation benchmark for vision language models intended to test reasoning from visual clues. We attach links to the benchmark, evaluation data, and other updates on this website: https://flageval-baai.github.io/LRM-Eval/","authors":["Bowen Qin","Chen Yue","Fang Yin","Hui Wang","JG Yao","Jiakang Liu","Jing-Shu Zheng","Miguel Hu Chen","Richeng Xuan","Shibei Meng","Shiqi Zhou","Teng Dai","Tong-Shuai Ren","Wei Cui","Xi Yang","Xialin Du","Xiaojing Xu","Xue Sun","Xuejing Li","Yaming Liu","Yesheng Liu","Ying Liu","Yonghua Lin","Yu Zhao","Yunduo Zhang","Yuwen Luo","Zheqi He","Zhiyuan He","Zhongyuan Wang"],"pdf_url":"","comment":"Project homepage: https://flageval-baai.github.io/LRM-Eval/ This work will also be presented at NeurIPS 2025 Workshop on Foundations of Reasoning in Language Models (FoRLM); update with trials on Gemini 3 Pro"},{"id":"http://arxiv.org/abs/2511.20549v1","updated":"2025-11-25T17:47:11Z","published":"2025-11-25T17:47:11Z","title":"Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning","summary":"Diffusion Models have emerged as a leading class of generative models, yet their iterative sampling process remains computationally expensive. Timestep distillation is a promising technique to accelerate generation, but it often requires extensive training and leads to image quality degradation. Furthermore, fine-tuning these distilled models for specific objectives, such as aesthetic appeal or user preference, using Reinforcement Learning (RL) is notoriously unstable and easily falls into reward hacking. In this work, we introduce Flash-DMD, a novel framework that enables fast convergence with distillation and joint RL-based refinement. Specifically, we first propose an efficient timestep-aware distillation strategy that significantly reduces training cost with enhanced realism, outperforming DMD2 with only $2.1\\%$ its training cost. Second, we introduce a joint training scheme where the model is fine-tuned with an RL objective while the timestep distillation training continues simultaneously. We demonstrate that the stable, well-defined loss from the ongoing distillation acts as a powerful regularizer, effectively stabilizing the RL training process and preventing policy collapse. Extensive experiments on score-based and flow matching models show that our proposed Flash-DMD not only converges significantly faster but also achieves state-of-the-art generation quality in the few-step sampling regime, outperforming existing methods in visual quality, human preference, and text-image alignment metrics. Our work presents an effective paradigm for training efficient, high-fidelity, and stable generative models. Codes are coming soon.","authors":["Guanjie Chen","Shirui Huang","Kai Liu","Jianchen Zhu","Xiaoye Qu","Peng Chen","Yu Cheng","Yifu Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20544v1","updated":"2025-11-25T17:44:50Z","published":"2025-11-25T17:44:50Z","title":"New York Smells: A Large Multimodal Dataset for Olfaction","summary":"While olfaction is central to how animals perceive the world, this rich chemical sensory modality remains largely inaccessible to machines. One key bottleneck is the lack of diverse, multimodal olfactory training data collected in natural settings. We present New York Smells, a large dataset of paired image and olfactory signals captured ``in the wild.'' Our dataset contains 7,000 smell-image pairs from 3,500 distinct objects across indoor and outdoor environments, with approximately 70$\\times$ more objects than existing olfactory datasets. Our benchmark has three tasks: cross-modal smell-to-image retrieval, recognizing scenes, objects, and materials from smell alone, and fine-grained discrimination between grass species. Through experiments on our dataset, we find that visual data enables cross-modal olfactory representation learning, and that our learned olfactory representations outperform widely-used hand-crafted features.","authors":["Ege Ozguroglu","Junbang Liang","Ruoshi Liu","Mia Chiquier","Michael DeTienne","Wesley Wei Qian","Alexandra Horowitz","Andrew Owens","Carl Vondrick"],"pdf_url":"","comment":"Project website at https://smell.cs.columbia.edu"},{"id":"http://arxiv.org/abs/2511.18617v2","updated":"2025-11-25T17:43:27Z","published":"2025-11-23T21:21:10Z","title":"AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations","summary":"AutoFocus-IL is a simple yet effective method to improve data efficiency and generalization in visual imitation learning by guiding policies to attend to task-relevant features rather than distractors and spurious correlations. Although saliency regularization has emerged as a promising way to achieve this, existing approaches typically require costly supervision such as human gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages vision-language models (VLMs) to automatically identify and track key objects in demonstrations, generating temporal saliency maps that highlight causal visual signals while suppressing distractors. These maps are then used to regularize behavior cloning policies, yielding stronger alignment between visual attention and task-relevant cues. Experiments in both the CARLA simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not only outperforms standard behavior cloning but also surpasses state-of-the-art baselines that assume privileged access to human supervision, such as gaze data. Code, datasets, and trained policy videos are available at https://AutoFocus-IL.github.io/.","authors":["Litian Gong","Fatemeh Bahrani","Yutai Zhou","Amin Banayeeanzade","Jiachen Li","Erdem Bıyık"],"pdf_url":"","comment":"8 pages, 6 figures. Code and datasets available at http://autofocus-il.github.io/"},{"id":"http://arxiv.org/abs/2412.14327v3","updated":"2025-11-25T17:43:20Z","published":"2024-12-18T20:43:38Z","title":"Personalized Generative Low-light Image Denoising and Enhancement","summary":"Modern cameras' performance in low-light conditions remains suboptimal due to fundamental limitations in photon shot noise and sensor read noise. Generative image restoration methods have shown promising results compared to traditional approaches, but they suffer from hallucinatory content generation when the signal-to-noise ratio (SNR) is low. Leveraging the availability of personalized photo galleries of the users, we introduce Diffusion-based Personalized Generative Denoising (DiffPGD), a new approach that builds a customized diffusion model for individual users. Our key innovation lies in the development of an identity-consistent physical buffer that extracts the physical attributes of the person from the gallery. This ID-consistent physical buffer serves as a robust prior that can be seamlessly integrated into the diffusion model to restore degraded images without the need for fine-tuning. Over a wide range of low-light testing scenarios, we show that DiffPGD achieves superior image denoising and enhancement performance compared to existing diffusion-based denoising approaches. Our project page can be found at \\href{https://genai-restore.github.io/DiffPGD/}{\\textcolor{purple}{\\textbf{https://genai-restore.github.io/DiffPGD/}}}.","authors":["Xijun Wang","Prateek Chennuri","Dilshan Godaliyadda","Yu Yuan","Bole Ma","Xingguang Zhang","Hamid R. Sheikh","Stanley Chan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20541v1","updated":"2025-11-25T17:42:11Z","published":"2025-11-25T17:42:11Z","title":"Automated Monitoring of Cultural Heritage Artifacts Using Semantic Segmentation","summary":"This paper addresses the critical need for automated crack detection in the preservation of cultural heritage through semantic segmentation. We present a comparative study of U-Net architectures, using various convolutional neural network (CNN) encoders, for pixel-level crack identification on statues and monuments. A comparative quantitative evaluation is performed on the test set of the OmniCrack30k dataset [1] using popular segmentation metrics including Mean Intersection over Union (mIoU), Dice coefficient, and Jaccard index. This is complemented by an out-of-distribution qualitative evaluation on an unlabeled test set of real-world cracked statues and monuments. Our findings provide valuable insights into the capabilities of different CNN- based encoders for fine-grained crack segmentation. We show that the models exhibit promising generalization capabilities to unseen cultural heritage contexts, despite never having been explicitly trained on images of statues or monuments.","authors":["Andrea Ranieri","Giorgio Palmieri","Silvia Biasotti"],"pdf_url":"","comment":"Keywords: Cultural Heritage, Monitoring, Deep Learning, U-Nets, Semantic Segmentation"},{"id":"http://arxiv.org/abs/2511.20531v1","updated":"2025-11-25T17:34:32Z","published":"2025-11-25T17:34:32Z","title":"Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models","summary":"Visual Language Models (VLMs) are powerful generative tools but often produce factually in- accurate outputs due to a lack of robust reason- ing capabilities. While extensive research has been conducted on integrating external knowl- edge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seam- lessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leverag- ing structured knowledge graphs for multi-hop verification using image-captioning task to il- lustrate our framework. Our approach enables systematic reasoning across multiple steps, in- cluding visual entity recognition, knowledge graph traversal, and fact-based caption refine- ment. We evaluate the framework using hi- erarchical, triple-based and bullet-point based knowledge representations, analyzing their ef- fectiveness in factual accuracy and logical infer- ence. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions re- vealing key insights into reasoning patterns and failure modes. This work demonstrates the po- tential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.","authors":["Shamima Hossain"],"pdf_url":"","comment":"Accepted as poster at NewInML Workshop ICML, 2025"},{"id":"http://arxiv.org/abs/2511.18780v2","updated":"2025-11-25T17:33:32Z","published":"2025-11-24T05:27:05Z","title":"ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection","summary":"Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation.Our code is available at https://github.com/Ruize-Ma/ConceptGuard.","authors":["Ruize Ma","Minghong Cai","Yilei Jiang","Jiaming Han","Yi Feng","Yingshui Tan","Xiaoyong Zhu","Bo Zhang","Bo Zheng","Xiangyu Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20525v1","updated":"2025-11-25T17:29:12Z","published":"2025-11-25T17:29:12Z","title":"Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos","summary":"We introduce Mistake Attribution (MATT), a task for fine-grained understanding of human mistakes in egocentric video. Unlike prior mistake understanding work, which lacks fine-grained output, MATT concretely attributes mistakes to the input instruction text or the attempt video. MATT determines what part of the instruction is violated (semantic role), when the deviation becomes irreversible (the Point-of-No-Return, PNR), and where the mistake appears in the PNR frame. We develop MisEngine, a data engine that automatically constructs attribution-rich mistake samples from existing datasets and inherits their annotations. Applied to large egocentric corpora, MisEngine yields EPIC-KITCHENS-M and Ego4D-M, two datasets that are up to two orders of magnitude larger than prior mistake datasets. We then present MisFormer, a unified attention-based model for mistake attribution across semantic (what), temporal (when), and spatial (where) dimensions, trained using MisEngine supervision. Experiments on our new datasets and prior benchmarks show that MisFormer outperforms strong video-language, temporal localization, hand-object interaction, and mistake-detection baselines.","authors":["Yayuan Li","Aadit Jain","Filippos Bellos","Jason J. Corso"],"pdf_url":"","comment":"11 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2508.01772v3","updated":"2025-11-25T17:27:39Z","published":"2025-08-03T14:12:42Z","title":"LoRA-based methods on Unet for transfer learning in Subarachnoid Hematoma Segmentation","summary":"Aneurysmal subarachnoid hemorrhage (SAH) is a life-threatening neurological emergency with mortality rates exceeding 30%. Transfer learning from related hematoma types represents a potentially valuable but underexplored approach. Although Unet architectures remain the gold standard for medical image segmentation due to their effectiveness on limited datasets, Low-Rank Adaptation (LoRA) methods for parameter-efficient transfer learning have been rarely applied to convolutional neural networks in medical imaging contexts. We implemented a Unet architecture pre-trained on computed tomography scans from 124 traumatic brain injury patients across multiple institutions, then fine-tuned on 30 aneurysmal SAH patients from the University of Michigan Health System using 3-fold cross-validation. We developed a novel CP-LoRA method based on tensor CP-decomposition and introduced DoRA variants (DoRA-C, convDoRA, CP-DoRA) that decompose weight matrices into magnitude and directional components. We compared these approaches against existing LoRA methods (LoRA-C, convLoRA) and standard fine-tuning strategies across different modules on a multi-view Unet model. LoRA-based methods consistently outperformed standard Unet fine-tuning. Performance varied by hemorrhage volume, with all methods showing improved accuracy for larger volumes. CP-LoRA achieved comparable performance to existing methods while using significantly fewer parameters. Over-parameterization with higher ranks consistently yielded better performance than strictly low-rank adaptations. This study demonstrates that transfer learning between hematoma types is feasible and that LoRA-based methods significantly outperform conventional Unet fine-tuning for aneurysmal SAH segmentation.","authors":["Cristian Minoccheri","Matthew Hodgman","Haoyuan Ma","Rameez Merchant","Emily Wittrup","Craig Williamson","Kayvan Najarian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05865v2","updated":"2025-11-25T17:27:33Z","published":"2025-11-08T05:38:18Z","title":"CGCE: Classifier-Guided Concept Erasure in Generative Models","summary":"Recent advancements in large-scale generative models have enabled the creation of high-quality images and videos, but have also raised significant safety concerns regarding the generation of unsafe content. To mitigate this, concept erasure methods have been developed to remove undesirable concepts from pre-trained models. However, existing methods remain vulnerable to adversarial attacks that can regenerate the erased content. Moreover, achieving robust erasure often degrades the model's generative quality for safe, unrelated concepts, creating a difficult trade-off between safety and performance. To address this challenge, we introduce Classifier-Guided Concept Erasure (CGCE), an efficient plug-and-play framework that provides robust concept erasure for diverse generative models without altering their original weights. CGCE uses a lightweight classifier operating on text embeddings to first detect and then refine prompts containing undesired concepts. This approach is highly scalable, allowing for multi-concept erasure by aggregating guidance from several classifiers. By modifying only unsafe embeddings at inference time, our method prevents harmful content generation while preserving the model's original quality on benign prompts. Extensive experiments show that CGCE achieves state-of-the-art robustness against a wide range of red-teaming attacks. Our approach also maintains high generative utility, demonstrating a superior balance between safety and performance. We showcase the versatility of CGCE through its successful application to various modern T2I and T2V models, establishing it as a practical and effective solution for safe generative AI.","authors":["Viet Nguyen","Vishal M. Patel"],"pdf_url":"","comment":"26 pages, 17 figures"},{"id":"http://arxiv.org/abs/2511.20520v1","updated":"2025-11-25T17:23:38Z","published":"2025-11-25T17:23:38Z","title":"HBridge: H-Shape Bridging of Heterogeneous Experts for Unified Multimodal Understanding and Generation","summary":"Recent unified models integrate understanding experts (e.g., LLMs) with generative experts (e.g., diffusion models), achieving strong multimodal performance. However, recent advanced methods such as BAGEL and LMFusion follow the Mixture-of-Transformers (MoT) paradigm, adopting a symmetric design that mirrors one expert to another for convenient initialization and fusion, which remains suboptimal due to inherent modality discrepancies. In this work, we propose HBridge, an asymmetric H-shaped architecture that enables heterogeneous experts to optimally leverage pretrained priors from their respective modality domains. Unlike prior dense fusion strategies that straightforwardly connect all layers between experts via shared attention, HBridge selectively bridges intermediate layers, reducing over 40% attention sharing, which improves efficiency and enhances generation quality. Shallow and deep layers, which capture modality-specific representations, are decoupled, while mid-layer bridging promotes semantic alignment. To further strengthen cross-modal coherence, we introduce semantic reconstruction tokens that explicitly guide the generative expert to reconstruct visual semantic tokens of the target image. Extensive experiments across multiple benchmarks demonstrate the effectiveness and superior performance of HBridge, establishing a new paradigm for unified multimodal generation.","authors":["Xiang Wang","Zhifei Zhang","He Zhang","Zhe Lin","Yuqian Zhou","Qing Liu","Shiwei Zhang","Yijun Li","Shaoteng Liu","Haitian Zheng","Jason Kuen","Yuehuan Wang","Changxin Gao","Nong Sang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.14421v2","updated":"2025-11-25T17:20:44Z","published":"2025-03-18T16:55:07Z","title":"ExDDV: A New Dataset for Explainable Deepfake Detection in Video","summary":"The ever growing realism and quality of generated videos makes it increasingly harder for humans to spot deepfake content, who need to rely more and more on automatic deepfake detectors. However, deepfake detectors are also prone to errors, and their decisions are not explainable, leaving humans vulnerable to deepfake-based fraud and misinformation. To this end, we introduce ExDDV, the first dataset and benchmark for Explainable Deepfake Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that are manually annotated with text descriptions (to explain the artifacts) and clicks (to point out the artifacts). We evaluate a number of vision-language models on ExDDV, performing experiments with various fine-tuning and in-context learning strategies. Our results show that text and click supervision are both required to develop robust explainable models for deepfake videos, which are able to localize and describe the observed artifacts. Our novel dataset and code to reproduce the results are available at https://github.com/vladhondru25/ExDDV.","authors":["Vlad Hondru","Eduard Hogea","Darian Onchis","Radu Tudor Ionescu"],"pdf_url":"","comment":"Accepted at WACV 2026"},{"id":"http://arxiv.org/abs/2511.20515v1","updated":"2025-11-25T17:19:47Z","published":"2025-11-25T17:19:47Z","title":"AlignBench: Benchmarking Fine-Grained Image-Text Alignment with Synthetic Image-Caption Pairs","summary":"Assessing image-text alignment models such as CLIP is crucial for bridging visual and linguistic representations. Yet existing benchmarks rely on rule-based perturbations or short captions, limiting their ability to measure fine-grained alignment. We introduce AlignBench, a benchmark that provides a new indicator of image-text alignment by evaluating detailed image-caption pairs generated by diverse image-to-text and text-to-image models. Each sentence is annotated for correctness, enabling direct assessment of VLMs as alignment evaluators. Benchmarking a wide range of decoder-based VLMs reveals three key findings: (i) CLIP-based models, even those tailored for compositional reasoning, remain nearly blind; (ii) detectors systematically over-score early sentences; and (iii) they show strong self-preference, favoring their own outputs and harming detection performance. Our project page will be available at https://dahlian00.github.io/AlignBench/.","authors":["Kuniaki Saito","Risa Shinoda","Shohei Tanaka","Tosho Hirasawa","Fumio Okura","Yoshitaka Ushiku"],"pdf_url":"","comment":"Project Page: https://dahlian00.github.io/AlignBench/"},{"id":"http://arxiv.org/abs/2511.20513v1","updated":"2025-11-25T17:19:10Z","published":"2025-11-25T17:19:10Z","title":"DesignPref: Capturing Personal Preferences in Visual Design Generation","summary":"Generative models, such as large language models and text-to-image diffusion models, are increasingly used to create visual designs like user interfaces (UIs) and presentation slides. Finetuning and benchmarking these generative models have often relied on datasets of human-annotated design preferences. Yet, due to the subjective and highly personalized nature of visual design, preference varies widely among individuals. In this paper, we study this problem by introducing DesignPref, a dataset of 12k pairwise comparisons of UI design generation annotated by 20 professional designers with multi-level preference ratings. We found that among trained designers, substantial levels of disagreement exist (Krippendorff's alpha = 0.25 for binary preferences). Natural language rationales provided by these designers indicate that disagreements stem from differing perceptions of various design aspect importance and individual preferences. With DesignPref, we demonstrate that traditional majority-voting methods for training aggregated judge models often do not accurately reflect individual preferences. To address this challenge, we investigate multiple personalization strategies, particularly fine-tuning or incorporating designer-specific annotations into RAG pipelines. Our results show that personalized models consistently outperform aggregated baseline models in predicting individual designers' preferences, even when using 20 times fewer examples. Our work provides the first dataset to study personalized visual design evaluation and support future research into modeling individual design taste.","authors":["Yi-Hao Peng","Jeffrey P. Bigham","Jason Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20501v1","updated":"2025-11-25T17:08:14Z","published":"2025-11-25T17:08:14Z","title":"A Physics-Informed Loss Function for Boundary-Consistent and Robust Artery Segmentation in DSA Sequences","summary":"Accurate extraction and segmentation of the cerebral arteries from digital subtraction angiography (DSA) sequences is essential for developing reliable clinical management models of complex cerebrovascular diseases. Conventional loss functions often rely solely on pixel-wise overlap, overlooking the geometric and physical consistency of vascular boundaries, which can lead to fragmented or unstable vessel predictions. To overcome this limitation, we propose a novel \\textit{Physics-Informed Loss} (PIL) that models the interaction between the predicted and ground-truth boundaries as an elastic process inspired by dislocation theory in materials physics. This formulation introduces a physics-based regularization term that enforces smooth contour evolution and structural consistency, allowing the network to better capture fine vascular geometry. The proposed loss is integrated into several segmentation architectures, including U-Net, U-Net++, SegFormer, and MedFormer, and evaluated on two public benchmarks: DIAS and DSCA. Experimental results demonstrate that PIL consistently outperforms conventional loss functions such as Cross-Entropy, Dice, Active Contour, and Surface losses, achieving superior sensitivity, F1 score, and boundary coherence. These findings confirm that the incorporation of physics-based boundary interactions into deep neural networks improves both the precision and robustness of vascular segmentation in dynamic angiographic imaging. The implementation of the proposed method is publicly available at https://github.com/irfantahir301/Physicsis_loss.","authors":["Muhammad Irfan","Nasir Rahim","Khalid Mahmood Malik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15613v2","updated":"2025-11-25T16:38:28Z","published":"2025-11-19T17:01:02Z","title":"When to Think and When to Look: Uncertainty-Guided Lookback","summary":"Test-time thinking (that is, generating explicit intermediate reasoning chains) is known to boost performance in large language models and has recently shown strong gains for large vision language models (LVLMs). However, despite these promising results, there is still no systematic analysis of how thinking actually affects visual reasoning. We provide the first such analysis with a large scale, controlled comparison of thinking for LVLMs, evaluating ten variants from the InternVL3.5 and Qwen3-VL families on MMMU-val under generous token budgets and multi pass decoding. We show that more thinking is not always better; long chains often yield long wrong trajectories that ignore the image and underperform the same models run in standard instruct mode. A deeper analysis reveals that certain short lookback phrases, which explicitly refer back to the image, are strongly enriched in successful trajectories and correlate with better visual grounding. Building on this insight, we propose uncertainty guided lookback, a training free decoding strategy that combines an uncertainty signal with adaptive lookback prompts and breadth search. Our method improves overall MMMU performance, delivers the largest gains in categories where standard thinking is weak, and outperforms several strong decoding baselines, setting a new state of the art under fixed model families and token budgets. We further show that this decoding strategy generalizes, yielding consistent improvements on five additional benchmarks, including two broad multimodal suites and math focused visual reasoning datasets.","authors":["Jing Bi","Filippos Bellos","Junjia Guo","Yayuan Li","Chao Huang","Yolo Y. Tang","Luchuan Song","Susan Liang","Zhongfei Mark Zhang","Jason J. Corso","Chenliang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20474v1","updated":"2025-11-25T16:35:42Z","published":"2025-11-25T16:35:42Z","title":"Modular Deep Learning Framework for Assistive Perception: Gaze, Affect, and Speaker Identification","summary":"Developing comprehensive assistive technologies requires the seamless integration of visual and auditory perception. This research evaluates the feasibility of a modular architecture inspired by core functionalities of perceptive systems like 'Smart Eye.' We propose and benchmark three independent sensing modules: a Convolutional Neural Network (CNN) for eye state detection (drowsiness/attention), a deep CNN for facial expression recognition, and a Long Short-Term Memory (LSTM) network for voice-based speaker identification. Utilizing the Eyes Image, FER2013, and customized audio datasets, our models achieved accuracies of 93.0%, 97.8%, and 96.89%, respectively. This study demonstrates that lightweight, domain-specific models can achieve high fidelity on discrete tasks, establishing a validated foundation for future real-time, multimodal integration in resource-constrained assistive devices.","authors":["Akshit Pramod Anchan","Jewelith Thomas","Sritama Roy"],"pdf_url":"","comment":"10 pages, 9 figures, and 3 tables"},{"id":"http://arxiv.org/abs/2511.20469v1","updated":"2025-11-25T16:33:45Z","published":"2025-11-25T16:33:45Z","title":"Dance Style Classification using Laban-Inspired and Frequency-Domain Motion Features","summary":"Dance is an essential component of human culture and serves as a tool for conveying emotions and telling stories. Identifying and distinguishing dance genres based on motion data is a complex problem in human activity recognition, as many styles share similar poses, gestures, and temporal motion patterns. This work presents a lightweight framework for classifying dance styles that determines motion characteristics based on pose estimates extracted from videos. We propose temporal-spatial descriptors inspired by Laban Movement Analysis. These features capture local joint dynamics such as velocity, acceleration, and angular movement of the upper body, enabling a structured representation of spatial coordination. To further encode rhythmic and periodic aspects of movement, we integrate Fast Fourier Transform features that characterize movement patterns in the frequency domain. The proposed approach achieves robust classification of different dance styles with low computational effort, as complex model architectures are not required, and shows that interpretable motion representations can effectively capture stylistic nuances.","authors":["Ben Hamscher","Arnold Brosch","Nicolas Binninger","Maksymilian Jan Dejna","Kira Maag"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20462v1","updated":"2025-11-25T16:27:58Z","published":"2025-11-25T16:27:58Z","title":"STARFlow-V: End-to-End Video Generative Modeling with Normalizing Flow","summary":"Normalizing flows (NFs) are end-to-end likelihood-based generative models for continuous data, and have recently regained attention with encouraging progress on image generation. Yet in the video generation domain, where spatiotemporal complexity and computational cost are substantially higher, state-of-the-art systems almost exclusively rely on diffusion-based models. In this work, we revisit this design space by presenting STARFlow-V, a normalizing flow-based video generator with substantial benefits such as end-to-end learning, robust causal prediction, and native likelihood estimation. Building upon the recently proposed STARFlow, STARFlow-V operates in the spatiotemporal latent space with a global-local architecture which restricts causal dependencies to a global latent space while preserving rich local within-frame interactions. This eases error accumulation over time, a common pitfall of standard autoregressive diffusion model generation. Additionally, we propose flow-score matching, which equips the model with a light-weight causal denoiser to improve the video generation consistency in an autoregressive fashion. To improve the sampling efficiency, STARFlow-V employs a video-aware Jacobi iteration scheme that recasts inner updates as parallelizable iterations without breaking causality. Thanks to the invertible structure, the same model can natively support text-to-video, image-to-video as well as video-to-video generation tasks. Empirically, STARFlow-V achieves strong visual fidelity and temporal consistency with practical sampling throughput relative to diffusion-based baselines. These results present the first evidence, to our knowledge, that NFs are capable of high-quality autoregressive video generation, establishing them as a promising research direction for building world models. Code and generated samples are available at https://github.com/apple/ml-starflow.","authors":["Jiatao Gu","Ying Shen","Tianrong Chen","Laurent Dinh","Yuyang Wang","Miguel Angel Bautista","David Berthelot","Josh Susskind","Shuangfei Zhai"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2511.20460v1","updated":"2025-11-25T16:25:54Z","published":"2025-11-25T16:25:54Z","title":"Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA via Adaptive Zoom Search","summary":"With advances in satellite constellations, sensor technologies, and imaging pipelines, ultra-high-resolution (Ultra-HR) remote sensing imagery is becoming increasingly widespread. However, current remote sensing foundation models are ill-suited to such inputs: full-image encoding exhausts token and memory budgets, while resize-based preprocessing loses fine-grained and answer-critical details. In this context, guiding the model look where it matters before prediction becomes crucial. Therefore, we present ZoomSearch, a training-free, plug-and-play pipeline that decouples 'where to look' from 'how to answer' for Ultra-HR Remote Sensing Visual Question Answering (RS-VQA). ZoomSearch combines Adaptive Multi-Branch Zoom Search, which performs a hierarchical search over image patches to localize query-relevant regions, with Layout-Aware Patch Reassembly, which reorganizes the selected patches into a compact, layout-faithful canvas. We conduct comprehensive experiments on Ultra-HR RS-VQA benchmarks MME-RealWorld-RS and LRS-VQA, comparing against (i) strong general foundation models, (ii) remote sensing foundation models, (iii) Ultra-HR RS-VQA methods, and (iv) plug-and-play search-based VQA methods. When integrated with LLaVA-ov, ZoomSearch attains state-of-the-art accuracy across diverse tasks, improving the LLaVA-ov baseline by 26.3% on LRS-VQA and 114.8\\% on MME-RealWorld-RS. Meanwhile, it achieves much higher inference efficiency, outperforming prior search-based methods by 20%~44% in speed.","authors":["Yunqi Zhou","Chengjie Jiang","Chun Yuan","Jing Li"],"pdf_url":"","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2506.00979v2","updated":"2025-11-25T16:18:38Z","published":"2025-06-01T12:20:22Z","title":"IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and Video AIGC Detection","summary":"The rapid development of Artificial Intelligence Generated Content (AIGC) techniques has enabled the creation of high-quality synthetic content, but it also raises significant security concerns. Current detection methods face two major limitations: (1) the lack of multidimensional explainable datasets for generated images and videos. Existing open-source datasets (e.g., WildFake, GenVideo) rely on oversimplified binary annotations, which restrict the explainability and trustworthiness of trained detectors. (2) Prior MLLM-based forgery detectors (e.g., FakeVLM) exhibit insufficiently fine-grained interpretability in their step-by-step reasoning, which hinders reliable localization and explanation. To address these challenges, we introduce Ivy-Fake, the first large-scale multimodal benchmark for explainable AIGC detection. It consists of over 106K richly annotated training samples (images and videos) and 5,000 manually verified evaluation examples, sourced from multiple generative models and real world datasets through a carefully designed pipeline to ensure both diversity and quality. Furthermore, we propose Ivy-xDetector, a reinforcement learning model based on Group Relative Policy Optimization (GRPO), capable of producing explainable reasoning chains and achieving robust performance across multiple synthetic content detection benchmarks. Extensive experiments demonstrate the superiority of our dataset and confirm the effectiveness of our approach. Notably, our method improves performance on GenImage from 86.88% to 96.32%, surpassing prior state-of-the-art methods by a clear margin.","authors":["Changjiang Jiang","Wenhui Dong","Zhonghao Zhang","Chenyang Si","Fengchang Yu","Wei Peng","Xinbin Yuan","Yifei Bi","Ming Zhao","Zian Zhou","Caifeng Shan"],"pdf_url":"","comment":"30 pages"},{"id":"http://arxiv.org/abs/2511.20446v1","updated":"2025-11-25T16:17:23Z","published":"2025-11-25T16:17:23Z","title":"Learning to Generate Human-Human-Object Interactions from Textual Descriptions","summary":"The way humans interact with each other, including interpersonal distances, spatial configuration, and motion, varies significantly across different situations. To enable machines to understand such complex, context-dependent behaviors, it is essential to model multiple people in relation to the surrounding scene context. In this paper, we present a novel research problem to model the correlations between two people engaged in a shared interaction involving an object. We refer to this formulation as Human-Human-Object Interactions (HHOIs). To overcome the lack of dedicated datasets for HHOIs, we present a newly captured HHOIs dataset and a method to synthesize HHOI data by leveraging image generative models. As an intermediary, we obtain individual human-object interaction (HOIs) and human-human interaction (HHIs) from the HHOIs, and with these data, we train an text-to-HOI and text-to-HHI model using score-based diffusion model. Finally, we present a unified generative framework that integrates the two individual model, capable of synthesizing complete HHOIs in a single advanced sampling process. Our method extends HHOI generation to multi-human settings, enabling interactions involving more than two individuals. Experimental results show that our method generates realistic HHOIs conditioned on textual descriptions, outperforming previous approaches that focus only on single-human HOIs. Furthermore, we introduce multi-human motion generation involving objects as an application of our framework.","authors":["Jeonghyeon Na","Sangwon Baik","Inhee Lee","Junyoung Lee","Hanbyul Joo"],"pdf_url":"","comment":"Project Page: https://tlb-miss.github.io/hhoi/"},{"id":"http://arxiv.org/abs/2511.04283v2","updated":"2025-11-25T16:15:06Z","published":"2025-11-06T11:21:16Z","title":"FastGS: Training 3D Gaussian Splatting in 100 Seconds","summary":"The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to properly regulate the number of Gaussians during training, causing redundant computational time overhead. In this paper, we propose FastGS, a novel, simple, and general acceleration framework that fully considers the importance of each Gaussian based on multi-view consistency, efficiently solving the trade-off between training time and rendering quality. We innovatively design a densification and pruning strategy based on multi-view consistency, dispensing with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks & Temples, and Deep Blending datasets demonstrate that our method significantly outperforms the state-of-the-art methods in training speed, achieving a 3.32$\\times$ training acceleration and comparable rendering quality compared with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\\times$ acceleration compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that FastGS exhibits strong generality, delivering 2-7$\\times$ training acceleration across various tasks, including dynamic scene reconstruction, surface reconstruction, sparse-view reconstruction, large-scale reconstruction, and simultaneous localization and mapping. The project page is available at https://fastgs.github.io/","authors":["Shiwei Ren","Tianci Wen","Yongchun Fang","Biao Lu"],"pdf_url":"","comment":"Project page: https://fastgs.github.io/"},{"id":"http://arxiv.org/abs/2511.20439v1","updated":"2025-11-25T16:12:32Z","published":"2025-11-25T16:12:32Z","title":"Object-Centric Vision Token Pruning for Vision Language Models","summary":"In Vision Language Models (VLMs), vision tokens are quantity-heavy yet information-dispersed compared with language tokens, thus consume too much unnecessary computation. Pruning redundant vision tokens for high VLM inference efficiency has been continuously studied but all existing methods resort to indirect and non-guaranteed ways. We propose OC-VTP, a direct and guaranteed approach to select the most representative vision tokens for high-efficiency yet accuracy-preserving VLM inference. Our OC-VTP requires merely light-weight pre-training of a small object-centric vision token pruner, which can then be inserted into existing VLMs, without fine-tuning of any models on any datasets. It is gauranteed that the most representative vision tokens are kept by minimizing the error in reconstructing the original unpruned tokens from the selected ones. Across any vision pruning ratios, i.e., inference efficiency, our OC-VTP consistently helps mainstream VLMs to preserve the highest inference accuracy. Our pruning also demonstrates interesting interpretability. Our codes are available at https://github.com/GarryLarry010131/OC-VTP.","authors":["Guangyuan Li","Rongzhen Zhao","Jinhong Deng","Yanbo Wang","Joni Pajarinen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20431v1","updated":"2025-11-25T16:03:38Z","published":"2025-11-25T16:03:38Z","title":"BRIC: Bridging Kinematic Plans and Physical Control at Test Time","summary":"We propose BRIC, a novel test-time adaptation (TTA) framework that enables long-term human motion generation by resolving execution discrepancies between diffusion-based kinematic motion planners and reinforcement learning-based physics controllers. While diffusion models can generate diverse and expressive motions conditioned on text and scene context, they often produce physically implausible outputs, leading to execution drift during simulation. To address this, BRIC dynamically adapts the physics controller to noisy motion plans at test time, while preserving pre-trained skills via a loss function that mitigates catastrophic forgetting. In addition, BRIC introduces a lightweight test-time guidance mechanism that steers the diffusion model in the signal space without updating its parameters. By combining both adaptation strategies, BRIC ensures consistent and physically plausible long-term executions across diverse environments in an effective and efficient manner. We validate the effectiveness of BRIC on a variety of long-term tasks, including motion composition, obstacle avoidance, and human-scene interaction, achieving state-of-the-art performance across all tasks.","authors":["Dohun Lim","Minji Kim","Jaewoon Lim","Sungchan Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.14917v2","updated":"2025-11-25T16:00:05Z","published":"2025-08-15T13:22:29Z","title":"Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis","summary":"High-throughput imaging workflows, such as Parallel Rapid Imaging with Spectroscopic Mapping (PRISM), generate data at rates that exceed conventional real-time processing capabilities. We present a scalable FPGA-based preprocessing pipeline for real-time denoising, implemented via High-Level Synthesis (HLS) and optimized for DRAM-backed buffering. Our architecture performs frame subtraction and averaging directly on streamed image data, minimizing latency through burst-mode AXI4 interfaces. The resulting kernel operates below the inter-frame interval, enabling inline denoising and reducing dataset size for downstream CPU/GPU analysis. Validated under PRISM-scale acquisition, this modular FPGA framework offers a practical solution for latency-sensitive imaging workflows in spectroscopy and microscopy.","authors":["Weichien Liao"],"pdf_url":"","comment":"FPGA-based denoising pipeline for PRISM-scale imaging. Real-time frame subtraction and averaging via burst-mode AXI4 and DRAM buffering. Benchmarked against CPU/GPU workflows; scalable across multi-bank FPGA setups. Acknowledgements revised for consistency with journal submission; scientific content remains unchanged"},{"id":"http://arxiv.org/abs/2511.20426v1","updated":"2025-11-25T15:52:58Z","published":"2025-11-25T15:52:58Z","title":"Block Cascading: Training Free Acceleration of Block-Causal Video Models","summary":"Block-causal video generation faces a stark speed-quality trade-off: small 1.3B models manage only 16 FPS while large 14B models crawl at 4.5 FPS, forcing users to choose between responsiveness and quality. Block Cascading significantly mitigates this trade-off through training-free parallelization. Our key insight: future video blocks do not need fully denoised current blocks to begin generation. By starting block generation with partially denoised context from predecessors, we transform sequential pipelines into parallel cascades where multiple blocks denoise simultaneously. With 5 GPUs exploiting temporal parallelism, we achieve ~2x acceleration across all model scales: 1.3B models accelerate from 16 to 30 FPS, 14B models from 4.5 to 12.5 FPS. Beyond inference speed, Block Cascading eliminates overhead from KV-recaching (of ~200ms) during context switches for interactive generation. Extensive evaluations validated against multiple block-causal pipelines demonstrate no significant loss in generation quality when switching from block-causal to Block Cascading pipelines for inference. Project Page: https://hmrishavbandy.github.io/block_cascading_page/","authors":["Hmrishav Bandyopadhyay","Nikhil Pinnaparaju","Rahim Entezari","Jim Scott","Yi-Zhe Song","Varun Jampani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.08015v2","updated":"2025-11-25T15:51:29Z","published":"2025-09-08T23:08:23Z","title":"CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models","summary":"Generative models of 3D cardiovascular anatomy can synthesize informative structures for clinical research and medical device evaluation, but face a trade-off between geometric controllability and realism. We propose CardioComposer: a programmable, inference-time framework for generating multi-class anatomical label maps based on interpretable ellipsoidal primitives. These primitives represent geometric attributes such as the size, shape, and position of discrete substructures. We specifically develop differentiable measurement functions based on voxel-wise geometric moments, enabling loss-based gradient guidance during diffusion model sampling. We demonstrate that these losses can constrain individual geometric attributes in a disentangled manner and provide compositional control over multiple substructures. Finally, we show that our method is compatible with a wide array of anatomical systems containing non-convex substructures, spanning cardiac, vascular, and skeletal organs.","authors":["Karim Kadry","Shoaib Goraya","Ajay Manicka","Abdalla Abdelwahed","Naravich Chutisilp","Farhad Nezami","Elazer Edelman"],"pdf_url":"","comment":"10 pages, 16 figures"},{"id":"http://arxiv.org/abs/2501.17690v4","updated":"2025-11-25T15:50:33Z","published":"2025-01-29T14:58:48Z","title":"Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment","summary":"We introduce a novel segmentation-aware joint training framework called generative reinforcement network (GRN) that integrates segmentation loss feedback to optimize both image generation and segmentation performance in a single stage. An image enhancement technique called segmentation-guided enhancement (SGE) is also developed, where the generator produces images tailored specifically for the segmentation model. Two variants of GRN were also developed, including GRN for sample-efficient learning (GRN-SEL) and GRN for semi-supervised learning (GRN-SSL). GRN's performance was evaluated using a dataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The annotations included six anatomical structures: dermis, superficial fat, superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and muscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up to 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient (DSC) compared to models trained on fully labeled datasets. GRN-SEL alone reduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling requirements by 70%, and GRN-SSL alone by 60%, all while maintaining performance comparable to fully supervised models. These findings suggest the effectiveness of the GRN framework in optimizing segmentation performance with significantly less labeled data, offering a scalable and efficient solution for ultrasound image analysis and reducing the burdens associated with data annotation.","authors":["Zixue Zeng","Xiaoyan Zhao","Matthew Cartier","Tong Yu","Jing Wang","Xin Meng","Zhiyu Sheng","Maryam Satarpour","John M Cormack","Allison Bean","Ryan Nussbaum","Maya Maurer","Emily Landis-Walkenhorst","Dinesh Kumbhare","Kang Kim","Ajay Wasan","Jiantao Pu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20422v1","updated":"2025-11-25T15:48:49Z","published":"2025-11-25T15:48:49Z","title":"VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning","summary":"Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.","authors":["Bo Pang","Chenxi Xu","Jierui Ren","Guoping Wang","Sheng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20418v1","updated":"2025-11-25T15:42:33Z","published":"2025-11-25T15:42:33Z","title":"StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections","summary":"Multi-object tracking (MOT) is one of the most challenging tasks in computer vision, where it is important to correctly detect objects and associate these detections across frames. Current approaches mainly focus on tracking objects in each frame of a video stream, making it almost impossible to run the model under conditions of limited computing resources. To address this issue, we propose StableTrack, a novel approach that stabilizes the quality of tracking on low-frequency detections. Our method introduces a new two-stage matching strategy to improve the cross-frame association between low-frequency detections. We propose a novel Bbox-Based Distance instead of the conventional Mahalanobis distance, which allows us to effectively match objects using the Re-ID model. Furthermore, we integrate visual tracking into the Kalman Filter and the overall tracking pipeline. Our method outperforms current state-of-the-art trackers in the case of low-frequency detections, achieving $\\textit{11.6%}$ HOTA improvement at $\\textit{1}$ Hz on MOT17-val, while keeping up with the best approaches on the standard MOT17, MOT20, and DanceTrack benchmarks with full-frequency detections.","authors":["Matvei Shelukhan","Timur Mamedov","Karina Kvanchiani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20415v1","updated":"2025-11-25T15:40:12Z","published":"2025-11-25T15:40:12Z","title":"MajutsuCity: Language-driven Aesthetic-adaptive City Generation with Controllable 3D Assets and Layouts","summary":"Generating realistic 3D cities is fundamental to world models, virtual reality, and game development, where an ideal urban scene must satisfy both stylistic diversity, fine-grained, and controllability. However, existing methods struggle to balance the creative flexibility offered by text-based generation with the object-level editability enabled by explicit structural representations. We introduce MajutsuCity, a natural language-driven and aesthetically adaptive framework for synthesizing structurally consistent and stylistically diverse 3D urban scenes. MajutsuCity represents a city as a composition of controllable layouts, assets, and materials, and operates through a four-stage pipeline. To extend controllability beyond initial generation, we further integrate MajutsuAgent, an interactive language-grounded editing agent} that supports five object-level operations. To support photorealistic and customizable scene synthesis, we also construct MajutsuDataset, a high-quality multimodal dataset} containing 2D semantic layouts and height maps, diverse 3D building assets, and curated PBR materials and skyboxes, each accompanied by detailed annotations. Meanwhile, we develop a practical set of evaluation metrics, covering key dimensions such as structural consistency, scene complexity, material fidelity, and lighting atmosphere. Extensive experiments demonstrate MajutsuCity reduces layout FID by 83.7% compared with CityDreamer and by 20.1% over CityCraft. Our method ranks first across all AQS and RDR scores, outperforming existing methods by a clear margin. These results confirm MajutsuCity as a new state-of-the-art in geometric fidelity, stylistic adaptability, and semantic controllability for 3D city generation. We expect our framework can inspire new avenues of research in 3D city generation. Our dataset and code will be released at https://github.com/LongHZ140516/MajutsuCity.","authors":["Zilong Huang","Jun He","Xiaobin Huang","Ziyi Xiong","Yang Luo","Junyan Ye","Weijia Li","Yiping Chen","Ting Han"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.20410v1","updated":"2025-11-25T15:36:20Z","published":"2025-11-25T15:36:20Z","title":"Image-Free Timestep Distillation via Continuous-Time Consistency with Trajectory-Sampled Pairs","summary":"Timestep distillation is an effective approach for improving the generation efficiency of diffusion models. The Consistency Model (CM), as a trajectory-based framework, demonstrates significant potential due to its strong theoretical foundation and high-quality few-step generation. Nevertheless, current continuous-time consistency distillation methods still rely heavily on training data and computational resources, hindering their deployment in resource-constrained scenarios and limiting their scalability to diverse domains. To address this issue, we propose Trajectory-Backward Consistency Model (TBCM), which eliminates the dependence on external training data by extracting latent representations directly from the teacher model's generation trajectory. Unlike conventional methods that require VAE encoding and large-scale datasets, our self-contained distillation paradigm significantly improves both efficiency and simplicity. Moreover, the trajectory-extracted samples naturally bridge the distribution gap between training and inference, thereby enabling more effective knowledge transfer. Empirically, TBCM achieves 6.52 FID and 28.08 CLIP scores on MJHQ-30k under one-step generation, while reducing training time by approximately 40% compared to Sana-Sprint and saving a substantial amount of GPU memory, demonstrating superior efficiency without sacrificing quality. We further reveal the diffusion-generation space discrepancy in continuous-time consistency distillation and analyze how sampling strategies affect distillation performance, offering insights for future distillation research. GitHub Link: https://github.com/hustvl/TBCM.","authors":["Bao Tang","Shuai Zhang","Yueting Zhu","Jijun Xiang","Xin Yang","Li Yu","Wenyu Liu","Xinggang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20401v1","updated":"2025-11-25T15:28:10Z","published":"2025-11-25T15:28:10Z","title":"A Training-Free Approach for Multi-ID Customization via Attention Adjustment and Spatial Control","summary":"Multi-ID customization is an interesting topic in computer vision and attracts considerable attention recently. Given the ID images of multiple individuals, its purpose is to generate a customized image that seamlessly integrates them while preserving their respective identities. Compared to single-ID customization, multi-ID customization is much more difficult and poses two major challenges. First, since the multi-ID customization model is trained to reconstruct an image from the cropped person regions, it often encounters the copy-paste issue during inference, leading to lower quality. Second, the model also suffers from inferior text controllability. The generated result simply combines multiple persons into one image, regardless of whether it is aligned with the input text. In this work, we propose MultiID to tackle this challenging task in a training-free manner. Since the existing single-ID customization models have less copy-paste issue, our key idea is to adapt these models to achieve multi-ID customization. To this end, we present an ID-decoupled cross-attention mechanism, injecting distinct ID embeddings into the corresponding image regions and thus generating multi-ID outputs. To enhance the generation controllability, we introduce three critical strategies, namely the local prompt, depth-guided spatial control, and extended self-attention, making the results more consistent with the text prompts and ID images. We also carefully build a benchmark, called IDBench, for evaluation. The extensive qualitative and quantitative results demonstrate the effectiveness of MultiID in solving the aforementioned two challenges. Its performance is comparable or even better than the training-based multi-ID customization methods.","authors":["Jiawei Lin","Guanlong Jiao","Jianjin Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26536v2","updated":"2025-11-25T15:21:05Z","published":"2025-09-30T17:09:32Z","title":"OceanGym: A Benchmark Environment for Underwater Embodied Agents","summary":"We introduce OceanGym, the first comprehensive benchmark for ocean underwater embodied agents, designed to advance AI in one of the most demanding real-world environments. Unlike terrestrial or aerial domains, underwater settings present extreme perceptual and decision-making challenges, including low visibility, dynamic ocean currents, making effective agent deployment exceptionally difficult. OceanGym encompasses eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), which integrates perception, memory, and sequential decision-making. Agents are required to comprehend optical and sonar data, autonomously explore complex environments, and accomplish long-horizon objectives under these harsh conditions. Extensive experiments reveal substantial gaps between state-of-the-art MLLM-driven agents and human experts, highlighting the persistent difficulty of perception, planning, and adaptability in ocean underwater environments. By providing a high-fidelity, rigorously designed platform, OceanGym establishes a testbed for developing robust embodied AI and transferring these capabilities to real-world autonomous ocean underwater vehicles, marking a decisive step toward intelligent agents capable of operating in one of Earth's last unexplored frontiers. The code and data are available at https://github.com/OceanGPT/OceanGym.","authors":["Yida Xue","Mingjun Mao","Xiangyuan Ru","Yuqi Zhu","Baochang Ren","Shuofei Qiao","Mengru Wang","Shumin Deng","Xinyu An","Ningyu Zhang","Ying Chen","Huajun Chen"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2510.20212v2","updated":"2025-11-25T15:15:11Z","published":"2025-10-23T04:58:29Z","title":"Target-aware Image Editing via Cycle-consistent Constraints","summary":"Recent advances in pre-trained text-to-image flow models have enabled remarkable progress in text-based image editing. Mainstream approaches always adopt a corruption-then-restoration paradigm, where the source image is first corrupted into an ``intermediate state'' and then restored to the target image under the prompt guidance. However, current methods construct this intermediate state in a target-agnostic manner, i.e., they primarily focus on realizing source image reconstruction while neglecting the semantic gaps towards the specific editing target. This design inherently results in limited editability or inconsistency when the desired modifications substantially deviate from the source. In this paper, we argue that the intermediate state should be target-aware, i.e., selectively corrupting editing-relevant contents while preserving editing-irrelevant ones. To this end, we propose FlowCycle, a novel inversion-free and flow-based editing framework that parameterizes corruption with learnable noises and optimizes them through a cycle-consistent process. By iteratively editing the source to the target and recovering back to the source with dual consistency constraints, FlowCycle learns to produce a target-aware intermediate state, enabling faithful modifications while preserving source consistency. Extensive ablations have demonstrated that FlowCycle achieves superior editing quality and consistency over state-of-the-art methods.","authors":["Yanghao Wang","Zhen Wang","Long Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16181v5","updated":"2025-11-25T15:13:39Z","published":"2025-04-22T18:14:43Z","title":"CLIP-IT: CLIP-based Pairing for Histology Images Classification","summary":"Multimodal learning has shown promise in medical imaging, combining complementary modalities like images and text. Vision-language models (VLMs) capture rich diagnostic cues but often require large paired datasets and prompt- or text-based inference, limiting their practicality due to annotation cost, privacy, and compute demands. Crucially, available free unpaired external text, like pathology reports, can still provide complementary diagnostic cues if semantically relevant content is retrievable per image. To address this, we introduce CLIP-IT, a novel framework that relies on rich unpaired text reports. Specifically, CLIP-IT uses a CLIP model pre-trained on histology image-text pairs from a separate dataset to retrieve the most relevant unpaired textual report for each image in the downstream unimodal dataset. These reports, sourced from the same disease domain and tissue type, form pseudo-pairs that reflect shared clinical semantics rather than exact alignment. Knowledge from these texts is distilled into the vision model during training, while LoRA-based adaptation mitigates the semantic gap between unaligned modalities. At inference, only the vision model is used, keeping overhead low while still benefiting from multimodal training without requiring paired data in the downstream dataset. Experiments on histology image datasets confirm that CLIP-IT consistently improves classification accuracy over both unimodal and multimodal CLIP-based baselines in most cases, without the burden of per-dataset paired annotation or inference-time complexity.","authors":["Banafsheh Karimian","Giulia Avanzato","Soufian Belharbi","Alexis Guichemerre","Luke McCaffrey","Mohammadhadi Shateri","Eric Granger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20390v1","updated":"2025-11-25T15:12:10Z","published":"2025-11-25T15:12:10Z","title":"FREE: Uncertainty-Aware Autoregression for Parallel Diffusion Transformers","summary":"Diffusion Transformers (DiTs) achieve state-of-the-art generation quality but require long sequential denoising trajectories, leading to high inference latency. Recent speculative inference methods enable lossless parallel sampling in U-Net-based diffusion models via a drafter-verifier scheme, but their acceleration is limited on DiTs due to insufficient draft accuracy during verification. To address this limitation, we analyze the DiTs' feature dynamics and find the features of the final transformer layer (top-block) exhibit strong temporal consistency and rich semantic abstraction. Based on this insight, we propose FREE, a novel framework that employs a lightweight drafter to perform feature-level autoregression with parallel verification, guaranteeing lossless acceleration with theoretical and empirical support. Meanwhile, prediction variance (uncertainty) of DiTs naturally increases in later denoising steps, reducing acceptance rates under speculative sampling. To mitigate this effect, we further introduce an uncertainty-guided relaxation strategy, forming FREE (relax), which dynamically adjusts the acceptance probability in response to uncertainty levels. Experiments on ImageNet-$512^2$ show that FREE achieves up to $1.86 \\times$ acceleration, and FREE (relax) further reaches $2.25 \\times$ speedup while maintaining high perceptual and quantitative fidelity in generation quality.","authors":["Xinwan Wen","Bowen Li","Jiajun Luo","Ye Li","Zhi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18866v2","updated":"2025-11-25T15:07:32Z","published":"2025-10-21T17:58:17Z","title":"LightMem: Lightweight and Efficient Memory-Augmented Generation","summary":"Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at https://github.com/zjunlp/LightMem.","authors":["Jizhan Fang","Xinle Deng","Haoming Xu","Ziyan Jiang","Yuqi Tang","Ziwen Xu","Shumin Deng","Yunzhi Yao","Mengru Wang","Shuofei Qiao","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2506.06836v2","updated":"2025-11-25T14:56:02Z","published":"2025-06-07T15:27:30Z","title":"Harnessing Vision-Language Models for Time Series Anomaly Detection","summary":"Time-series anomaly detection (TSAD) has played a vital role in a variety of fields, including healthcare, finance, and sensor-based condition monitoring. Prior methods, which mainly focus on training domain-specific models on numerical data, lack the visual-temporal understanding capacity that human experts have to identify contextual anomalies. To fill this gap, we explore a solution based on vision language models (VLMs). Recent studies have shown the ability of VLMs for visual understanding tasks, yet their direct application to time series has fallen short on both accuracy and efficiency. To harness the power of VLMs for TSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening stage built on a relatively lightweight pre-trained vision encoder, which leverages 2D time series representations to accurately localize candidate anomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal context and VLM's visual understanding capacity to refine the detection upon the candidates provided by ViT4TS. We show that without any time-series training, VLM4TS outperforms time-series pre-trained and from-scratch baselines in most cases, yielding a 24.6% improvement in F1-max score over the best baseline. Moreover, VLM4TS also consistently outperforms existing language model-based TSAD methods and is on average 36x more efficient in token usage.","authors":["Zelin He","Sarah Alnegheimish","Matthew Reimherr"],"pdf_url":"","comment":"Accepted at AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2505.21912v2","updated":"2025-11-25T14:53:24Z","published":"2025-05-28T02:58:41Z","title":"Detecting Cultural Differences in News Video Thumbnails via Computational Aesthetics","summary":"We propose a two-step approach for detecting differences in the style of images across sources of differing cultural affinity, where images are first clustered into finer visual themes based on content before their aesthetic features are compared. We test this approach on 2,400 YouTube video thumbnails taken equally from two U.S. and two Chinese YouTube channels, and relating equally to COVID-19 and the Ukraine conflict. Our results suggest that while Chinese thumbnails are less formal and more candid, U.S. channels tend to use more deliberate, proper photographs as thumbnails. In particular, U.S. thumbnails are less colorful, more saturated, darker, more finely detailed, less symmetric, sparser, less varied, and more up close and personal than Chinese thumbnails. We suggest that most of these differences reflect cultural preferences, and that our methods and observations can serve as a baseline against which suspected visual propaganda can be computed and compared.","authors":["Marvin Limpijankit","John Kender"],"pdf_url":"","comment":"ICWSM'24 Workshop"},{"id":"http://arxiv.org/abs/2511.20366v1","updated":"2025-11-25T14:45:59Z","published":"2025-11-25T14:45:59Z","title":"VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild","summary":"Reconstructing topologically consistent facial geometry is crucial for the digital avatar creation pipelines. Existing methods either require tedious manual efforts, lack generalization to in-the-wild data, or are constrained by the limited expressiveness of 3D Morphable Models. To address these limitations, we propose VGGTFace, an automatic approach that innovatively applies the 3D foundation model, \\emph{i.e.} VGGT, for topologically consistent facial geometry reconstruction from in-the-wild multi-view images captured by everyday users. Our key insight is that, by leveraging VGGT, our method naturally inherits strong generalization ability and expressive power from its large-scale training and point map representation. However, it is unclear how to reconstruct a topologically consistent mesh from VGGT, as the topology information is missing in its prediction. To this end, we augment VGGT with Pixel3DMM for injecting topology information via pixel-aligned UV values. In this manner, we convert the pixel-aligned point map of VGGT to a point cloud with topology. Tailored to this point cloud with known topology, we propose a novel Topology-Aware Bundle Adjustment strategy to fuse them, where we construct a Laplacian energy for the Bundle Adjustment objective. Our method achieves high-quality reconstruction in 10 seconds for 16 views on a single NVIDIA RTX 4090. Experiments demonstrate state-of-the-art results on benchmarks and impressive generalization to in-the-wild data. Code is available at https://github.com/grignarder/vggtface.","authors":["Xin Ming","Yuxuan Han","Tianyu Huang","Feng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20359v1","updated":"2025-11-25T14:39:17Z","published":"2025-11-25T14:39:17Z","title":"From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations","summary":"Image manipulation localization (IML) faces a fundamental trade-off between minimizing annotation cost and achieving fine-grained localization accuracy. Existing fully-supervised IML methods depend heavily on dense pixel-level mask annotations, which limits scalability to large datasets or real-world deployment.In contrast, the majority of existing weakly-supervised IML approaches are based on image-level labels, which greatly reduce annotation effort but typically lack precise spatial localization. To address this dilemma, we propose BoxPromptIML, a novel weakly-supervised IML framework that effectively balances annotation cost and localization performance. Specifically, we propose a coarse region annotation strategy, which can generate relatively accurate manipulation masks at lower cost. To improve model efficiency and facilitate deployment, we further design an efficient lightweight student model, which learns to perform fine-grained localization through knowledge distillation from a fixed teacher model based on the Segment Anything Model (SAM). Moreover, inspired by the human subconscious memory mechanism, our feature fusion module employs a dual-guidance strategy that actively contextualizes recalled prototypical patterns with real-time observational cues derived from the input. Instead of passive feature extraction, this strategy enables a dynamic process of knowledge recollection, where long-term memory is adapted to the specific context of the current image, significantly enhancing localization accuracy and robustness. Extensive experiments across both in-distribution and out-of-distribution datasets show that BoxPromptIML outperforms or rivals fully-supervised models, while maintaining strong generalization, low annotation cost, and efficient deployment characteristics.","authors":["Zhiqing Guo","Dongdong Xi","Songlin Li","Gaobo Yang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2502.17159v4","updated":"2025-11-25T14:36:57Z","published":"2025-02-24T13:52:05Z","title":"RobustMerge: Parameter-Efficient Model Merging for MLLMs with Direction Robustness","summary":"Fine-tuning pre-trained models with custom data leads to numerous expert models on specific tasks. Merging models into one universal model to empower multi-task ability refraining from data leakage has gained popularity. With the expansion in data and model size, parameter-efficient tuning becomes the common practice for obtaining task-specific models efficiently. However, few methods are dedicated to efficient merging, and existing methods designed for full fine-tuning merging fail under efficient merging. To address the issue, we analyze from low-rank decomposition and reveal that direction robustness during merging is crucial for merging efficient modules. We furthermore uncover that compensating for the gap between stark singular values contributes to direction robustness. Therefore, we propose RobustMerge, a training-free parameter-efficient merging method with complementary parameter adaptation to maintain direction robustness. Specifically, we (1) prune parameters and scale coefficients from inter-parameter relation for singular values to maintain direction stability away from task interference, and (2) perform cross-task normalization to enhance unseen task generalization. We establish a benchmark consisting of diverse multimodal tasks, on which we conduct experiments to certify the outstanding performance and generalizability of our method. Additional studies and extensive analyses further showcase the effectiveness. Code is available at https://github.com/AuroraZengfh/RobustMerge.","authors":["Fanhu Zeng","Haiyang Guo","Fei Zhu","Li Shen","Hao Tang"],"pdf_url":"","comment":"NeurIPS 2025 (Spotlight) Fix some typos"},{"id":"http://arxiv.org/abs/2511.20354v1","updated":"2025-11-25T14:33:31Z","published":"2025-11-25T14:33:31Z","title":"GS-Checker: Tampering Localization for 3D Gaussian Splatting","summary":"Recent advances in editing technologies for 3D Gaussian Splatting (3DGS) have made it simple to manipulate 3D scenes. However, these technologies raise concerns about potential malicious manipulation of 3D content. To avoid such malicious applications, localizing tampered regions becomes crucial. In this paper, we propose GS-Checker, a novel method for locating tampered areas in 3DGS models. Our approach integrates a 3D tampering attribute into the 3D Gaussian parameters to indicate whether the Gaussian has been tampered. Additionally, we design a 3D contrastive mechanism by comparing the similarity of key attributes between 3D Gaussians to seek tampering cues at 3D level. Furthermore, we introduce a cyclic optimization strategy to refine the 3D tampering attribute, enabling more accurate tampering localization. Notably, our approach does not require expensive 3D labels for supervision. Extensive experimental results demonstrate the effectiveness of our proposed method to locate the tampered 3DGS area.","authors":["Haoliang Han","Ziyuan Luo","Jun Qi","Anderson Rocha","Renjie Wan"],"pdf_url":"","comment":"Accepted by AAAI2026"},{"id":"http://arxiv.org/abs/2505.11895v2","updated":"2025-11-25T14:31:52Z","published":"2025-05-17T08:26:04Z","title":"Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration","summary":"Recent unified multi-modal encoders align a wide range of modalities into a shared representation space, enabling diverse cross-modal tasks. Despite their impressive capabilities, the robustness of these models under adversarial perturbations remains underexplored, which is a critical concern for safety-sensitive applications. In this work, we present the first comprehensive study of adversarial vulnerability in unified multi-modal encoders. We find that even mild adversarial perturbations lead to substantial performance drops across all modalities. Non-visual inputs, such as audio and point clouds, are especially fragile, while visual inputs like images and videos also degrade significantly. To address this, we propose an efficient adversarial calibration framework that improves robustness across modalities without modifying pretrained encoders or semantic centers, ensuring compatibility with existing foundation models. Our method introduces modality-specific projection heads trained solely on adversarial examples, while keeping the backbone and embeddings frozen. We explore three training objectives: fixed-center cross-entropy, clean-to-adversarial L2 alignment, and clean-adversarial InfoNCE, and we introduce a regularization strategy to ensure modality-consistent alignment under attack. Experiments on six modalities and three Bind-style models show that our method improves adversarial robustness by up to 47.3 percent at epsilon = 4/255, while preserving or even improving clean zero-shot and retrieval performance with less than 1 percent trainable parameters.","authors":["Chih-Ting Liao","Zhangquan Chen","Chunlei Meng","Tzu-Yu Huang","Xin Cao","Xu Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20351v1","updated":"2025-11-25T14:30:10Z","published":"2025-11-25T14:30:10Z","title":"Thinking in 360°: Humanoid Visual Search in the Wild","summary":"Humans rely on the synergistic control of head (cephalomotor) and eye (oculomotor) to efficiently search for visual information in 360°. However, prior approaches to visual search are limited to a static image, neglecting the physical embodiment and its interaction with the 3D world. How can we develop embodied visual search agents as efficient as humans while bypassing the constraints imposed by real-world hardware? To this end, we propose humanoid visual search where a humanoid agent actively rotates its head to search for objects or paths in an immersive world represented by a 360° panoramic image. To study visual search in visually-crowded real-world scenarios, we build H* Bench, a new benchmark that moves beyond household scenes to challenging in-the-wild scenes that necessitate advanced visual-spatial reasoning capabilities, such as transportation hubs, large-scale retail spaces, urban streets, and public institutions. Our experiments first reveal that even top-tier proprietary models falter, achieving only ~30% success in object and path search. We then use post-training techniques to enhance the open-source Qwen2.5-VL, increasing its success rate by over threefold for both object search (14.83% to 47.38%) and path search (6.44% to 24.94%). Notably, the lower ceiling of path search reveals its inherent difficulty, which we attribute to the demand for sophisticated spatial commonsense. Our results not only show a promising path forward but also quantify the immense challenge that remains in building MLLM agents that can be seamlessly integrated into everyday human life.","authors":["Heyang Yu","Yinan Han","Xiangyu Zhang","Baiqiao Yin","Bowen Chang","Xiangyu Han","Xinhao Liu","Jing Zhang","Marco Pavone","Chen Feng","Saining Xie","Yiming Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20348v1","updated":"2025-11-25T14:25:19Z","published":"2025-11-25T14:25:19Z","title":"Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin","summary":"3D reconstruction for Digital Twins often relies on LiDAR-based methods, which provide accurate geometry but lack the semantics and textures naturally captured by cameras. Traditional LiDAR-camera fusion approaches require complex calibration and still struggle with certain materials like glass, which are visible in images but poorly represented in point clouds. We propose a camera-only pipeline that reconstructs scenes using 3D Gaussian Splatting from multi-view images, extracts semantic material masks via vision models, converts Gaussian representations to mesh surfaces with projected material labels, and assigns physics-based material properties for accurate sensor simulation in modern graphics engines and simulators. This approach combines photorealistic reconstruction with physics-based material assignment, providing sensor simulation fidelity comparable to LiDAR-camera fusion while eliminating hardware complexity and calibration requirements. We validate our camera-only method using an internal dataset from an instrumented test vehicle, leveraging LiDAR as ground truth for reflectivity validation alongside image similarity metrics.","authors":["João Malheiro Silva","Andy Huynh","Tong Duy Son","Holger Caesar"],"pdf_url":"","comment":"8 pages, 5 figures. Submitted to IEEE Intelligent Vehicles Symposium (IV) 2026 for possible publication"},{"id":"http://arxiv.org/abs/2510.11512v2","updated":"2025-11-25T14:24:21Z","published":"2025-10-13T15:19:07Z","title":"LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference","summary":"Intuitive physics understanding in video diffusion models plays an essential role in building general-purpose physically plausible world simulators, yet accurately evaluating such capacity remains a challenging task due to the difficulty in disentangling physics correctness from visual appearance in generation. To the end, we introduce LikePhys, a training-free method that evaluates intuitive physics in video diffusion models by distinguishing physically valid and impossible videos using the denoising objective as an ELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs. By testing on our constructed benchmark of twelve scenarios spanning over four physics domains, we show that our evaluation metric, Plausibility Preference Error (PPE), demonstrates strong alignment with human preference, outperforming state-of-the-art evaluator baselines. We then systematically benchmark intuitive physics understanding in current video diffusion models. Our study further analyses how model design and inference settings affect intuitive physics understanding and highlights domain-specific capacity variations across physical laws. Empirical results show that, despite current models struggling with complex and chaotic dynamics, there is a clear trend of improvement in physics understanding as model capacity and inference settings scale.","authors":["Jianhao Yuan","Fabio Pizzati","Francesco Pinto","Lars Kunze","Ivan Laptev","Paul Newman","Philip Torr","Daniele De Martini"],"pdf_url":"","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.20343v1","updated":"2025-11-25T14:23:04Z","published":"2025-11-25T14:23:04Z","title":"AMB3R: Accurate Feed-forward Metric-scale 3D Reconstruction with Backend","summary":"We present AMB3R, a multi-view feed-forward model for dense 3D reconstruction on a metric-scale that addresses diverse 3D vision tasks. The key idea is to leverage a sparse, yet compact, volumetric scene representation as our backend, enabling geometric reasoning with spatial compactness. Although trained solely for multi-view reconstruction, we demonstrate that AMB3R can be seamlessly extended to uncalibrated visual odometry (online) or large-scale structure from motion without the need for task-specific fine-tuning or test-time optimization. Compared to prior pointmap-based models, our approach achieves state-of-the-art performance in camera pose, depth, and metric-scale estimation, 3D reconstruction, and even surpasses optimization-based SLAM and SfM methods with dense reconstruction priors on common benchmarks.","authors":["Hengyi Wang","Lourdes Agapito"],"pdf_url":"","comment":"Project page: https://hengyiwang.github.io/projects/amber"},{"id":"http://arxiv.org/abs/2506.04704v5","updated":"2025-11-25T14:16:10Z","published":"2025-06-05T07:26:34Z","title":"HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model","summary":"Despite emerging efforts to enhance the safety of Vision-Language Models (VLMs), current approaches face two main shortcomings. 1) Existing safety-tuning datasets and benchmarks only partially consider how image-text interactions can yield harmful content, often overlooking contextually unsafe outcomes from seemingly benign pairs. This narrow coverage leaves VLMs vulnerable to jailbreak attacks in unseen configurations. 2) Prior methods rely primarily on data-centric tuning, with limited architectural innovations to intrinsically strengthen safety. We address these gaps by introducing a holistic safety dataset and benchmark, \\textbf{HoliSafe}, that spans all five safe/unsafe image-text combinations, providing a more robust basis for both training and evaluation (HoliSafe-Bench). We further propose a novel modular framework for enhancing VLM safety with a visual guard module (VGM) designed to assess the harmfulness of input images for VLMs. This module endows VLMs with a dual functionality: they not only learn to generate safer responses but can also provide an interpretable harmfulness classification to justify their refusal decisions. A significant advantage of this approach is its modularity; the VGM is designed as a plug-in component, allowing for seamless integration with diverse pre-trained VLMs across various scales. Experiments show that Safe-VLM with VGM, trained on our HoliSafe, achieves state-of-the-art safety performance across multiple VLM benchmarks. Additionally, the HoliSafe-Bench itself reveals critical vulnerabilities in existing VLM models. We hope that HoliSafe and VGM will spur further research into robust and interpretable VLM safety, expanding future avenues for multimodal alignment.","authors":["Youngwan Lee","Kangsan Kim","Kwanyong Park","Ilcahe Jung","Soojin Jang","Seanie Lee","Yong-Ju Lee","Sung Ju Hwang"],"pdf_url":"","comment":"Project page: https://youngwanlee.github.io/holisafe"},{"id":"http://arxiv.org/abs/2511.20335v1","updated":"2025-11-25T14:14:17Z","published":"2025-11-25T14:14:17Z","title":"ShelfRectNet: Single View Shelf Image Rectification with Homography Estimation","summary":"Estimating homography from a single image remains a challenging yet practically valuable task, particularly in domains like retail, where only one viewpoint is typically available for shelf monitoring and product alignment. In this paper, we present a deep learning framework that predicts a 4-point parameterized homography matrix to rectify shelf images captured from arbitrary angles. Our model leverages a ConvNeXt-based backbone for enhanced feature representation and adopts normalized coordinate regression for improved stability. To address data scarcity and promote generalization, we introduce a novel augmentation strategy by modeling and sampling synthetic homographies. Our method achieves a mean corner error of 1.298 pixels on the test set. When compared with both classical computer vision and deep learning-based approaches, our method demonstrates competitive performance in both accuracy and inference speed. Together, these results establish our approach as a robust and efficient solution for realworld single-view rectification. To encourage further research in this domain, we will make our dataset, ShelfRectSet, and code publicly available","authors":["Onur Berk Tore","Ibrahim Samil Yalciner","Server Calap"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20332v1","updated":"2025-11-25T14:09:44Z","published":"2025-11-25T14:09:44Z","title":"3D Motion Perception of Binocular Vision Target with PID-CNN","summary":"This article trained a network for perceiving three-dimensional motion information of binocular vision target, which can provide real-time three-dimensional coordinate, velocity, and acceleration, and has a basic spatiotemporal perception capability. Understood the ability of neural networks to fit nonlinear problems from the perspective of PID. Considered a single-layer neural network as using a second-order difference equation and a nonlinearity to describe a local problem. Multilayer networks gradually transform the raw representation to the desired representation through multiple such combinations. Analysed some reference principles for designing neural networks. Designed a relatively small PID convolutional neural network, with a total of 17 layers and 413 thousand parameters. Implemented a simple but practical feature reuse method by concatenation and pooling. The network was trained and tested using the simulated randomly moving ball datasets, and the experimental results showed that the prediction accuracy was close to the upper limit that the input image resolution can represent. Analysed the experimental results and errors, as well as the existing shortcomings and possible directions for improvement. Finally, discussed the advantages of high-dimensional convolution in improving computational efficiency and feature space utilization. As well as the potential advantages of using PID information to implement memory and attention mechanisms.","authors":["Shi Jiazhao","Pan Pan","Shi Haotian"],"pdf_url":"","comment":"7 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2511.20330v1","updated":"2025-11-25T14:07:17Z","published":"2025-11-25T14:07:17Z","title":"ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation","summary":"Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.","authors":["Yuhan Wu","Tiantian Wei","Shuo Wang","ZhiChao Wang","Yanyong Zhang","Daniel Cremers","Yan Xia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20325v1","updated":"2025-11-25T13:57:24Z","published":"2025-11-25T13:57:24Z","title":"AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous Driving with Impartial World Models","summary":"End-to-end models for autonomous driving hold the promise of learning complex behaviors directly from sensor data, but face critical challenges in safety and handling long-tail events. Reinforcement Learning (RL) offers a promising path to overcome these limitations, yet its success in autonomous driving has been elusive. We identify a fundamental flaw hindering this progress: a deep seated optimistic bias in the world models used for RL. To address this, we introduce a framework for post-training policy refinement built around an Impartial World Model. Our primary contribution is to teach this model to be honest about danger. We achieve this with a novel data synthesis pipeline, Counterfactual Synthesis, which systematically generates a rich curriculum of plausible collisions and off-road events. This transforms the model from a passive scene completer into a veridical forecaster that remains faithful to the causal link between actions and outcomes. We then integrate this Impartial World Model into our closed-loop RL framework, where it serves as an internal critic. During refinement, the agent queries the critic to ``dream\" of the outcomes for candidate actions. We demonstrate through extensive experiments, including on a new Risk Foreseeing Benchmark, that our model significantly outperforms baselines in predicting failures. Consequently, when used as a critic, it enables a substantial reduction in safety violations in challenging simulations, proving that teaching a model to dream of danger is a critical step towards building truly safe and intelligent autonomous agents.","authors":["Tianyi Yan","Tao Tang","Xingtai Gui","Yongkang Li","Jiasen Zhesng","Weiyao Huang","Lingdong Kong","Wencheng Han","Xia Zhou","Xueyang Zhang","Yifei Zhan","Kun Zhan","Cheng-zhong Xu","Jianbing Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20319v1","updated":"2025-11-25T13:53:54Z","published":"2025-11-25T13:53:54Z","title":"IrisNet: Infrared Image Status Awareness Meta Decoder for Infrared Small Targets Detection","summary":"Infrared Small Target Detection (IRSTD) faces significant challenges due to low signal-to-noise ratios, complex backgrounds, and the absence of discernible target features. While deep learning-based encoder-decoder frameworks have advanced the field, their static pattern learning suffers from pattern drift across diverse scenarios (\\emph{e.g.}, day/night variations, sky/maritime/ground domains), limiting robustness. To address this, we propose IrisNet, a novel meta-learned framework that dynamically adapts detection strategies to the input infrared image status. Our approach establishes a dynamic mapping between infrared image features and entire decoder parameters via an image-to-decoder transformer. More concretely, we represent the parameterized decoder as a structured 2D tensor preserving hierarchical layer correlations and enable the transformer to model inter-layer dependencies through self-attention while generating adaptive decoding patterns via cross-attention. To further enhance the perception ability of infrared images, we integrate high-frequency components to supplement target-position and scene-edge information. Experiments on NUDT-SIRST, NUAA-SIRST, and IRSTD-1K datasets demonstrate the superiority of our IrisNet, achieving state-of-the-art performance.","authors":["Xuelin Qian","Jiaming Lu","Zixuan Wang","Wenxuan Wang","Zhongling Huang","Dingwen Zhang","Junwei Han"],"pdf_url":"","comment":"10pages,5figures"},{"id":"http://arxiv.org/abs/2509.19805v3","updated":"2025-11-25T13:53:02Z","published":"2025-09-24T06:42:32Z","title":"StrCGAN: A Generative Framework for Stellar Image Restoration","summary":"We introduce StrCGAN (Stellar Cyclic GAN), a generative model designed to enhance low-resolution astrophotography images. Our goal is to reconstruct high fidelity ground truth like representations of stellar objects, a task that is challenging due to the limited resolution and quality of small-telescope observations such as the MobilTelesco dataset. Traditional models such as CycleGAN provide a foundation for image to image translation but often distort the morphology of stars and produce barely resembling images. To overcome these limitations, we extend the CycleGAN framework with some key innovations: multi-spectral fusion to align optical and near infrared (NIR) domains, and astrophysical regularization modules to preserve stellar morphology. Ground truth references from multi-mission all sky surveys spanning optical to NIR guide the training process, ensuring that reconstructions remain consistent across spectral bands. Together, these components allow StrCGAN to generate reconstructions that are visually sharper outperforming standard GAN models in the task of astrophysical image enhancement.","authors":["Shantanusinh Parmar","Silas Janke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20307v1","updated":"2025-11-25T13:46:05Z","published":"2025-11-25T13:46:05Z","title":"TReFT: Taming Rectified Flow Models For One-Step Image Translation","summary":"Rectified Flow (RF) models have advanced high-quality image and video synthesis via optimal transport theory. However, when applied to image-to-image translation, they still depend on costly multi-step denoising, hindering real-time applications. Although the recent adversarial training paradigm, CycleGAN-Turbo, works in pretrained diffusion models for one-step image translation, we find that directly applying it to RF models leads to severe convergence issues. In this paper, we analyze these challenges and propose TReFT, a novel method to Tame Rectified Flow models for one-step image Translation. Unlike previous works, TReFT directly uses the velocity predicted by pretrained DiT or UNet as output-a simple yet effective design that tackles the convergence issues under adversarial training with one-step inference. This design is mainly motivated by a novel observation that, near the end of the denoising process, the velocity predicted by pretrained RF models converges to the vector from origin to the final clean image, a property we further justify through theoretical analysis. When applying TReFT to large pretrained RF models such as SD3.5 and FLUX, we introduce memory-efficient latent cycle-consistency and identity losses during training, as well as lightweight architectural simplifications for faster inference. Pretrained RF models finetuned with TReFT achieve performance comparable to sota methods across multiple image translation datasets while enabling real-time inference.","authors":["Shengqian Li","Ming Gao","Yi Liu","Zuzeng Lin","Feng Wang","Feng Dai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20306v1","updated":"2025-11-25T13:44:29Z","published":"2025-11-25T13:44:29Z","title":"TaCo: Capturing Spatio-Temporal Semantic Consistency in Remote Sensing Change Detection","summary":"Remote sensing change detection (RSCD) aims to identify surface changes across bi-temporal satellite images. Most previous methods rely solely on mask supervision, which effectively guides spatial localization but provides limited constraints on the temporal semantic transitions. Consequently, they often produce spatially coherent predictions while still suffering from unresolved semantic inconsistencies. To address this limitation, we propose TaCo, a spatio-temporal semantic consistent network, which enriches the existing mask-supervised framework with a spatio-temporal semantic joint constraint. TaCo conceptualizes change as a semantic transition between bi-temporal states, in which one temporal feature representation can be derived from the other via dedicated transition features. To realize this, we introduce a Text-guided Transition Generator that integrates textual semantics with bi-temporal visual features to construct the cross-temporal transition features. In addition, we propose a spatio-temporal semantic joint constraint consisting of bi-temporal reconstruct constraints and a transition constraint: the former enforces alignment between reconstructed and original features, while the latter enhances discrimination for changes. This design can yield substantial performance gains without introducing any additional computational overhead during inference. Extensive experiments on six public datasets, spanning both binary and semantic change detection tasks, demonstrate that TaCo consistently achieves SOTA performance.","authors":["Han Guo","Chenyang Liu","Haotian Zhang","Bowen Chen","Zhengxia Zou","Zhenwei Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20302v1","updated":"2025-11-25T13:41:59Z","published":"2025-11-25T13:41:59Z","title":"CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation","summary":"In Remote Sensing (RS), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a key approach to activate the generalizable representation ability of foundation models for downstream tasks. However, existing specialized PEFT methods often fail when applied to large-scale Earth observation tasks, as they are unable to fully handle the multifaceted and unpredictable domain gaps (\\eg, spatial, semantic, and frequency shifts) inherent in RS data. To overcome this, we propose CrossEarth-Gate, which introduces two primary contributions. First, we establish a comprehensive RS module toolbox to address multifaceted domain gaps, comprising spatial, semantic, and frequency modules. Second, we develop a Fisher-guided adaptive selection mechanism that operates on this toolbox. This selection is guided by Fisher Information to quantify each module's importance by measuring its contribution to the task-specific gradient flow. It dynamically activates only the most critical modules at the appropriate layers, guiding the gradient flow to maximize adaptation effectiveness and efficiency. Comprehensive experiments validate the efficacy and generalizability of our method, where CrossEarth-Gate achieves state-of-the-art performance across 16 cross-domain benchmarks for RS semantic segmentation. The code of the work will be released.","authors":["Shilei Cao","Ziyang Gong","Hehai Lin","Yang Liu","Jiashun Cheng","Xiaoxing Hu","Haoyuan Liang","Guowen Li","Chengwei Qin","Hong Cheng","Xue Yang","Juepeng Zheng","Haohuan Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20296v1","updated":"2025-11-25T13:31:53Z","published":"2025-11-25T13:31:53Z","title":"Prompting Lipschitz-constrained network for multiple-in-one sparse-view CT reconstruction","summary":"Despite significant advancements in deep learning-based sparse-view computed tomography (SVCT) reconstruction algorithms, these methods still encounter two primary limitations: (i) It is challenging to explicitly prove that the prior networks of deep unfolding algorithms satisfy Lipschitz constraints due to their empirically designed nature. (ii) The substantial storage costs of training a separate model for each setting in the case of multiple views hinder practical clinical applications. To address these issues, we elaborate an explicitly provable Lipschitz-constrained network, dubbed LipNet, and integrate an explicit prompt module to provide discriminative knowledge of different sparse sampling settings, enabling the treatment of multiple sparse view configurations within a single model. Furthermore, we develop a storage-saving deep unfolding framework for multiple-in-one SVCT reconstruction, termed PromptCT, which embeds LipNet as its prior network to ensure the convergence of its corresponding iterative algorithm. In simulated and real data experiments, PromptCT outperforms benchmark reconstruction algorithms in multiple-in-one SVCT reconstruction, achieving higher-quality reconstructions with lower storage costs. On the theoretical side, we explicitly demonstrate that LipNet satisfies boundary property, further proving its Lipschitz continuity and subsequently analyzing the convergence of the proposed iterative algorithms. The data and code are publicly available at https://github.com/shibaoshun/PromptCT.","authors":["Baoshun Shi","Ke Jiang","Qiusheng Lian","Xinran Yu","Huazhu Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20295v1","updated":"2025-11-25T13:31:30Z","published":"2025-11-25T13:31:30Z","title":"Back to the Feature: Explaining Video Classifiers with Video Counterfactual Explanations","summary":"Counterfactual explanations (CFEs) are minimal and semantically meaningful modifications of the input of a model that alter the model predictions. They highlight the decisive features the model relies on, providing contrastive interpretations for classifiers. State-of-the-art visual counterfactual explanation methods are designed to explain image classifiers. The generation of CFEs for video classifiers remains largely underexplored. For the counterfactual videos to be useful, they have to be physically plausible, temporally coherent, and exhibit smooth motion trajectories. Existing CFE image-based methods, designed to explain image classifiers, lack the capacity to generate temporally coherent, smooth and physically plausible video CFEs. To address this, we propose Back To The Feature (BTTF), an optimization framework that generates video CFEs. Our method introduces two novel features, 1) an optimization scheme to retrieve the initial latent noise conditioned by the first frame of the input video, 2) a two-stage optimization strategy to enable the search for counterfactual videos in the vicinity of the input video. Both optimization processes are guided solely by the target classifier, ensuring the explanation is faithful. To accelerate convergence, we also introduce a progressive optimization strategy that incrementally increases the number of denoising steps. Extensive experiments on video datasets such as Shape-Moving (motion classification), MEAD (emotion classification), and NTU RGB+D (action classification) show that our BTTF effectively generates valid, visually similar and realistic counterfactual videos that provide concrete insights into the classifier's decision-making mechanism.","authors":["Chao Wang","Chengan Che","Xinyue Chen","Sophia Tsoka","Luis C. Garcia-Peraza-Herrera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20280v1","updated":"2025-11-25T13:09:03Z","published":"2025-11-25T13:09:03Z","title":"Bootstrapping Physics-Grounded Video Generation through VLM-Guided Iterative Self-Refinement","summary":"Recent progress in video generation has led to impressive visual quality, yet current models still struggle to produce results that align with real-world physical principles. To this end, we propose an iterative self-refinement framework that leverages large language models and vision-language models to provide physics-aware guidance for video generation. Specifically, we introduce a multimodal chain-of-thought (MM-CoT) process that refines prompts based on feedback from physical inconsistencies, progressively enhancing generation quality. This method is training-free and plug-and-play, making it readily applicable to a wide range of video generation models. Experiments on the PhyIQ benchmark show that our method improves the Physics-IQ score from 56.31 to 62.38. We hope this work serves as a preliminary exploration of physics-consistent video generation and may offer insights for future research.","authors":["Yang Liu","Xilin Zhao","Peisong Wen","Siran Dai","Qingming Huang"],"pdf_url":"","comment":"ICCV 2025 Physics-IQ Challenge Third Place Solution"},{"id":"http://arxiv.org/abs/2511.20279v1","updated":"2025-11-25T13:08:09Z","published":"2025-11-25T13:08:09Z","title":"SelfMOTR: Revisiting MOTR with Self-Generating Detection Priors","summary":"Despite progress toward end-to-end tracking with transformer architectures, poor detection performance and the conflict between detection and association in a joint architecture remain critical concerns. Recent approaches aim to mitigate these issues by (i) employing advanced denoising or label assignment strategies, or (ii) incorporating detection priors from external object detectors via distillation or anchor proposal techniques. Inspired by the success of integrating detection priors and by the key insight that MOTR-like models are secretly strong detection models, we introduce SelfMOTR, a novel tracking transformer that relies on self-generated detection priors. Through extensive analysis and ablation studies, we uncover and demonstrate the hidden detection capabilities of MOTR-like models, and present a practical set of tools for leveraging them effectively. On DanceTrack, SelfMOTR achieves strong performance, competing with recent state-of-the-art end-to-end tracking methods.","authors":["Fabian Gülhan","Emil Mededovic","Yuli Wu","Johannes Stegmaier"],"pdf_url":"","comment":"11 pages, 5 figures, 10 tables"},{"id":"http://arxiv.org/abs/2511.20278v1","updated":"2025-11-25T13:07:27Z","published":"2025-11-25T13:07:27Z","title":"DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion","summary":"Domain adaptive point cloud completion (DA PCC) aims to narrow the geometric and semantic discrepancies between the labeled source and unlabeled target domains. Existing methods either suffer from limited receptive fields or quadratic complexity due to using CNNs or vision Transformers. In this paper, we present the first work that studies the adaptability of State Space Models (SSMs) in DA PCC and find that directly applying SSMs to DA PCC will encounter several challenges: directly serializing 3D point clouds into 1D sequences often disrupts the spatial topology and local geometric features of the target domain. Besides, the overlook of designs in the learning domain-agnostic representations hinders the adaptation performance. To address these issues, we propose a novel framework, DAPointMamba for DA PCC, that exhibits strong adaptability across domains and has the advantages of global receptive fields and efficient linear complexity. It has three novel modules. In particular, Cross-Domain Patch-Level Scanning introduces patch-level geometric correspondences, enabling effective local alignment. Cross-Domain Spatial SSM Alignment further strengthens spatial consistency by modulating patch features based on cross-domain similarity, effectively mitigating fine-grained structural discrepancies. Cross-Domain Channel SSM Alignment actively addresses global semantic gaps by interleaving and aligning feature channels. Extensive experiments on both synthetic and real-world benchmarks demonstrate that our DAPointMamba outperforms state-of-the-art methods with less computational complexity and inference latency.","authors":["Yinghui Li","Qianyu Zhou","Di Shao","Hao Yang","Ye Zhu","Richard Dazeley","Xuequan Lu"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20274v1","updated":"2025-11-25T12:59:31Z","published":"2025-11-25T12:59:31Z","title":"ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis","summary":"Until recently, the general corpus of CLIP-type fundamental models has widely explored either the retrieval of short descriptions or the classification of objects in the scene as SINGLE-object image classification task. The same holds for retrieving the image embedding (image retrieval task) given a text prompt. However, real-world scene images exhibit rich compositional structure involving multiple objects and actions. The latest methods in the CLIP-based literature improve class-level discrimination by mining harder negative image-text pairs and by refining permanent text prompts, often using LLMs. However, these improvements remain confined to predefined class lists and do not explicitly model relational or compositional structure. PyramidCLIP partially addresses this gap by aligning global and local visual features, yet it still lacks explicit modeling of inter-object relations. Hence, to further leverage this aspect for scene analysis, the proposed ScenarioCLIP model accepts input texts, grounded relations, and input images, along with focused regions highlighting relations. The proposed model is pretrained on curated scenario data, and finetuned for specialized downstream tasks, such as cross-modal retrieval and fine-grained visual understanding tasks. To address the lack of domain-specific datasets, we generate a novel dataset by extending image-text pairs from existing diverse indoor and outdoor scenario datasets that are publicly available. We used a pipeline of existing language models to ground action, object, and relations, filled by manual and automatic curation. We established a comprehensive benchmark for several scenario-based tasks and compared it with many baseline methods. ScenarioCLIP demonstrates robust zero-shot and finetune performance on various domain-specific tasks. Our code and dataset are available at https://github.com/scenario-clip/ScenarioCLIP","authors":["Advik Sinha","Saurabh Atreya","Aashutosh A","Sk Aziz Ali","Abhijit Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20272v1","updated":"2025-11-25T12:58:32Z","published":"2025-11-25T12:58:32Z","title":"VKnowU: Evaluating Visual Knowledge Understanding in Multimodal LLMs","summary":"While Multimodal Large Language Models (MLLMs) have become adept at recognizing objects, they often lack the intuitive, human-like understanding of the world's underlying physical and social principles. This high-level vision-grounded semantics, which we term visual knowledge, forms a bridge between perception and reasoning, yet remains an underexplored area in current MLLMs. To systematically evaluate this capability, we present VKnowU, a comprehensive benchmark featuring 1,680 questions in 1,249 videos, covering 8 core types of visual knowledge spanning both world-centric (e.g., intuitive physics) and human-centric (e.g., subjective intentions). Evaluation of 23 SOTA MLLMs reveals that leading models still fall short of human performance, with particularly notable gaps in the world-centric. To bridge this gap, we introduce a new dataset, VKnowQA, and VideoKnow+, a baseline model that explicitly incorporates visual knowledge into MLLMs. VideoKnow+ follows a structured See-Think-Answer paradigm and adopts reinforcement learning with visual knowledge reward, achieving a +3.7% improvement on VKnowU and consistent gains on MVBench, Video-MME, and MMVU. Our work highlights visual knowledge as a missing cornerstone for developing more generalizable MLLMs that can not only see but also truly understand our physical and social worlds.","authors":["Tianxiang Jiang","Sheng Xia","Yicheng Xu","Linquan Wu","Xiangyu Zeng","Limin Wang","Yu Qiao","Yi Wang"],"pdf_url":"","comment":"Data & Code: this https URL"},{"id":"http://arxiv.org/abs/2511.20270v1","updated":"2025-11-25T12:53:53Z","published":"2025-11-25T12:53:53Z","title":"DRL-Guided Neural Batch Sampling for Semi-Supervised Pixel-Level Anomaly Detection","summary":"Anomaly detection in industrial visual inspection is challenging due to the scarcity of defective samples. Most existing methods rely on unsupervised reconstruction using only normal data, often resulting in overfitting and poor detection of subtle defects. We propose a semi-supervised deep reinforcement learning framework that integrates a neural batch sampler, an autoencoder, and a predictor. The RL-based sampler adaptively selects informative patches by balancing exploration and exploitation through a composite reward. The autoencoder generates loss profiles highlighting abnormal regions, while the predictor performs segmentation in the loss-profile space. This interaction enables the system to effectively learn both normal and defective patterns with limited labeled data. Experiments on the MVTec AD dataset demonstrate that our method achieves higher accuracy and better localization of subtle anomalies than recent state-of-the-art approaches while maintaining low complexity, yielding an average improvement of 0.15 in F1_max and 0.06 in AUC, with a maximum gain of 0.37 in F1_max in the best case.","authors":["Amirhossein Khadivi Noghredeh","Abdollah Safari","Fatemeh Ziaeetabar","Firoozeh Haghighi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19435v2","updated":"2025-11-25T12:53:29Z","published":"2025-11-24T18:59:54Z","title":"Are Image-to-Video Models Good Zero-Shot Image Editors?","summary":"Large-scale video diffusion models show strong world simulation and temporal reasoning abilities, but their use as zero-shot image editors remains underexplored. We introduce IF-Edit, a tuning-free framework that repurposes pretrained image-to-video diffusion models for instruction-driven image editing. IF-Edit addresses three key challenges: prompt misalignment, redundant temporal latents, and blurry late-stage frames. It includes (1) a chain-of-thought prompt enhancement module that transforms static editing instructions into temporally grounded reasoning prompts; (2) a temporal latent dropout strategy that compresses frame latents after the expert-switch point, accelerating denoising while preserving semantic and temporal coherence; and (3) a self-consistent post-refinement step that sharpens late-stage frames using a short still-video trajectory. Experiments on four public benchmarks, covering non-rigid editing, physical and temporal reasoning, and general instruction edits, show that IF-Edit performs strongly on reasoning-centric tasks while remaining competitive on general-purpose edits. Our study provides a systematic view of video diffusion models as image editors and highlights a simple recipe for unified video-image generative reasoning.","authors":["Zechuan Zhang","Zhenyuan Chen","Zongxin Yang","Yi Yang"],"pdf_url":"","comment":"technical report"},{"id":"http://arxiv.org/abs/2511.20263v1","updated":"2025-11-25T12:42:26Z","published":"2025-11-25T12:42:26Z","title":"Advancing Image Classification with Discrete Diffusion Classification Modeling","summary":"Image classification is a well-studied task in computer vision, and yet it remains challenging under high-uncertainty conditions, such as when input images are corrupted or training data are limited. Conventional classification approaches typically train models to directly predict class labels from input images, but this might lead to suboptimal performance in such scenarios. To address this issue, we propose Discrete Diffusion Classification Modeling (DiDiCM), a novel framework that leverages a diffusion-based procedure to model the posterior distribution of class labels conditioned on the input image. DiDiCM supports diffusion-based predictions either on class probabilities or on discrete class labels, providing flexibility in computation and memory trade-offs. We conduct a comprehensive empirical study demonstrating the superior performance of DiDiCM over standard classifiers, showing that a few diffusion iterations achieve higher classification accuracy on the ImageNet dataset compared to baselines, with accuracy gains increasing as the task becomes more challenging. We release our code at https://github.com/omerb01/didicm .","authors":["Omer Belhasin","Shelly Golan","Ran El-Yaniv","Michael Elad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20258v1","updated":"2025-11-25T12:38:28Z","published":"2025-11-25T12:38:28Z","title":"Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization","summary":"Weight Averaging (WA) has emerged as a powerful technique for enhancing generalization by promoting convergence to a flat loss landscape, which correlates with stronger out-of-distribution performance. However, applying WA directly to multi-modal domain generalization (MMDG) is challenging: differences in optimization speed across modalities lead WA to overfit to faster-converging ones in early stages, suppressing the contribution of slower yet complementary modalities, thereby hindering effective modality fusion and skewing the loss surface toward sharper, less generalizable minima. To address this issue, we propose MBCD, a unified collaborative distillation framework that retains WA's flatness-inducing advantages while overcoming its shortcomings in multi-modal contexts. MBCD begins with adaptive modality dropout in the student model to curb early-stage bias toward dominant modalities. A gradient consistency constraint then aligns learning signals between uni-modal branches and the fused representation, encouraging coordinated and smoother optimization. Finally, a WA-based teacher conducts cross-modal distillation by transferring fused knowledge to each uni-modal branch, which strengthens cross-modal interactions and steer convergence toward flatter solutions. Extensive experiments on MMDG benchmarks show that MBCD consistently outperforms existing methods, achieving superior accuracy and robustness across diverse unseen domains.","authors":["Xiaohan Wang","Zhangtao Cheng","Ting Zhong","Leiting Chen","Fan Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20256v1","updated":"2025-11-25T12:35:57Z","published":"2025-11-25T12:35:57Z","title":"The Image as Its Own Reward: Reinforcement Learning with Adversarial Reward for Image Generation","summary":"A reliable reward function is essential for reinforcement learning (RL) in image generation. Most current RL approaches depend on pre-trained preference models that output scalar rewards to approximate human preferences. However, these rewards often fail to capture human perception and are vulnerable to reward hacking, where higher scores do not correspond to better images. To address this, we introduce Adv-GRPO, an RL framework with an adversarial reward that iteratively updates both the reward model and the generator. The reward model is supervised using reference images as positive samples and can largely avoid being hacked. Unlike KL regularization that constrains parameter updates, our learned reward directly guides the generator through its visual outputs, leading to higher-quality images. Moreover, while optimizing existing reward functions can alleviate reward hacking, their inherent biases remain. For instance, PickScore may degrade image quality, whereas OCR-based rewards often reduce aesthetic fidelity. To address this, we take the image itself as a reward, using reference images and vision foundation models (e.g., DINO) to provide rich visual rewards. These dense visual signals, instead of a single scalar, lead to consistent gains across image quality, aesthetics, and task-specific metrics. Finally, we show that combining reference samples with foundation-model rewards enables distribution transfer and flexible style customization. In human evaluation, our method outperforms Flow-GRPO and SD3, achieving 70.0% and 72.4% win rates in image quality and aesthetics, respectively. Code and models have been released.","authors":["Weijia Mao","Hao Chen","Zhenheng Yang","Mike Zheng Shou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20254v1","updated":"2025-11-25T12:29:10Z","published":"2025-11-25T12:29:10Z","title":"XiCAD: Camera Activation Detection in the Da Vinci Xi User Interface","summary":"Purpose: Robot-assisted minimally invasive surgery relies on endoscopic video as the sole intraoperative visual feedback. The DaVinci Xi system overlays a graphical user interface (UI) that indicates the state of each robotic arm, including the activation of the endoscope arm. Detecting this activation provides valuable metadata such as camera movement information, which can support downstream surgical data science tasks including tool tracking, skill assessment, or camera control automation.\n  Methods: We developed a lightweight pipeline based on a ResNet18 convolutional neural network to automatically identify the position of the camera tile and its activation state within the DaVinci Xi UI. The model was fine-tuned on manually annotated data from the SurgToolLoc dataset and evaluated across three public datasets comprising over 70,000 frames.\n  Results: The model achieved F1-scores between 0.993 and 1.000 for the binary detection of active cameras and correctly localized the camera tile in all cases without false multiple-camera detections.\n  Conclusion: The proposed pipeline enables reliable, real-time extraction of camera activation metadata from surgical videos, facilitating automated preprocessing and analysis for diverse downstream applications. All code, trained models, and annotations are publicly available.","authors":["Alexander C. Jenke","Gregor Just","Claas de Boer","Martin Wagner","Sebastian Bodenstedt","Stefanie Speidel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20253v1","updated":"2025-11-25T12:29:06Z","published":"2025-11-25T12:29:06Z","title":"Zoo3D: Zero-Shot 3D Object Detection at Scene Level","summary":"3D object detection is fundamental for spatial understanding. Real-world environments demand models capable of recognizing diverse, previously unseen objects, which remains a major limitation of closed-set methods. Existing open-vocabulary 3D detectors relax annotation requirements but still depend on training scenes, either as point clouds or images. We take this a step further by introducing Zoo3D, the first training-free 3D object detection framework. Our method constructs 3D bounding boxes via graph clustering of 2D instance masks, then assigns semantic labels using a novel open-vocabulary module with best-view selection and view-consensus mask generation. Zoo3D operates in two modes: the zero-shot Zoo3D$_0$, which requires no training at all, and the self-supervised Zoo3D$_1$, which refines 3D box prediction by training a class-agnostic detector on Zoo3D$_0$-generated pseudo labels. Furthermore, we extend Zoo3D beyond point clouds to work directly with posed and even unposed images. Across ScanNet200 and ARKitScenes benchmarks, both Zoo3D$_0$ and Zoo3D$_1$ achieve state-of-the-art results in open-vocabulary 3D object detection. Remarkably, our zero-shot Zoo3D$_0$ outperforms all existing self-supervised methods, hence demonstrating the power and adaptability of training-free, off-the-shelf approaches for real-world 3D understanding. Code is available at https://github.com/col14m/zoo3d .","authors":["Andrey Lemeshko","Bulat Gabdullin","Nikita Drozdov","Anton Konushin","Danila Rukhovich","Maksim Kolodiazhnyi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20251v1","updated":"2025-11-25T12:25:41Z","published":"2025-11-25T12:25:41Z","title":"PromptMoG: Enhancing Diversity in Long-Prompt Image Generation via Prompt Embedding Mixture-of-Gaussian Sampling","summary":"Recent advances in text-to-image (T2I) generation have achieved remarkable visual outcomes through large-scale rectified flow models. However, how these models behave under long prompts remains underexplored. Long prompts encode rich content, spatial, and stylistic information that enhances fidelity but often suppresses diversity, leading to repetitive and less creative outputs. In this work, we systematically study this fidelity-diversity dilemma and reveal that state-of-the-art models exhibit a clear drop in diversity as prompt length increases. To enable consistent evaluation, we introduce LPD-Bench, a benchmark designed for assessing both fidelity and diversity in long-prompt generation. Building on our analysis, we develop a theoretical framework that increases sampling entropy through prompt reformulation and propose a training-free method, PromptMoG, which samples prompt embeddings from a Mixture-of-Gaussians in the embedding space to enhance diversity while preserving semantics. Extensive experiments on four state-of-the-art models, SD3.5-Large, Flux.1-Krea-Dev, CogView4, and Qwen-Image, demonstrate that PromptMoG consistently improves long-prompt generation diversity without semantic drifting.","authors":["Bo-Kai Ruan","Teng-Fang Hsiao","Ling Lo","Yi-Lun Wu","Hong-Han Shuai"],"pdf_url":"","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2511.20250v1","updated":"2025-11-25T12:25:20Z","published":"2025-11-25T12:25:20Z","title":"Uplifting Table Tennis: A Robust, Real-World Application for 3D Trajectory and Spin Estimation","summary":"Obtaining the precise 3D motion of a table tennis ball from standard monocular videos is a challenging problem, as existing methods trained on synthetic data struggle to generalize to the noisy, imperfect ball and table detections of the real world. This is primarily due to the inherent lack of 3D ground truth trajectories and spin annotations for real-world video. To overcome this, we propose a novel two-stage pipeline that divides the problem into a front-end perception task and a back-end 2D-to-3D uplifting task. This separation allows us to train the front-end components with abundant 2D supervision from our newly created TTHQ dataset, while the back-end uplifting network is trained exclusively on physically-correct synthetic data. We specifically re-engineer the uplifting model to be robust to common real-world artifacts, such as missing detections and varying frame rates. By integrating a ball detector and a table keypoint detector, our approach transforms a proof-of-concept uplifting method into a practical, robust, and high-performing end-to-end application for 3D table tennis trajectory and spin analysis.","authors":["Daniel Kienzle","Katja Ludwig","Julian Lorenz","Shin'ichi Satoh","Rainer Lienhart"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20245v1","updated":"2025-11-25T12:20:50Z","published":"2025-11-25T12:20:50Z","title":"HistoSpeckle-Net: Mutual Information-Guided Deep Learning for high-fidelity reconstruction of complex OrganAMNIST images via perturbed Multimode Fibers","summary":"Existing deep learning methods in multimode fiber (MMF) imaging often focus on simpler datasets, limiting their applicability to complex, real-world imaging tasks. These models are typically data-intensive, a challenge that becomes more pronounced when dealing with diverse and complex images. In this work, we propose HistoSpeckle-Net, a deep learning architecture designed to reconstruct structurally rich medical images from MMF speckles. To build a clinically relevant dataset, we develop an optical setup that couples laser light through a spatial light modulator (SLM) into an MMF, capturing output speckle patterns corresponding to input OrganAMNIST images. Unlike previous MMF imaging approaches, which have not considered the underlying statistics of speckles and reconstructed images, we introduce a distribution-aware learning strategy. We employ a histogram-based mutual information loss to enhance model robustness and reduce reliance on large datasets. Our model includes a histogram computation unit that estimates smooth marginal and joint histograms for calculating mutual information loss. It also incorporates a unique Three-Scale Feature Refinement Module, which leads to multiscale Structural Similarity Index Measure (SSIM) loss computation. Together, these two loss functions enhance both the structural fidelity and statistical alignment of the reconstructed images. Our experiments on the complex OrganAMNIST dataset demonstrate that HistoSpeckle-Net achieves higher fidelity than baseline models such as U-Net and Pix2Pix. It gives superior performance even with limited training samples and across varying fiber bending conditions. By effectively reconstructing complex anatomical features with reduced data and under fiber perturbations, HistoSpeckle-Net brings MMF imaging closer to practical deployment in real-world clinical environments.","authors":["Jawaria Maqbool","M. Imran Cheema"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.23150v2","updated":"2025-11-25T12:15:51Z","published":"2025-06-29T09:01:28Z","title":"AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation","summary":"Single-image-to-3D models typically follow a sequential generation and reconstruction workflow. However, intermediate multi-view images synthesized by pre-trained generation models often lack cross-view consistency (CVC), significantly degrading 3D reconstruction performance. While recent methods attempt to refine CVC by feeding reconstruction results back into the multi-view generator, these approaches struggle with noisy and unstable reconstruction outputs that limit effective CVC improvement. We introduce AlignCVC, a novel framework that fundamentally re-frames single-image-to-3D generation through distribution alignment rather than relying on strict regression losses. Our key insight is to align both generated and reconstructed multi-view distributions toward the ground-truth multi-view distribution, establishing a principled foundation for improved CVC. Observing that generated images exhibit weak CVC while reconstructed images display strong CVC due to explicit rendering, we propose a soft-hard alignment strategy with distinct objectives for generation and reconstruction models. This approach not only enhances generation quality but also dramatically accelerates inference to as few as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC, seamlessly integrates various multi-view generation models with 3D reconstruction models. Extensive experiments demonstrate the effectiveness and efficiency of AlignCVC for single-image-to-3D generation.","authors":["Xinyue Liang","Zhiyuan Ma","Lingchen Sun","Yanjun Guo","Lei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10068v2","updated":"2025-11-25T12:12:13Z","published":"2025-10-11T07:05:34Z","title":"Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning","summary":"The computer vision domain has greatly benefited from an abundance of data across many modalities to improve on various visual tasks. Recently, there has been a lot of focus on self-supervised pre-training methods through Masked Autoencoders (MAE) \\cite{he2022masked,bachmann2022multimae}, usually used as a first step before optimizing for a downstream task, such as classification or regression. This is very useful as it doesn't require any manually labeled data. In this work, we introduce Probabilistic Hyper-Graphs using Masked Autoencoders (PHG-MAE): a novel model that unifies the classical work on neural graphs \\cite{leordeanu2021semi} with the modern approach of masked autoencoders under a common theoretical framework. Through random masking of entire modalities, not just patches, the model samples from the distribution of hyper-edges on each forward pass. Additionally, the model adapts the standard MAE algorithm by combining pre-training and fine-tuning into a single training loop. Moreover, our approach enables the creation of inference-time ensembles which, through aggregation, boost the final prediction performance and consistency. Lastly, we show that we can apply knowledge distillation on top of the ensembles with little loss in performance, even with models that have fewer than 1M parameters. While our work mostly focuses on outdoor UAV scenes that contain multiple world interpretations and modalities, the same steps can be followed in other similar domains, such as autonomous driving or indoor robotics. In order to streamline the process of integrating external pre-trained experts for computer vision multi-modal multi-task learning (MTL) scenarios, we developed a data-pipeline software. Using this tool, we have created and released a fully-automated extension of the Dronescapes dataset. All the technical details, code and reproduction steps are publicly released.","authors":["Pîrvu Mihai-Cristian","Marius Leordeanu"],"pdf_url":"","comment":"Submitted to Neurocomputing"},{"id":"http://arxiv.org/abs/2511.18463v2","updated":"2025-11-25T11:57:42Z","published":"2025-11-23T14:14:14Z","title":"Alternating Perception-Reasoning for Hallucination-Resistant Video Understanding","summary":"Sufficient visual perception is the foundation of video reasoning. Nevertheless, existing Video Reasoning LLMs suffer from perception shortcuts, relying on a flawed single-step perception paradigm. This paradigm describes the video and then conducts reasoning, which runs the risk of insufficient evidence and emergent hallucinations. To address these issues, we introduce a new framework that integrates a loop-based paradigm with an anti-hallucination reward. First, to address the insufficient evidence, we introduce the Perception Loop Reasoning (PLR) paradigm. Instead of describing the video at once, each loop requires the model to describe a video segment with precise timestamps, analyze this segment, and decide the next action. Second, for the risk of hallucinations, the Factual-Aware Evaluator (FAE) evaluates each perception result as a reliable anti-hallucination reward. This reward encourages the model to provide sufficient and precise video evidence. Our FAE, which performs comparably to GPT-4o, is tuned on our AnetHallu-117K, a large-scale hallucination judgment preference dataset. Extensive experiments show that our Video-PLR achieves the state-of-the-art in both 3B and 7B parameter scales and has the best data efficiency. Our code, models, and datasets are released on: https://github.com/BoweiPu/VideoPLR.","authors":["Bowei Pu","Chuanbin Liu","Yifan Ge","Peicheng Zhou","Yiwei Sun","Zhiying Lu","Jiankang Wang","Hongtao Xie"],"pdf_url":"","comment":"32 pages, 36 figures"},{"id":"http://arxiv.org/abs/2508.06982v2","updated":"2025-11-25T11:52:52Z","published":"2025-08-09T13:29:39Z","title":"WeatherDiffusion: Controllable Weather Editing in Intrinsic Space","summary":"We present WeatherDiffusion, a diffusion-based framework for controllable weather editing in intrinsic space. Our framework includes two components based on diffusion priors: an inverse renderer that estimates material properties, scene geometry, and lighting as intrinsic maps from an input image, and a forward renderer that utilizes these geometry and material maps along with a text prompt that describes specific weather conditions to generate a final image. The intrinsic maps enhance controllability compared to traditional pixel-space editing approaches.We propose an intrinsic map-aware attention mechanism that improves spatial correspondence and decomposition quality in large outdoor scenes. For forward rendering, we leverage CLIP-space interpolation of weather prompts to achieve fine-grained weather control. We also introduce a synthetic and a real-world dataset, containing 38k and 18k images under various weather conditions, each with intrinsic map annotations. WeatherDiffusion outperforms state-of-the-art pixel-space editing approaches, weather restoration methods, and rendering-based methods, showing promise for downstream tasks such as autonomous driving, enhancing the robustness of detection and segmentation in challenging weather scenarios.","authors":["Yixin Zhu","Zuoliang Zhu","Jian Yang","Miloš Hašan","Jin Xie","Beibei Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20223v1","updated":"2025-11-25T11:51:17Z","published":"2025-11-25T11:51:17Z","title":"V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs","summary":"Adversarial attacks have evolved from simply disrupting predictions on conventional task-specific models to the more complex goal of manipulating image semantics on Large Vision-Language Models (LVLMs). However, existing methods struggle with controllability and fail to precisely manipulate the semantics of specific concepts in the image. We attribute this limitation to semantic entanglement in the patch-token representations on which adversarial attacks typically operate: global context aggregated by self-attention in the vision encoder dominates individual patch features, making them unreliable handles for precise local semantic manipulation. Our systematic investigation reveals a key insight: value features (V) computed within the transformer attention block serve as much more precise handles for manipulation. We show that V suppresses global-context channels, allowing it to retain high-entropy, disentangled local semantic information. Building on this discovery, we propose V-Attack, a novel method designed for precise local semantic attacks. V-Attack targets the value features and introduces two core components: (1) a Self-Value Enhancement module to refine V's intrinsic semantic richness, and (2) a Text-Guided Value Manipulation module that leverages text prompts to locate source concept and optimize it toward a target concept. By bypassing the entangled patch features, V-Attack achieves highly effective semantic control. Extensive experiments across diverse LVLMs, including LLaVA, InternVL, DeepseekVL and GPT-4o, show that V-Attack improves the attack success rate by an average of 36% over state-of-the-art methods, exposing critical vulnerabilities in modern visual-language understanding. Our code and data are available https://github.com/Summu77/V-Attack.","authors":["Sen Nie","Jie Zhang","Jianxin Yan","Shiguang Shan","Xilin Chen"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2511.20221v1","updated":"2025-11-25T11:49:18Z","published":"2025-11-25T11:49:18Z","title":"Patch-Level Glioblastoma Subregion Classification with a Contrastive Learning-Based Encoder","summary":"The significant molecular and pathological heterogeneity of glioblastoma, an aggressive brain tumor, complicates diagnosis and patient stratification. While traditional histopathological assessment remains the standard, deep learning offers a promising path toward objective and automated analysis of whole slide images. For the BraTS-Path 2025 Challenge, we developed a method that fine-tunes a pre-trained Vision Transformer (ViT) encoder with a dedicated classification head on the official training dataset. Our model's performance on the online validation set, evaluated via the Synapse platform, yielded a Matthews Correlation Coefficient (MCC) of 0.7064 and an F1-score of 0.7676. On the final test set, the model achieved an MCC of 0.6509 and an F1-score of 0.5330, which secured our team second place in the BraTS-Pathology 2025 Challenge. Our results establish a solid baseline for ViT-based histopathological analysis, and future efforts will focus on bridging the performance gap observed on the unseen validation data.","authors":["Juexin Zhang","Qifeng Zhong","Ying Weng","Ke Chen"],"pdf_url":"","comment":"Accepted by the International Brain Tumor Segmentation (BraTS) challenge organized at MICCAI 2025 conference"},{"id":"http://arxiv.org/abs/2511.20218v1","updated":"2025-11-25T11:43:58Z","published":"2025-11-25T11:43:58Z","title":"Text-guided Controllable Diffusion for Realistic Camouflage Images Generation","summary":"Camouflage Images Generation (CIG) is an emerging research area that focuses on synthesizing images in which objects are harmoniously blended and exhibit high visual consistency with their surroundings. Existing methods perform CIG by either fusing objects into specific backgrounds or outpainting the surroundings via foreground object-guided diffusion. However, they often fail to obtain natural results because they overlook the logical relationship between camouflaged objects and background environments. To address this issue, we propose CT-CIG, a Controllable Text-guided Camouflage Images Generation method that produces realistic and logically plausible camouflage images. Leveraging Large Visual Language Models (VLM), we design a Camouflage-Revealing Dialogue Mechanism (CRDM) to annotate existing camouflage datasets with high-quality text prompts. Subsequently, the constructed image-prompt pairs are utilized to finetune Stable Diffusion, incorporating a lightweight controller to guide the location and shape of camouflaged objects for enhanced camouflage scene fitness. Moreover, we design a Frequency Interaction Refinement Module (FIRM) to capture high-frequency texture features, facilitating the learning of complex camouflage patterns. Extensive experiments, including CLIPScore evaluation and camouflage effectiveness assessment, demonstrate the semantic alignment of our generated text prompts and CT-CIG's ability to produce photorealistic camouflage images.","authors":["Yuhang Qian","Haiyan Chen","Wentong Li","Ningzhong Liu","Jie Qin"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20216v1","updated":"2025-11-25T11:42:28Z","published":"2025-11-25T11:42:28Z","title":"CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents","summary":"Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.","authors":["Haebin Seong","Sungmin Kim","Minchan Kim","Yongjun Cho","Myunchul Joe","Suhwan Choi","Jaeyoon Jung","Jiyong Youn","Yoonshik Kim","Samwoo Seong","Yubeen Park","Youngjae Yu","Yunsung Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.05513v4","updated":"2025-11-25T11:38:35Z","published":"2025-05-07T10:33:45Z","title":"Exploring Convolutional Neural Networks for Rice Grain Classification: An Explainable AI Approach","summary":"Rice is an essential staple food worldwide that is important in promoting international trade, economic growth, and nutrition. Asian countries such as China, India, Pakistan, Thailand, Vietnam, and Indonesia are notable for their significant contribution to the cultivation and utilization of rice. These nations are also known for cultivating different rice grains, including short and long grains. These sizes are further classified as basmati, jasmine, kainat saila, ipsala, arborio, etc., catering to diverse culinary preferences and cultural traditions. For both local and international trade, inspecting and maintaining the quality of rice grains to satisfy customers and preserve a country's reputation is necessary. Manual quality check and classification is quite a laborious and time-consuming process. It is also highly prone to mistakes. Therefore, an automatic solution must be proposed for the effective and efficient classification of different varieties of rice grains. This research paper presents an automatic framework based on a convolutional neural network (CNN) for classifying different varieties of rice grains. We evaluated the proposed model based on performance metrics such as accuracy, recall, precision, and F1-Score. The CNN model underwent rigorous training and validation, achieving a remarkable accuracy rate and a perfect area under each class's Receiver Operating Characteristic (ROC) curve. The confusion matrix analysis confirmed the model's effectiveness in distinguishing between the different rice varieties, indicating minimal misclassifications. Additionally, the integration of explainability techniques such as LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations) provided valuable insights into the model's decision-making process, revealing how specific features of the rice grains influenced classification outcomes.","authors":["Muhammad Junaid Asif","Hamza Khan","Rabia Tehseen","Rana Fayyaz Ahmad","Mujtaba Asad","Syed Tahir Hussain Rizvi","Shazia Saqib"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.16334v3","updated":"2025-11-25T11:35:44Z","published":"2025-05-22T07:44:10Z","title":"Panoptic Captioning: An Equivalence Bridge for Image and Text","summary":"This work introduces panoptic captioning, a novel task striving to seek the minimum text equivalent of images, which has broad potential applications. We take the first step towards panoptic captioning by formulating it as a task of generating a comprehensive textual description for an image, which encapsulates all entities, their respective locations and attributes, relationships among entities, as well as global image state. Through an extensive evaluation, our work reveals that state-of-the-art Multi-modal Large Language Models (MLLMs) have limited performance in solving panoptic captioning. To address this, we propose an effective data engine named PancapEngine to produce high-quality data and a novel method named PancapChain to improve panoptic captioning. Specifically, our PancapEngine first detects diverse categories of entities in images by an elaborate detection suite, and then generates required panoptic captions using entity-aware prompts. Additionally, our PancapChain explicitly decouples the challenging panoptic captioning task into multiple stages and generates panoptic captions step by step. More importantly, we contribute a comprehensive metric named PancapScore and a human-curated test set for reliable model evaluation. Experiments show that our PancapChain-13B model can beat state-of-the-art open-source MLLMs like InternVL-2.5-78B and even surpass proprietary models like GPT-4o and Gemini-2.0-Pro, demonstrating the effectiveness of our data engine and method. Project page: https://visual-ai.github.io/pancap/","authors":["Kun-Yu Lin","Hongjun Wang","Weining Ren","Kai Han"],"pdf_url":"","comment":"NeurIPS 2025; Project page: https://visual-ai.github.io/pancap/"},{"id":"http://arxiv.org/abs/2511.20211v1","updated":"2025-11-25T11:34:51Z","published":"2025-11-25T11:34:51Z","title":"OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA Generation","summary":"Generative models have excelled in RGB synthesis, but real-world applications require RGBA manipulation. This has led to a fragmented landscape: specialized, single-task models handle alpha but lack versatility, while unified multi-task frameworks are confined to the RGB domain. To bridge this critical gap, we propose OmniAlpha, the first unified, multi-task generative framework for sequence-to-sequence RGBA image generation and editing. Its architecture features MSRoPE-BiL, a novel RoPE method with a bi-directionally extendable layer axis for its Diffusion Transformer (DiT) backbone, enabling the concurrent processing of multiple input and target RGBA layers. To power this framework, we introduce AlphaLayers, a new dataset of 1,000 high-quality, multi-layer triplets, built via a novel automated synthesis and filter pipeline. Jointly training OmniAlpha on this dataset across a comprehensive suite of 21 diverse tasks, extensive experiments demonstrate that our unified approach consistently outperforms strong, specialized baselines. Most notably, OmniAlpha achieves a dramatic 84.8% relative reduction in SAD for mask-free matting on AIM-500 and wins over 90% of human preferences in layer-conditioned completion. Our work proves that a unified, multi-task model can learn a superior shared representation for RGBA, paving the way for more powerful, layer-aware generative systems.","authors":["Hao Yu","Jiabo Zhan","Zile Wang","Jinglin Wang","Huaisong Zhang","Hongyu Li","Xinrui Chen","Yongxian Wei","Chun Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20202v1","updated":"2025-11-25T11:26:10Z","published":"2025-11-25T11:26:10Z","title":"Robust 3D Brain MRI Inpainting with Random Masking Augmentation","summary":"The ASNR-MICCAI BraTS-Inpainting Challenge was established to mitigate dataset biases that limit deep learning models in the quantitative analysis of brain tumor MRI. This paper details our submission to the 2025 challenge, a novel deep learning framework for synthesizing healthy tissue in 3D scans. The core of our method is a U-Net architecture trained to inpaint synthetically corrupted regions, enhanced with a random masking augmentation strategy to improve generalization. Quantitative evaluation confirmed the efficacy of our approach, yielding an SSIM of 0.873$\\pm$0.004, a PSNR of 24.996$\\pm$4.694, and an MSE of 0.005$\\pm$0.087 on the validation set. On the final online test set, our method achieved an SSIM of 0.919$\\pm$0.088, a PSNR of 26.932$\\pm$5.057, and an RMSE of 0.052$\\pm$0.026. This performance secured first place in the BraTS-Inpainting 2025 challenge and surpassed the winning solutions from the 2023 and 2024 competitions on the official leaderboard.","authors":["Juexin Zhang","Ying Weng","Ke Chen"],"pdf_url":"","comment":"Accepted by the International Brain Tumor Segmentation (BraTS) challenge organized at MICCAI 2025 conference"},{"id":"http://arxiv.org/abs/2511.20201v1","updated":"2025-11-25T11:24:25Z","published":"2025-11-25T11:24:25Z","title":"GHR-VQA: Graph-guided Hierarchical Relational Reasoning for Video Question Answering","summary":"We propose GHR-VQA, Graph-guided Hierarchical Relational Reasoning for Video Question Answering (Video QA), a novel human-centric framework that incorporates scene graphs to capture intricate human-object interactions within video sequences. Unlike traditional pixel-based methods, each frame is represented as a scene graph and human nodes across frames are linked to a global root, forming the video-level graph and enabling cross-frame reasoning centered on human actors. The video-level graphs are then processed by Graph Neural Networks (GNNs), transforming them into rich, context-aware embeddings for efficient processing. Finally, these embeddings are integrated with question features in a hierarchical network operating across different abstraction levels, enhancing both local and global understanding of video content. This explicit human-rooted structure enhances interpretability by decomposing actions into human-object interactions and enables a more profound understanding of spatiotemporal dynamics. We validate our approach on the Action Genome Question Answering (AGQA) dataset, achieving significant performance improvements, including a 7.3% improvement in object-relation reasoning over the state of the art.","authors":["Dionysia Danai Brilli","Dimitrios Mallis","Vassilis Pitsikalis","Petros Maragos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.14228v3","updated":"2025-11-25T11:20:07Z","published":"2025-03-18T13:05:41Z","title":"Panoramic Distortion-Aware Tokenization for Person Detection and Localization in Overhead Fisheye Images","summary":"Person detection in overhead fisheye images is challenging due to person rotation and small persons. Prior work has mainly addressed person rotation, leaving the small-person problem underexplored. We remap fisheye images to equirectangular panoramas to handle rotation and exploit panoramic geometry to handle small persons more effectively. Conventional detection methods tend to favor larger persons because they dominate the attention maps, causing smaller persons to be missed. In hemispherical equirectangular panoramas, we find that apparent person height decreases approximately linearly with the vertical angle near the top of the image. Using this finding, we introduce panoramic distortion-aware tokenization to enhance the detection of small persons. This tokenization procedure divides panoramic features using self-similar figures that enable the determination of optimal divisions without gaps, and we leverage the maximum significance values in each tile of the token groups to preserve the significance areas of smaller persons. We propose a transformer-based person detection and localization method that combines panoramic-image remapping and the tokenization procedure. Extensive experiments demonstrated that our method outperforms conventional methods on large-scale datasets.","authors":["Nobuhiko Wakai","Satoshi Sato","Yasunori Ishii","Takayoshi Yamashita"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20190v1","updated":"2025-11-25T11:14:39Z","published":"2025-11-25T11:14:39Z","title":"SFA: Scan, Focus, and Amplify toward Guidance-aware Answering for Video TextVQA","summary":"Video text-based visual question answering (Video TextVQA) task aims to answer questions about videos by leveraging the visual text appearing within the videos. This task poses significant challenges, requiring models to accurately perceive and comprehend scene text that varies in scale, orientation, and clarity across frames, while effectively integrating temporal and semantic context to generate precise answers. Moreover, the model must identify question-relevant textual cues and filter out redundant or irrelevant information to ensure answering is guided by the most relevant and informative cues. To address these challenges, we propose SFA, a training-free framework and the first Video-LLM-based method tailored for Video TextVQA, motivated by the human process of answering questions. By adaptively scanning video frames, selectively focusing on key regions, and directly amplifying them, SFA effectively guides the Video-LLM's attention toward essential cues, enabling it to generate more accurate answers. SFA achieves new state-of-the-art results across several public Video TextVQA datasets and surpasses previous methods by a substantial margin, demonstrating its effectiveness and generalizability.","authors":["Haibin He","Qihuang Zhong","Juhua Liu","Bo Du","Peng Wang","Jing Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.17818v2","updated":"2025-11-25T11:13:38Z","published":"2025-09-22T14:13:31Z","title":"ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment","summary":"Training-free video object editing aims to achieve precise object-level manipulation, including object insertion, swapping, and deletion. However, it faces significant challenges in maintaining fidelity and temporal consistency. Existing methods, often designed for U-Net architectures, suffer from two primary limitations: inaccurate inversion due to first-order solvers, and contextual conflicts caused by crude \"hard\" feature replacement. These issues are more challenging in Diffusion Transformers (DiTs), where the unsuitability of prior layer-selection heuristics makes effective guidance challenging. To address these limitations, we introduce ContextFlow, a novel training-free framework for DiT-based video object editing. In detail, we first employ a high-order Rectified Flow solver to establish a robust editing foundation. The core of our framework is Adaptive Context Enrichment (for specifying what to edit), a mechanism that addresses contextual conflicts. Instead of replacing features, it enriches the self-attention context by concatenating Key-Value pairs from parallel reconstruction and editing paths, empowering the model to dynamically fuse information. Additionally, to determine where to apply this enrichment (for specifying where to edit), we propose a systematic, data-driven analysis to identify task-specific vital layers. Based on a novel Guidance Responsiveness Metric, our method pinpoints the most influential DiT blocks for different tasks (e.g., insertion, swapping), enabling targeted and highly effective guidance. Extensive experiments show that ContextFlow significantly outperforms existing training-free methods and even surpasses several state-of-the-art training-based approaches, delivering temporally coherent, high-fidelity results.","authors":["Yiyang Chen","Xuanhua He","Xiujun Ma","Yue Ma"],"pdf_url":"","comment":"The project page is at https://yychen233.github.io/ContextFlow-page"},{"id":"http://arxiv.org/abs/2511.20186v1","updated":"2025-11-25T11:08:37Z","published":"2025-11-25T11:08:37Z","title":"Exo2EgoSyn: Unlocking Foundation Video Generation Models for Exocentric-to-Egocentric Video Synthesis","summary":"Foundation video generation models such as WAN 2.2 exhibit strong text- and image-conditioned synthesis abilities but remain constrained to the same-view generation setting. In this work, we introduce Exo2EgoSyn, an adaptation of WAN 2.2 that unlocks Exocentric-to-Egocentric(Exo2Ego) cross-view video synthesis. Our framework consists of three key modules. Ego-Exo View Alignment(EgoExo-Align) enforces latent-space alignment between exocentric and egocentric first-frame representations, reorienting the generative space from the given exo view toward the ego view. Multi-view Exocentric Video Conditioning (MultiExoCon) aggregates multi-view exocentric videos into a unified conditioning signal, extending WAN2.2 beyond its vanilla single-image or text conditioning. Furthermore, Pose-Aware Latent Injection (PoseInj) injects relative exo-to-ego camera pose information into the latent state, guiding geometry-aware synthesis across viewpoints. Together, these modules enable high-fidelity ego view video generation from third-person observations without retraining from scratch. Experiments on ExoEgo4D validate that Exo2EgoSyn significantly improves Ego2Exo synthesis, paving the way for scalable cross-view video generation with foundation models. Source code and models will be released publicly.","authors":["Mohammad Mahdi","Yuqian Fu","Nedko Savov","Jiancheng Pan","Danda Pani Paudel","Luc Van Gool"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17126v3","updated":"2025-11-25T11:06:54Z","published":"2025-11-21T10:41:54Z","title":"OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation","summary":"Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2.","authors":["Qi Jiang","Xiaolong Qian","Yao Gao","Lei Sun","Kailun Yang","Zhonghua Yi","Wenyong Li","Ming-Hsuan Yang","Luc Van Gool","Kaiwei Wang"],"pdf_url":"","comment":"The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2"},{"id":"http://arxiv.org/abs/2511.20175v1","updated":"2025-11-25T10:58:23Z","published":"2025-11-25T10:58:23Z","title":"Realizing Fully-Integrated, Low-Power, Event-Based Pupil Tracking with Neuromorphic Hardware","summary":"Eye tracking is fundamental to numerous applications, yet achieving robust, high-frequency tracking with ultra-low power consumption remains challenging for wearable platforms. While event-based vision sensors offer microsecond resolution and sparse data streams, they have lacked fully integrated, low-power processing solutions capable of real-time inference. In this work, we present the first battery-powered, wearable pupil-center-tracking system with complete on-device integration, combining event-based sensing and neuromorphic processing on the commercially available Speck2f system-on-chip with lightweight coordinate decoding on a low-power microcontroller. Our solution features a novel uncertainty-quantifying spiking neural network with gated temporal decoding, optimized for strict memory and bandwidth constraints, complemented by systematic deployment mechanisms that bridge the reality gap. We validate our system on a new multi-user dataset and demonstrate a wearable prototype with dual neuromorphic devices achieving robust binocular pupil tracking at 100 Hz with an average power consumption below 5 mW per eye. Our work demonstrates that end-to-end neuromorphic computing enables practical, always-on eye tracking for next-generation energy-efficient wearable systems.","authors":["Federico Paredes-Valles","Yoshitaka Miyatani","Kirk Y. W. Scheper"],"pdf_url":"","comment":"17 pages, 14 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.19200v2","updated":"2025-11-25T10:49:13Z","published":"2025-11-24T15:09:32Z","title":"Can Modern Vision Models Understand the Difference Between an Object and a Look-alike?","summary":"Recent advances in computer vision have yielded models with strong performance on recognition benchmarks; however, significant gaps remain in comparison to human perception. One subtle ability is to judge whether an image looks like a given object without being an instance of that object. We study whether vision-language models such as CLIP capture this distinction. We curated a dataset named RoLA (Real or Lookalike) of real and lookalike exemplars (e.g., toys, statues, drawings, pareidolia) across multiple categories, and first evaluate a prompt-based baseline with paired \"real\"/\"lookalike\" prompts. We then estimate a direction in CLIP's embedding space that moves representations between real and lookalike. Applying this direction to image and text embeddings improves discrimination in cross-modal retrieval on Conceptual12M, and also enhances captions produced by a CLIP prefix captioner.","authors":["Itay Cohen","Ethan Fetaya","Amir Rosenfeld"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20169v1","updated":"2025-11-25T10:47:48Z","published":"2025-11-25T10:47:48Z","title":"ADNet: A Large-Scale and Extensible Multi-Domain Benchmark for Anomaly Detection Across 380 Real-World Categories","summary":"Anomaly detection (AD) aims to identify defects using normal-only training data. Existing anomaly detection benchmarks (e.g., MVTec-AD with 15 categories) cover only a narrow range of categories, limiting the evaluation of cross-context generalization and scalability. We introduce ADNet, a large-scale, multi-domain benchmark comprising 380 categories aggregated from 49 publicly available datasets across Electronics, Industry, Agrifood, Infrastructure, and Medical domains. The benchmark includes a total of 196,294 RGB images, consisting of 116,192 normal samples for training and 80,102 test images, of which 60,311 are anomalous. All images are standardized with MVTec-style pixel-level annotations and structured text descriptions spanning both spatial and visual attributes, enabling multimodal anomaly detection tasks. Extensive experiments reveal a clear scalability challenge: existing state-of-the-art methods achieve 90.6% I-AUROC in one-for-one settings but drop to 78.5% when scaling to all 380 categories in a multi-class setting. To address this, we propose Dinomaly-m, a context-guided Mixture-of-Experts extension of Dinomaly that expands decoder capacity without increasing inference cost. It achieves 83.2% I-AUROC and 93.1% P-AUROC, demonstrating superior performance over existing approaches. ADNet is designed as a standardized and extensible benchmark, supporting the community in expanding anomaly detection datasets across diverse domains and providing a scalable foundation for future anomaly detection foundation models. Dataset: https://grainnet.github.io/ADNet","authors":["Hai Ling","Jia Guo","Zhulin Tao","Yunkang Cao","Donglin Di","Hongyan Xu","Xiu Su","Yang Song","Lei Fan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.12959v2","updated":"2025-11-25T10:42:06Z","published":"2025-09-16T11:02:36Z","title":"Time-step Mixup for Efficient Spiking Knowledge Transfer from Appearance to Event Domain","summary":"The integration of event cameras and spiking neural networks holds great promise for energy-efficient visual processing. However, the limited availability of event data and the sparse nature of DVS outputs pose challenges for effective training. Although some prior work has attempted to transfer semantic knowledge from RGB datasets to DVS, they often overlook the significant distribution gap between the two modalities. In this paper, we propose Time-step Mixup knowledge transfer (TMKT), a novel fine-grained mixing strategy that exploits the asynchronous nature of SNNs by interpolating RGB and DVS inputs at various time-steps. To enable label mixing in cross-modal scenarios, we further introduce modality-aware auxiliary learning objectives. These objectives support the time-step mixup process and enhance the model's ability to discriminate effectively across different modalities. Our approach enables smoother knowledge transfer, alleviates modality shift during training, and achieves superior performance in spiking image classification tasks. Extensive experiments demonstrate the effectiveness of our method across multiple datasets. The code will be released after the double-blind review process.","authors":["Yuqi Xie","Shuhan Ye","Yi Yu","Chong Wang","Qixin Zhang","Jiazhen Xu","Le Shen","Yuanbin Qian","Jiangbo Qian","Guoqi Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04115v2","updated":"2025-11-25T10:42:01Z","published":"2025-06-04T16:09:16Z","title":"Multi-view Surface Reconstruction Using Normal and Reflectance Cues","summary":"Achieving high-fidelity 3D surface reconstruction while preserving fine details remains challenging, especially in the presence of materials with complex reflectance properties and without a dense-view setup. In this paper, we introduce a versatile framework that incorporates multi-view normal and optionally reflectance maps into radiance-based surface reconstruction. Our approach employs a pixel-wise joint re-parametrization of reflectance and surface normals, representing them as a vector of radiances under simulated, varying illumination. This formulation enables seamless incorporation into standard surface reconstruction pipelines, such as traditional multi-view stereo (MVS) frameworks or modern neural volume rendering (NVR) ones. Combined with the latter, our approach achieves state-of-the-art performance on multi-view photometric stereo (MVPS) benchmark datasets, including DiLiGenT-MV, LUCES-MV and Skoltech3D. In particular, our method excels in reconstructing fine-grained details and handling challenging visibility conditions. The present paper is an extended version of the earlier conference paper by Brument et al. (in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024), featuring an accelerated and more robust algorithm as well as a broader empirical evaluation. The code and data relative to this article is available at https://github.com/RobinBruneau/RNb-NeuS2.","authors":["Robin Bruneau","Baptiste Brument","Yvain Quéau","Jean Mélou","François Bernard Lauze","Jean-Denis Durou","Lilian Calvet"],"pdf_url":"","comment":"22 pages, 15 figures, 11 tables. A thorough qualitative and quantitive study is available in the supplementary material at https://drive.google.com/file/d/1KDfCKediXNP5Os954TL_QldaUWS0nKcD/view?usp=drive_link. Accepted to IJCV"},{"id":"http://arxiv.org/abs/2505.16565v2","updated":"2025-11-25T10:41:11Z","published":"2025-05-22T11:58:54Z","title":"M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo Video Conversion","summary":"We tackle the problem of monocular-to-stereo video conversion and propose a novel architecture for inpainting and refinement of the warped right view obtained by depth-based reprojection of the input left view. We extend the Stable Video Diffusion (SVD) model to utilize the input left video, the warped right video, and the disocclusion masks as conditioning input to generate a high-quality right camera view. In order to effectively exploit information from neighboring frames for inpainting, we modify the attention layers in SVD to compute full attention for discoccluded pixels. Our model is trained to generate the right view video in an end-to-end manner without iterative diffusion steps by minimizing image space losses to ensure high-quality generation. Our approach outperforms previous state-of-the-art methods, being ranked best 2.6x more often than the second-place method in a user study, while being 6x faster.","authors":["Nina Shvetsova","Goutam Bhat","Prune Truong","Hilde Kuehne","Federico Tombari"],"pdf_url":"","comment":"To be published at 3DV 2026, project webpage https://m2svid.github.io/"},{"id":"http://arxiv.org/abs/2511.20162v1","updated":"2025-11-25T10:38:41Z","published":"2025-11-25T10:38:41Z","title":"While recognizing actions, LMMs struggle to detect core interaction events","summary":"Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes.","authors":["Daniel Harari","Michael Sidorov","Liel David","Chen Shterental","Abrham Kahsay Gebreselasie","Muhammad Haris Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20158v1","updated":"2025-11-25T10:34:51Z","published":"2025-11-25T10:34:51Z","title":"Harmonious Parameter Adaptation in Continual Visual Instruction Tuning for Safety-Aligned MLLMs","summary":"While continual visual instruction tuning (CVIT) has shown promise in adapting multimodal large language models (MLLMs), existing studies predominantly focus on models without safety alignment. This critical oversight ignores the fact that real-world MLLMs inherently require such mechanisms to mitigate potential risks. In this work, we shift our focus to CVIT for safety-aligned MLLMs and observe that during continual adaptation, the model not only suffers from task forgetting but also exhibits degradation in its safety. Achieving a harmonious balance between safety and task performance remains a crucial challenge. To address this, we propose Harmonious Parameter Adaptation (HPA), a post-training framework composed of focusing-based parameter partition, harmoniously balanced parameter selection, and orthogonal parameter adjustment. Specifically, HPA partitions parameters into two types based on their focus on safety or task performance, and selects the focused ones to preserve from a balanced perspective. In addition, HPA imposes orthogonality constraints on parameter updates to further alleviate catastrophic forgetting. Extensive experiments on the CVIT benchmark and safety evaluation datasets demonstrate that HPA better maintains high safety and mitigates forgetting than existing baselines.","authors":["Ziqi Wang","Chang Che","Qi Wang","Hui Ma","Zenglin Shi","Cees G. M. Snoek","Meng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20157v1","updated":"2025-11-25T10:33:17Z","published":"2025-11-25T10:33:17Z","title":"SKEL-CF: Coarse-to-Fine Biomechanical Skeleton and Surface Mesh Recovery","summary":"Parametric 3D human models such as SMPL have driven significant advances in human pose and shape estimation, yet their simplified kinematics limit biomechanical realism. The recently proposed SKEL model addresses this limitation by re-rigging SMPL with an anatomically accurate skeleton. However, estimating SKEL parameters directly remains challenging due to limited training data, perspective ambiguities, and the inherent complexity of human articulation. We introduce SKEL-CF, a coarse-to-fine framework for SKEL parameter estimation. SKEL-CF employs a transformer-based encoder-decoder architecture, where the encoder predicts coarse camera and SKEL parameters, and the decoder progressively refines them in successive layers. To ensure anatomically consistent supervision, we convert the existing SMPL-based dataset 4DHuman into a SKEL-aligned version, 4DHuman-SKEL, providing high-quality training data for SKEL estimation. In addition, to mitigate depth and scale ambiguities, we explicitly incorporate camera modeling into the SKEL-CF pipeline and demonstrate its importance across diverse viewpoints. Extensive experiments validate the effectiveness of the proposed design. On the challenging MOYO dataset, SKEL-CF achieves 85.0 MPJPE / 51.4 PA-MPJPE, significantly outperforming the previous SKEL-based state-of-the-art HSMR (104.5 / 79.6). These results establish SKEL-CF as a scalable and anatomically faithful framework for human motion analysis, bridging the gap between computer vision and biomechanics. Our implementation is available on the project page: https://pokerman8.github.io/SKEL-CF/.","authors":["Da Li","Ji-Ping Jin","Xuanlong Yu","Wei Liu","Xiaodong Cun","Kai Chen","Rui Fan","Jiangang Kong","Shen Xi"],"pdf_url":"","comment":"15 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.17361v2","updated":"2025-11-25T10:31:55Z","published":"2025-11-21T16:26:31Z","title":"SuperQuadricOcc: Multi-Layer Gaussian Approximation of Superquadrics for Real-Time Self-Supervised Occupancy Estimation","summary":"Semantic occupancy estimation enables comprehensive scene understanding for automated driving, providing dense spatial and semantic information essential for perception and planning. While Gaussian representations have been widely adopted in self-supervised occupancy estimation, the deployment of a large number of Gaussian primitives drastically increases memory requirements and is not suitable for real-time inference. In contrast, superquadrics permit reduced primitive count and lower memory requirements due to their diverse shape set. However, implementation into a self-supervised occupancy model is nontrivial due to the absence of a superquadric rasterizer to enable model supervision. Our proposed method, SuperQuadricOcc, employs a superquadric-based scene representation. By leveraging a multi-layer icosphere-tessellated Gaussian approximation of superquadrics, we enable Gaussian rasterization for supervision during training. On the Occ3D dataset, SuperQuadricOcc achieves a 75% reduction in memory footprint, 124% faster inference, and a 5.9% improvement in mIoU compared to previous Gaussian-based methods, without the use of temporal labels. To our knowledge, this is the first occupancy model to enable real-time inference while maintaining competitive performance. The use of superquadrics reduces the number of primitives required for scene modeling by 84% relative to Gaussian-based approaches. Finally, evaluation against prior methods is facilitated by our fast superquadric voxelization module. The code will be made available at https://github.com/seamie6/SuperQuadricOcc.","authors":["Seamie Hayes","Reenu Mohandas","Tim Brophy","Alexandre Boulch","Ganesh Sistu","Ciaran Eising"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20156v1","updated":"2025-11-25T10:30:26Z","published":"2025-11-25T10:30:26Z","title":"Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving","summary":"Motion planning for autonomous driving must handle multiple plausible futures while remaining computationally efficient. Recent end-to-end systems and world-model-based planners predict rich multi-modal trajectories, but typically rely on handcrafted anchors or reinforcement learning to select a single best mode for training and control. This selection discards information about alternative futures and complicates optimization. We propose MAP-World, a prior-free multi-modal planning framework that couples masked action planning with a path-weighted world model. The Masked Action Planning (MAP) module treats future ego motion as masked sequence completion: past waypoints are encoded as visible tokens, future waypoints are represented as mask tokens, and a driving-intent path provides a coarse scaffold. A compact latent planning state is expanded into multiple trajectory queries with injected noise, yielding diverse, temporally consistent modes without anchor libraries or teacher policies. A lightweight world model then rolls out future BEV semantics conditioned on each candidate trajectory. During training, semantic losses are computed as an expectation over modes, using trajectory probabilities as discrete path weights, so the planner learns from the full distribution of plausible futures instead of a single selected path. On NAVSIM, our method matches anchor-based approaches and achieves state-of-the-art performance among world-model-based methods, while avoiding reinforcement learning and maintaining real-time inference latency.","authors":["Bin Hu","Zijian Lu","Haicheng Liao","Chengran Yuan","Bin Rao","Yongkang Li","Guofa Li","Zhiyong Cui","Cheng-zhong Xu","Zhenning Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20154v1","updated":"2025-11-25T10:28:37Z","published":"2025-11-25T10:28:37Z","title":"Alzheimers Disease Progression Prediction Based on Manifold Mapping of Irregularly Sampled Longitudinal Data","summary":"The uncertainty of clinical examinations frequently leads to irregular observation intervals in longitudinal imaging data, posing challenges for modeling disease progression.Most existing imaging-based disease prediction models operate in Euclidean space, which assumes a flat representation of data and fails to fully capture the intrinsic continuity and nonlinear geometric structure of irregularly sampled longitudinal images. To address the challenge of modeling Alzheimers disease (AD) progression from irregularly sampled longitudinal structural Magnetic Resonance Imaging (sMRI) data, we propose a Riemannian manifold mapping, a Time-aware manifold Neural ordinary differential equation, and an Attention-based riemannian Gated recurrent unit (R-TNAG) framework. Our approach first projects features extracted from high-dimensional sMRI into a manifold space to preserve the intrinsic geometry of disease progression. On this representation, a time-aware Neural Ordinary Differential Equation (TNODE) models the continuous evolution of latent states between observations, while an Attention-based Riemannian Gated Recurrent Unit (ARGRU) adaptively integrates historical and current information to handle irregular intervals. This joint design improves temporal consistency and yields robust AD trajectory prediction under irregular sampling.Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art models in both disease status prediction and cognitive score regression. Ablation studies verify the contributions of each module, highlighting their complementary roles in enhancing predictive accuracy. Moreover, the model exhibits stable performance across varying sequence lengths and missing data rates, indicating strong temporal generalizability. Cross-dataset validation further confirms its robustness and applicability in diverse clinical settings.","authors":["Xin Hong","Ying Shi","Yinhao Li","Yen-Wei Chen"],"pdf_url":"","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.20152v1","updated":"2025-11-25T10:22:26Z","published":"2025-11-25T10:22:26Z","title":"Restora-Flow: Mask-Guided Image Restoration with Flow Matching","summary":"Flow matching has emerged as a promising generative approach that addresses the lengthy sampling times associated with state-of-the-art diffusion models and enables a more flexible trajectory design, while maintaining high-quality image generation. This capability makes it suitable as a generative prior for image restoration tasks. Although current methods leveraging flow models have shown promising results in restoration, some still suffer from long processing times or produce over-smoothed results. To address these challenges, we introduce Restora-Flow, a training-free method that guides flow matching sampling by a degradation mask and incorporates a trajectory correction mechanism to enforce consistency with degraded inputs. We evaluate our approach on both natural and medical datasets across several image restoration tasks involving a mask-based degradation, i.e., inpainting, super-resolution and denoising. We show superior perceptual quality and processing time compared to diffusion and flow matching-based reference methods.","authors":["Arnela Hadzic","Franz Thaler","Lea Bogensperger","Simon Johannes Joham","Martin Urschler"],"pdf_url":"","comment":"Accepted for WACV 2026"},{"id":"http://arxiv.org/abs/2511.20151v1","updated":"2025-11-25T10:21:42Z","published":"2025-11-25T10:21:42Z","title":"Hybrid Convolution and Frequency State Space Network for Image Compression","summary":"Learned image compression (LIC) has recently benefited from Transformer based and state space model (SSM) based architectures. Convolutional neural networks (CNNs) effectively capture local high frequency details, whereas Transformers and SSMs provide strong long range modeling capabilities but may cause structural information loss or ignore frequency characteristics that are crucial for compression. In this work we propose HCFSSNet, a Hybrid Convolution and Frequency State Space Network for LIC. HCFSSNet uses CNNs to extract local high frequency structures and introduces a Vision Frequency State Space (VFSS) block that models long range low frequency information. The VFSS block combines an Omni directional Neighborhood State Space (VONSS) module, which scans features horizontally, vertically and diagonally, with an Adaptive Frequency Modulation Module (AFMM) that applies content adaptive weighting of discrete cosine transform frequency components for more efficient bit allocation. To further reduce redundancy in the entropy model, we integrate AFMM with a Swin Transformer to form a Frequency Swin Transformer Attention Module (FSTAM) for frequency aware side information modeling. Experiments on the Kodak, Tecnick and CLIC Professional Validation datasets show that HCFSSNet achieves competitive rate distortion performance compared with recent SSM based codecs such as MambaIC, while using significantly fewer parameters. On Kodak, Tecnick and CLIC, HCFSSNet reduces BD rate over the VTM anchor by 18.06, 24.56 and 22.44 percent, respectively, providing an efficient and interpretable hybrid architecture for future learned image compression systems.","authors":["Haodong Pan","Hao Wei","Yusong Wang","Nanning Zheng","Caigui Jiang"],"pdf_url":"","comment":"36 pages, 8 figures"},{"id":"http://arxiv.org/abs/2504.19687v3","updated":"2025-11-25T10:10:42Z","published":"2025-04-28T11:23:57Z","title":"Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network for Low-Dose CT MAR","summary":"Low-dose CT (LDCT) is capable of reducing X-ray radiation exposure, but it will potentially degrade image quality, even yields metal artifacts at the case of metallic implants. For simultaneous LDCT reconstruction and metal artifact reduction (LDMAR), existing deep learning-based efforts face two main limitations: i) the network design neglects multi-scale and within-scale information; ii) training a distinct model for each dose necessitates significant storage space for multiple doses. To fill these gaps, we propose a prompt guiding multi-scale adaptive sparse representation-driven network, abbreviated as PMSRNet, for LDMAR task. Specifically, we construct PMSRNet inspired from multi-scale sparsifying frames, and it can simultaneously employ within-scale characteristics and cross-scale complementarity owing to an elaborated prompt guiding scale-adaptive threshold generator (PSATG) and a built multi-scale coefficient fusion module (MSFuM). The PSATG can adaptively capture multiple contextual information to generate more faithful thresholds, achieved by fusing features from local, regional, and global levels. Furthermore, we elaborate a model interpretable dual domain LDMAR framework called PDuMSRNet, and train single model with a prompt guiding strategy for multiple dose levels. We build a prompt guiding module, whose input contains dose level, metal mask and input instance, to provide various guiding information, allowing a single model to accommodate various CT dose settings. Extensive experiments at various dose levels demonstrate that the proposed methods outperform the state-of-the-art LDMAR methods.","authors":["Baoshun Shi","Bing Chen","Shaolei Zhang","Huazhu Fu","Zhanli Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20145v1","updated":"2025-11-25T10:07:57Z","published":"2025-11-25T10:07:57Z","title":"Vision-Language Models for Automated 3D PET/CT Report Generation","summary":"Positron emission tomography/computed tomography (PET/CT) is essential in oncology, yet the rapid expansion of scanners has outpaced the availability of trained specialists, making automated PET/CT report generation (PETRG) increasingly important for reducing clinical workload. Compared with structural imaging (e.g., X-ray, CT, and MRI), functional PET poses distinct challenges: metabolic patterns vary with tracer physiology, and whole-body 3D contextual information is required rather than local-region interpretation. To advance PETRG, we propose PETRG-3D, an end-to-end 3D dual-branch framework that separately encodes PET and CT volumes and incorporates style-adaptive prompts to mitigate inter-hospital variability in reporting practices. We construct PETRG-Lym, a multi-center lymphoma dataset collected from four hospitals (824 reports w/ 245,509 paired PET/CT slices), and construct AutoPET-RG-Lym, a publicly accessible PETRG benchmark derived from open imaging data but equipped with new expert-written, clinically validated reports (135 cases). To assess clinical utility, we introduce PETRG-Score, a lymphoma-specific evaluation protocol that jointly measures metabolic and structural findings across curated anatomical regions. Experiments show that PETRG-3D substantially outperforms existing methods on both natural language metrics (e.g., +31.49\\% ROUGE-L) and clinical efficacy metrics (e.g., +8.18\\% PET-All), highlighting the benefits of volumetric dual-modality modeling and style-aware prompting. Overall, this work establishes a foundation for future PET/CT-specific models emphasizing disease-aware reasoning and clinically reliable evaluation. Codes, models, and AutoPET-RG-Lym will be released.","authors":["Wenpei Jiao","Kun Shang","Hui Li","Ke Yan","Jiajin Zhang","Guangjie Yang","Lijuan Guo","Yan Wan","Xing Yang","Dakai Jin","Zhaoheng Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07901v3","updated":"2025-11-25T10:06:37Z","published":"2025-08-11T12:17:38Z","title":"Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation","summary":"Generating high-fidelity human videos that match user-specified identities is important yet challenging in the field of generative AI. Existing methods often rely on an excessive number of training parameters and lack compatibility with other AIGC tools. In this paper, we propose Stand-In, a lightweight and plug-and-play framework for identity preservation in video generation. Specifically, we introduce a conditional image branch into the pre-trained video generation model. Identity control is achieved through restricted self-attentions with conditional position mapping. Thanks to these designs, which greatly preserve the pre-trained prior of the video generation model, our approach is able to outperform other full-parameter training methods in video quality and identity preservation, even with just $\\sim$1% additional parameters and only 2000 training pairs. Moreover, our framework can be seamlessly integrated for other tasks, such as subject-driven video generation, pose-referenced video generation, stylization, and face swapping.","authors":["Bowen Xue","Zheng-Peng Duan","Qixin Yan","Wenjing Wang","Hao Liu","Chun-Le Guo","Chongyi Li","Chen Li","Jing Lyu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.00777v3","updated":"2025-11-25T09:53:49Z","published":"2025-08-01T17:00:12Z","title":"Zero-Shot Anomaly Detection with Dual-Branch Prompt Selection","summary":"Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects in unseen categories by relying solely on generalizable features rather than requiring any labeled examples of anomalies. However, existing ZSAD methods, whether using fixed or learned prompts, struggle under domain shifts because their training data are derived from limited training domains and fail to generalize to new distributions. In this paper, we introduce PILOT, a framework designed to overcome these challenges through two key innovations: (1) a novel dual-branch prompt learning mechanism that dynamically integrates a pool of learnable prompts with structured semantic attributes, enabling the model to adaptively weight the most relevant anomaly cues for each input image; and (2) a label-free test-time adaptation strategy that updates the learnable prompt parameters using high-confidence pseudo-labels from unlabeled test data. Extensive experiments on 13 industrial and medical benchmarks demonstrate that PILOT achieves state-of-the-art performance in both anomaly detection and localization under domain shift.","authors":["Zihan Wang","Samira Ebrahimi Kahou","Narges Armanfard"],"pdf_url":"","comment":"Accepted at BMVC 2025"},{"id":"http://arxiv.org/abs/2506.08640v2","updated":"2025-11-25T09:46:44Z","published":"2025-06-10T09:54:37Z","title":"Orientation Matters: Making 3D Generative Models Orientation-Aligned","summary":"Humans intuitively perceive object shape and orientation from a single image, guided by strong priors about canonical poses. However, existing 3D generative models often produce misaligned results due to inconsistent training data, limiting their usability in downstream tasks. To address this gap, we introduce the task of orientation-aligned 3D object generation: producing 3D objects from single images with consistent orientations across categories. To facilitate this, we construct Objaverse-OA, a dataset of 14,832 orientation-aligned 3D models spanning 1,008 categories. Leveraging Objaverse-OA, we fine-tune two representative 3D generative models based on multi-view diffusion and 3D variational autoencoder frameworks to produce aligned objects that generalize well to unseen objects across various categories. Experimental results demonstrate the superiority of our method over post-hoc alignment approaches. Furthermore, we showcase downstream applications enabled by our aligned object generation, including zero-shot object orientation estimation via analysis-by-synthesis and efficient arrow-based object rotation manipulation.","authors":["Yichong Lu","Yuzhuo Tian","Zijin Jiang","Yikun Zhao","Yuanbo Yang","Hao Ouyang","Haoji Hu","Huimin Yu","Yujun Shen","Yiyi Liao"],"pdf_url":"","comment":"Accepted by NeurIPS 2025. Project Page: https://xdimlab.github.io/Orientation_Matters"},{"id":"http://arxiv.org/abs/2511.20123v1","updated":"2025-11-25T09:44:10Z","published":"2025-11-25T09:44:10Z","title":"UltraViCo: Breaking Extrapolation Limits in Video Diffusion Transformers","summary":"Despite advances, video diffusion transformers still struggle to generalize beyond their training length, a challenge we term video length extrapolation. We identify two failure modes: model-specific periodic content repetition and a universal quality degradation. Prior works attempt to solve repetition via positional encodings, overlooking quality degradation and achieving only limited extrapolation. In this paper, we revisit this challenge from a more fundamental view: attention maps, which directly govern how context influences outputs. We identify that both failure modes arise from a unified cause: attention dispersion, where tokens beyond the training window dilute learned attention patterns. This leads to quality degradation and repetition emerges as a special case when this dispersion becomes structured into periodic attention patterns, induced by harmonic properties of positional encodings. Building on this insight, we propose UltraViCo, a training-free, plug-and-play method that suppresses attention for tokens beyond the training window via a constant decay factor. By jointly addressing both failure modes, we outperform a broad set of baselines largely across models and extrapolation ratios, pushing the extrapolation limit from 2x to 4x. Remarkably, it improves Dynamic Degree and Imaging Quality by 233% and 40.5% over the previous best method at 4x extrapolation. Furthermore, our method generalizes seamlessly to downstream tasks such as controllable video synthesis and editing.","authors":["Min Zhao","Hongzhou Zhu","Yingze Wang","Bokai Yan","Jintao Zhang","Guande He","Ling Yang","Chongxuan Li","Jun Zhu"],"pdf_url":"","comment":"Project page: https://thu-ml.github.io/UltraViCo.github.io/"},{"id":"http://arxiv.org/abs/2411.16417v2","updated":"2025-11-25T09:38:47Z","published":"2024-11-25T14:20:53Z","title":"Comparison of Generative Learning Methods for Turbulence Surrogates","summary":"Numerical simulations of turbulent flows present significant challenges in fluid dynamics due to their complexity and high computational cost. High resolution techniques such as Direct Numerical Simulation (DNS) and Large Eddy Simulation (LES) are generally not computationally affordable, particularly for technologically relevant problems. Recent advances in machine learning, specifically in generative probabilistic models, offer promising alternatives as surrogates for turbulence. This paper investigates the application of three generative models - Variational Autoencoders (VAE), Deep Convolutional Generative Adversarial Networks (DCGAN), and Denoising Diffusion Probabilistic Models (DDPM) - in simulating a von Kármán vortex street around a fixed cylinder projected into 2D, as well as a real-world experimental dataset of the wake flow of a cylinder array. Training data was obtained by means of LES in the simulated case and Particle Image Velocimetry (PIV) in the experimental case. We evaluate each model's ability to capture the statistical properties and spatial structures of the turbulent flow. Our results demonstrate that DDPM and DCGAN effectively replicate all flow distributions, highlighting their potential as efficient and accurate tools for turbulence surrogacy. We find a strong argument for DCGAN, as although they are more difficult to train (due to problems such as mode collapse), they show the fastest inference and training time, require less data to train compared to VAE and DDPM, and provide the results most closely aligned with the input stream. In contrast, VAE train quickly (and can generate samples quickly) but do not produce adequate results, and DDPM, whilst effective, are significantly slower at both, inference and training time.","authors":["Claudia Drygala","Edmund Ross","Francesca di Mare","Hanno Gottschalk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20116v1","updated":"2025-11-25T09:38:10Z","published":"2025-11-25T09:38:10Z","title":"LungEvaty: A Scalable, Open-Source Transformer-based Deep Learning Model for Lung Cancer Risk Prediction in LDCT Screening","summary":"Lung cancer risk estimation is gaining increasing importance as more countries introduce population-wide screening programs using low-dose CT (LDCT). As imaging volumes grow, scalable methods that can process entire lung volumes efficiently are essential to tap into the full potential of these large screening datasets. Existing approaches either over-rely on pixel-level annotations, limiting scalability, or analyze the lung in fragments, weakening performance. We present LungEvaty, a fully transformer-based framework for predicting 1-6 year lung cancer risk from a single LDCT scan. The model operates on whole-lung inputs, learning directly from large-scale screening data to capture comprehensive anatomical and pathological cues relevant for malignancy risk. Using only imaging data and no region supervision, LungEvaty matches state-of-the-art performance, refinable by an optional Anatomically Informed Attention Guidance (AIAG) loss that encourages anatomically focused attention. In total, LungEvaty was trained on more than 90,000 CT scans, including over 28,000 for fine-tuning and 6,000 for evaluation. The framework offers a simple, data-efficient, and fully open-source solution that provides an extensible foundation for future research in longitudinal and multimodal lung cancer risk prediction.","authors":["Johannes Brandt","Maulik Chevli","Rickmer Braren","Georgios Kaissis","Philip Müller","Daniel Rueckert"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.04594v6","updated":"2025-11-25T09:38:06Z","published":"2025-05-07T17:37:23Z","title":"Unleashing the Power of Chain-of-Prediction for Monocular 3D Object Detection","summary":"Monocular 3D detection (Mono3D) aims to infer 3D bounding boxes from a single RGB image. Without auxiliary sensors such as LiDAR, this task is inherently ill-posed since the 3D-to-2D projection introduces depth ambiguity. Previous works often predict 3D attributes (e.g., depth, size, and orientation) in parallel, overlooking that these attributes are inherently correlated through the 3D-to-2D projection. However, simply enforcing such correlations through sequential prediction can propagate errors across attributes, especially when objects are occluded or truncated, where inaccurate size or orientation predictions can further amplify depth errors. Therefore, neither parallel nor sequential prediction is optimal. In this paper, we propose MonoCoP, an adaptive framework that learns when and how to leverage inter-attribute correlations with two complementary designs. A Chain-of-Prediction (CoP) explores inter-attribute correlations through feature-level learning, propagation, and aggregation, while an Uncertainty-Guided Selector (GS) dynamically switches between CoP and parallel paradigms for each object based on the predicted uncertainty. By combining their strengths, MonoCoP achieves state-of-the-art (SOTA) performance on KITTI, nuScenes, and Waymo, significantly improving depth accuracy, particularly for distant objects.","authors":["Zhihao Zhang","Abhinav Kumar","Girish Chandar Ganesan","Xiaoming Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21962v2","updated":"2025-11-25T09:38:02Z","published":"2025-05-28T04:28:13Z","title":"A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding","summary":"While unmanned aerial vehicles (UAVs) offer wide-area, high-altitude coverage for anomaly detection, they face challenges such as dynamic viewpoints, scale variations, and complex scenes. Existing datasets and methods, mainly designed for fixed ground-level views, struggle to adapt to these conditions, leading to significant performance drops in drone-view scenarios. To bridge this gap, we introduce A2Seek (Aerial Anomaly Seek), a large-scale, reasoning-centric benchmark dataset for aerial anomaly understanding. This dataset covers various scenarios and environmental conditions, providing high-resolution real-world aerial videos with detailed annotations, including anomaly categories, frame-level timestamps, region-level bounding boxes, and natural language explanations for causal reasoning. Building on this dataset, we propose A2Seek-R1, a novel reasoning framework that generalizes R1-style strategies to aerial anomaly understanding, enabling a deeper understanding of \"Where\" anomalies occur and \"Why\" they happen in aerial frames. To this end, A2Seek-R1 first employs a graph-of-thought (GoT)-guided supervised fine-tuning approach to activate the model's latent reasoning capabilities on A2Seek. Then, we introduce Aerial Group Relative Policy Optimization (A-GRPO) to design rule-based reward functions tailored to aerial scenarios. Furthermore, we propose a novel \"seeking\" mechanism that simulates UAV flight behavior by directing the model's attention to informative regions. Extensive experiments demonstrate that A2Seek-R1 achieves up to a 22.04% improvement in AP for prediction accuracy and a 13.9% gain in mIoU for anomaly localization, exhibiting strong generalization across complex environments and out-of-distribution scenarios. Our dataset and code are released at https://2-mo.github.io/A2Seek/.","authors":["Mengjingcheng Mo","Xinyang Tong","Mingpi Tan","Jiaxu Leng","Jiankang Zheng","Yiran Liu","Haosheng Chen","Ji Gan","Weisheng Li","Xinbo Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.09022v3","updated":"2025-11-25T09:30:41Z","published":"2025-08-12T15:37:17Z","title":"Leveraging Unlabeled Data from Unknown Sources via Dual-Path Guidance for Deepfake Face Detection","summary":"Existing deepfake detection methods heavily rely on static labeled datasets. However, with the proliferation of generative models, real-world scenarios are flooded with massive amounts of unlabeled fake face data from unknown sources. This presents a critical dilemma: detectors relying solely on existing data face generalization failure, while manual labeling for this new stream is infeasible due to the high realism of fakes. A more fundamental challenge is that, unlike typical unsupervised learning tasks where categories are clearly defined, real and fake faces share the same semantics, which leads to a decline in the performance of traditional unsupervised strategies. Therefore, there is an urgent need for a new paradigm designed specifically for this scenario to effectively utilize these unlabeled data. Accordingly, this paper proposes a dual-path guided network (DPGNet) to address two key challenges: (1) bridging the domain differences between faces generated by different generative models; and (2) utilizing unlabeled image samples. The method comprises two core modules: text-guided cross-domain alignment, which uses learnable cues to unify visual and textual embeddings into a domain-invariant feature space; and curriculum-driven pseudo-label generation, which dynamically utilizes unlabeled samples. Extensive experiments on multiple mainstream datasets show that DPGNet significantly outperforms existing techniques,, highlighting its effectiveness in addressing the challenges posed by the deepfakes using unlabeled data.","authors":["Zhiqiang Yang","Renshuai Tao","Chunjie Zhang","guodong yang","Xiaolong Zheng","Yao Zhao"],"pdf_url":"","comment":"11pages,4figures"},{"id":"http://arxiv.org/abs/2511.20101v1","updated":"2025-11-25T09:19:20Z","published":"2025-11-25T09:19:20Z","title":"Multi Head Attention Enhanced Inception v3 for Cardiomegaly Detection","summary":"The healthcare industry has been revolutionized significantly by novel imaging technologies, not just in the diagnosis of cardiovascular diseases but also by the visualization of structural abnormalities like cardiomegaly. This article explains an integrated approach to the use of deep learning tools and attention mechanisms for automatic detection of cardiomegaly using X-ray images. The initiation of the project is grounded on a strong Data Collection phase and gathering the data of annotated X-ray images of various types. Then, while the Preprocessing module fine-tunes image quality, it is feasible to utilize the best out of the data quality in the proposed system. In our proposed system, the process is a CNN configuration leveraging the inception V3 model as one of the key blocks. Besides, we also employ a multilayer attention mechanism to enhance the strength. The most important feature of the method is the multi-head attention mechanism that can learn features automatically. By exact selective focusing on only some regions of input, the model can thus identify cardiomegaly in a sensitive manner. Attention rating is calculated, duplicated, and applied to enhance representation of main data, and therefore there is a successful diagnosis. The Evaluation stage will be extremely strict and it will thoroughly evaluate the model based on such measures as accuracy and precision. This will validate that the model can identify cardiomegaly and will also show the clinical significance of this method. The model has accuracy of 95.6, precision of 95.2, recall of 96.2, sensitivity of 95.7, specificity of 96.1 and an Area Under Curve(AUC) of 96.0 and their respective graphs are plotted for visualisation.","authors":["Abishek Karthik","Pandiyaraju V"],"pdf_url":"","comment":null}],"Systems and Control":[{"id":"http://arxiv.org/abs/2511.20612v1","updated":"2025-11-25T18:39:50Z","published":"2025-11-25T18:39:50Z","title":"Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition","summary":"Many consequential real-world systems, like wind fields and ocean currents, are dynamic and hard to model. Learning their governing dynamics remains a central challenge in scientific machine learning. Dynamic Mode Decomposition (DMD) provides a simple, data-driven approximation, but practical use is limited by sparse/noisy observations from continuous fields, reliance on linear approximations, and the lack of principled uncertainty quantification. To address these issues, we introduce Stochastic NODE-DMD, a probabilistic extension of DMD that models continuous-time, nonlinear dynamics while remaining interpretable. Our approach enables continuous spatiotemporal reconstruction at arbitrary coordinates and quantifies predictive uncertainty. Across four benchmarks, a synthetic setting and three physics-based flows, it surpasses a baseline in reconstruction accuracy when trained from only 10% observation density. It further recovers the dynamical structure by aligning learned modes and continuous-time eigenvalues with ground truth. Finally, on datasets with multiple realizations, our method learns a calibrated distribution over latent dynamics that preserves ensemble variability rather than averaging across regimes. Our code is available at: https://github.com/sedan-group/Stochastic-NODE-DMD","authors":["Yujin Kim","Sarah Dean"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20603v1","updated":"2025-11-25T18:32:57Z","published":"2025-11-25T18:32:57Z","title":"Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency","summary":"Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance.","authors":["Winfrey Paul Sagayam Dennis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20593v1","updated":"2025-11-25T18:24:11Z","published":"2025-11-25T18:24:11Z","title":"Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning","summary":"Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.","authors":["Allen Emmanuel Binny","Mahathi Anand","Hugo T. M. Kussaba","Lingyun Chen","Shreenabh Agrawal","Fares J. Abu-Dakka","Abdalla Swikir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20552v1","updated":"2025-11-25T17:48:27Z","published":"2025-11-25T17:48:27Z","title":"From Features to States: Data-Driven Selection of Measured State Variables via RFE-DMDc","summary":"The behavior of a dynamical system under a given set of inputs can be captured by tracking the response of an optimal subset of process variables (\\textit{state variables}). For many engineering systems, however, first-principles, model-based identification is impractical, motivating data-driven approaches for Digital Twins used in control and diagnostics. In this paper, we present RFE-DMDc, a supervised, data-driven workflow that uses Recursive Feature Elimination (RFE) to select a minimal, physically meaningful set of variables to monitor and then derives a linear state-space model via Dynamic Mode Decomposition with Control (DMDc). The workflow includes a cross-subsystem selection step that mitigates feature \\textit{overshadowing} in multi-component systems. To corroborate the results, we implement a GA-DMDc baseline that jointly optimizes the state set and model fit under a common accuracy cost on states and outputs. Across a truth-known RLC benchmark and a realistic Integrated Energy System (IES) with multiple thermally coupled components and thousands of candidate variables, RFE-DMDc consistently recovers compact state sets (\\(\\approx 10\\) variables) that achieve test errors comparable to GA-DMDc while requiring an order of magnitude less computational time. The selected variables retain clear physical interpretation across subsystems, and the resulting models demonstrate competitive predictive accuracy, computational efficiency, and robustness to overfitting.","authors":["Haoyu Wang","Andrea Alfonsi","Roberto Ponciroli","Richard Vilim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20508v1","updated":"2025-11-25T17:17:31Z","published":"2025-11-25T17:17:31Z","title":"Causal Feature Selection for Weather-Driven Residential Load Forecasting","summary":"Weather is a dominant external driver of residential electricity demand, but adding many meteorological covariates can inflate model complexity and may even impair accuracy. Selecting appropriate exogenous features is non-trivial and calls for a principled selection framework, given the direct operational implications for day-to-day planning and reliability. This work investigates whether causal feature selection can retain the most informative weather drivers while improving parsimony and robustness for short-term load forecasting. We present a case study on Southern Ontario with two open-source datasets: (i) IESO hourly electricity consumption by Forward Sortation Areas; (ii) ERA5 weather reanalysis data. We compare different feature selection regimes (no feature selection, non-causal selection, PCMCI-causal selection) on city-level forecasting with three different time series forecasting models: GRU, TCN, PatchTST. In the feature analysis, non-causal selection prioritizes radiation and moisture variables that show correlational dependence, whereas PCMCI-causal selection emphasizes more direct thermal drivers and prunes the indirect covariates. We detail the evaluation pipeline and report diagnostics on prediction accuracy and extreme-weather robustness, positioning causal feature selection as a practical complement to modern forecasters when integrating weather into residential load forecasting.","authors":["Elise Zhang","François Mirallès","Stéphane Dellacherie","Di Wu","Benoit Boulet"],"pdf_url":"","comment":"5 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.20467v1","updated":"2025-11-25T16:31:43Z","published":"2025-11-25T16:31:43Z","title":"Power-Efficient Autonomous Mobile Robots","summary":"This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.","authors":["Liangkai Liu","Weisong Shi","Kang G. Shin"],"pdf_url":"","comment":"13 pages, 16 figures"},{"id":"http://arxiv.org/abs/2511.20463v1","updated":"2025-11-25T16:29:33Z","published":"2025-11-25T16:29:33Z","title":"Learning Control Barrier Functions with Deterministic Safety Guarantees","summary":"Barrier functions (BFs) characterize safe sets of dynamical systems, where hard constraints are never violated as the system evolves over time. Computing a valid safe set and BF for a nonlinear (and potentially unmodeled), non-autonomous dynamical system is a difficult task. This work explores the design of BFs using data to obtain safe sets with deterministic assurances of control invariance. We leverage ReLU neural networks (NNs) to create continuous piecewise affine (CPA) BFs with deterministic safety guarantees for Lipschitz continuous, discrete-time dynamical system using sampled one-step trajectories. The CPA structure admits a novel classifier term to create a relaxed \\ac{bf} condition and construction via a data driven constrained optimization. We use iterative convex overbounding (ICO) to solve this nonconvex optimization problem through a series of convex optimization steps. We then demonstrate our method's efficacy on two-dimensional autonomous and non-autonomous dynamical systems.","authors":["Amy K. Strong","Ali Kashani","Claus Danielson","Leila Bridgeman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20453v1","updated":"2025-11-25T16:23:45Z","published":"2025-11-25T16:23:45Z","title":"Digital Twin-Assisted High-Precision Massive MIMO Localization in Urban Canyons","summary":"High-precision wireless localization in urban canyons is challenged by noisy measurements and severe non-line-of-sight (NLOS) propagation. This paper proposes a robust three-stage algorithm synergizing a digital twin (DT) model with the random sample consensus (RANSAC) algorithm to overcome these limitations. The method leverages the DT for geometric path association and employs RANSAC to identify reliable line-of-sight (LOS) and single-bounce NLOS paths while rejecting multi-bounce outliers. A final optimization on the resulting inlier set estimates the user's position and clock bias. Simulations validate that by effectively turning NLOS paths into valuable geometric information via the DT, the approach enables accurate localization, reduces reliance on direct LOS, and significantly lowers system deployment costs, making it suitable for practical deployment.","authors":["Ziqin Zhou","Hui Chen","Gerhard Steinböck","Henk Wymeersch"],"pdf_url":"","comment":"6 pages, 5 figures. accepted to 2026 IEEE JC&S"},{"id":"http://arxiv.org/abs/2511.20443v1","updated":"2025-11-25T16:16:12Z","published":"2025-11-25T16:16:12Z","title":"Adaptive Meshing for CPA Lyapunov Function Synthesis","summary":"Continuous piecewise affine (CPA) Lyapunov function synthesis is one method to perform Lyapunov stability analysis for nonlinear systems. This method first generates a mesh over the region of interest in the system's state space and then solves a linear program (LP), which enforces constraints on each vertex of the mesh, to synthesize a Lyapunov function. Finer meshes broaden the class of Lyapunov function candidates, but CPA function synthesis is more computationally expensive for finer meshes -- particularly so in higher dimensional systems. This paper explores methods to mesh the region of interest more efficiently so that a Lyapunov function can be synthesized using less computational effort. Three methods are explored -- adaptive meshing, meshing using knowledge of the system model, and a combination of the two. Numerical examples for two and three dimensional nonlinear dynamical systems are used to compare the efficacy of the three methods.","authors":["Amy K. Strong","Samuel Akinwande","Leila Bridgeman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20416v1","updated":"2025-11-25T15:40:23Z","published":"2025-11-25T15:40:23Z","title":"Nonuniform-Grid Markov Chain Approximation of Continuous Processes with Time-Linear Moments","summary":"We propose a method to approximate continuous-time, continuous-state stochastic processes by a discrete-time Markov chain defined on a nonuniform grid. Our method provides exact moment matching for processes whose first and second moments are linear functions of time. In particular, we show that, under certain conditions, the transition probabilities of a Markov chain can be chosen so that its first two moments match prescribed linear functions of time. These conditions depend on the grid points of the Markov chain and the coefficients of the linear mean and variance functions. Our proof relies on two recurrence relations for the expectation and variance across time. This approach enables simulation-based numerical analysis of continuous processes while preserving their key characteristics. We illustrate its efficacy by approximating continuous processes describing heat diffusion and geometric Brownian motion (GBM). For heat diffusion, we show that the heat profile at a set of points can be investigated by embedding those points inside the nonuniform grid of our Markov chain. For GBM, numerical simulations demonstrate that our approach, combined with suitable nonuniform grids, yields accurate approximations, with consistently small empirical Wasserstein-1 distances at long time horizons.","authors":["Do Hyun Kim","Ahemt Cetinkaya"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20411v1","updated":"2025-11-25T15:36:56Z","published":"2025-11-25T15:36:56Z","title":"Self-Identifying Internal Model-Based Online Optimization","summary":"In this paper, we propose a novel online optimization algorithm built by combining ideas from control theory and system identification. The foundation of our algorithm is a control-based design that makes use of the internal model of the online problem. Since such prior knowledge of this internal model might not be available in practice, we incorporate an identification routine that learns this model on the fly. The algorithm is designed starting from quadratic online problems but can be applied to general problems. For quadratic cases, we characterize the asymptotic convergence to the optimal solution trajectory. We compare the proposed algorithm with existing approaches, and demonstrate how the identification routine ensures its adaptability to changes in the underlying internal model. Numerical results also indicate strong performance beyond the quadratic setting.","authors":["Wouter J. A. van Weerelt","Lantian Zhang","Silun Zhang","Nicola Bastianello"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20383v1","updated":"2025-11-25T15:05:49Z","published":"2025-11-25T15:05:49Z","title":"Accelerating Time-Optimal Trajectory Planning for Connected and Automated Vehicles with Graph Neural Networks","summary":"In this paper, we present a learning-based framework that accelerates time- and energy-optimal trajectory planning for connected and automated vehicles (CAVs) using graph neural networks (GNNs). We formulate the multi-agent coordination problem encountered in traffic scenarios as a cooperative trajectory planning problem that minimizes travel time, subject to motion primitives derived from energy-optimal solutions. The effectiveness of this framework can be further improved through replanning at each time step, enabling the system to incorporate newly observed information. To achieve real-time execution of such a multi-agent replanning scheme, we employ a GNN architecture to learn the solutions of the time-optimal trajectory planning problem from offline-generated data. The trained model produces online predictions that serve as warm-start solutions for numerical optimization, thereby enabling rapid computation of minimal exit times and the associated feasible trajectories. This learning-augmented approach substantially reduces computation time while ensuring that all state, input, and safety constraints are satisfied.","authors":["Viet-Anh Le","Andreas A. Malikopoulos"],"pdf_url":"","comment":"submitted to IFAC WC 2026"},{"id":"http://arxiv.org/abs/2511.20294v1","updated":"2025-11-25T13:27:45Z","published":"2025-11-25T13:27:45Z","title":"SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms","summary":"Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness.","authors":["Dnyandeep Mandaokar","Bernhard Rinner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20276v1","updated":"2025-11-25T13:05:02Z","published":"2025-11-25T13:05:02Z","title":"LLM-Driven Transient Stability Assessment: From Automated Simulation to Neural Architecture Design","summary":"This paper presents an LLM-driven, end-to-end workflow that addresses the lack of automation and intelligence in power system transient stability assessment (TSA). The proposed agentic framework integrates large language models (LLMs) with a professional simulator (ANDES) to automatically generate and filter disturbance scenarios from natural language, and employs an LLM-driven Neural Network Design (LLM-NND) pipeline to autonomously design and optimize TSA models through performance-guided, closed-loop feedback. On the IEEE 39-bus system, the LLM-NND models achieve 93.71% test accuracy on four-class TSA with only 4.78M parameters, while maintaining real-time inference latency (less than 0.95 ms per sample). Compared with a manually designed DenseNet (25.9M parameters, 80.05% accuracy), the proposed approach jointly improves accuracy and efficiency. Ablation studies confirm that the synergy among domain-grounded retrieval, reasoning augmentation, and feedback mechanisms is essential for robust automation. The results demonstrate that LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm that is readily extensible to other power system tasks such as optimal power flow, fault analysis, and market operations.","authors":["Lianzhe Hu","Yu Wang","Bikash Pal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.17773v3","updated":"2025-11-25T12:29:22Z","published":"2025-01-29T17:09:28Z","title":"SafePR: Unified Approach for Safe Parallel Robots by Contact Detection and Reaction with Redundancy Resolution","summary":"Fast and safe motion is crucial for the successful deployment of physically interactive robots. Parallel robots (PRs) offer the potential for higher speeds while maintaining the same energy limits due to their low moving masses. However, they require methods for contact detection and reaction while avoiding singularities and self-collisions. We address this issue and present SafePR - a unified approach for the detection and localization, including the distinction between collision and clamping to perform a reaction that is safe for humans and feasible for PRs. Our approach uses information from the encoders and motor currents to estimate forces via a generalized-momentum observer. Neural networks and particle filters classify and localize the contacts. We introduce reactions with redundancy resolution to avoid self-collisions and type-II singularities. Our approach detected and terminated 72 real-world collision and clamping contacts with end-effector speeds of up to 1.5 m/s, each within 25-275 ms. The forces were below the thresholds from ISO/TS 15066. By using built-in sensors, SafePR enables safe interaction with already assembled PRs without the need for new hardware components.","authors":["Aran Mohammad","Tim-Lukas Habich","Thomas Seel","Moritz Schappler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20239v1","updated":"2025-11-25T12:13:36Z","published":"2025-11-25T12:13:36Z","title":"Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection","summary":"This paper addresses multi-object systems, where objects may occlude one another relative to the sensor. The standard point-object model for detection-based sensors is enhanced so that the probability of detection considers the presence of all objects. A principled tracking method is derived, assigning each object an expected probability of detection, where the expectation is taken over the reduced Palm density, which means conditionally on the object's existence. The assigned probability thus considers the object's visibility relative to the sensor, under the presence of other objects. Unlike existing methods, the proposed method systematically accounts for uncertainties related to all objects in a clear and manageable way. The method is demonstrated through a visual tracking application using the multi-Bernoulli mixture (MBM) filter with marks.","authors":["Jan Krejčí","Oliver Kost","Yuxuan Xia","Lennart Svensson","Ondřej Straka"],"pdf_url":"","comment":"Submitted to IEEE Transactions on Aerospace and Electronic Systems (TAES)"},{"id":"http://arxiv.org/abs/2511.20237v1","updated":"2025-11-25T12:11:34Z","published":"2025-11-25T12:11:34Z","title":"Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis","summary":"The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions.","authors":["Zeynab Kaseb","Matthias Moller","Lindsay Spoor","Jerry J. Guo","Yu Xiang","Peter Palensky","Pedro P. Vergara"],"pdf_url":"","comment":"10 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.20220v1","updated":"2025-11-25T11:47:47Z","published":"2025-11-25T11:47:47Z","title":"Communication-Efficient Learning for Satellite Constellations","summary":"Satellite constellations in low-Earth orbit are now widespread, enabling positioning, Earth imaging, and communications. In this paper we address the solution of learning problems using these satellite constellations. In particular, we focus on a federated approach, where satellites collect and locally process data, with the ground station aggregating local models. We focus on designing a novel, communication-efficient algorithm that still yields accurate trained models. To this end, we employ several mechanisms to reduce the number of communications with the ground station (local training) and their size (compression). We then propose an error feedback mechanism that enhances accuracy, which yields, as a byproduct, an algorithm-agnostic error feedback scheme that can be more broadly applied. We analyze the convergence of the resulting algorithm, and compare it with the state of the art through simulations in a realistic space scenario, showcasing superior performance.","authors":["Ruxandra-Stefania Tudose","Moritz H. W. Grüss","Grace Ra Kim","Karl H. Johansson","Nicola Bastianello"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.08161v2","updated":"2025-11-25T11:19:49Z","published":"2024-11-12T20:12:09Z","title":"Shaping Frequency Dynamics in Modern Power Systems with Grid-forming Converters","summary":"In this paper, frequency dynamics in modern power systems with a high penetration of converter-based generation is analysed. A fundamental analysis of the frequency dynamics is performed to identify the limitations and challenges when the converter penetration is increased. The voltage-source behaviour is found as an essential characteristic of converters to improve the initial frequency derivative of Synchronous Generators (SGs). A detailed small-signal analysis, based on the system's eigenvalues, participation factors and mode shapes, is then performed in a reduced system for different converter penetrations, showing that the flexibility of grid-forming (GFOR) converters as well as the system's inertia reduction may lead to have a more controllable system frequency. First-order frequency responses can be programmed for high converter penetrations, when GFOR operation can impose their dominance over SGs. These results have been validated in the IEEE 118-bus system simulated in PSCAD.","authors":["Carlos Collados-Rodriguez","Daniel Westerman Spier","Marc Cheah-Mane","Eduardo Prieto-Araujo","Oriol Gomis-Bellmunt"],"pdf_url":"","comment":"11 pages, 17 figures"},{"id":"http://arxiv.org/abs/2511.08420v2","updated":"2025-11-25T11:01:03Z","published":"2025-11-11T16:29:44Z","title":"Computable Characterisations of Scaled Relative Graphs of Closed Operators","summary":"Scaled Relative Graphs (SRGs) provide a promising tool for stability and robustness analysis of multi-input-multi-output systems. In this paper, we provide tools for exact and computable constructions of the SRG for closed linear operators, based on maximum and minimum gain computations. The results are suitable for bounded and unbounded operators, and we specify how they can be used to draw SRGs for the typical operators that are used to model linear-time-invariant dynamical systems. Furthermore, for the special case of state-space models, we show how the Bounded Real Lemma can be used to construct the SRG.","authors":["Talitha Nauta","Richard Pates"],"pdf_url":"","comment":"12 pages, 5 figures, submitted to the 2026 European Control Conference (ECC)"},{"id":"http://arxiv.org/abs/2404.10665v5","updated":"2025-11-25T10:44:45Z","published":"2024-04-16T15:42:20Z","title":"Iterated Invariant Extended Kalman Filter (IterIEKF)","summary":"We study the mathematical properties of the Invariant Extended Kalman Filter (IEKF) when iterating on the measurement update step, following the principles of the well-known Iterated Extended Kalman Filter. This iterative variant of the IEKF (IterIEKF) systematically improves its accuracy through Gauss-Newton-based relinearization, and exhibits additional theoretical properties, particularly in the low-noise regime, that resemble those of the linear Kalman filter. We apply the proposed approach to the problem of estimating the extended pose of a crane payload using an inertial measurement unit. Our results suggest that the IterIEKF significantly outperforms the IEKF when measurements are highly accurate.","authors":["Sven Goffin","Axel Barrau","Silvère Bonnabel","Olivier Brüls","Pierre Sacré"],"pdf_url":"","comment":"8 pages, 2 figures, IEEE Transactions on Automatic Control"},{"id":"http://arxiv.org/abs/2501.11655v2","updated":"2025-11-25T10:30:53Z","published":"2025-01-20T18:38:51Z","title":"KKL Observer Synthesis for Nonlinear Systems via Physics-Informed Learning","summary":"This paper proposes a novel learning approach for designing Kazantzis-Kravaris/Luenberger (KKL) observers for autonomous nonlinear systems. The design of a KKL observer involves finding an injective map that transforms the system state into a higher-dimensional observer state, whose dynamics is linear and stable. The observer's state is then mapped back to the original system coordinates via the inverse map to obtain the state estimate. However, finding this transformation and its inverse is quite challenging. We propose learning the forward mapping using a physics-informed neural network, and then learning its inverse mapping with a conventional feedforward neural network. Theoretical guarantees for the robustness of state estimation against approximation error and system uncertainties are provided, including non-asymptotic learning guarantees that link approximation quality to finite sample sizes. The effectiveness of the proposed approach is demonstrated through numerical simulations on benchmark examples, showing superior generalization capability outside the training domain compared to state-of-the-art methods.","authors":["M. Umar B. Niazi","John Cao","Matthieu Barreau","Karl Henrik Johansson"],"pdf_url":"","comment":"27 pages, 7 figures, submitted to Automatica"},{"id":"http://arxiv.org/abs/2510.05834v6","updated":"2025-11-25T08:29:38Z","published":"2025-10-07T11:59:36Z","title":"Time-causal and time-recursive wavelets","summary":"When to apply wavelet analysis to real-time temporal signals, where the future cannot be accessed, it is essential to base all the steps in the signal processing pipeline on computational mechanisms that are truly time-causal.\n  This paper describes how a time-causal wavelet analysis can be performed based on concepts developed in the area of temporal scale-space theory, originating from a complete classification of temporal smoothing kernels that guarantee non-creation of new structures from finer to coarser temporal scale levels. By necessity, convolution with truncated exponential kernels in cascade constitutes the only permissable class of kernels, as well as their temporal derivatives as a natural complement to fulfil the admissibility conditions of wavelet representations. For a particular way of choosing the time constants in the resulting infinite convolution of truncated exponential kernels, to ensure temporal scale covariance and thus self-similarity over temporal scales, we describe how mother wavelets can be chosen as temporal derivatives of the resulting time-causal limit kernel.\n  By developing connections between wavelet theory and scale-space theory, we characterize and quantify how the continuous scaling properties transfer to the discrete implementation, demonstrating how the proposed time-causal wavelet representation can reflect the duration of locally dominant temporal structures in the input signals.\n  We propose that this notion of time-causal wavelet analysis could be a valuable tool for signal processing tasks, where streams of signals are to be processed in real time, specifically for signals that may contain local variations over a rich span of temporal scales, or more generally for analysing physical or biophysical temporal phenomena, where a fully time-causal analysis is called for to be physically realistic.","authors":["Tony Lindeberg"],"pdf_url":"","comment":"28 pages, 11 figures"},{"id":"http://arxiv.org/abs/2511.20043v1","updated":"2025-11-25T08:11:35Z","published":"2025-11-25T08:11:35Z","title":"Assessing the Technical and Environmental Impacts of Energy Management Systems in Smart Ports","summary":"A vital strategy for ports to mitigate the environmental impact of the maritime industry, while complying with frameworks such as the European Green Deal and the Sustainable Development Goals (SDGs), entails the systematic implementation of comprehensive energy management solutions. This paper provides a baseline evaluation of the energy management systems (EMSs) implementation and their impact on energy consumption, carbon emissions, and operational costs in smart ports. Initially, we provide a systematic review of the literature focusing on case studies from prominent ports, including Hamburg, Genoa, Jurong, and Shanghai Yangshan Phase IV. The analysis emphasises key aspects such as energy efficiency, reductions in emissions, and the minimization of operational costs. Subsequently, we formulate an optimisation model to simulate load dispatch, carbon emission reduction, and transport scheduling. Results indicate that EMS deployment reduces annual energy consumption and carbon emissions significantly by approximately 7%-8% and 11%-12% respectively, while achieving substantial cost savings of 30%. The study also identifies critical challenges, including system integration, data quality issues, cybersecurity risks, and the need for standardization. These findings provide valuable insights for port authorities and policymakers, supporting the transition toward more sustainable and efficient port operations.","authors":["Youzhe Yang","Hafiz Majid Hussain","Juha Haakana","Pedro Nardelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20015v1","updated":"2025-11-25T07:32:49Z","published":"2025-11-25T07:32:49Z","title":"iRadioDiff: Physics-Informed Diffusion Model for Indoor Radio Map Construction and Localization","summary":"Radio maps (RMs) serve as environment-aware electromagnetic (EM) representations that connect scenario geometry and material properties to the spatial distribution of signal strength, enabling localization without costly in-situ measurements. However, constructing high-fidelity indoor RMs remains challenging due to the prohibitive latency of EM solvers and the limitations of learning-based methods, which often rely on sparse measurements or assumptions of homogeneous material, which are misaligned with the heterogeneous and multipath-rich nature of indoor environments. To overcome these challenges, we propose iRadioDiff, a sampling-free diffusion-based framework for indoor RM construction. iRadioDiff is conditioned on access point (AP) positions, and physics-informed prompt encoded by material reflection and transmission coefficients. It further incorporates multipath-critical priors, including diffraction points, strong transmission boundaries, and line-of-sight (LoS) contours, to guide the generative process via conditional channels and boundary-weighted objectives. This design enables accurate modeling of nonstationary field discontinuities and efficient construction of physically consistent RMs. Experiments demonstrate that iRadioDiff achieves state-of-the-art performance in indoor RM construction and received signal strength based indoor localization, which offers effective generalization across layouts and material configurations. Code is available at https://github.com/UNIC-Lab/iRadioDiff.","authors":["Xiucheng Wang","Tingwei Yuan","Yang Cao","Nan Cheng","Ruijin Sun","Weihua Zhuang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05900v2","updated":"2025-11-25T06:39:10Z","published":"2025-11-08T07:50:53Z","title":"Disentangled Control of Multi-Agent Systems","summary":"This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments.","authors":["Ruoyu Lin","Gennaro Notomista","Magnus Egerstedt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19961v1","updated":"2025-11-25T06:10:14Z","published":"2025-11-25T06:10:14Z","title":"Toward Trustworthy Digital Twins in Agentic AI-based Wireless Network Optimization: Challenges, Solutions, and Opportunities","summary":"Optimizing modern wireless networks is exceptionally challenging due to their high dynamism and complexity. While the agentic artificial intelligence (AI) powered by reinforcement learning (RL) offers a promising solution, its practical application is limited by prohibitive exploration costs and potential risks in the real world. The emerging digital twin (DT) technology provides a safe and controlled virtual environment for agentic AI training, but its effectiveness critically depends on the DT's fidelity. Policies trained in a low-fidelity DT that does not accurately represent the physical network may experience severe performance degradation upon real-world deployment. In this article, we introduce a unified DT evaluation framework to ensure trustworthy DTs in agentic AI-based network optimization. This evaluation framework shifts from conventional isolated physical accuracy metrics, such as wireless channel and user trajectory similarities, to a more holistic, task-centric DT assessment. We demonstrate it as an effective guideline for design, selection, and lifecycle management of wireless network DTs. A comprehensive case study on a real-world wireless network testbed shows how this evaluation framework is used to pre-filter candidate DTs, leading to a significant reduction in training and testing costs without sacrificing deployment performance. Finally, potential research opportunities are discussed.","authors":["Zhenyu Tao","Wei Xu","Xiaohu You"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.10418v3","updated":"2025-11-25T03:54:14Z","published":"2024-06-14T21:32:48Z","title":"An Adaptive Method for Contextual Stochastic Multi-armed Bandits with Rewards Generated by a Linear Dynamical System","summary":"Online decision-making can be formulated as the popular stochastic multi-armed bandit problem where a learner makes decisions (or takes actions) to maximize cumulative rewards collected from an unknown environment. This paper proposes to model a stochastic multi-armed bandit as an unknown linear Gaussian dynamical system, as many applications, such as bandits for dynamic pricing problems or hyperparameter selection for machine learning models, can benefit from this perspective. Following this approach, we can build a matrix representation of the system's steady-state Kalman filter that takes a set of previously collected observations from a time interval of length $s$ to predict the next reward that will be returned for each action. This paper proposes a solution in which the parameter $s$ is determined via an adaptive algorithm by analyzing the model uncertainty of the matrix representation. This algorithm helps the learner adaptively adjust its model size and its length of exploration based on the uncertainty of its environmental model. The effectiveness of the proposed scheme is demonstrated through extensive numerical studies, revealing that the proposed scheme is capable of increasing the rate of collected cumulative rewards.","authors":["Jonathan Gornet","Mehdi Hosseinzadeh","Bruno Sinopoli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19884v1","updated":"2025-11-25T03:44:29Z","published":"2025-11-25T03:44:29Z","title":"An Exact Solution Algorithm for the Bi-Level Optimization Problem of Electric Vehicles Charging Station Placement","summary":"This work addresses electric vehicle (EV) charging station placement through a bi-level optimization model, where the upper-level planner maximizes net revenue by selecting station locations under budget constraints, while EV users at the lower level choose routes and charging stations to minimize travel and charging costs. To account for range anxiety, we construct a battery-expanded network and apply a shortest path algorithm with Frank-Wolfe traffic assignment. Our primary contribution is developing the first exact solution algorithm for large scale EV charging station placement problems. We propose a Branch-and-Price-and-Cut algorithm enhanced with value function cuts and column generation. While existing research relies on heuristic methods that provide no optimality guarantees or exact algorithms that require prohibitively long runtimes, our exact algorithm delivers globally optimal solutions with mathematical certainty under a reasonable runtime. Computational experiments on the Eastern Massachusetts network (74 nodes, 248 links), the Anaheim network (416 nodes, 914 links), and the Barcelona network (110 zones, 1,020 nodes, and 2,512 links) demonstrate exceptional performance. Our algorithm terminates within minutes rather than hours, while achieving optimality gaps below 1% across all instances. This result represents a computational speedup of over two orders of magnitude compared to existing methods. The algorithm successfully handles problems with over 300,000 feasible combinations, which transform EV charging infrastructure planning from a computationally prohibitive problem into a tractable optimization task suitable for practical decision making problem for real world networks.","authors":["Mobina Nankali","Michael W. Levin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11386v3","updated":"2025-11-25T03:05:31Z","published":"2025-10-13T13:28:21Z","title":"Optimization of High-Order Quarter-Wave Plate for Residual Birefringence Suppression in FOCS","summary":"Fiber optic current sensors (FOCS) are widely adopted in modern power grids due to high sensitivity, excellent insulation, and strong immunity to electromagnetic interference. This prominence necessitates precise investigation into their error sources and corresponding optimization. This study examines reflective FOCS based on the Faraday effect. A theoretical model is established to simulate phase error caused by linear birefringence from the quarter-wave plate. Conventional methods using circular birefringence are analyzed, revealing inherent limitations. Innovatively, a compensation strategy employing high-order quarter-wave plates is proposed to effectively eliminate linear birefringence effects. This approach significantly enhances the accuracy and practicality of FOCS in precision metrology.","authors":["Yuechen Liu","Boqi Meng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20914v1","updated":"2025-11-25T23:06:09Z","published":"2025-11-25T23:06:09Z","title":"Distributionally Robust Cascading Risk in Multi-Agent Rendezvous: Extended Analysis of Parameter-Induced Ambiguity","summary":"Ensuring safety in autonomous multi-agent systems during time-critical tasks such as rendezvous is a fundamental challenge, particularly under communication delays and uncertainty in system parameters. In this paper, we develop a theoretical framework to analyze the \\emph{distributionally robust risk of cascading failures} in multi-agent rendezvous, where system parameters lie within bounded uncertainty sets around nominal values. Using a time-delayed dynamical network as a benchmark model, we quantify how small deviations in these parameters impact collective safety. We introduce a \\emph{conditional distributionally robust functional}, grounded in a bivariate Gaussian model, to characterize risk propagation between agents. This yields a \\emph{closed-form risk expression} that captures the complex interaction between time delays, network structure, noise statistics, and failure modes. These expressions expose key sensitivity patterns and provide actionable insight for the design of robust and resilient multi-agent networks. Extensive simulations validate the theoretical results and demonstrate the effectiveness of our framework.","authors":["Vivek Pandey","Nader Motee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20895v1","updated":"2025-11-25T22:26:36Z","published":"2025-11-25T22:26:36Z","title":"Adaptive Gradient Descent MPPT Algorithm With Complexity-Aware Benchmarking for Low-Power PV Systems","summary":"This paper proposes a computationally efficient, real-time maximum power point tracking (MPPT) algorithm tailored for low-power photovoltaic (PV) systems operating under fast-changing irradiance and partial shading conditions (PSC). The proposed method augments the classical perturb and observe (P&O) algorithm with an adaptive gradient descent mechanism that dynamically scales the perturbation step size based on the instantaneous power-voltage slope, thereby minimizing tracking time and steady-state oscillations. An optional initialization routine enhances global MPP (GMPP) tracking under PSC. Extensive simulations, including irradiance recordings from freely moving rodent subjects relevant to the targeted application, and tests across varying converter topologies and temperatures, demonstrate its robust, topology-independent performance. The proposed algorithm achieves 99.94 percent MPPT efficiency under standard test conditions (STC), 99.21 percent when applied to experimental data, and more than 99.6 percent for the tested temperature profiles. Under PSC, the initialization routine improves tracking efficiency by up to 7.8 percent. A normalized gate-level complexity analysis and a unified figure-of-merit (FoM) incorporating efficiency, tracking time, and computational cost demonstrate that the proposed algorithm outperforms 35 state-of-the-art P&O-based MPPT algorithms. These results underscore its suitability for integration in low-power power management integrated circuits (PMICs) operating under dynamic and resource-constrained conditions.","authors":["Kimia Ahmadi","Wouter A. Serdijn"],"pdf_url":"","comment":"12 pages, 13 figures"},{"id":"http://arxiv.org/abs/2509.08656v2","updated":"2025-11-25T22:17:09Z","published":"2025-09-10T14:52:14Z","title":"Analysis and Control of Acoustic Emissions from Marine Energy Converters","summary":"Environmental licensing related to underwater acoustic emissions represents a critical bottleneck for the commercial deployment of marine renewable energy. This study presents a control engineering framework to mitigate acoustic risks from tidal current converters without compromising project viability. A MATLAB/Simulink model of a tidal current converter was utilised to evaluate two distinct mitigation tiers: (1) architectural modification, comparing a geared induction generator against a direct-drive permanent magnet synchronous generator, and (2) operational control, analysing the impact of switching frequencies and maximum power point tracking coefficient tuning. Results indicate that lowering switching frequencies is ineffective, increasing power electronic losses by over 2000% with negligible acoustic benefit. Conversely, the direct-drive permanent magnet synchronous generator architecture reduced sound pressure levels, effectively eliminating mechanical tonal noise. For existing geared systems, de-tuning the maximum power point tracking coefficient by a factor of 1.2 reduced the probability of exceeding temporary threshold shift limits for marine mammals, with a quantified energy yield reduction of 3.58%. These findings propose a hierarchical mitigation strategy: selecting direct-drive topologies for acoustically sensitive sites, and utilising maximum power point tracking coefficient based power curtailment as a transient operational mode during critical biological migration periods.","authors":["Jiaqin He","Max Malyi","Jonathan Shek"],"pdf_url":"","comment":"A major revision, reframed as an engineering study of acoustic emissions with environmental compliance as a constraint. Methods, results, and discussion substantially expanded, figures updated. Supersedes the review oriented presentation in the previous version"},{"id":"http://arxiv.org/abs/2511.20874v1","updated":"2025-11-25T21:39:47Z","published":"2025-11-25T21:39:47Z","title":"Dynamic Modeling of Load Demand in Electrified Highways Based on the EV Composition","summary":"Electrified roadways (ERs) equipped with the dynamic wireless power transfer (DWPT) technology can achieve longer driving range and reduce on-board battery requirements for electric vehicles (EVs). Due to the spatial arrangement of transmitter (Tx) coils embedded into the ER pavement, the power drawn by the EV's receiver (Rx) coil is oscillatory in nature. Therefore, understanding the dynamic behavior of the total DWPT load is important for power system dynamic studies. To this end, we model the load of individual EVs in the time and frequency domains for constant EV speed. We establish that a nonlinear control scheme implemented in existing DWPT-enabled EVs exhibits milder frequency harmonics compared to its linear alternative. According to this model, the harmonics of an EV load decrease in amplitude with the Rx coil length. We further propose and analyze stochastic models for the total DWPT load served by an ER segment. Our models explain how the EV composition on the ER affects its frequency spectrum. Interestingly, we show that serving more EVs with longer Rx coils (trucks) does not necessarily entail milder harmonics. Our analytical findings are corroborated using realistic flows from a traffic simulator and offer valuable insights to grid operators and ER designers.","authors":["Ashutossh Gupta","Vassilis Kekatos","Dionysios Aliprantis","Steve Pekarek"],"pdf_url":"","comment":"5 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2511.20848v1","updated":"2025-11-25T20:56:27Z","published":"2025-11-25T20:56:27Z","title":"NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities","summary":"Neural Signal Operated Intelligent Robots (NOIR) system is a versatile brain-robot interface that allows humans to control robots for daily tasks using their brain signals. This interface utilizes electroencephalography (EEG) to translate human intentions regarding specific objects and desired actions directly into commands that robots can execute. We present NOIR 2.0, an enhanced version of NOIR. NOIR 2.0 includes faster and more accurate brain decoding algorithms, which reduce task completion time by 46%. NOIR 2.0 uses few-shot robot learning algorithms to adapt to individual users and predict their intentions. The new learning algorithms leverage foundation models for more sample-efficient learning and adaptation (15 demos vs. a single demo), significantly reducing overall human time by 65%.","authors":["Tasha Kim","Yingke Wang","Hanvit Cho","Alex Hodges"],"pdf_url":"","comment":"Conference on Robot Learning (CoRL 2024), CoRoboLearn"},{"id":"http://arxiv.org/abs/2507.00826v3","updated":"2025-11-25T20:56:10Z","published":"2025-07-01T14:57:48Z","title":"Unlocking Transmission Flexibility under Uncertainty: Getting Dynamic Line Ratings into Electricity Markets","summary":"Static transmission line ratings may lead to underutilization of line capacity due to overly conservative assumptions. Grid-enhancing technologies (GETs) such as dynamic line ratings (DLRs), which adjust line capacity based on real-time conditions, are a techno-economically viable alternative to increase the utilization of existing power lines. Nonetheless, their adoption has been slow, partly due to the absence of operational tools that effectively account for simultaneous impacts on dispatch and pricing. In this paper, we represent transmission capacity with DLRs as a stock-like resource with time-variant interdependency, which is modeled via an approximation of line temperature evolution process, decoupling the impacts of ambient weather conditions and power flow on transmission line temperature and thus capacity. We integrate DLRs into a multi-period DC optimal power flow problem, with chance constrains addressing correlated uncertainty in DLRs and renewable generation. This yields non-convex problems that we transform into a tractable convex form by linearization. We derive locational marginal energy and ancillary services prices consistent with a competitive equilibrium. Numerical experiments on the 11-zone and 1814-node NYISO systems demonstrate its performance, including impacts on dispatch, pricing, and marginal carbon emissions.","authors":["Zhiyi Zhou","Christoph Graf","Yury Dvorkin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20843v1","updated":"2025-11-25T20:47:48Z","published":"2025-11-25T20:47:48Z","title":"A Review of Pseudospectral Optimal Control: From Theory to Flight","summary":"The home space for optimal control is a Sobolev space. The home space for pseudospectral theory is also a Sobolev space. It thus seems natural to combine pseudospectral theory with optimal control theory and construct ``pseudospectral optimal control theory,'' a term coined by Ross. In this paper, we review key theoretical results in pseudospectral optimal control that have proven to be critical for a successful flight. Implementation details of flight demonstrations onboard NASA spacecraft are discussed along with emerging trends and techniques in both theory and practice. The 2011 launch of pseudospectral optimal control in embedded platforms is changing the way in which we see solutions to challenging control problems in aerospace and autonomous systems.","authors":["I. M. Ross","M. Karpenko"],"pdf_url":"","comment":"https://www.sciencedirect.com/science/article/abs/pii/S1367578812000375"},{"id":"http://arxiv.org/abs/2511.20838v1","updated":"2025-11-25T20:40:45Z","published":"2025-11-25T20:40:45Z","title":"Local Dissipativity Analysis of Nonlinear Systems","summary":"Dissipativity is an input-output (IO) characterization of nonlinear systems that enables compositional robust control through Vidyasagar's Network Dissipativity Theorem. However, determining the dissipativity of a system is an involved and, often, model-specific process. We present a general method to determine the local dissipativity properties of nonlinear, control affine systems. We simultaneously search for the optimal IO characterization of a system and synthesize a continuous piecewise affine (CPA) storage function via a convex optimization problem. To do so, we reformulate the relationship between the Hamilton-Jacobi inequality and the dissipation inequality as an linear matrix inequality (LMI) and develop novel LMI bounds for a triangulation. Further, we develop a method to synthesize a combined quadratic and CPA storage function to expand the systems the optimization problem is applicable to. Finally, we demonstrate that our method will always find a feasible IO characterization and a CPA or quadratic storage function given that the system is strictly locally dissipative.","authors":["Amy K. Strong","Leila Bridgeman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20603v1","updated":"2025-11-25T18:32:57Z","published":"2025-11-25T18:32:57Z","title":"Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region: A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency","summary":"Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance.","authors":["Winfrey Paul Sagayam Dennis"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2511.20643v1","updated":"2025-11-25T18:58:07Z","published":"2025-11-25T18:58:07Z","title":"Concept-Aware Batch Sampling Improves Language-Image Pretraining","summary":"What data should a vision-language model be trained on? To answer this question, many data curation efforts center on the quality of a dataset. However, most of these existing methods are (i) offline, i.e. they produce a static dataset from a set of predetermined filtering criteria, and (ii) concept-agnostic, i.e. they use model-based filters which induce additional data biases. In this work, we go beyond such offline, concept-agnostic methods and advocate for more flexible, task-adaptive online concept-based curation. Our first contribution is DataConcept, a collection of 128M web-crawled image-text pairs annotated with fine-grained details about their concept composition. Building on DataConcept, we introduce Concept-Aware Batch Sampling (CABS), a simple yet effective batch sampling framework that flexibly constructs batches on-the-fly based on specific target distributions. We propose two variants: (i) Diversity Maximization (CABS-DM) to curate batches with a broad coverage of available concepts, and (ii) Frequency Maximization (CABS-FM) to curate batches with high object multiplicity. Through extensive evaluations across 28 benchmarks, we demonstrate that our CABS method significantly benefits CLIP/SigLIP model classes and yields highly performant models. Overall, CABS represents a strong open-source alternative to proprietary online data curation algorithms, enabling practitioners to define custom concept distributions that optimize for specific downstream tasks.","authors":["Adhiraj Ghosh","Vishaal Udandarao","Thao Nguyen","Matteo Farina","Mehdi Cherti","Jenia Jitsev","Sewoong Oh","Elisa Ricci","Ludwig Schmidt","Matthias Bethge"],"pdf_url":"","comment":"Tech Report"},{"id":"http://arxiv.org/abs/2511.20641v1","updated":"2025-11-25T18:57:28Z","published":"2025-11-25T18:57:28Z","title":"Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition","summary":"Long-tailed multi-label visual recognition poses a significant challenge, as images typically contain multiple labels with highly imbalanced class distributions, leading to biased models that favor head classes while underperforming on tail classes. Recent efforts have leveraged pre-trained vision-language models, such as CLIP, alongside long-tailed learning techniques to exploit rich visual-textual priors for improved performance. However, existing methods often derive semantic inter-class relationships directly from imbalanced datasets, resulting in unreliable correlations for tail classes due to data scarcity. Moreover, CLIP's zero-shot paradigm is optimized for single-label image-text matching, making it suboptimal for multi-label tasks. To address these issues, we propose the correlation adaptation prompt network (CAPNET), a novel end-to-end framework that explicitly models label correlations from CLIP's textual encoder. The framework incorporates a graph convolutional network for label-aware propagation and learnable soft prompts for refined embeddings. It utilizes a distribution-balanced Focal loss with class-aware re-weighting for optimized training under imbalance. Moreover, it improves generalization through test-time ensembling and realigns visual-textual modalities using parameter-efficient fine-tuning to avert overfitting on tail classes without compromising head class performance. Extensive experiments and ablation studies on benchmarks including VOC-LT, COCO-LT, and NUS-WIDE demonstrate that CAPNET achieves substantial improvements over state-of-the-art methods, validating its effectiveness for real-world long-tailed multi-label visual recognition.","authors":["Wei Tang","Zuo-Zheng Wang","Kun Zhang","Tong Wei","Min-Ling Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20640v1","updated":"2025-11-25T18:57:25Z","published":"2025-11-25T18:57:25Z","title":"MotionV2V: Editing Motion in a Video","summary":"While generative video models have achieved remarkable fidelity and consistency, applying these capabilities to video editing remains a complex challenge. Recent research has explored motion controllability as a means to enhance text-to-video generation or image animation; however, we identify precise motion control as a promising yet under-explored paradigm for editing existing videos. In this work, we propose modifying video motion by directly editing sparse trajectories extracted from the input. We term the deviation between input and output trajectories a \"motion edit\" and demonstrate that this representation, when coupled with a generative backbone, enables powerful video editing capabilities. To achieve this, we introduce a pipeline for generating \"motion counterfactuals\", video pairs that share identical content but distinct motion, and we fine-tune a motion-conditioned video diffusion architecture on this dataset. Our approach allows for edits that start at any timestamp and propagate naturally. In a four-way head-to-head user study, our model achieves over 65 percent preference against prior work. Please see our project page: https://ryanndagreat.github.io/MotionV2V","authors":["Ryan Burgert","Charles Herrmann","Forrester Cole","Michael S Ryoo","Neal Wadhwa","Andrey Voynov","Nataniel Ruiz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20639v1","updated":"2025-11-25T18:56:57Z","published":"2025-11-25T18:56:57Z","title":"Latent Collaboration in Multi-Agent Systems","summary":"Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.","authors":["Jiaru Zou","Xiyuan Yang","Ruizhong Qiu","Gaotang Li","Katherine Tieu","Pan Lu","Ke Shen","Hanghang Tong","Yejin Choi","Jingrui He","James Zou","Mengdi Wang","Ling Yang"],"pdf_url":"","comment":"Project: https://github.com/Gen-Verse/LatentMAS"},{"id":"http://arxiv.org/abs/2511.09219v3","updated":"2025-11-25T18:56:26Z","published":"2025-11-12T11:28:08Z","title":"Planning in Branch-and-Bound: Model-Based Reinforcement Learning for Exact Combinatorial Optimization","summary":"Mixed-Integer Linear Programming (MILP) lies at the core of many real-world combinatorial optimization (CO) problems, traditionally solved by branch-and-bound (B&B). A key driver influencing B&B solvers efficiency is the variable selection heuristic that guides branching decisions. Looking to move beyond static, hand-crafted heuristics, recent work has explored adapting traditional reinforcement learning (RL) algorithms to the B&B setting, aiming to learn branching strategies tailored to specific MILP distributions. In parallel, RL agents have achieved remarkable success in board games, a very specific type of combinatorial problems, by leveraging environment simulators to plan via Monte Carlo Tree Search (MCTS). Building on these developments, we introduce Plan-and-Branch-and-Bound (PlanB&B), a model-based reinforcement learning (MBRL) agent that leverages a learned internal model of the B&B dynamics to discover improved branching strategies. Computational experiments empirically validate our approach, with our MBRL branching agent outperforming previous state-of-the-art RL methods across four standard MILP benchmarks.","authors":["Paul Strang","Zacharie Alès","Côme Bissuel","Olivier Juan","Safia Kedad-Sidhoum","Emmanuel Rachelson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20636v1","updated":"2025-11-25T18:55:12Z","published":"2025-11-25T18:55:12Z","title":"Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model","summary":"Mechanical design and manufacturing workflows conventionally begin with conceptual design, followed by the creation of a computer-aided design (CAD) model and fabrication through material-extrusion (MEX) printing. This process requires converting CAD geometry into machine-readable G-code through slicing and path planning. While each step is well established, dependence on CAD modeling remains a major bottleneck: constructing object-specific 3D geometry is slow and poorly suited to rapid prototyping. Even minor design variations typically necessitate manual updates in CAD software, making iteration time-consuming and difficult to scale. To address this limitation, we introduce Image2Gcode, an end-to-end data-driven framework that bypasses the CAD stage and generates printer-ready G-code directly from images and part drawings. Instead of relying on an explicit 3D model, a hand-drawn or captured 2D image serves as the sole input. The framework first extracts slice-wise structural cues from the image and then employs a denoising diffusion probabilistic model (DDPM) over G-code sequences. Through iterative denoising, the model transforms Gaussian noise into executable print-move trajectories with corresponding extrusion parameters, establishing a direct mapping from visual input to native toolpaths. By producing structured G-code directly from 2D imagery, Image2Gcode eliminates the need for CAD or STL intermediates, lowering the entry barrier for additive manufacturing and accelerating the design-to-fabrication cycle. This approach supports on-demand prototyping from simple sketches or visual references and integrates with upstream 2D-to-3D reconstruction modules to enable an automated pipeline from concept to physical artifact. The result is a flexible, computationally efficient framework that advances accessibility in design iteration, repair workflows, and distributed manufacturing.","authors":["Ziyue Wang","Yayati Jadhav","Peter Pak","Amir Barati Farimani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20629v1","updated":"2025-11-25T18:49:21Z","published":"2025-11-25T18:49:21Z","title":"MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models","summary":"Reinforcement learning from human feedback (RLHF) with reward models has advanced alignment of generative models to human aesthetic and perceptual preferences. However, jointly optimizing multiple rewards often incurs an alignment tax, improving one dimension while degrading others. To address this, we introduce two complementary methods: MapReduce LoRA and Reward-aware Token Embedding (RaTE). MapReduce LoRA trains preference-specific LoRA experts in parallel and iteratively merges them to refine a shared base model; RaTE learns reward-specific token embeddings that compose at inference for flexible preference control. Experiments on Text-to-Image generation (Stable Diffusion 3.5 Medium and FLUX.1-dev) show improvements of 36.1%, 4.6%, and 55.7%, and 32.7%, 4.3%, and 67.1% on GenEval, PickScore, and OCR, respectively. On Text-to-Video generation (HunyuanVideo), visual and motion quality improve by 48.1% and 90.0%, respectively. On the language task, Helpful Assistant, with Llama-2 7B, helpful and harmless improve by 43.4% and 136.7%, respectively. Our framework sets a new state-of-the-art multi-preference alignment recipe across modalities.","authors":["Chieh-Yun Chen","Zhonghao Wang","Qi Chen","Zhifan Ye","Min Shi","Yue Zhao","Yinan Zhao","Hui Qu","Wei-An Lin","Yiru Shen","Ajinkya Kale","Irfan Essa","Humphrey Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20626v1","updated":"2025-11-25T18:48:05Z","published":"2025-11-25T18:48:05Z","title":"ROOT: Robust Orthogonalized Optimizer for Neural Network Training","summary":"The optimization of large language models (LLMs) remains a critical challenge, particularly as model scaling exacerbates sensitivity to algorithmic imprecision and training instability. Recent advances in optimizers have improved convergence efficiency through momentum orthogonalization, but suffer from two key robustness limitations: dimensional fragility in orthogonalization precision and vulnerability to outlier-induced noise. To address these robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer that enhances training stability through dual robustness mechanisms. First, we develop a dimension-robust orthogonalization scheme using adaptive Newton iterations with fine-grained coefficients tailored to specific matrix sizes, ensuring consistent precision across diverse architectural configurations. Second, we introduce an optimization-robust framework via proximal optimization that suppresses outlier noise while preserving meaningful gradient directions. Extensive experiments demonstrate that ROOT achieves significantly improved robustness, with faster convergence and superior final performance compared to both Muon and Adam-based optimizers, particularly in noisy and non-convex scenarios. Our work establishes a new paradigm for developing robust and precise optimizers capable of handling the complexities of modern large-scale model training. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/ROOT.","authors":["Wei He","Kai Han","Hang Zhou","Hanting Chen","Zhicheng Liu","Xinghao Chen","Yunhe Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20621v1","updated":"2025-11-25T18:44:22Z","published":"2025-11-25T18:44:22Z","title":"DiFR: Inference Verification Despite Nondeterminism","summary":"As demand for LLM inference grows, it is becoming increasingly important that providers and their customers can verify that inference processes are performed correctly, without errors or tampering. However, re-running the same inference process twice often leads to different results due to benign numerical noise, making it difficult to distinguish legitimate variation from actual problems. To address this problem, we introduce Token-DiFR (Token-Divergence-From-Reference), a method for verifying inference outputs by comparing generated tokens against predictions made by a trusted reference implementation conditioned on the same random seed. Sampling seed synchronization tightly constrains valid outputs, leaving providers minimal room to deviate from correct inference, which allows output tokens themselves to serve as auditable evidence of correctness at zero additional cost to the provider. Token-DiFR reliably identifies sampling errors, simulated bugs, and model quantization, detecting 4-bit quantization with AUC $>$ 0.999 within 300 output tokens. For applications requiring sample-efficient forward-pass verification, we additionally introduce Activation-DiFR, a scheme that uses random orthogonal projections to compress activations into compact fingerprints for subsequent verification. Activation-DiFR detects 4-bit quantization with AUC $>$ 0.999 using just 2 output tokens, while reducing communication overhead by 25-75% relative to existing methods. We release an open-source integration with vLLM to accelerate practical deployment of verifiable inference.","authors":["Adam Karvonen","Daniel Reuter","Roy Rinberg","Luke Marks","Adrià Garriga-Alonso","Keri Warr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20613v1","updated":"2025-11-25T18:40:22Z","published":"2025-11-25T18:40:22Z","title":"Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning","summary":"The rapid proliferation of Large Language Models (LLMs) has revolutionized AI-assisted code generation. This rapid development of LLMs has outpaced our ability to properly benchmark them. Prevailing benchmarks emphasize unit-test pass rates and syntactic correctness. Such metrics understate the difficulty of many real-world problems that require planning, optimization, and strategic interaction. We introduce a multi-agent reasoning-driven benchmark based on a real-world logistics optimization problem (Auction, Pickup, and Delivery Problem) that couples competitive auctions with capacity-constrained routing. The benchmark requires building agents that can (i) bid strategically under uncertainty and (ii) optimize planners that deliver tasks while maximizing profit. We evaluate 40 LLM-coded agents (by a wide range of state-of-the-art LLMs under multiple prompting methodologies, including vibe coding) against 17 human-coded agents developed before the advent of LLMs. Our results over 12 double all-play-all tournaments and $\\sim 40$k matches demonstrate (i) a clear superiority of human(graduate students)-coded agents: the top 5 spots are consistently won by human-coded agents, (ii) the majority of LLM-coded agents (33 out of 40) are beaten by very simple baselines, and (iii) given the best human solution as an input and prompted to improve upon, the best performing LLM makes the solution significantly worse instead of improving it. Our results highlight a gap in LLMs' ability to produce code that works competitively in the real-world, and motivate new evaluations that emphasize reasoning-driven code synthesis in real-world scenarios.","authors":["Panayiotis Danassis","Naman Goel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20612v1","updated":"2025-11-25T18:39:50Z","published":"2025-11-25T18:39:50Z","title":"Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition","summary":"Many consequential real-world systems, like wind fields and ocean currents, are dynamic and hard to model. Learning their governing dynamics remains a central challenge in scientific machine learning. Dynamic Mode Decomposition (DMD) provides a simple, data-driven approximation, but practical use is limited by sparse/noisy observations from continuous fields, reliance on linear approximations, and the lack of principled uncertainty quantification. To address these issues, we introduce Stochastic NODE-DMD, a probabilistic extension of DMD that models continuous-time, nonlinear dynamics while remaining interpretable. Our approach enables continuous spatiotemporal reconstruction at arbitrary coordinates and quantifies predictive uncertainty. Across four benchmarks, a synthetic setting and three physics-based flows, it surpasses a baseline in reconstruction accuracy when trained from only 10% observation density. It further recovers the dynamical structure by aligning learned modes and continuous-time eigenvalues with ground truth. Finally, on datasets with multiple realizations, our method learns a calibrated distribution over latent dynamics that preserves ensemble variability rather than averaging across regimes. Our code is available at: https://github.com/sedan-group/Stochastic-NODE-DMD","authors":["Yujin Kim","Sarah Dean"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20609v1","updated":"2025-11-25T18:36:47Z","published":"2025-11-25T18:36:47Z","title":"Adaptive Hopfield Network: Rethinking Similarities in Associative Memory","summary":"Associative memory models are content-addressable memory systems fundamental to biological intelligence and are notable for their high interpretability. However, existing models evaluate the quality of retrieval based on proximity, which cannot guarantee that the retrieved pattern has the strongest association with the query, failing correctness. We reframe this problem by proposing that a query is a generative variant of a stored memory pattern, and define a variant distribution to model this subtle context-dependent generative process. Consequently, correct retrieval should return the memory pattern with the maximum a posteriori probability of being the query's origin. This perspective reveals that an ideal similarity measure should approximate the likelihood of each stored pattern generating the query in accordance with variant distribution, which is impossible for fixed and pre-defined similarities used by existing associative memories. To this end, we develop adaptive similarity, a novel mechanism that learns to approximate this insightful but unknown likelihood from samples drawn from context, aiming for correct retrieval. We theoretically prove that our proposed adaptive similarity achieves optimal correct retrieval under three canonical and widely applicable types of variants: noisy, masked, and biased. We integrate this mechanism into a novel adaptive Hopfield network (A-Hop), and empirical results show that it achieves state-of-the-art performance across diverse tasks, including memory retrieval, tabular classification, image classification, and multiple instance learning.","authors":["Shurong Wang","Yuqi Pan","Zhuoyang Shen","Meng Zhang","Hongwei Wang","Guoqi Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.03151v2","updated":"2025-11-25T18:35:07Z","published":"2025-04-04T04:04:56Z","title":"Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1)","summary":"Reasoning is central to human intelligence, enabling structured problem-solving across diverse tasks. Recent advances in large language models (LLMs) have greatly enhanced their reasoning abilities in arithmetic, commonsense, and symbolic domains. However, effectively extending these capabilities into multimodal contexts-where models must integrate both visual and textual inputs-continues to be a significant challenge. Multimodal reasoning introduces complexities, such as handling conflicting information across modalities, which require models to adopt advanced interpretative strategies. Addressing these challenges involves not only sophisticated algorithms but also robust methodologies for evaluating reasoning accuracy and coherence. This paper offers a concise yet insightful overview of reasoning techniques in both textual and multimodal LLMs. Through a thorough and up-to-date comparison, we clearly formulate core reasoning challenges and opportunities, highlighting practical methods for post-training optimization and test-time inference. Our work provides valuable insights and guidance, bridging theoretical frameworks and practical implementations, and sets clear directions for future research.","authors":["Jing Bi","Susan Liang","Xiaofei Zhou","Pinxin Liu","Junjia Guo","Yunlong Tang","Luchuan Song","Chao Huang","Ali Vosoughi","Guangyu Sun","Jinxi He","Jiarui Wu","Shu Yang","Daoan Zhang","Chen Chen","Lianggong Bruce Wen","Zhang Liu","Jiebo Luo","Chenliang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20605v1","updated":"2025-11-25T18:34:33Z","published":"2025-11-25T18:34:33Z","title":"How to Purchase Labels? A Cost-Effective Approach Using Active Learning Markets","summary":"We introduce and analyse active learning markets as a way to purchase labels, in situations where analysts aim to acquire additional data to improve model fitting, or to better train models for predictive analytics applications. This comes in contrast to the many proposals that already exist to purchase features and examples. By originally formalising the market clearing as an optimisation problem, we integrate budget constraints and improvement thresholds into the label acquisition process. We focus on a single-buyer-multiple-seller setup and propose the use of two active learning strategies (variance based and query-by-committee based), paired with distinct pricing mechanisms. They are compared to a benchmark random sampling approach. The proposed strategies are validated on real-world datasets from two critical application domains: real estate pricing and energy forecasting. Results demonstrate the robustness of our approach, consistently achieving superior performance with fewer labels acquired compared to conventional methods. Our proposal comprises an easy-to-implement practical solution for optimising data acquisition in resource-constrained environments.","authors":["Xiwen Huang","Pierre Pinson"],"pdf_url":"","comment":"Submitted as a preprint. 34 pages, 14 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.20604v1","updated":"2025-11-25T18:33:24Z","published":"2025-11-25T18:33:24Z","title":"On Evaluating LLM Alignment by Evaluating LLMs as Judges","summary":"Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.","authors":["Yixin Liu","Pengfei Liu","Arman Cohan"],"pdf_url":"","comment":"NeurIPS 2025 Camera Ready"},{"id":"http://arxiv.org/abs/2511.20601v1","updated":"2025-11-25T18:30:55Z","published":"2025-11-25T18:30:55Z","title":"The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to Autocorrelation in Blood Glucose Forecasting","summary":"Deep sequence models for blood glucose forecasting consistently fail to leverage clinically informative drivers--insulin, meals, and activity--despite well-understood physiological mechanisms. We term this Driver-Blindness and formalize it via $Δ_{\\text{drivers}}$, the performance gain of multivariate models over matched univariate baselines. Across the literature, $Δ_{\\text{drivers}}$ is typically near zero. We attribute this to three interacting factors: architectural biases favoring autocorrelation (C1), data fidelity gaps that render drivers noisy and confounded (C2), and physiological heterogeneity that undermines population-level models (C3). We synthesize strategies that partially mitigate Driver-Blindness--including physiological feature encoders, causal regularization, and personalization--and recommend that future work routinely report $Δ_{\\text{drivers}}$ to prevent driver-blind models from being considered state-of-the-art.","authors":["Heman Shakeri"],"pdf_url":"","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2506.09738v2","updated":"2025-11-25T18:30:49Z","published":"2025-06-11T13:41:29Z","title":"Towards Multimodal Graph Large Language Model","summary":"Multi-modal graphs, which integrate diverse multi-modal features and relations, are ubiquitous in real-world applications. However, existing multi-modal graph learning methods are typically trained from scratch for specific graph data and tasks, failing to generalize across various multi-modal graph data and tasks. To bridge this gap, we explore the potential of Multi-modal Graph Large Language Models (MG-LLM) to unify and generalize across diverse multi-modal graph data and tasks. We propose a unified framework of multi-modal graph data, task, and model, discovering the inherent multi-granularity and multi-scale characteristics in multi-modal graphs. Specifically, we present five key desired characteristics for MG-LLM: 1) unified space for multi-modal structures and attributes, 2) capability of handling diverse multi-modal graph tasks, 3) multi-modal graph in-context learning, 4) multi-modal graph interaction with natural language, and 5) multi-modal graph reasoning. We then elaborate on the key challenges, review related works, and highlight promising future research directions towards realizing these ambitious characteristics. Finally, we summarize existing multi-modal graph datasets pertinent for model training. We believe this paper can contribute to the ongoing advancement of the research towards MG-LLM for generalization across multi-modal graph data and tasks.","authors":["Xin Wang","Zeyang Zhang","Linxin Xiao","Haibo Chen","Chendi Ge","Wenwu Zhu"],"pdf_url":"","comment":"4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2511.20597v1","updated":"2025-11-25T18:28:35Z","published":"2025-11-25T18:28:35Z","title":"BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents","summary":"The integration of artificial intelligence (AI) agents into web browsers introduces security challenges that go beyond traditional web application threat models. Prior work has identified prompt injection as a new attack vector for web agents, yet the resulting impact within real-world environments remains insufficiently understood.\n  In this work, we examine the landscape of prompt injection attacks and synthesize a benchmark of attacks embedded in realistic HTML payloads. Our benchmark goes beyond prior work by emphasizing injections that can influence real-world actions rather than mere text outputs, and by presenting attack payloads with complexity and distractor frequency similar to what real-world agents encounter. We leverage this benchmark to conduct a comprehensive empirical evaluation of existing defenses, assessing their effectiveness across a suite of frontier AI models. We propose a multi-layered defense strategy comprising both architectural and model-based defenses to protect against evolving prompt injection attacks. Our work offers a blueprint for designing practical, secure web agents through a defense-in-depth approach.","authors":["Kaiyuan Zhang","Mark Tenenholtz","Kyle Polley","Jerry Ma","Denis Yarats","Ninghui Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20592v1","updated":"2025-11-25T18:21:33Z","published":"2025-11-25T18:21:33Z","title":"Latent Diffusion Inversion Requires Understanding the Latent Space","summary":"The recovery of training data from generative models (``model inversion'') has been extensively studied for diffusion models in the data domain. The encoder/decoder pair and corresponding latent codes have largely been ignored by inversion techniques applied to latent space generative models, e.g., Latent Diffusion models (LDMs). In this work we describe two key findings: (1) The diffusion model exhibits non-uniform memorization across latent codes, tending to overfit samples located in high-distortion regions of the decoder pullback metric. (2) Even within a single latent code, different dimensions contribute unequally to memorization. We introduce a principled method to rank latent dimensions by their per-dimensional contribution to the decoder pullback metric, identifying those most responsible for memorization. Empirically, removing less-memorizing dimensions when computing attack statistics for score-based membership inference attacker significantly improves performance, with average AUROC gains of 2.7\\% and substantial increases in TPR@1\\%FPR (6.42\\%) across diverse datasets including CIFAR-10, CelebA, ImageNet-1K, Pokémon, MS-COCO, and Flickr. This indicates stronger confidence in identifying members under extremely low false-positive tolerance. Our results highlight the overlooked influence of the auto-encoder geometry on LDM memorization and provide a new perspective for analyzing privacy risks in diffusion-based generative models.","authors":["Mingxing Rao","Bowen Qu","Daniel Moyer"],"pdf_url":"","comment":"14 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.20591v1","updated":"2025-11-25T18:20:42Z","published":"2025-11-25T18:20:42Z","title":"Attention Trajectories as a Diagnostic Axis for Deep Reinforcement Learning","summary":"The learning process of a reinforcement learning (RL) agent remains poorly understood beyond the mathematical formulation of its learning algorithm. To address this gap, we introduce attention-oriented metrics (ATOMs) to investigate the development of an RL agent's attention during training. In a controlled experiment, we tested ATOMs on three variations of a Pong game, each designed to teach the agent distinct behaviours, complemented by a behavioural assessment. ATOMs successfully delineate the attention patterns of an agent trained on each game variation, and that these differences in attention patterns translate into differences in the agent's behaviour. Through continuous monitoring of ATOMs during training, we observed that the agent's attention developed in phases, and that these phases were consistent across game variations. Overall, we believe that ATOM could help improve our understanding of the learning processes of RL agents and better understand the relationship between attention and learning.","authors":["Charlotte Beylier","Hannah Selder","Arthur Fleig","Simon M. Hofmann","Nico Scherf"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20587v1","updated":"2025-11-25T18:18:16Z","published":"2025-11-25T18:18:16Z","title":"Anatomica: Localized Control over Geometric and Topological Properties for Anatomical Diffusion Models","summary":"We present Anatomica: an inference-time framework for generating multi-class anatomical voxel maps with localized geo-topological control. During generation, we use cuboidal control domains of varying dimensionality, location, and shape to slice out relevant substructures. These local substructures are used to compute differentiable penalty functions that steer the sample towards target constraints. We control geometric features such as size, shape, and position through voxel-wise moments, while topological features such as connected components, loops, and voids are enforced through persistent homology. Lastly, we implement Anatomica for latent diffusion models, where neural field decoders partially extract substructures, enabling the efficient control of anatomical properties. Anatomica applies flexibly across diverse anatomical systems, composing constraints to control complex structures over arbitrary dimensions and coordinate systems, thereby enabling the rational design of synthetic datasets for virtual trials or machine learning workflows.","authors":["Karim Kadry","Abdallah Abdelwahed","Shoaib Goraya","Ajay Manicka","Naravich Chutisilp","Farhad Nezami","Elazer Edelman"],"pdf_url":"","comment":"8 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.20586v1","updated":"2025-11-25T18:15:36Z","published":"2025-11-25T18:15:36Z","title":"PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic","summary":"Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \\emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \\emph{Trust Nodes} and \\emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \\emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \\emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.","authors":["Koffi Ismael Ouattara","Ioannis Krontiris","Theo Dimitrakos","Dennis Eisermann","Frank Kargl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20584v1","updated":"2025-11-25T18:13:53Z","published":"2025-11-25T18:13:53Z","title":"A Tale of Two Geometries: Adaptive Optimizers and Non-Euclidean Descent","summary":"Adaptive optimizers can reduce to normalized steepest descent (NSD) when only adapting to the current gradient, suggesting a close connection between the two algorithmic families. A key distinction between their analyses, however, lies in the geometries, e.g., smoothness notions, they rely on. In the convex setting, adaptive optimizers are governed by a stronger adaptive smoothness condition, while NSD relies on the standard notion of smoothness. We extend the theory of adaptive smoothness to the nonconvex setting and show that it precisely characterizes the convergence of adaptive optimizers. Moreover, we establish that adaptive smoothness enables acceleration of adaptive optimizers with Nesterov momentum in the convex setting, a guarantee unattainable under standard smoothness for certain non-Euclidean geometry. We further develop an analogous comparison for stochastic optimization by introducing adaptive gradient variance, which parallels adaptive smoothness and leads to dimension-free convergence guarantees that cannot be achieved under standard gradient variance for certain non-Euclidean geometry.","authors":["Shuo Xie","Tianhao Wang","Beining Wu","Zhiyuan Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20577v1","updated":"2025-11-25T18:09:42Z","published":"2025-11-25T18:09:42Z","title":"MSTN: Fast and Efficient Multivariate Time Series Model","summary":"Real-world time-series data is highly non stationary and complex in dynamics that operate across multiple timescales, ranging from fast, short-term changes to slow, long-term trends. Most existing models rely on fixed-scale structural priors, such as patch-based tokenization, fixed frequency transformations, or frozen backbone architectures. This often leads to over-regularization of temporal dynamics, which limits their ability to adaptively model the full spectrum of temporal variations and impairs their performance on unpredictable, Sudden, high-magnitude events. To address this, we introduce the Multi-scale Temporal Network (MSTN), a novel deep learning architecture founded on a hierarchical multi-scale and sequence modeling principle. The MSTN framework integrates: (i) a multi-scale convolutional encoder that constructs a hierarchical feature pyramid for local patterns (ii) a sequence modeling component for long-range temporal dependencies. We empirically validate this with BiLSTM and Transformer variants, establishing a flexible foundation for future architectural advancements. and (iii) a gated fusion mechanism augmented with squeeze-and-excitation (SE) and multi-head temporal attention (MHTA) for dynamic, context-aware feature integration. This design enables MSTN to adaptively model temporal patterns from milliseconds to long-range dependencies within a unified framework. Extensive evaluations across time-series long-horizon forecasting, imputation, classification and generalizability study demonstrate that MSTN achieves competitive state-of-the-art (SOTA) performance, showing improvements over contemporary approaches including EMTSF, LLM4TS, HiMTM, TIME-LLM, MTST, SOFTS, iTransformer, TimesNet, and PatchTST. In total, MSTN establishes new SOTA performance on 24 of 32 benchmark datasets, demonstrating its consistent performance across diverse temporal tasks.","authors":["Sumit S Shevtekar","Chandresh K Maurya","Gourab Sil"],"pdf_url":"","comment":"21 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2511.20570v1","updated":"2025-11-25T18:05:05Z","published":"2025-11-25T18:05:05Z","title":"Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics","summary":"Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.","authors":["Tasha Kim","Oiwi Parker Jones"],"pdf_url":"","comment":"Embodied and Safe-Assured Robotic Systems workshop at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20564v1","updated":"2025-11-25T17:59:22Z","published":"2025-11-25T17:59:22Z","title":"E2E-GRec: An End-to-End Joint Training Framework for Graph Neural Networks and Recommender Systems","summary":"Graph Neural Networks (GNNs) have emerged as powerful tools for modeling graph-structured data and have been widely used in recommender systems, such as for capturing complex user-item and item-item relations. However, most industrial deployments adopt a two-stage pipeline: GNNs are first pre-trained offline to generate node embeddings, which are then used as static features for downstream recommender systems. This decoupled paradigm leads to two key limitations: (1) high computational overhead, since large-scale GNN inference must be repeatedly executed to refresh embeddings; and (2) lack of joint optimization, as the gradient from the recommender system cannot directly influence the GNN learning process, causing the GNN to be suboptimally informative for the recommendation task. In this paper, we propose E2E-GRec, a novel end-to-end training framework that unifies GNN training with the recommender system. Our framework is characterized by three key components: (i) efficient subgraph sampling from a large-scale cross-domain heterogeneous graph to ensure training scalability and efficiency; (ii) a Graph Feature Auto-Encoder (GFAE) serving as an auxiliary self-supervised task to guide the GNN to learn structurally meaningful embeddings; and (iii) a two-level feature fusion mechanism combined with Gradnorm-based dynamic loss balancing, which stabilizes graph-aware multi-task end-to-end training. Extensive offline evaluations, online A/B tests (e.g., a +0.133% relative improvement in stay duration, a 0.3171% reduction in the average number of videos a user skips) on large-scale production data, together with theoretical analysis, demonstrate that E2E-GRec consistently surpasses traditional approaches, yielding significant gains across multiple recommendation metrics.","authors":["Rui Xue","Shichao Zhu","Liang Qin","Guangmou Pan","Yang Song","Tianfu Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20558v1","updated":"2025-11-25T17:56:43Z","published":"2025-11-25T17:56:43Z","title":"Spatio-Temporal Hierarchical Causal Models","summary":"The abundance of fine-grained spatio-temporal data, such as traffic sensor networks, offers vast opportunities for scientific discovery. However, inferring causal relationships from such observational data remains challenging, particularly due to unobserved confounders that are specific to units (e.g., geographical locations) yet influence outcomes over time. Most existing methods for spatio-temporal causal inference assume that all confounders are observed, an assumption that is often violated in practice. In this paper, we introduce Spatio-Temporal Hierarchical Causal Models (ST-HCMs), a novel graphical framework that extends hierarchical causal modeling to the spatio-temporal domain. At the core of our approach is the Spatio-Temporal Collapse Theorem, which shows that a complex ST-HCM converges to a simpler flat causal model as the amount of subunit data increases. This theoretical result enables a general procedure for causal identification, allowing ST-HCMs to recover causal effects even in the presence of unobserved, time-invariant unit-level confounders, a scenario where standard non-hierarchical models fail. We validate the effectiveness of our framework on both synthetic and real-world datasets, demonstrating its potential for robust causal inference in complex dynamic systems.","authors":["Xintong Li","Haoran Zhang","Xiao Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.17177v3","updated":"2025-11-25T17:49:27Z","published":"2025-09-21T17:53:30Z","title":"FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions","summary":"We conduct a moderate-scale contamination-free (to some extent) evaluation of current large reasoning models (LRMs) with some preliminary findings. We also release ROME, our evaluation benchmark for vision language models intended to test reasoning from visual clues. We attach links to the benchmark, evaluation data, and other updates on this website: https://flageval-baai.github.io/LRM-Eval/","authors":["Bowen Qin","Chen Yue","Fang Yin","Hui Wang","JG Yao","Jiakang Liu","Jing-Shu Zheng","Miguel Hu Chen","Richeng Xuan","Shibei Meng","Shiqi Zhou","Teng Dai","Tong-Shuai Ren","Wei Cui","Xi Yang","Xialin Du","Xiaojing Xu","Xue Sun","Xuejing Li","Yaming Liu","Yesheng Liu","Ying Liu","Yonghua Lin","Yu Zhao","Yunduo Zhang","Yuwen Luo","Zheqi He","Zhiyuan He","Zhongyuan Wang"],"pdf_url":"","comment":"Project homepage: https://flageval-baai.github.io/LRM-Eval/ This work will also be presented at NeurIPS 2025 Workshop on Foundations of Reasoning in Language Models (FoRLM); update with trials on Gemini 3 Pro"},{"id":"http://arxiv.org/abs/2511.20544v1","updated":"2025-11-25T17:44:50Z","published":"2025-11-25T17:44:50Z","title":"New York Smells: A Large Multimodal Dataset for Olfaction","summary":"While olfaction is central to how animals perceive the world, this rich chemical sensory modality remains largely inaccessible to machines. One key bottleneck is the lack of diverse, multimodal olfactory training data collected in natural settings. We present New York Smells, a large dataset of paired image and olfactory signals captured ``in the wild.'' Our dataset contains 7,000 smell-image pairs from 3,500 distinct objects across indoor and outdoor environments, with approximately 70$\\times$ more objects than existing olfactory datasets. Our benchmark has three tasks: cross-modal smell-to-image retrieval, recognizing scenes, objects, and materials from smell alone, and fine-grained discrimination between grass species. Through experiments on our dataset, we find that visual data enables cross-modal olfactory representation learning, and that our learned olfactory representations outperform widely-used hand-crafted features.","authors":["Ege Ozguroglu","Junbang Liang","Ruoshi Liu","Mia Chiquier","Michael DeTienne","Wesley Wei Qian","Alexandra Horowitz","Andrew Owens","Carl Vondrick"],"pdf_url":"","comment":"Project website at https://smell.cs.columbia.edu"},{"id":"http://arxiv.org/abs/2511.20543v1","updated":"2025-11-25T17:44:28Z","published":"2025-11-25T17:44:28Z","title":"Feature-Modulated UFNO for Improved Prediction of Multiphase Flow in Porous Media","summary":"The UNet-enhanced Fourier Neural Operator (UFNO) extends the Fourier Neural Operator (FNO) by incorporating a parallel UNet pathway, enabling the retention of both high- and low-frequency components. While UFNO improves predictive accuracy over FNO, it inefficiently treats scalar inputs (e.g., temperature, injection rate) as spatially distributed fields by duplicating their values across the domain. This forces the model to process redundant constant signals within the frequency domain. Additionally, its standard loss function does not account for spatial variations in error sensitivity, limiting performance in regions of high physical importance. We introduce UFNO-FiLM, an enhanced architecture that incorporates two key innovations. First, we decouple scalar inputs from spatial features using a Feature-wise Linear Modulation (FiLM) layer, allowing the model to modulate spatial feature maps without introducing constant signals into the Fourier transform. Second, we employ a spatially weighted loss function that prioritizes learning in critical regions. Our experiments on subsurface multiphase flow demonstrate a 21\\% reduction in gas saturation Mean Absolute Error (MAE) compared to UFNO, highlighting the effectiveness of our approach in improving predictive accuracy.","authors":["Alhasan Abdellatif","Hannah P. Menke","Ahmed H. Elsheikh","Florian Doster","Kamaljit Singh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20541v1","updated":"2025-11-25T17:42:11Z","published":"2025-11-25T17:42:11Z","title":"Automated Monitoring of Cultural Heritage Artifacts Using Semantic Segmentation","summary":"This paper addresses the critical need for automated crack detection in the preservation of cultural heritage through semantic segmentation. We present a comparative study of U-Net architectures, using various convolutional neural network (CNN) encoders, for pixel-level crack identification on statues and monuments. A comparative quantitative evaluation is performed on the test set of the OmniCrack30k dataset [1] using popular segmentation metrics including Mean Intersection over Union (mIoU), Dice coefficient, and Jaccard index. This is complemented by an out-of-distribution qualitative evaluation on an unlabeled test set of real-world cracked statues and monuments. Our findings provide valuable insights into the capabilities of different CNN- based encoders for fine-grained crack segmentation. We show that the models exhibit promising generalization capabilities to unseen cultural heritage contexts, despite never having been explicitly trained on images of statues or monuments.","authors":["Andrea Ranieri","Giorgio Palmieri","Silvia Biasotti"],"pdf_url":"","comment":"Keywords: Cultural Heritage, Monitoring, Deep Learning, U-Nets, Semantic Segmentation"},{"id":"http://arxiv.org/abs/2510.03809v2","updated":"2025-11-25T17:40:32Z","published":"2025-10-04T13:33:48Z","title":"Spectral Thresholds for Identifiability and Stability:Finite-Sample Phase Transitions in High-Dimensional Learning","summary":"In high-dimensional learning, models remain stable until they collapse abruptly once the sample size falls below a critical level. This instability is not algorithm-specific but a geometric mechanism: when the weakest Fisher eigendirection falls beneath sample-level fluctuations, identifiability fails. Our Fisher Threshold Theorem formalizes this by proving that stability requires the minimal Fisher eigenvalue to exceed an explicit $O(\\sqrt{d/n})$ bound. Unlike prior asymptotic or model-specific criteria, this threshold is finite-sample and necessary, marking a sharp phase transition between reliable concentration and inevitable failure. To make the principle constructive, we introduce the Fisher floor, a verifiable spectral regularization robust to smoothing and preconditioning. Synthetic experiments on Gaussian mixtures and logistic models confirm the predicted transition, consistent with $d/n$ scaling. Statistically, the threshold sharpens classical eigenvalue conditions into a non-asymptotic law; learning-theoretically, it defines a spectral sample-complexity frontier, bridging theory with diagnostics for robust high-dimensional inference.","authors":["William Hao-Cheng Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20531v1","updated":"2025-11-25T17:34:32Z","published":"2025-11-25T17:34:32Z","title":"Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models","summary":"Visual Language Models (VLMs) are powerful generative tools but often produce factually in- accurate outputs due to a lack of robust reason- ing capabilities. While extensive research has been conducted on integrating external knowl- edge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seam- lessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leverag- ing structured knowledge graphs for multi-hop verification using image-captioning task to il- lustrate our framework. Our approach enables systematic reasoning across multiple steps, in- cluding visual entity recognition, knowledge graph traversal, and fact-based caption refine- ment. We evaluate the framework using hi- erarchical, triple-based and bullet-point based knowledge representations, analyzing their ef- fectiveness in factual accuracy and logical infer- ence. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions re- vealing key insights into reasoning patterns and failure modes. This work demonstrates the po- tential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.","authors":["Shamima Hossain"],"pdf_url":"","comment":"Accepted as poster at NewInML Workshop ICML, 2025"},{"id":"http://arxiv.org/abs/2410.13148v3","updated":"2025-11-25T17:31:36Z","published":"2024-10-17T02:07:54Z","title":"Learning Efficient Representations of Neutrino Telescope Events","summary":"Neutrino telescopes detect rare interactions of particles produced in some of the most extreme environments in the Universe. This is accomplished by instrumenting a cubic-kilometer scale volume of naturally occurring transparent medium with light sensors. Given their substantial size and the high frequency of background interactions, these telescopes amass an enormous quantity of large variance, high-dimensional data. These attributes create substantial challenges for analyzing and reconstructing interactions, particularly when utilizing machine learning (ML) techniques. In this paper, we present a novel approach, called om2vec, that employs transformer-based variational autoencoders to efficiently represent the detected photon arrival time distributions of neutrino telescope events by learning compact and descriptive latent representations. We demonstrate that these latent representations offer enhanced flexibility and improved computational efficiency, thereby facilitating downstream tasks in data analysis.","authors":["Felix J. Yu","Nicholas Kamp","Carlos A. Argüelles"],"pdf_url":"","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2310.15074v4","updated":"2025-11-25T17:28:34Z","published":"2023-10-23T16:32:18Z","title":"MGAS: Multi-Granularity Architecture Search for Trade-Off Between Model Effectiveness and Efficiency","summary":"Neural architecture search (NAS) has gained significant traction in automating the design of neural networks. To reduce search time, differentiable architecture search (DAS) reframes the traditional paradigm of discrete candidate sampling and evaluation into a differentiable optimization over a super-net, followed by discretization. However, most existing DAS methods primarily focus on optimizing the coarse-grained operation-level topology, while neglecting finer-grained structures such as filter-level and weight-level patterns. This limits their ability to balance model performance with model size. Additionally, many methods compromise search quality to save memory during the search process. To tackle these issues, we propose Multi-Granularity Differentiable Architecture Search (MG-DARTS), a unified framework which aims to discover both effective and efficient architectures from scratch by comprehensively yet memory-efficiently exploring a multi-granularity search space. Specifically, we improve the existing DAS methods in two aspects. First, we adaptively adjust the retention ratios of searchable units across different granularity levels through adaptive pruning, which is achieved by learning granularity-specific discretization functions along with the evolving architecture. Second, we decompose the super-net optimization and discretization into multiple stages, each operating on a sub-net, and introduce progressive re-evaluation to enable re-pruning and regrowth of previous units, thereby mitigating potential bias. Extensive experiments on CIFAR-10, CIFAR-100 and ImageNet demonstrate that MG-DARTS outperforms other state-of-the-art methods in achieving a better trade-off between model accuracy and parameter efficiency. Codes are available at https://github.com/lxy12357/MG_DARTS.","authors":["Xiaoyun Liu","Divya Saxena","Jiannong Cao","Yuqing Zhao","Penghui Ruan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.14421v2","updated":"2025-11-25T17:20:44Z","published":"2025-03-18T16:55:07Z","title":"ExDDV: A New Dataset for Explainable Deepfake Detection in Video","summary":"The ever growing realism and quality of generated videos makes it increasingly harder for humans to spot deepfake content, who need to rely more and more on automatic deepfake detectors. However, deepfake detectors are also prone to errors, and their decisions are not explainable, leaving humans vulnerable to deepfake-based fraud and misinformation. To this end, we introduce ExDDV, the first dataset and benchmark for Explainable Deepfake Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that are manually annotated with text descriptions (to explain the artifacts) and clicks (to point out the artifacts). We evaluate a number of vision-language models on ExDDV, performing experiments with various fine-tuning and in-context learning strategies. Our results show that text and click supervision are both required to develop robust explainable models for deepfake videos, which are able to localize and describe the observed artifacts. Our novel dataset and code to reproduce the results are available at https://github.com/vladhondru25/ExDDV.","authors":["Vlad Hondru","Eduard Hogea","Darian Onchis","Radu Tudor Ionescu"],"pdf_url":"","comment":"Accepted at WACV 2026"},{"id":"http://arxiv.org/abs/2511.20516v1","updated":"2025-11-25T17:20:40Z","published":"2025-11-25T17:20:40Z","title":"Adam Simplified: Bias Correction Simplified","summary":"The Adam optimizer is a cornerstone of modern deep learning, yet the empirical necessity of each of its individual components is often taken for granted. This paper presents a focused investigation into the role of bias-correction, a feature whose contribution remains poorly understood. Through a series of systematic ablations on vision and language modelling tasks, we demonstrate that the conventional wisdom surrounding bias correction is misleading. In particular, we demonstrate that in the optimal hyper-parameter configuration, the inclusion of bias correction leads to no improvement in final test performance. Moreover, unless appropriate learning rate scheduling is implemented, the inclusion of bias correction can sometimes be detrimental to performance. We further reinterpret bias correction as a form of implicit learning rate scheduling whose behaviour is strongly dependent on the choice of smoothing hyper-parameters $β_1, β_2 \\in [0,1)$. Our findings challenge the universal inclusion of this component.","authors":["Sam Laing","Antonio Orvieto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20509v1","updated":"2025-11-25T17:17:48Z","published":"2025-11-25T17:17:48Z","title":"DP-MicroAdam: Private and Frugal Algorithm for Training and Fine-tuning","summary":"Adaptive optimizers are the de facto standard in non-private training as they often enable faster convergence and improved performance. In contrast, differentially private (DP) training is still predominantly performed with DP-SGD, typically requiring extensive compute and hyperparameter tuning. We propose DP-MicroAdam, a memory-efficient and sparsity-aware adaptive DP optimizer. We prove that DP-MicroAdam converges in stochastic non-convex optimization at the optimal $\\mathcal{O}(1/\\sqrt{T})$ rate, up to privacy-dependent constants. Empirically, DP-MicroAdam outperforms existing adaptive DP optimizers and achieves competitive or superior accuracy compared to DP-SGD across a range of benchmarks, including CIFAR-10, large-scale ImageNet training, and private fine-tuning of pretrained transformers. These results demonstrate that adaptive optimization can improve both performance and stability under differential privacy.","authors":["Mihaela Hudişteanu","Edwige Cyffers","Nikita P. Kalinin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20503v1","updated":"2025-11-25T17:12:42Z","published":"2025-11-25T17:12:42Z","title":"Generative Modeling with Manifold Percolation","summary":"Generative modeling is typically framed as learning mapping rules, but from an observer's perspective without access to these rules, the task manifests as disentangling the geometric support from the probability distribution. We propose that Continuum Percolation is uniquely suited for this support analysis, as the sampling process effectively projects high-dimensional density estimation onto a geometric counting problem on the support. In this work, we establish a rigorous isomorphism between the topological phase transitions of Random Geometric Graphs and the underlying data manifold in high-dimensional space. By analyzing the relationship between our proposed Percolation Shift metric and FID, we demonstrate that our metric captures structural pathologies (such as implicit mode collapse) where statistical metrics fail. Finally, we translate this topological phenomenon into a differentiable loss function to guide training. Experimental results confirm that this approach not only prevents manifold shrinkage but drives the model toward a state of \"Hyper-Generalization,\" achieving good fidelity and verified topological expansion.","authors":["Rui Tong"],"pdf_url":"","comment":"13 pages, 7 figures. Correspondence: Rui.Tong@warwick.ac.uk"},{"id":"http://arxiv.org/abs/2301.12250v3","updated":"2025-11-25T17:10:32Z","published":"2023-01-28T16:57:46Z","title":"Fast, Sample-Efficient, Affine-Invariant Private Mean and Covariance Estimation for Subgaussian Distributions","summary":"We present a fast, differentially private algorithm for high-dimensional covariance-aware mean estimation with nearly optimal sample complexity. Only exponential-time estimators were previously known to achieve this guarantee. Given $n$ samples from a (sub-)Gaussian distribution with unknown mean $μ$ and covariance $Σ$, our $(\\varepsilon,δ)$-differentially private estimator produces $\\tildeμ$ such that $\\|μ- \\tildeμ\\|_Σ \\leq α$ as long as $n \\gtrsim \\tfrac d {α^2} + \\tfrac{d \\sqrt{\\log 1/δ}}{α\\varepsilon}+\\frac{d\\log 1/δ}{\\varepsilon}$. The Mahalanobis error metric $\\|μ- \\hatμ\\|_Σ$ measures the distance between $\\hat μ$ and $μ$ relative to $Σ$; it characterizes the error of the sample mean. Our algorithm runs in time $\\tilde{O}(nd^{ω- 1} + nd/\\varepsilon)$, where $ω< 2.38$ is the matrix multiplication exponent.\n  We adapt an exponential-time approach of Brown, Gaboardi, Smith, Ullman, and Zakynthinou (2021), giving efficient variants of stable mean and covariance estimation subroutines that also improve the sample complexity to the nearly optimal bound above.\n  Our stable covariance estimator can be turned to private covariance estimation for unrestricted subgaussian distributions. With $n\\gtrsim d^{3/2}$ samples, our estimate is accurate in spectral norm. This is the first such algorithm using $n= o(d^2)$ samples, answering an open question posed by Alabi et al. (2022). With $n\\gtrsim d^2$ samples, our estimate is accurate in Frobenius norm. This leads to a fast, nearly optimal algorithm for private learning of unrestricted Gaussian distributions in TV distance.\n  Duchi, Haque, and Kuditipudi (2023) obtained similar results independently and concurrently.","authors":["Gavin Brown","Samuel B. Hopkins","Adam Smith"],"pdf_url":"","comment":"45 pages. Appeared at COLT 2023. New version fixes typos, improves some proofs and constants, and links to github"},{"id":"http://arxiv.org/abs/2511.20501v1","updated":"2025-11-25T17:08:14Z","published":"2025-11-25T17:08:14Z","title":"A Physics-Informed Loss Function for Boundary-Consistent and Robust Artery Segmentation in DSA Sequences","summary":"Accurate extraction and segmentation of the cerebral arteries from digital subtraction angiography (DSA) sequences is essential for developing reliable clinical management models of complex cerebrovascular diseases. Conventional loss functions often rely solely on pixel-wise overlap, overlooking the geometric and physical consistency of vascular boundaries, which can lead to fragmented or unstable vessel predictions. To overcome this limitation, we propose a novel \\textit{Physics-Informed Loss} (PIL) that models the interaction between the predicted and ground-truth boundaries as an elastic process inspired by dislocation theory in materials physics. This formulation introduces a physics-based regularization term that enforces smooth contour evolution and structural consistency, allowing the network to better capture fine vascular geometry. The proposed loss is integrated into several segmentation architectures, including U-Net, U-Net++, SegFormer, and MedFormer, and evaluated on two public benchmarks: DIAS and DSCA. Experimental results demonstrate that PIL consistently outperforms conventional loss functions such as Cross-Entropy, Dice, Active Contour, and Surface losses, achieving superior sensitivity, F1 score, and boundary coherence. These findings confirm that the incorporation of physics-based boundary interactions into deep neural networks improves both the precision and robustness of vascular segmentation in dynamic angiographic imaging. The implementation of the proposed method is publicly available at https://github.com/irfantahir301/Physicsis_loss.","authors":["Muhammad Irfan","Nasir Rahim","Khalid Mahmood Malik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20500v1","updated":"2025-11-25T17:07:41Z","published":"2025-11-25T17:07:41Z","title":"From One Attack Domain to Another: Contrastive Transfer Learning with Siamese Networks for APT Detection","summary":"Advanced Persistent Threats (APT) pose a major cybersecurity challenge due to their stealth, persistence, and adaptability. Traditional machine learning detectors struggle with class imbalance, high dimensional features, and scarce real world traces. They often lack transferability-performing well in the training domain but degrading in novel attack scenarios. We propose a hybrid transfer framework that integrates Transfer Learning, Explainable AI (XAI), contrastive learning, and Siamese networks to improve cross-domain generalization. An attention-based autoencoder supports knowledge transfer across domains, while Shapley Additive exPlanations (SHAP) select stable, informative features to reduce dimensionality and computational cost. A Siamese encoder trained with a contrastive objective aligns source and target representations, increasing anomaly separability and mitigating feature drift. We evaluate on real-world traces from the DARPA Transparent Computing (TC) program and augment with synthetic attack scenarios to test robustness. Across source to target transfers, the approach delivers improved detection scores with classical and deep baselines, demonstrating a scalable, explainable, and transferable solution for APT detection.","authors":["Sidahmed Benabderrahmane","Talal Rahwan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20490v1","updated":"2025-11-25T16:56:25Z","published":"2025-11-25T16:56:25Z","title":"MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology","summary":"Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.","authors":["Kiril Vasilev","Alexandre Misrahi","Eeshaan Jain","Phil F Cheng","Petros Liakopoulos","Olivier Michielin","Michael Moor","Charlotte Bunne"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20489v1","updated":"2025-11-25T16:55:43Z","published":"2025-11-25T16:55:43Z","title":"InferF: Declarative Factorization of AI/ML Inferences over Joins","summary":"Real-world AI/ML workflows often apply inference computations to feature vectors joined from multiple datasets. To avoid the redundant AI/ML computations caused by repeated data records in the join's output, factorized ML has been proposed to decompose ML computations into sub-computations to be executed on each normalized dataset. However, there is insufficient discussion on how factorized ML could impact AI/ML inference over multi-way joins. To address the limitations, we propose a novel declarative InferF system, focusing on the factorization of arbitrary inference workflows represented as analyzable expressions over the multi-way joins. We formalize our problem to flexibly push down partial factorized computations to qualified nodes in the join tree to minimize the overall inference computation and join costs and propose two algorithms to resolve the problem: (1) a greedy algorithm based on a per-node cost function that estimates the influence on overall latency if a subset of factorized computations is pushed to a node, and (2) a genetic algorithm for iteratively enumerating and evaluating promising factorization plans. We implement InferF on Velox, an open-sourced database engine from Meta, evaluate it on real-world datasets, observed up to 11.3x speedups, and systematically summarized the factors that determine when factorized ML can benefit AI/ML inference workflows.","authors":["Kanchan Chowdhury","Lixi Zhou","Lulu Xie","Xinwei Fu","Jia Zou"],"pdf_url":"","comment":"Accepted to SIGMOD 2026 as full research paper. This archived version has a full appendix"},{"id":"http://arxiv.org/abs/2510.21945v3","updated":"2025-11-25T16:44:25Z","published":"2025-10-24T18:19:32Z","title":"Generalization Bounds for Rank-sparse Neural Networks","summary":"It has been recently observed in much of the literature that neural networks exhibit a bottleneck rank property: for larger depths, the activation and weights of neural networks trained with gradient-based methods tend to be of approximately low rank. In fact, the rank of the activations of each layer converges to a fixed value referred to as the ``bottleneck rank'', which is the minimum rank required to represent the training data. This perspective is in line with the observation that regularizing linear networks (without activations) with weight decay is equivalent to minimizing the Schatten $p$ quasi norm of the neural network. In this paper we investigate the implications of this phenomenon for generalization. More specifically, we prove generalization bounds for neural networks which exploit the approximate low rank structure of the weight matrices if present. The final results rely on the Schatten $p$ quasi norms of the weight matrices: for small $p$, the bounds exhibit a sample complexity $ \\widetilde{O}(WrL^2)$ where $W$ and $L$ are the width and depth of the neural network respectively and where $r$ is the rank of the weight matrices. As $p$ increases, the bound behaves more like a norm-based bound instead.","authors":["Antoine Ledent","Rodrigo Alves","Yunwen Lei"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20480v1","updated":"2025-11-25T16:42:12Z","published":"2025-11-25T16:42:12Z","title":"Ranking-Enhanced Anomaly Detection Using Active Learning-Assisted Attention Adversarial Dual AutoEncoders","summary":"Advanced Persistent Threats (APTs) pose a significant challenge in cybersecurity due to their stealthy and long-term nature. Modern supervised learning methods require extensive labeled data, which is often scarce in real-world cybersecurity environments. In this paper, we propose an innovative approach that leverages AutoEncoders for unsupervised anomaly detection, augmented by active learning to iteratively improve the detection of APT anomalies. By selectively querying an oracle for labels on uncertain or ambiguous samples, we minimize labeling costs while improving detection rates, enabling the model to improve its detection accuracy with minimal data while reducing the need for extensive manual labeling. We provide a detailed formulation of the proposed Attention Adversarial Dual AutoEncoder-based anomaly detection framework and show how the active learning loop iteratively enhances the model. The framework is evaluated on real-world imbalanced provenance trace databases produced by the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004\\% of the data. The datasets span multiple operating systems, including Android, Linux, BSD, and Windows, and cover two attack scenarios. The results have shown significant improvements in detection rates during active learning and better performance compared to other existing approaches.","authors":["Sidahmed Benabderrahmane","James Cheney","Talal Rahwan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20478v1","updated":"2025-11-25T16:41:25Z","published":"2025-11-25T16:41:25Z","title":"NVIDIA Nemotron Parse 1.1","summary":"We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0. Nemotron-Parse-1.1 delivers improved capabilities across general OCR, markdown formatting, structured table parsing, and text extraction from pictures, charts, and diagrams. It also supports a longer output sequence length for visually dense documents. As with its predecessor, it extracts bounding boxes of text segments, as well as corresponding semantic classes. Nemotron-Parse-1.1 follows an encoder-decoder architecture with 885M parameters, including a compact 256M-parameter language decoder. It achieves competitive accuracy on public benchmarks making it a strong lightweight OCR solution. We release the model weights publicly on Huggingface, as well as an optimized NIM container, along with a subset of the training data as part of the broader Nemotron-VLM-v2 dataset. Additionally, we release Nemotron-Parse-1.1-TC which operates on a reduced vision token length, offering a 20% speed improvement with minimal quality degradation.","authors":["Kateryna Chumachenko","Amala Sanjay Deshmukh","Jarno Seppanen","Ilia Karmanov","Chia-Chih Chen","Lukas Voegtle","Philipp Fischer","Marek Wawrzos","Saeid Motiian","Roman Ageev","Kedi Wu","Alexandre Milesi","Maryam Moosaei","Krzysztof Pawelec","Padmavathy Subramanian","Mehrzad Samadi","Xin Yu","Celina Dear","Sarah Stoddard","Jenna Diamond","Jesse Oliver","Leanna Chraghchian","Patrick Skelly","Tom Balough","Yao Xu","Jane Polak Scowcroft","Daniel Korzekwa","Darragh Hanley","Sandip Bhaskar","Timo Roman","Karan Sapra","Andrew Tao","Bryan Catanzaro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20474v1","updated":"2025-11-25T16:35:42Z","published":"2025-11-25T16:35:42Z","title":"Modular Deep Learning Framework for Assistive Perception: Gaze, Affect, and Speaker Identification","summary":"Developing comprehensive assistive technologies requires the seamless integration of visual and auditory perception. This research evaluates the feasibility of a modular architecture inspired by core functionalities of perceptive systems like 'Smart Eye.' We propose and benchmark three independent sensing modules: a Convolutional Neural Network (CNN) for eye state detection (drowsiness/attention), a deep CNN for facial expression recognition, and a Long Short-Term Memory (LSTM) network for voice-based speaker identification. Utilizing the Eyes Image, FER2013, and customized audio datasets, our models achieved accuracies of 93.0%, 97.8%, and 96.89%, respectively. This study demonstrates that lightweight, domain-specific models can achieve high fidelity on discrete tasks, establishing a validated foundation for future real-time, multimodal integration in resource-constrained assistive devices.","authors":["Akshit Pramod Anchan","Jewelith Thomas","Sritama Roy"],"pdf_url":"","comment":"10 pages, 9 figures, and 3 tables"},{"id":"http://arxiv.org/abs/2412.15947v4","updated":"2025-11-25T16:34:49Z","published":"2024-12-20T14:43:02Z","title":"Mamba-based Deep Learning Approach for Sleep Staging on a Wireless Multimodal Wearable System without Electroencephalography","summary":"Study Objectives: We investigate a Mamba-based deep learning approach for sleep staging on signals from ANNE One (Sibel Health, Evanston, IL), a non-intrusive dual-module wireless wearable system measuring chest electrocardiography (ECG), triaxial accelerometry, and chest temperature, and finger photoplethysmography and finger temperature.\n  Methods: We obtained wearable sensor recordings from 357 adults undergoing concurrent polysomnography (PSG) at a tertiary care sleep lab. Each PSG recording was manually scored and these annotations served as ground truth labels for training and evaluation of our models. PSG and wearable sensor data were automatically aligned using their ECG channels with manual confirmation by visual inspection. We trained a Mamba-based recurrent neural network architecture on these recordings. Ensembling of model variants with similar architectures was performed.\n  Results: After ensembling, the model attains a 3-class (wake, non rapid eye movement [NREM] sleep, rapid eye movement [REM] sleep) balanced accuracy of 84.02%, F1 score of 84.23%, Cohen's $κ$ of 72.89%, and a Matthews correlation coefficient (MCC) score of 73.00%; a 4-class (wake, light NREM [N1/N2], deep NREM [N3], REM) balanced accuracy of 75.30%, F1 score of 74.10%, Cohen's $κ$ of 61.51%, and MCC score of 61.95%; a 5-class (wake, N1, N2, N3, REM) balanced accuracy of 65.11%, F1 score of 66.15%, Cohen's $κ$ of 53.23%, MCC score of 54.38%.\n  Conclusions: Our Mamba-based deep learning model can successfully infer major sleep stages from the ANNE One, a wearable system without electroencephalography (EEG), and can be applied to data from adults attending a tertiary care sleep clinic.","authors":["Andrew H. Zhang","Alex He-Mo","Richard Fei Yin","Chunlin Li","Yuzhi Tang","Dharmendra Gurve","Veronique van der Horst","Aron S. Buchman","Nasim Montazeri Ghahjaverestan","Maged Goubran","Bo Wang","Andrew S. P. Lim"],"pdf_url":"","comment":"40 pages, 24 figures. Authors Andrew H. Zhang, Alex He-Mo, and Richard Fei Yin contributed equally"},{"id":"http://arxiv.org/abs/2511.20469v1","updated":"2025-11-25T16:33:45Z","published":"2025-11-25T16:33:45Z","title":"Dance Style Classification using Laban-Inspired and Frequency-Domain Motion Features","summary":"Dance is an essential component of human culture and serves as a tool for conveying emotions and telling stories. Identifying and distinguishing dance genres based on motion data is a complex problem in human activity recognition, as many styles share similar poses, gestures, and temporal motion patterns. This work presents a lightweight framework for classifying dance styles that determines motion characteristics based on pose estimates extracted from videos. We propose temporal-spatial descriptors inspired by Laban Movement Analysis. These features capture local joint dynamics such as velocity, acceleration, and angular movement of the upper body, enabling a structured representation of spatial coordination. To further encode rhythmic and periodic aspects of movement, we integrate Fast Fourier Transform features that characterize movement patterns in the frequency domain. The proposed approach achieves robust classification of different dance styles with low computational effort, as complex model architectures are not required, and shows that interpretable motion representations can effectively capture stylistic nuances.","authors":["Ben Hamscher","Arnold Brosch","Nicolas Binninger","Maksymilian Jan Dejna","Kira Maag"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20462v1","updated":"2025-11-25T16:27:58Z","published":"2025-11-25T16:27:58Z","title":"STARFlow-V: End-to-End Video Generative Modeling with Normalizing Flow","summary":"Normalizing flows (NFs) are end-to-end likelihood-based generative models for continuous data, and have recently regained attention with encouraging progress on image generation. Yet in the video generation domain, where spatiotemporal complexity and computational cost are substantially higher, state-of-the-art systems almost exclusively rely on diffusion-based models. In this work, we revisit this design space by presenting STARFlow-V, a normalizing flow-based video generator with substantial benefits such as end-to-end learning, robust causal prediction, and native likelihood estimation. Building upon the recently proposed STARFlow, STARFlow-V operates in the spatiotemporal latent space with a global-local architecture which restricts causal dependencies to a global latent space while preserving rich local within-frame interactions. This eases error accumulation over time, a common pitfall of standard autoregressive diffusion model generation. Additionally, we propose flow-score matching, which equips the model with a light-weight causal denoiser to improve the video generation consistency in an autoregressive fashion. To improve the sampling efficiency, STARFlow-V employs a video-aware Jacobi iteration scheme that recasts inner updates as parallelizable iterations without breaking causality. Thanks to the invertible structure, the same model can natively support text-to-video, image-to-video as well as video-to-video generation tasks. Empirically, STARFlow-V achieves strong visual fidelity and temporal consistency with practical sampling throughput relative to diffusion-based baselines. These results present the first evidence, to our knowledge, that NFs are capable of high-quality autoregressive video generation, establishing them as a promising research direction for building world models. Code and generated samples are available at https://github.com/apple/ml-starflow.","authors":["Jiatao Gu","Ying Shen","Tianrong Chen","Laurent Dinh","Yuyang Wang","Miguel Angel Bautista","David Berthelot","Josh Susskind","Shuangfei Zhai"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2511.20457v1","updated":"2025-11-25T16:24:52Z","published":"2025-11-25T16:24:52Z","title":"A Fully Probabilistic Tensor Network for Regularized Volterra System Identification","summary":"Modeling nonlinear systems with Volterra series is challenging because the number of kernel coefficients grows exponentially with the model order. This work introduces Bayesian Tensor Network Volterra kernel machines (BTN-V), extending the Bayesian Tensor Network framework to Volterra system identification. BTN-V represents Volterra kernels using canonical polyadic decomposition, reducing model complexity from O(I^D) to O(DIR). By treating all tensor components and hyperparameters as random variables, BTN-V provides predictive uncertainty estimation at no additional computational cost. Sparsity-inducing hierarchical priors enable automatic rank determination and the learning of fading-memory behavior directly from data, improving interpretability and preventing overfitting. Empirical results demonstrate competitive accuracy, enhanced uncertainty quantification, and reduced computational cost.","authors":["Afra Kilic","Kim Batselier"],"pdf_url":"","comment":"6 pages, 3 figures, 1 table. Submitted to IFAC 2026. Code available at: https://github.com/afrakilic/BTN_Volterra_Sys_ID"},{"id":"http://arxiv.org/abs/2511.20456v1","updated":"2025-11-25T16:24:29Z","published":"2025-11-25T16:24:29Z","title":"Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks","summary":"Machine learning has become integral to Channel State Information (CSI)-based human sensing systems and is expected to power applications such as device-free activity recognition and identity detection in future cellular and Wi-Fi generations. However, these systems rely on models whose decisions can be subtly perturbed, raising concerns for security and reliability in ubiquitous sensing. Quantifying and understanding the robustness of such models, defined as their ability to maintain accurate predictions under adversarial perturbations, is therefore critical before wireless sensing can be safely deployed in real-world environments.\n  This work presents a systematic evaluation of the robustness of CSI deep learning models under diverse threat models (white-box, black-box/transfer, and universal perturbations) and varying degrees of attack realism. We establish a framework to compare compact temporal autoencoder models with larger deep architectures across three public datasets, quantifying how model scale, training regime, and physical constraints influence robustness. Our experiments show that smaller models, while efficient and equally performant on clean data, are markedly less robust. We further confirm that physically realizable signal-space perturbations, designed to be feasible in real wireless channels, significantly reduce attack success compared to unconstrained feature-space attacks. Adversarial training mitigates these vulnerabilities, improving mean robust accuracy with only moderate degradation in clean performance across both model classes. As wireless sensing advances towards reliable, cross-domain operation, these findings provide quantitative baselines for robustness estimation and inform design principles for secure and trustworthy human-centered sensing systems.","authors":["Shreevanth Krishnaa Gopalakrishnan","Stephen Hailes"],"pdf_url":"","comment":"19 pages, 8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2511.20445v1","updated":"2025-11-25T16:17:12Z","published":"2025-11-25T16:17:12Z","title":"Diffusion for Fusion: Designing Stellarators with Generative AI","summary":"Stellarators are a prospective class of fusion-based power plants that confine a hot plasma with three-dimensional magnetic fields. Typically framed as a PDE-constrained optimization problem, stellarator design is a time-consuming process that can take hours to solve on a computing cluster. Developing fast methods for designing stellarators is crucial for advancing fusion research. Given the recent development of large datasets of optimized stellarators, machine learning approaches have emerged as a potential candidate. Motivated by this, we present an open inverse problem to the machine learning community: to rapidly generate high-quality stellarator designs which have a set of desirable characteristics. As a case study in the problem space, we train a conditional diffusion model on data from the QUASR database to generate quasisymmetric stellarator designs with desirable characteristics (aspect ratio and mean rotational transform). The diffusion model is applied to design stellarators with characteristics not seen during training. We provide evaluation protocols and show that many of the generated stellarators exhibit solid performance: less than 5% deviation from quasisymmetry and the target characteristics. The modest deviation from quasisymmetry highlights an opportunity to reach the sub 1% target. Beyond the case study, we share multiple promising avenues for generative modeling to advance stellarator design.","authors":["Misha Padidar","Teresa Huang","Andrew Giuliani","Marina Spivak"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.08015v2","updated":"2025-11-25T15:51:29Z","published":"2025-09-08T23:08:23Z","title":"CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models","summary":"Generative models of 3D cardiovascular anatomy can synthesize informative structures for clinical research and medical device evaluation, but face a trade-off between geometric controllability and realism. We propose CardioComposer: a programmable, inference-time framework for generating multi-class anatomical label maps based on interpretable ellipsoidal primitives. These primitives represent geometric attributes such as the size, shape, and position of discrete substructures. We specifically develop differentiable measurement functions based on voxel-wise geometric moments, enabling loss-based gradient guidance during diffusion model sampling. We demonstrate that these losses can constrain individual geometric attributes in a disentangled manner and provide compositional control over multiple substructures. Finally, we show that our method is compatible with a wide array of anatomical systems containing non-convex substructures, spanning cardiac, vascular, and skeletal organs.","authors":["Karim Kadry","Shoaib Goraya","Ajay Manicka","Abdalla Abdelwahed","Naravich Chutisilp","Farhad Nezami","Elazer Edelman"],"pdf_url":"","comment":"10 pages, 16 figures"},{"id":"http://arxiv.org/abs/2501.17690v4","updated":"2025-11-25T15:50:33Z","published":"2025-01-29T14:58:48Z","title":"Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment","summary":"We introduce a novel segmentation-aware joint training framework called generative reinforcement network (GRN) that integrates segmentation loss feedback to optimize both image generation and segmentation performance in a single stage. An image enhancement technique called segmentation-guided enhancement (SGE) is also developed, where the generator produces images tailored specifically for the segmentation model. Two variants of GRN were also developed, including GRN for sample-efficient learning (GRN-SEL) and GRN for semi-supervised learning (GRN-SSL). GRN's performance was evaluated using a dataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The annotations included six anatomical structures: dermis, superficial fat, superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and muscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up to 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient (DSC) compared to models trained on fully labeled datasets. GRN-SEL alone reduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling requirements by 70%, and GRN-SSL alone by 60%, all while maintaining performance comparable to fully supervised models. These findings suggest the effectiveness of the GRN framework in optimizing segmentation performance with significantly less labeled data, offering a scalable and efficient solution for ultrasound image analysis and reducing the burdens associated with data annotation.","authors":["Zixue Zeng","Xiaoyan Zhao","Matthew Cartier","Tong Yu","Jing Wang","Xin Meng","Zhiyu Sheng","Maryam Satarpour","John M Cormack","Allison Bean","Ryan Nussbaum","Maya Maurer","Emily Landis-Walkenhorst","Dinesh Kumbhare","Kang Kim","Ajay Wasan","Jiantao Pu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20418v1","updated":"2025-11-25T15:42:33Z","published":"2025-11-25T15:42:33Z","title":"StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections","summary":"Multi-object tracking (MOT) is one of the most challenging tasks in computer vision, where it is important to correctly detect objects and associate these detections across frames. Current approaches mainly focus on tracking objects in each frame of a video stream, making it almost impossible to run the model under conditions of limited computing resources. To address this issue, we propose StableTrack, a novel approach that stabilizes the quality of tracking on low-frequency detections. Our method introduces a new two-stage matching strategy to improve the cross-frame association between low-frequency detections. We propose a novel Bbox-Based Distance instead of the conventional Mahalanobis distance, which allows us to effectively match objects using the Re-ID model. Furthermore, we integrate visual tracking into the Kalman Filter and the overall tracking pipeline. Our method outperforms current state-of-the-art trackers in the case of low-frequency detections, achieving $\\textit{11.6%}$ HOTA improvement at $\\textit{1}$ Hz on MOT17-val, while keeping up with the best approaches on the standard MOT17, MOT20, and DanceTrack benchmarks with full-frequency detections.","authors":["Matvei Shelukhan","Timur Mamedov","Karina Kvanchiani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20407v1","updated":"2025-11-25T15:34:59Z","published":"2025-11-25T15:34:59Z","title":"Tight Margin-Based Generalization Bounds for Voting Classifiers over Finite Hypothesis Sets","summary":"We prove the first margin-based generalization bound for voting classifiers, that is asymptotically tight in the tradeoff between the size of the hypothesis set, the margin, the fraction of training points with the given margin, the number of training samples and the failure probability.","authors":["Kasper Green Larsen","Natascha Schalburg"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20406v1","updated":"2025-11-25T15:34:46Z","published":"2025-11-25T15:34:46Z","title":"Short-Range Oversquashing","summary":"Message Passing Neural Networks (MPNNs) are widely used for learning on graphs, but their ability to process long-range information is limited by the phenomenon of oversquashing. This limitation has led some researchers to advocate Graph Transformers as a better alternative, whereas others suggest that it can be mitigated within the MPNN framework, using virtual nodes or other rewiring techniques.\n  In this work, we demonstrate that oversquashing is not limited to long-range tasks, but can also arise in short-range problems. This observation allows us to disentangle two distinct mechanisms underlying oversquashing: (1) the bottleneck phenomenon, which can arise even in low-range settings, and (2) the vanishing gradient phenomenon, which is closely associated with long-range tasks.\n  We further show that the short-range bottleneck effect is not captured by existing explanations for oversquashing, and that adding virtual nodes does not resolve it. In contrast, transformers do succeed in such tasks, positioning them as the more compelling solution to oversquashing, compared to specialized MPNNs.","authors":["Yaaqov Mishayev","Yonatan Sverdlov","Tal Amir","Nadav Dym"],"pdf_url":"","comment":"Accepted to Learning on Graphs (LoG) 2025. Version identical to the camera-ready paper"},{"id":"http://arxiv.org/abs/2505.12366v4","updated":"2025-11-25T15:34:10Z","published":"2025-05-18T11:08:32Z","title":"DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization","summary":"The recent success and openness of DeepSeek-R1 have brought widespread attention to Group Relative Policy Optimization (GRPO) as a reinforcement learning method for large reasoning models (LRMs). In this work, we analyze the GRPO objective under a binary reward setting and reveal an inherent limitation of question-level difficulty bias. We also identify a connection between GRPO and traditional discriminative methods in supervised learning. Motivated by these insights, we introduce a new Discriminative Constrained Optimization (DisCO) framework for reinforcing LRMs, grounded in the principle of discriminative learning. The main differences between DisCO and GRPO and its recent variants are: (1) it replaces the group relative objective with a discriminative objective defined by a scoring function; (2) it abandons clipping-based surrogates in favor of non-clipping RL surrogate objectives used as scoring functions; (3) it employs a simple yet effective constrained optimization approach to enforce the KL divergence constraint. As a result, DisCO offers notable advantages over GRPO and its variants: (i) it completely eliminates difficulty bias by adopting discriminative objectives; (ii) it addresses the entropy instability in GRPO and its variants through the use of non-clipping scoring functions and a constrained optimization approach, yielding long and stable training dynamics; (iii) it allows the incorporation of advanced discriminative learning techniques to address data imbalance, where a significant number of questions have more negative than positive generated answers during training. Our experiments on enhancing the mathematical reasoning capabilities of SFT-finetuned models show that DisCO significantly outperforms GRPO and its improved variants such as DAPO, achieving average gains of 7\\% over GRPO and 6\\% over DAPO across six benchmark tasks for an 1.5B model.","authors":["Gang Li","Ming Lin","Tomer Galanti","Zhengzhong Tu","Tianbao Yang"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2509.26536v2","updated":"2025-11-25T15:21:05Z","published":"2025-09-30T17:09:32Z","title":"OceanGym: A Benchmark Environment for Underwater Embodied Agents","summary":"We introduce OceanGym, the first comprehensive benchmark for ocean underwater embodied agents, designed to advance AI in one of the most demanding real-world environments. Unlike terrestrial or aerial domains, underwater settings present extreme perceptual and decision-making challenges, including low visibility, dynamic ocean currents, making effective agent deployment exceptionally difficult. OceanGym encompasses eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), which integrates perception, memory, and sequential decision-making. Agents are required to comprehend optical and sonar data, autonomously explore complex environments, and accomplish long-horizon objectives under these harsh conditions. Extensive experiments reveal substantial gaps between state-of-the-art MLLM-driven agents and human experts, highlighting the persistent difficulty of perception, planning, and adaptability in ocean underwater environments. By providing a high-fidelity, rigorously designed platform, OceanGym establishes a testbed for developing robust embodied AI and transferring these capabilities to real-world autonomous ocean underwater vehicles, marking a decisive step toward intelligent agents capable of operating in one of Earth's last unexplored frontiers. The code and data are available at https://github.com/OceanGPT/OceanGym.","authors":["Yida Xue","Mingjun Mao","Xiangyuan Ru","Yuqi Zhu","Baochang Ren","Shuofei Qiao","Mengru Wang","Shumin Deng","Xinyu An","Ningyu Zhang","Ying Chen","Huajun Chen"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2511.20397v1","updated":"2025-11-25T15:21:00Z","published":"2025-11-25T15:21:00Z","title":"Model-Based Learning of Whittle indices","summary":"We present BLINQ, a new model-based algorithm that learns the Whittle indices of an indexable, communicating and unichain Markov Decision Process (MDP). Our approach relies on building an empirical estimate of the MDP and then computing its Whittle indices using an extended version of a state-of-the-art existing algorithm. We provide a proof of convergence to the Whittle indices we want to learn as well as a bound on the time needed to learn them with arbitrary precision. Moreover, we investigate its computational complexity. Our numerical experiments suggest that BLINQ significantly outperforms existing Q-learning approaches in terms of the number of samples needed to get an accurate approximation. In addition, it has a total computational cost even lower than Q-learning for any reasonably high number of samples. These observations persist even when the Q-learning algorithms are speeded up using pre-trained neural networks to predict Q-values.","authors":["Joël Charles-Rebuffé","Nicolas Gast","Bruno Gaujal"],"pdf_url":"","comment":"31 pages, 8 figures, submitted to TOMPECS"},{"id":"http://arxiv.org/abs/2511.20395v1","updated":"2025-11-25T15:19:57Z","published":"2025-11-25T15:19:57Z","title":"Identifying environmental factors associated with tetrodotoxin contamination in bivalve mollusks using eXplainable AI","summary":"Since 2012, tetrodotoxin (TTX) has been found in seafoods such as bivalve mollusks in temperate European waters. TTX contamination leads to food safety risks and economic losses, making early prediction of TTX contamination vital to the food industry and competent authorities. Recent studies have pointed to shallow habitats and water temperature as main drivers to TTX contamination in bivalve mollusks. However, the temporal relationships between abiotic factors, biotic factors, and TTX contamination remain unexplored.\n  We have developed an explainable, deep learning-based model to predict TTX contamination in the Dutch Zeeland estuary. Inputs for the model were meteorological and hydrological features; output was the presence or absence of TTX contamination.\n  Results showed that the time of sunrise, time of sunset, global radiation, water temperature, and chloride concentration contributed most to TTX contamination. Thus, the effective number of sun hours, represented by day length and global radiation, was an important driver for tetrodotoxin contamination in bivalve mollusks.\n  To conclude, our explainable deep learning model identified the aforementioned environmental factors (number of sun hours, global radiation, water temperature, and water chloride concentration) to be associated with tetrodotoxin contamination in bivalve mollusks; making our approach a valuable tool to mitigate marine toxin risks for food industry and competent authorities.","authors":["M. C. Schoppema","B. H. M. van der Velden","A. Hürriyetoğlu","M. D. Klijnstra","E. J. Faassen","A. Gerssen","H. J. van der Fels-Klerx"],"pdf_url":"","comment":"18 pages, 6 figures, submitted to Nature Food"},{"id":"http://arxiv.org/abs/2510.18866v2","updated":"2025-11-25T15:07:32Z","published":"2025-10-21T17:58:17Z","title":"LightMem: Lightweight and Efficient Memory-Augmented Generation","summary":"Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at https://github.com/zjunlp/LightMem.","authors":["Jizhan Fang","Xinle Deng","Haoming Xu","Ziyan Jiang","Yuqi Tang","Ziwen Xu","Shumin Deng","Yunzhi Yao","Mengru Wang","Shuofei Qiao","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2511.20382v1","updated":"2025-11-25T15:04:06Z","published":"2025-11-25T15:04:06Z","title":"MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained Transformers","summary":"Representation learning on multi-omics data is challenging due to extreme dimensionality, modality heterogeneity, and cohort-specific batch effects. While pre-trained transformer backbones have shown broad generalization capabilities in biological sequence modeling, their application to multi-omics integration remains underexplored. We present MoRE (Multi-Omics Representation Embedding), a framework that repurposes frozen pre-trained transformers to align heterogeneous assays into a shared latent space. Unlike purely generative approaches, MoRE employs a parameter-efficient fine-tuning (PEFT) strategy, prioritizing cross-sample and cross-modality alignment over simple sequence reconstruction. Specifically, MoRE attaches lightweight, modality-specific adapters and a task-adaptive fusion layer to the frozen backbone. It optimizes a masked modeling objective jointly with supervised contrastive and batch-invariant alignment losses, yielding structure-preserving embeddings that generalize across unseen cell types and platforms. We benchmark MoRE against established baselines, including scGPT, scVI, and Harmony with scArches, evaluating integration fidelity, rare population detection, and modality transfer. Our results demonstrate that MoRE achieves competitive batch robustness and biological conservation while significantly reducing trainable parameters compared to fully fine-tuned models. This work positions MoRE as a practical step toward general-purpose omics foundation models.","authors":["Audrey Pei-Hsuan Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20380v1","updated":"2025-11-25T15:01:55Z","published":"2025-11-25T15:01:55Z","title":"Differentiable Attenuation Filters for Feedback Delay Networks","summary":"We introduce a novel method for designing attenuation filters in digital audio reverberation systems based on Feedback Delay Net- works (FDNs). Our approach uses Second Order Sections (SOS) of Infinite Impulse Response (IIR) filters arranged as parametric equalizers (PEQ), enabling fine control over frequency-dependent reverberation decay. Unlike traditional graphic equalizer designs, which require numerous filters per delay line, we propose a scal- able solution where the number of filters can be adjusted. The fre- quency, gain, and quality factor (Q) parameters are shared parame- ters across delay lines and only the gain is adjusted based on delay length. This design not only reduces the number of optimization parameters, but also remains fully differentiable and compatible with gradient-based learning frameworks. Leveraging principles of analog filter design, our method allows for efficient and accu- rate filter fitting using supervised learning. Our method delivers a flexible and differentiable design, achieving state-of-the-art per- formance while significantly reducing computational cost.","authors":["Ilias Ibnyahya","Joshua D. Reiss"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06836v2","updated":"2025-11-25T14:56:02Z","published":"2025-06-07T15:27:30Z","title":"Harnessing Vision-Language Models for Time Series Anomaly Detection","summary":"Time-series anomaly detection (TSAD) has played a vital role in a variety of fields, including healthcare, finance, and sensor-based condition monitoring. Prior methods, which mainly focus on training domain-specific models on numerical data, lack the visual-temporal understanding capacity that human experts have to identify contextual anomalies. To fill this gap, we explore a solution based on vision language models (VLMs). Recent studies have shown the ability of VLMs for visual understanding tasks, yet their direct application to time series has fallen short on both accuracy and efficiency. To harness the power of VLMs for TSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening stage built on a relatively lightweight pre-trained vision encoder, which leverages 2D time series representations to accurately localize candidate anomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal context and VLM's visual understanding capacity to refine the detection upon the candidates provided by ViT4TS. We show that without any time-series training, VLM4TS outperforms time-series pre-trained and from-scratch baselines in most cases, yielding a 24.6% improvement in F1-max score over the best baseline. Moreover, VLM4TS also consistently outperforms existing language model-based TSAD methods and is on average 36x more efficient in token usage.","authors":["Zelin He","Sarah Alnegheimish","Matthew Reimherr"],"pdf_url":"","comment":"Accepted at AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2505.11355v2","updated":"2025-11-25T14:50:10Z","published":"2025-05-16T15:18:15Z","title":"Sparse Techniques for Regression in Deep Gaussian Processes","summary":"Gaussian processes (GPs) have gained popularity as flexible machine learning models for regression and function approximation with an in-built method for uncertainty quantification. However, GPs suffer when the amount of training data is large or when the underlying function contains multi-scale features that are difficult to represent by a stationary kernel. To address the former, training of GPs with large-scale data is often performed through inducing point approximations, also known as sparse GP regression (GPR), where the size of the covariance matrices in GPR is reduced considerably through a greedy search on the data set. To aid the latter, deep GPs have gained traction as hierarchical models that resolve multi-scale features by combining multiple GPs. Posterior inference in deep GPs requires a sampling or, more usual, a variational approximation. Variational approximations lead to large-scale stochastic, non-convex optimisation problems and the resulting approximation tends to represent uncertainty incorrectly. In this work, we combine variational learning with MCMC to develop a particle-based expectation-maximisation method to simultaneously find inducing points within the large-scale data (variationally) and accurately train the deep GPs (sampling-based). The result is a highly efficient and accurate methodology for deep GP training on large-scale data. We test our method on standard benchmark problems.","authors":["Jonas Latz","Aretha L. Teckentrup","Simon Urbainczyk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20362v1","updated":"2025-11-25T14:43:14Z","published":"2025-11-25T14:43:14Z","title":"PRISM: Periodic Representation with multIscale and Similarity graph Modelling for enhanced crystal structure property prediction","summary":"Crystal structures are characterised by repeating atomic patterns within unit cells across three-dimensional space, posing unique challenges for graph-based representation learning. Current methods often overlook essential periodic boundary conditions and multiscale interactions inherent to crystalline structures. In this paper, we introduce PRISM, a graph neural network framework that explicitly integrates multiscale representations and periodic feature encoding by employing a set of expert modules, each specialised in encoding distinct structural and chemical aspects of periodic systems. Extensive experiments across crystal structure-based benchmarks demonstrate that PRISM improves state-of-the-art predictive accuracy, significantly enhancing crystal property prediction.","authors":["Àlex Solé","Albert Mosella-Montoro","Joan Cardona","Daniel Aravena","Silvia Gómez-Coca","Eliseo Ruiz","Javier Ruiz-Hidalgo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20361v1","updated":"2025-11-25T14:43:13Z","published":"2025-11-25T14:43:13Z","title":"Extension and neural operator approximation of the electrical impedance tomography inverse map","summary":"This paper considers the problem of noise-robust neural operator approximation for the solution map of Calderón's inverse conductivity problem. In this continuum model of electrical impedance tomography (EIT), the boundary measurements are realized as a noisy perturbation of the Neumann-to-Dirichlet map's integral kernel. The theoretical analysis proceeds by extending the domain of the inversion operator to a Hilbert space of kernel functions. The resulting extension shares the same stability properties as the original inverse map from kernels to conductivities, but is now amenable to neural operator approximation. Numerical experiments demonstrate that Fourier neural operators excel at reconstructing infinite-dimensional piecewise constant and lognormal conductivities in noisy setups both within and beyond the theory's assumptions. The methodology developed in this paper for EIT exemplifies a broader strategy for addressing nonlinear inverse problems with a noise-aware operator learning framework.","authors":["Maarten V. de Hoop","Nikola B. Kovachki","Matti Lassas","Nicholas H. Nelsen"],"pdf_url":"","comment":"80 pages (49 main text, 20 appendix, and 11 references pages), 14 figures, 2 tables"},{"id":"http://arxiv.org/abs/2509.10390v4","updated":"2025-11-25T14:26:56Z","published":"2025-09-12T16:31:16Z","title":"Vendi Information Gain for Active Learning and its Application to Ecology","summary":"While monitoring biodiversity through camera traps has become an important endeavor for ecological research, identifying species in the captured image data remains a major bottleneck due to limited labeling resources. Active learning -- a machine learning paradigm that selects the most informative data to label and train a predictive model -- offers a promising solution, but typically focuses on uncertainty in the individual predictions without considering uncertainty across the entire dataset. We introduce a new active learning policy, Vendi information gain (VIG), that selects images based on their impact on dataset-wide prediction uncertainty, capturing both informativeness and diversity. We applied VIG to the Snapshot Serengeti dataset and compared it against common active learning methods. VIG needs only 3% of the available data to reach 75% accuracy, a level that baselines require more than 10% of the data to achieve. With 10% of the data, VIG attains 88% predictive accuracy, 12% higher than the best of the baselines. This improvement in performance is consistent across metrics and batch sizes, and we show that VIG also collects more diverse data in the feature space. VIG has broad applicability beyond ecology, and our results highlight its value for biodiversity monitoring in data-limited environments.","authors":["Quan Nguyen","Adji Bousso Dieng"],"pdf_url":"","comment":"Accepted at the AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE) 2026"},{"id":"http://arxiv.org/abs/2511.20349v1","updated":"2025-11-25T14:25:57Z","published":"2025-11-25T14:25:57Z","title":"Complexity Reduction Study Based on RD Costs Approximation for VVC Intra Partitioning","summary":"In this paper, a complexity study is conducted for Versatile Video Codec (VVC) intra partitioning to accelerate the exhaustive search involved in Rate-Distortion Optimization (RDO) process. To address this problem, two main machine learning techniques are proposed and compared. Unlike existing methods, the proposed approaches are size independent and incorporate the Rate-Distortion (RD) costs of neighboring blocks as input features. The first method is a regression based technique that predicts normalized RD costs of a given Coding Unit (CU). As partitioning possesses the Markov property, the associated decision-making problem can be modeled as a Markov Decision Process (MDP) and solved by Reinforcement Learning (RL). The second approach is a RL agent learned from trajectories of CU decision across two depths with Deep Q-Network (DQN) algorithm. Then a pre-determined thresholds are applied for both methods to select a suitable split for the current CU.","authors":["M. E. A. Kherchouche","F. Galpin","T. Dumas","F. Schnitzler","D. Menard","L. Zhang"],"pdf_url":"","comment":"2025 Data Compression Conference (DCC)"},{"id":"http://arxiv.org/abs/2511.20347v1","updated":"2025-11-25T14:25:19Z","published":"2025-11-25T14:25:19Z","title":"Soft Adaptive Policy Optimization","summary":"Reinforcement learning (RL) plays an increasingly important role in enhancing the reasoning capabilities of large language models (LLMs), yet stable and performant policy optimization remains challenging. Token-level importance ratios often exhibit high variance-a phenomenon exacerbated in Mixture-of-Experts models-leading to unstable updates. Existing group-based policy optimization methods, such as GSPO and GRPO, alleviate this problem via hard clipping, making it difficult to maintain both stability and effective learning. We propose Soft Adaptive Policy Optimization (SAPO), which replaces hard clipping with a smooth, temperature-controlled gate that adaptively attenuates off-policy updates while preserving useful learning signals. Compared with GSPO and GRPO, SAPO is both sequence-coherent and token-adaptive. Like GSPO, SAPO maintains sequence-level coherence, but its soft gating forms a continuous trust region that avoids the brittle hard clipping band used in GSPO. When a sequence contains a few highly off-policy tokens, GSPO suppresses all gradients for that sequence, whereas SAPO selectively down-weights only the offending tokens and preserves the learning signal from the near-on-policy ones, improving sample efficiency. Relative to GRPO, SAPO replaces hard token-level clipping with smooth, temperature-controlled scaling, enabling more informative and stable updates. Empirical results on mathematical reasoning benchmarks indicate that SAPO exhibits improved training stability and higher Pass@1 performance under comparable training budgets. Moreover, we employ SAPO to train the Qwen3-VL model series, demonstrating that SAPO yields consistent performance gains across diverse tasks and different model sizes. Overall, SAPO provides a more reliable, scalable, and effective optimization strategy for RL training of LLMs.","authors":["Chang Gao","Chujie Zheng","Xiong-Hui Chen","Kai Dang","Shixuan Liu","Bowen Yu","An Yang","Shuai Bai","Jingren Zhou","Junyang Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.15236v3","updated":"2025-11-25T14:24:38Z","published":"2024-10-20T00:00:56Z","title":"Jailbreaking and Mitigation of Vulnerabilities in Large Language Models","summary":"Large Language Models (LLMs) have transformed artificial intelligence by advancing natural language understanding and generation, enabling applications across fields beyond healthcare, software engineering, and conversational systems. Despite these advancements in the past few years, LLMs have shown considerable vulnerabilities, particularly to prompt injection and jailbreaking attacks. This review analyzes the state of research on these vulnerabilities and presents available defense strategies. We roughly categorize attack approaches into prompt-based, model-based, multimodal, and multilingual, covering techniques such as adversarial prompting, backdoor injections, and cross-modality exploits. We also review various defense mechanisms, including prompt filtering, transformation, alignment techniques, multi-agent defenses, and self-regulation, evaluating their strengths and shortcomings. We also discuss key metrics and benchmarks used to assess LLM safety and robustness, noting challenges like the quantification of attack success in interactive contexts and biases in existing datasets. Identifying current research gaps, we suggest future directions for resilient alignment strategies, advanced defenses against evolving attacks, automation of jailbreak detection, and consideration of ethical and societal impacts. This review emphasizes the need for continued research and cooperation within the AI community to enhance LLM security and ensure their safe deployment.","authors":["Benji Peng","Keyu Chen","Qian Niu","Ziqian Bi","Ming Liu","Pohsun Feng","Tianyang Wang","Lawrence K. Q. Yan","Yizhu Wen","Yichao Zhang","Caitlyn Heqi Yin","Xinyuan Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20333v1","updated":"2025-11-25T14:10:44Z","published":"2025-11-25T14:10:44Z","title":"NNGPT: Rethinking AutoML with Large Language Models","summary":"Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.","authors":["Roman Kochnev","Waleed Khalid","Tolgay Atinc Uzun","Xi Zhang","Yashkumar Sanjaybhai Dhameliya","Furui Qin","Chandini Vysyaraju","Raghuvir Duvvuri","Avi Goyal","Dmitry Ignatov","Radu Timofte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20327v1","updated":"2025-11-25T13:58:53Z","published":"2025-11-25T13:58:53Z","title":"MXtalTools: A Toolkit for Machine Learning on Molecular Crystals","summary":"We present MXtalTools, a flexible Python package for the data-driven modelling of molecular crystals, facilitating machine learning studies of the molecular solid state. MXtalTools comprises several classes of utilities: (1) synthesis, collation, and curation of molecule and crystal datasets, (2) integrated workflows for model training and inference, (3) crystal parameterization and representation, (4) crystal structure sampling and optimization, (5) end-to-end differentiable crystal sampling, construction and analysis. Our modular functions can be integrated into existing workflows or combined and used to build novel modelling pipelines. MXtalTools leverages CUDA acceleration to enable high-throughput crystal modelling. The Python code is available open-source on our GitHub page, with detailed documentation on ReadTheDocs.","authors":["Michael Kilgour","Mark E. Tuckerman","Jutta Rogal"],"pdf_url":"","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2508.21380v2","updated":"2025-11-25T13:55:48Z","published":"2025-08-29T07:51:45Z","title":"Iterative Inference in a Chess-Playing Neural Network","summary":"Do neural networks build their representations through smooth, gradual refinement, or via more complex computational processes? We investigate this by extending the logit lens to analyze the policy network of Leela Chess Zero, a superhuman chess engine. Although playing strength and puzzle-solving ability improve consistently across layers, capability progression occurs in distinct computational phases with move preferences undergoing continuous reevaluation--move rankings remain poorly correlated with final outputs until late, and correct puzzle solutions found in middle layers are sometimes overridden. This late-layer reversal is accompanied by concept preference analyses showing final layers prioritize safety over aggression, suggesting a mechanism by which heuristic priors can override tactical solutions.","authors":["Elias Sandmann","Sebastian Lapuschkin","Wojciech Samek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20315v1","updated":"2025-11-25T13:52:46Z","published":"2025-11-25T13:52:46Z","title":"Geometry of Decision Making in Language Models","summary":"Large Language Models (LLMs) show strong generalization across diverse tasks, yet the internal decision-making processes behind their predictions remain opaque. In this work, we study the geometry of hidden representations in LLMs through the lens of \\textit{intrinsic dimension} (ID), focusing specifically on decision-making dynamics in a multiple-choice question answering (MCQA) setting. We perform a large-scale study, with 28 open-weight transformer models and estimate ID across layers using multiple estimators, while also quantifying per-layer performance on MCQA tasks. Our findings reveal a consistent ID pattern across models: early layers operate on low-dimensional manifolds, middle layers expand this space, and later layers compress it again, converging to decision-relevant representations. Together, these results suggest LLMs implicitly learn to project linguistic inputs onto structured, low-dimensional manifolds aligned with task-specific decisions, providing new geometric insights into how generalization and reasoning emerge in language models.","authors":["Abhinav Joshi","Divyanshu Bhatt","Ashutosh Modi"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2403.15511v2","updated":"2025-11-25T13:27:15Z","published":"2024-03-22T03:54:04Z","title":"Multiple-Input Auto-Encoder Guided Feature Selection for IoT Intrusion Detection Systems","summary":"While intrusion detection systems (IDSs) benefit from the diversity and generalization of IoT data features, the data diversity (e.g., the heterogeneity and high dimensions of data) also makes it difficult to train effective machine learning models in IoT IDSs. This also leads to potentially redundant/noisy features that may decrease the accuracy of the detection engine in IDSs. This paper first introduces a novel neural network architecture called Multiple-Input Auto-Encoder (MIAE). MIAE consists of multiple sub-encoders that can process inputs from different sources with different characteristics. The MIAE model is trained in an unsupervised learning mode to transform the heterogeneous inputs into lower-dimensional representation, which helps classifiers distinguish between normal behaviour and different types of attacks. To distil and retain more relevant features but remove less important/redundant ones during the training process, we further design and embed a feature selection layer right after the representation layer of MIAE resulting in a new model called MIAEFS. This layer learns the importance of features in the representation vector, facilitating the selection of informative features from the representation vector. The results on three IDS datasets, i.e., NSLKDD, UNSW-NB15, and IDS2017, show the superior performance of MIAE and MIAEFS compared to other methods, e.g., conventional classifiers, dimensionality reduction models, unsupervised representation learning methods with different input dimensions, and unsupervised feature selection models. Moreover, MIAE and MIAEFS combined with the Random Forest (RF) classifier achieve accuracy of 96.5% in detecting sophisticated attacks, e.g., Slowloris. The average running time for detecting an attack sample using RF with the representation of MIAE and MIAEFS is approximate 1.7E-6 seconds, whilst the model size is lower than 1 MB.","authors":["Phai Vu Dinh","Diep N. Nguyen","Dinh Thai Hoang","Quang Uy Nguyen","Eryk Dutkiewicz","Son Pham Bao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20293v1","updated":"2025-11-25T13:25:59Z","published":"2025-11-25T13:25:59Z","title":"Forgetting by Pruning: Data Deletion in Join Cardinality Estimation","summary":"Machine unlearning in learned cardinality estimation (CE) systems presents unique challenges due to the complex distributional dependencies in multi-table relational data. Specifically, data deletion, a core component of machine unlearning, faces three critical challenges in learned CE models: attribute-level sensitivity, inter-table propagation and domain disappearance leading to severe overestimation in multi-way joins. We propose Cardinality Estimation Pruning (CEP), the first unlearning framework specifically designed for multi-table learned CE systems. CEP introduces Distribution Sensitivity Pruning, which constructs semi-join deletion results and computes sensitivity scores to guide parameter pruning, and Domain Pruning, which removes support for value domains entirely eliminated by deletion. We evaluate CEP on state-of-the-art architectures NeuroCard and FACE across IMDB and TPC-H datasets. Results demonstrate CEP consistently achieves the lowest Q-error in multi-table scenarios, particularly under high deletion ratios, often outperforming full retraining. Furthermore, CEP significantly reduces convergence iterations, incurring negligible computational overhead of 0.3%-2.5% of fine-tuning time.","authors":["Chaowei He","Yuanjun Liu","Qingzhi Ma","Shenyuan Ren","Xizhao Luo","Lei Zhao","An Liu"],"pdf_url":"","comment":"AAAI26"},{"id":"http://arxiv.org/abs/2508.12145v4","updated":"2025-11-25T13:11:12Z","published":"2025-08-16T19:41:57Z","title":"DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy","summary":"Recently, autoencoders (AEs) have gained interest for creating parametric and invertible projections of multidimensional data. Parametric projections make it possible to embed new, unseen samples without recalculating the entire projection, while invertible projections allow the synthesis of new data instances. However, existing methods perform poorly when dealing with out-of-distribution samples in either the data or embedding space. Thus, we propose DE-VAE, an uncertainty-aware variational AE using differential entropy (DE) to improve the learned parametric and invertible projections. Given a fixed projection, we train DE-VAE to learn a mapping into 2D space and an inverse mapping back to the original space. We conduct quantitative and qualitative evaluations on four well-known datasets, using UMAP and t-SNE as baseline projection methods. Our findings show that DE-VAE can create parametric and inverse projections with comparable accuracy to other current AE-based approaches while enabling the analysis of embedding uncertainty.","authors":["Frederik L. Dennig","Daniel A. Keim"],"pdf_url":"","comment":"5 pages, 3 figures, LaTeX; fixed typos; added DOI"},{"id":"http://arxiv.org/abs/2511.20283v1","updated":"2025-11-25T13:11:03Z","published":"2025-11-25T13:11:03Z","title":"Solving Heterogeneous Agent Models with Physics-informed Neural Networks","summary":"Understanding household behaviour is essential for modelling macroeconomic dynamics and designing effective policy. While heterogeneous agent models offer a more realistic alternative to representative agent frameworks, their implementation poses significant computational challenges, particularly in continuous time. The Aiyagari-Bewley-Huggett (ABH) framework, recast as a system of partial differential equations, typically relies on grid-based solvers that suffer from the curse of dimensionality, high computational cost, and numerical inaccuracies. This paper introduces the ABH-PINN solver, an approach based on Physics-Informed Neural Networks (PINNs), which embeds the Hamilton-Jacobi-Bellman and Kolmogorov Forward equations directly into the neural network training objective. By replacing grid-based approximation with mesh-free, differentiable function learning, the ABH-PINN solver benefits from the advantages of PINNs of improved scalability, smoother solutions, and computational efficiency. Preliminary results show that the PINN-based approach is able to obtain economically valid results matching the established finite-difference solvers.","authors":["Marta Grzeskiewicz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.16786v2","updated":"2025-11-25T13:07:39Z","published":"2025-10-19T10:32:18Z","title":"More with Less: An Empirical Study of Turn-Control Strategies for Efficient Coding Agents","summary":"LLM-powered coding agents, which operate in iterative loops (turns) to solve software engineering tasks, are becoming increasingly powerful. However, their practical deployment is hindered by significant and unpredictable costs. This challenge arises from a combination of factors: quadratically growing token counts with each turn, the high price of models, the large number of turns required for real-world tasks, and the tendency of agents to take inefficient or unnecessary actions. While existing research focuses on optimizing individual turns, the strategic control of the total number of turns remains an underexplored area for managing agent performance and cost. To address this gap, we conduct a comprehensive empirical study on SWE-bench using three state-of-the-art models and evaluate the impact of three distinct turn-control strategies: an unrestricted baseline, a fixed-turn limit with reminders, and a novel dynamic-turn strategy that grants extensions on-demand. Our findings first reveal a fundamental trade-off in the unrestricted setting, where no single model excels across performance, cost, and turn efficiency. We then show that a fixed-turn limit, specifically at the 75th percentile of the baseline, serves as a \"sweet spot\", substantially reducing costs (by 24%-68%) with minimal impact on solve rates. Most significantly, the dynamic-turn strategy consistently outperforms fixed-limit approaches, achieving comparable or better solve rates while further reducing costs by an additional 12%-24% by intelligently allocating resources only to tasks that need them. This work provides the first systematic analysis of turn-control strategies, offering simple yet effective guidelines for developers to balance cost and efficacy. We demonstrate that dynamic resource allocation is a superior, easy-to-implement approach for deploying powerful yet economically viable coding agents.","authors":["Pengfei Gao","Chao Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20277v1","updated":"2025-11-25T13:05:40Z","published":"2025-11-25T13:05:40Z","title":"HVAdam: A Full-Dimension Adaptive Optimizer","summary":"Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer's ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity\n  , allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad's hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.","authors":["Yiheng Zhang","Shaowu Wu","Yuanzhuo Xu","Jiajun Wu","Shang Xu","Steve Drew","Xiaoguang Niu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20273v1","updated":"2025-11-25T12:59:15Z","published":"2025-11-25T12:59:15Z","title":"Beyond Components: Singular Vector-Based Interpretability of Transformer Circuits","summary":"Transformer-based language models exhibit complex and distributed behavior, yet their internal computations remain poorly understood. Existing mechanistic interpretability methods typically treat attention heads and multilayer perceptron layers (MLPs) (the building blocks of a transformer architecture) as indivisible units, overlooking possibilities of functional substructure learned within them. In this work, we introduce a more fine-grained perspective that decomposes these components into orthogonal singular directions, revealing superposed and independent computations within a single head or MLP. We validate our perspective on widely used standard tasks like Indirect Object Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that previously identified canonical functional heads, such as the name mover, encode multiple overlapping subfunctions aligned with distinct singular directions. Nodes in a computational graph, that are previously identified as circuit elements show strong activation along specific low-rank directions, suggesting that meaningful computations reside in compact subspaces. While some directions remain challenging to interpret fully, our results highlight that transformer computations are more distributed, structured, and compositional than previously assumed. This perspective opens new avenues for fine-grained mechanistic interpretability and a deeper understanding of model internals.","authors":["Areeb Ahmad","Abhinav Joshi","Ashutosh Modi"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2406.12841v4","updated":"2025-11-25T12:43:13Z","published":"2024-06-18T17:57:11Z","title":"Demystifying Higher-Order Graph Neural Networks","summary":"Higher-order graph neural networks (HOGNNs) and the related architectures from Topological Deep Learning are an important class of GNN models that harness polyadic relations between vertices beyond plain edges. They have been used to eliminate issues such as over-smoothing or over-squashing, to significantly enhance the accuracy of GNN predictions, to improve the expressiveness of GNN architectures, and for numerous other goals. A plethora of HOGNN models have been introduced, and they come with diverse neural architectures, and even with different notions of what the \"higher-order\" means. This richness makes it very challenging to appropriately analyze and compare HOGNN models, and to decide in what scenario to use specific ones. To alleviate this, we first design an in-depth taxonomy and a blueprint for HOGNNs. This facilitates designing models that maximize performance. Then, we use our taxonomy to analyze and compare the available HOGNN models. The outcomes of our analysis are synthesized in a set of insights that help to select the most beneficial GNN model in a given scenario, and a comprehensive list of challenges and opportunities for further research into more powerful HOGNNs.","authors":["Maciej Besta","Florian Scheidl","Lukas Gianinazzi","Grzegorz Kwasniewski","Shachar Klaiman","Jürgen Müller","Torsten Hoefler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.13334v5","updated":"2025-11-25T12:39:17Z","published":"2024-10-17T08:46:09Z","title":"BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models","summary":"Although large language models (LLMs) demonstrate impressive proficiency in various tasks, they present potential safety risks, such as `jailbreaks', where malicious inputs can coerce LLMs into generating harmful content bypassing safety alignments. In this paper, we delve into the ethical biases in LLMs and examine how those biases could be exploited for jailbreaks. Notably, these biases result in a jailbreaking success rate in GPT-4o models that differs by 20\\% between non-binary and cisgender keywords and by 16\\% between white and black keywords, even when the other parts of the prompts are identical. We introduce the concept of BiasJailbreak, highlighting the inherent risks posed by these safety-induced biases. BiasJailbreak generates biased keywords automatically by asking the target LLM itself, and utilizes the keywords to generate harmful output. Additionally, we propose an efficient defense method BiasDefense, which prevents jailbreak attempts by injecting defense prompts prior to generation. BiasDefense stands as an appealing alternative to Guard Models, such as Llama-Guard, that require additional inference cost after text generation. Our findings emphasize that ethical biases in LLMs can actually lead to generating unsafe output, and suggest a method to make the LLMs more secure and unbiased. To enable further research and improvements, we open-source our code and artifacts of BiasJailbreak, providing the community with tools to better understand and mitigate safety-induced biases in LLMs.","authors":["Isack Lee","Haebin Seong"],"pdf_url":"","comment":"Accepted as a workshop paper at AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20258v1","updated":"2025-11-25T12:38:28Z","published":"2025-11-25T12:38:28Z","title":"Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization","summary":"Weight Averaging (WA) has emerged as a powerful technique for enhancing generalization by promoting convergence to a flat loss landscape, which correlates with stronger out-of-distribution performance. However, applying WA directly to multi-modal domain generalization (MMDG) is challenging: differences in optimization speed across modalities lead WA to overfit to faster-converging ones in early stages, suppressing the contribution of slower yet complementary modalities, thereby hindering effective modality fusion and skewing the loss surface toward sharper, less generalizable minima. To address this issue, we propose MBCD, a unified collaborative distillation framework that retains WA's flatness-inducing advantages while overcoming its shortcomings in multi-modal contexts. MBCD begins with adaptive modality dropout in the student model to curb early-stage bias toward dominant modalities. A gradient consistency constraint then aligns learning signals between uni-modal branches and the fused representation, encouraging coordinated and smoother optimization. Finally, a WA-based teacher conducts cross-modal distillation by transferring fused knowledge to each uni-modal branch, which strengthens cross-modal interactions and steer convergence toward flatter solutions. Extensive experiments on MMDG benchmarks show that MBCD consistently outperforms existing methods, achieving superior accuracy and robustness across diverse unseen domains.","authors":["Xiaohan Wang","Zhangtao Cheng","Ting Zhong","Leiting Chen","Fan Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20257v1","updated":"2025-11-25T12:36:27Z","published":"2025-11-25T12:36:27Z","title":"Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling","summary":"Accurate and interpretable air pollution forecasting is crucial for public health, but most models face a trade-off between performance and interpretability. This study proposes a physics-guided, interpretable-by-design spatiotemporal learning framework. The model decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules. The first is a physics-guided transport kernel with directed weights conditioned on wind and geography (advection). The second is an explainable attention mechanism that learns local responses and attributes future concentrations to specific historical lags and exogenous drivers. Evaluated on a comprehensive dataset from the Stockholm region, our model consistently outperforms state-of-the-art baselines across multiple forecasting horizons. Our model's integration of high predictive performance and spatiotemporal interpretability provides a more reliable foundation for operational air-quality management in real-world applications.","authors":["Zhiguo Zhang","Xiaoliang Ma","Daniel Schlesinger"],"pdf_url":"","comment":"Accepted to 2025 IEEE International Conference on Big Data"},{"id":"http://arxiv.org/abs/2511.18958v2","updated":"2025-11-25T12:33:40Z","published":"2025-11-24T10:19:58Z","title":"Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation","summary":"As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation. We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both high- and low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.","authors":["Qisen Chai","Yansong Wang","Junjie Huang","Tao Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.15577v2","updated":"2025-11-25T12:28:01Z","published":"2025-08-21T13:51:45Z","title":"LFaB: Low fidelity as Bias for Active Learning in the chemical configuration space","summary":"Active learning promises to provide an optimal training sample selection procedure in the construction of machine learning models. It often relies on minimizing the model's variance, which is assumed to decrease the prediction error. Still, it is frequently even less efficient than pure random sampling. Motivated by the bias-variance decomposition, we propose to minimize the model's bias instead of its variance. By doing so, we are able to almost exactly match the best-case error over all possible greedy sample selection procedures for a relevant application. Our bias approximation is based on using cheap to calculate low fidelity data as known from $Δ$-ML or multifidelity machine learning. We exemplify our approach for a wider class of applications in quantum chemistry including predicting excitation energies and ab initio potential energy surfaces. Here, the proposed method reduces training data consumption by up to an order of magnitude compared to standard active learning.","authors":["Vivin Vinod","Peter Zaspel"],"pdf_url":"","comment":"SI included in main"},{"id":"http://arxiv.org/abs/2511.09118v2","updated":"2025-11-25T12:27:48Z","published":"2025-11-12T08:47:08Z","title":"Learning to Validate Generative Models: a Goodness-of-Fit Approach","summary":"Generative models are increasingly central to scientific workflows, yet their systematic use and interpretation require a proper understanding of their limitations through rigorous validation. Classic approaches struggle with scalability, statistical power, or interpretability when applied to high-dimensional data, making it difficult to certify the reliability of these models in realistic, high-dimensional scientific settings. Here, we propose the use of the New Physics Learning Machine (NPLM), a learning-based approach to goodness-of-fit testing inspired by the Neyman--Pearson construction, to test generative networks trained on high-dimensional scientific data. We demonstrate the performance of NPLM for validation in two benchmark cases: generative models trained on mixtures of Gaussian models with increasing dimensionality, and a public end-to-end model, known as FlowSim, developed to generate high-energy physics collision events. We demonstrate that the NPLM can serve as a powerful validation method while also providing a means to diagnose sub-optimally modeled regions of the data.","authors":["Pietro Cappelli","Gaia Grosso","Marco Letizia","Humberto Reyes-González","Marco Zanetti"],"pdf_url":"","comment":"16 pages, 6 figures. v2: improved clarity"},{"id":"http://arxiv.org/abs/2511.20250v1","updated":"2025-11-25T12:25:20Z","published":"2025-11-25T12:25:20Z","title":"Uplifting Table Tennis: A Robust, Real-World Application for 3D Trajectory and Spin Estimation","summary":"Obtaining the precise 3D motion of a table tennis ball from standard monocular videos is a challenging problem, as existing methods trained on synthetic data struggle to generalize to the noisy, imperfect ball and table detections of the real world. This is primarily due to the inherent lack of 3D ground truth trajectories and spin annotations for real-world video. To overcome this, we propose a novel two-stage pipeline that divides the problem into a front-end perception task and a back-end 2D-to-3D uplifting task. This separation allows us to train the front-end components with abundant 2D supervision from our newly created TTHQ dataset, while the back-end uplifting network is trained exclusively on physically-correct synthetic data. We specifically re-engineer the uplifting model to be robust to common real-world artifacts, such as missing detections and varying frame rates. By integrating a ball detector and a table keypoint detector, our approach transforms a proof-of-concept uplifting method into a practical, robust, and high-performing end-to-end application for 3D table tennis trajectory and spin analysis.","authors":["Daniel Kienzle","Katja Ludwig","Julian Lorenz","Shin'ichi Satoh","Rainer Lienhart"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13053v3","updated":"2025-11-25T12:12:18Z","published":"2025-11-17T06:58:34Z","title":"Self-Organization and Spectral Mechanism of Attractor Landscapes in High-Capacity Kernel Hopfield Networks","summary":"Kernel-based learning methods can dramatically increase the storage capacity of Hopfield networks, yet the dynamical mechanism behind this enhancement remains poorly understood. We address this gap by unifying the geometric analysis of the attractor landscape with the spectral theory of kernel machines. Using a novel metric, \"Pinnacle Sharpness,\" we first uncover a rich phase diagram of attractor stability, identifying a \"Ridge of Optimization\" where the network achieves maximal robustness under high-load conditions. Phenomenologically, this ridge is characterized by a \"Force Antagonism,\" where a strong driving force is balanced by a collective feedback force. Theoretically, we reveal that this phenomenon arises from a specific reorganization of the weight spectrum, which we term \\textit{Spectral Concentration}. Unlike a simple rank-1 collapse, our analysis shows that the network on the ridge self-organizes into a critical state: the leading eigenvalue is amplified to maximize global stability (Direct Force), while the trailing eigenvalues are preserved to maintain high memory capacity (Indirect Force). These findings provide a complete physical picture of how high-capacity associative memories are formed, demonstrating that optimal performance is achieved by tuning the system to a spectral \"Goldilocks zone\" between rank collapse and diffusion.","authors":["Akira Tamamori"],"pdf_url":"","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.20237v1","updated":"2025-11-25T12:11:34Z","published":"2025-11-25T12:11:34Z","title":"Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis","summary":"The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions.","authors":["Zeynab Kaseb","Matthias Moller","Lindsay Spoor","Jerry J. Guo","Yu Xiang","Peter Palensky","Pedro P. Vergara"],"pdf_url":"","comment":"10 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.20236v1","updated":"2025-11-25T12:09:36Z","published":"2025-11-25T12:09:36Z","title":"Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints","summary":"Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.","authors":["Szymon Bobek","Łukasz Bałec","Grzegorz J. Nalepa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20234v1","updated":"2025-11-25T12:07:25Z","published":"2025-11-25T12:07:25Z","title":"Leveraging weights signals - Predicting and improving generalizability in reinforcement learning","summary":"Generalizability of Reinforcement Learning (RL) agents (ability to perform on environments different from the ones they have been trained on) is a key problem as agents have the tendency to overfit to their training environments. In order to address this problem and offer a solution to increase the generalizability of RL agents, we introduce a new methodology to predict the generalizability score of RL agents based on the internal weights of the agent's neural networks. Using this prediction capability, we propose some changes in the Proximal Policy Optimization (PPO) loss function to boost the generalization score of the agents trained with this upgraded version. Experimental results demonstrate that our improved PPO algorithm yields agents with stronger generalizability compared to the original version.","authors":["Olivier Moulin","Vincent Francois-lavet","Paul Elbers","Mark Hoogendoorn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.19329v2","updated":"2025-11-25T11:59:57Z","published":"2024-12-26T18:58:38Z","title":"Deep learning and whole-brain networks for biomarker discovery: modeling the dynamics of brain fluctuations in resting-state and cognitive tasks","summary":"Background: Brain network models offer insights into brain dynamics, but the utility of model-derived bifurcation parameters as biomarkers remains underexplored. Objective: This study evaluates bifurcation parameters from a whole-brain network model as biomarkers for distinguishing brain states associated with resting-state and task-based cognitive conditions. Methods: Synthetic BOLD signals were generated using a supercritical Hopf brain network model to train deep learning models for bifurcation parameter prediction. Inference was performed on Human Connectome Project data, including both resting-state and task-based conditions. Statistical analyses assessed the separability of brain states based on bifurcation parameter distributions. Results: Bifurcation parameter distributions differed significantly across task and resting-state conditions ($p < 0.0001$ for all but one comparison). Task-based brain states exhibited higher bifurcation values compared to rest. Conclusion: Bifurcation parameters effectively differentiate cognitive and resting states, warranting further investigation as biomarkers for brain state characterization and neurological disorder assessment.","authors":["Facundo Roffet","Gustavo Deco","Claudio Delrieux","Gustavo Patow"],"pdf_url":"","comment":"15 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2511.20225v1","updated":"2025-11-25T11:55:02Z","published":"2025-11-25T11:55:02Z","title":"DiCaP: Distribution-Calibrated Pseudo-labeling for Semi-Supervised Multi-Label Learning","summary":"Semi-supervised multi-label learning (SSMLL) aims to address the challenge of limited labeled data in multi-label learning (MLL) by leveraging unlabeled data to improve the model's performance. While pseudo-labeling has become a dominant strategy in SSMLL, most existing methods assign equal weights to all pseudo-labels regardless of their quality, which can amplify the impact of noisy or uncertain predictions and degrade the overall performance. In this paper, we theoretically verify that the optimal weight for a pseudo-label should reflect its correctness likelihood. Empirically, we observe that on the same dataset, the correctness likelihood distribution of unlabeled data remains stable, even as the number of labeled training samples varies. Building on this insight, we propose Distribution-Calibrated Pseudo-labeling (DiCaP), a correctness-aware framework that estimates posterior precision to calibrate pseudo-label weights. We further introduce a dual-thresholding mechanism to separate confident and ambiguous regions: confident samples are pseudo-labeled and weighted accordingly, while ambiguous ones are explored by unsupervised contrastive learning. Experiments conducted on multiple benchmark datasets verify that our method achieves consistent improvements, surpassing state-of-the-art methods by up to 4.27%.","authors":["Bo Han","Zhuoming Li","Xiaoyu Wang","Yaxin Hou","Hui Liu","Junhui Hou","Yuheng Jia"],"pdf_url":"","comment":"Accepted by AAAI-26"},{"id":"http://arxiv.org/abs/2511.20222v1","updated":"2025-11-25T11:50:34Z","published":"2025-11-25T11:50:34Z","title":"Decoupling and Damping: Structurally-Regularized Gradient Matching for Multimodal Graph Condensation","summary":"In critical web applications such as e-commerce and recommendation systems, multimodal graphs integrating rich visual and textual attributes are increasingly central, yet their large scale introduces substantial computational burdens for training Graph Neural Networks (GNNs). While Graph Condensation (GC) offers a promising solution by synthesizing smaller datasets, existing methods falter in the multimodal setting. We identify a dual challenge causing this failure: (1) conflicting gradients arising from semantic misalignments between modalities, and (2) the GNN's message-passing architecture pathologically amplifying this gradient noise across the graph structure. To address this, we propose Structurally-Regularized Gradient Matching (SR-GM), a novel condensation framework tailored for multimodal graphs. SR-GM introduces two synergistic components: first, a gradient decoupling mechanism that resolves inter-modality conflicts at their source via orthogonal projection; and second, a structural damping regularizer that acts directly on the gradient field. By leveraging the graph's Dirichlet energy, this regularizer transforms the topology from a noise amplifier into a stabilizing force during optimization. Extensive experiments demonstrate that SR-GM significantly improves accuracy and accelerates convergence compared to baseline methods. Ablation studies confirm that addressing both gradient conflict and structural amplification in tandem is essential for achieving superior performance. Moreover, the condensed multimodal graphs exhibit strong cross-architecture generalization and promise to accelerate applications like Neural Architecture Search. This research provides a scalable methodology for multimodal graph-based learning in resource-constrained environments.","authors":["Lian Shen","Zhendan Chen","Yinhui jiang","Meijia Song","Ziming Su","Juan Liu","Xiangrong Liu"],"pdf_url":"","comment":"11pages,5 figures,6 tables"},{"id":"http://arxiv.org/abs/2511.20220v1","updated":"2025-11-25T11:47:47Z","published":"2025-11-25T11:47:47Z","title":"Communication-Efficient Learning for Satellite Constellations","summary":"Satellite constellations in low-Earth orbit are now widespread, enabling positioning, Earth imaging, and communications. In this paper we address the solution of learning problems using these satellite constellations. In particular, we focus on a federated approach, where satellites collect and locally process data, with the ground station aggregating local models. We focus on designing a novel, communication-efficient algorithm that still yields accurate trained models. To this end, we employ several mechanisms to reduce the number of communications with the ground station (local training) and their size (compression). We then propose an error feedback mechanism that enhances accuracy, which yields, as a byproduct, an algorithm-agnostic error feedback scheme that can be more broadly applied. We analyze the convergence of the resulting algorithm, and compare it with the state of the art through simulations in a realistic space scenario, showcasing superior performance.","authors":["Ruxandra-Stefania Tudose","Moritz H. W. Grüss","Grace Ra Kim","Karl H. Johansson","Nicola Bastianello"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.15046v4","updated":"2025-11-25T11:42:54Z","published":"2024-11-22T16:31:36Z","title":"On Feasible Rewards in Multi-Agent Inverse Reinforcement Learning","summary":"Multi-agent Inverse Reinforcement Learning (MAIRL) aims to recover agent reward functions from expert demonstrations. We characterize the feasible reward set in Markov games, identifying all reward functions that rationalize a given equilibrium. However, equilibrium-based observations are often ambiguous: a single Nash equilibrium can correspond to many reward structures, potentially changing the game's nature in multi-agent systems. We address this by introducing entropy-regularized Markov games, which yield a unique equilibrium while preserving strategic incentives. For this setting, we provide a sample complexity analysis detailing how errors affect learned policy performance. Our work establishes theoretical foundations and practical insights for MAIRL.","authors":["Till Freihaut","Giorgia Ramponi"],"pdf_url":"","comment":"Currently under review"},{"id":"http://arxiv.org/abs/2511.20216v1","updated":"2025-11-25T11:42:28Z","published":"2025-11-25T11:42:28Z","title":"CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents","summary":"Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.","authors":["Haebin Seong","Sungmin Kim","Minchan Kim","Yongjun Cho","Myunchul Joe","Suhwan Choi","Jaeyoon Jung","Jiyong Youn","Yoonshik Kim","Samwoo Seong","Yubeen Park","Youngjae Yu","Yunsung Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.08746v5","updated":"2025-11-25T11:34:54Z","published":"2025-08-12T08:41:00Z","title":"Interpretable Reward Model via Sparse Autoencoder","summary":"Large language models (LLMs) have been widely deployed across numerous fields. Reinforcement Learning from Human Feedback (RLHF) leverages reward models (RMs) as proxies for human preferences to align LLM behaviors with human values, making the accuracy, reliability, and interpretability of RMs critical for effective alignment. However, traditional RMs lack interpretability, offer limited insight into the reasoning behind reward assignments, and are inflexible toward user preference shifts. While recent multidimensional RMs aim for improved interpretability, they often fail to provide feature-level attribution and require costly annotations. To overcome these limitations, we introduce the Sparse Autoencoder-enhanced Reward Model (SARM), a novel architecture that integrates a pretrained Sparse Autoencoder (SAE) into a reward model. SARM maps the hidden activations of LLM-based RM into an interpretable, sparse, and monosemantic feature space, from which a scalar head aggregates feature activations to produce transparent and conceptually meaningful reward scores. Empirical evaluations demonstrate that SARM facilitates direct feature-level attribution of reward assignments, allows dynamic adjustment to preference shifts, and achieves superior alignment performance compared to conventional reward models. Our code is available at https://github.com/schrieffer-z/sarm.","authors":["Shuyi Zhang","Wei Shi","Sihang Li","Jiayi Liao","Hengxing Cai","Xiang Wang"],"pdf_url":"","comment":"AAAI 2026 Oral"},{"id":"http://arxiv.org/abs/2406.01423v3","updated":"2025-11-25T11:29:35Z","published":"2024-06-03T15:24:15Z","title":"Value Improved Actor Critic Algorithms","summary":"To learn approximately optimal acting policies for decision problems, modern Actor Critic algorithms rely on deep Neural Networks (DNNs) to parameterize the acting policy and greedification operators to iteratively improve it. The reliance on DNNs suggests an improvement that is gradient based, which is per step much less greedy than the improvement possible by greedier operators such as the greedy update used by Q-learning algorithms. On the other hand, slow changes to the policy can also be beneficial for the stability of the learning process, resulting in a tradeoff between greedification and stability. To better address this tradeoff, we propose to decouple the acting policy from the policy evaluated by the critic. This allows the agent to separately improve the critic's policy (e.g. value improvement) with greedier updates while maintaining the slow gradient-based improvement to the parameterized acting policy. We investigate the convergence of this approach using the popular analysis scheme of generalized Policy Iteration in the finite-horizon domain. Empirically, incorporating value-improvement into the popular off-policy actor-critic algorithms TD3 and SAC significantly improves or matches performance over their respective baselines, across different environments from the DeepMind continuous control domain, with negligible compute and implementation cost.","authors":["Yaniv Oren","Moritz A. Zanger","Pascal R. van der Vaart","Mustafa Mert Celikok","Matthijs T. J. Spaan","Wendelin Bohmer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.15691v3","updated":"2025-11-25T11:27:22Z","published":"2025-10-17T14:35:03Z","title":"Exploring the Synergy of Quantitative Factors and Newsflow Representations from Large Language Models for Stock Return Prediction","summary":"In quantitative investing, return prediction supports various tasks, including stock selection, portfolio optimization, and risk management. Quantitative factors, such as valuation, quality, and growth, capture various characteristics of stocks. Unstructured data, like news and transcripts, has attracted growing attention, driven by recent advances in large language models (LLMs). This paper examines effective methods for leveraging multimodal factors and newsflow in return prediction and stock selection. First, we introduce a fusion learning framework to learn a unified representation from factors and newsflow representations generated by an LLM. Within this framework, we compare three methods of different architectural complexities: representation combination, representation summation, and attentive representations. Next, building on the limitation of fusion learning observed in empirical comparison, we explore the mixture model that adaptively combines predictions made by single modalities and their fusion. To mitigate the training instability of the mixture model, we introduce a decoupled training approach with theoretical insights. Finally, our experiments on real investment universes yield several insights into effective multimodal modeling of factors and news for stock return prediction and selection.","authors":["Tian Guo","Emmanuel Hauptmann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20194v1","updated":"2025-11-25T11:19:58Z","published":"2025-11-25T11:19:58Z","title":"In-Context Compositional Learning via Sparse Coding Transformer","summary":"Transformer architectures have achieved remarkable success across language, vision, and multimodal tasks, and there is growing demand for them to address in-context compositional learning tasks. In these tasks, models solve the target problems by inferring compositional rules from context examples, which are composed of basic components structured by underlying rules. However, some of these tasks remain challenging for Transformers, which are not inherently designed to handle compositional tasks and offer limited structural inductive bias. In this work, inspired by the principle of sparse coding, we propose a reformulation of the attention to enhance its capability for compositional tasks. In sparse coding, data are represented as sparse combinations of dictionary atoms with coefficients that capture their compositional rules. Specifically, we reinterpret the attention block as a mapping of inputs into outputs through projections onto two sets of learned dictionary atoms: an encoding dictionary and a decoding dictionary. The encoding dictionary decomposes the input into a set of coefficients, which represent the compositional structure of the input. To enhance structured representations, we impose sparsity on these coefficients. The sparse coefficients are then used to linearly combine the decoding dictionary atoms to generate the output. Furthermore, to assist compositional generalization tasks, we propose estimating the coefficients of the target problem as a linear combination of the coefficients obtained from the context examples. We demonstrate the effectiveness of our approach on the S-RAVEN and RAVEN datasets. For certain compositional generalization tasks, our method maintains performance even when standard Transformers fail, owing to its ability to learn and apply compositional rules.","authors":["Wei Chen","Jingxi Yu","Zichen Miao","Qiang Qiu"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20189v1","updated":"2025-11-25T11:13:05Z","published":"2025-11-25T11:13:05Z","title":"Learning Subgroups with Maximum Treatment Effects without Causal Heuristics","summary":"Discovering subgroups with the maximum average treatment effect is crucial for targeted decision making in domains such as precision medicine, public policy, and education. While most prior work is formulated in the potential outcome framework, the corresponding structural causal model (SCM) for this task has been largely overlooked. In practice, two approaches dominate. The first estimates pointwise conditional treatment effects and then fits a tree on those estimates, effectively turning subgroup estimation into the harder problem of accurate pointwise estimation. The second constructs decision trees or rule sets with ad-hoc 'causal' heuristics, typically without rigorous justification for why a given heuristic may be used or whether such heuristics are necessary at all. We address these issues by studying the problem directly under the SCM framework. Under the assumption of a partition-based model, we show that optimal subgroup discovery reduces to recovering the data-generating models and hence a standard supervised learning problem (regression or classification). This allows us to adopt any partition-based methods to learn the subgroup from data. We instantiate the approach with CART, arguably one of the most widely used tree-based methods, to learn the subgroup with maximum treatment effect. Finally, on a large collection of synthetic and semi-synthetic datasets, we compare our method against a wide range of baselines and find that our approach, which avoids such causal heuristics, more accurately identifies subgroups with maximum treatment effect. Our source code is available at https://github.com/ylincen/causal-subgroup.","authors":["Lincen Yang","Zhong Li","Matthijs van Leeuwen","Saber Salehkaleybar"],"pdf_url":"","comment":"The full version (including the Appendix). Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2511.17126v3","updated":"2025-11-25T11:06:54Z","published":"2025-11-21T10:41:54Z","title":"OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation","summary":"Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2.","authors":["Qi Jiang","Xiaolong Qian","Yao Gao","Lei Sun","Kailun Yang","Zhonghua Yi","Wenyong Li","Ming-Hsuan Yang","Luc Van Gool","Kaiwei Wang"],"pdf_url":"","comment":"The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2"},{"id":"http://arxiv.org/abs/2411.08706v3","updated":"2025-11-25T10:51:57Z","published":"2024-11-13T15:50:32Z","title":"Searching Latent Program Spaces","summary":"General intelligence requires systems that acquire new skills efficiently and generalize beyond their training distributions. Although program synthesis approaches have strong generalization power, they face scaling issues due to the large combinatorial spaces that quickly render them impractical, requiring human-generated DSLs or pre-trained priors to narrow this search space. On the other hand, deep learning methods have had high successes, but they lack structured test-time adaptation and rely on heavy stochastic sampling or expensive gradient updates for fine-tuning. In this work, we propose the Latent Program Network (LPN), a novel architecture that builds in test-time search directly into neural models. LPN learns a latent space of implicit programs -- neurally mapping inputs to outputs -- through which it can search using gradients at test time. LPN combines the adaptability of symbolic approaches and the scalability of neural methods. It searches through a compact latent space at test time and bypasses the need for pre-defined domain-specific languages. On a range of programming-by-examples tasks, LPN either outperforms or matches performance compared to in-context learning and test-time training methods. Tested on the ARC-AGI benchmark, we demonstrate that LPN can both learn a compact program space and search through it at test time to adapt to novel tasks. LPN doubles its performance on out-of-distribution tasks when test-time search is switched on.","authors":["Matthew V Macfarlane","Clement Bonnet"],"pdf_url":"","comment":"NeurIPS 2025 spotlight. Code available at https://github.com/clement-bonnet/lpn"},{"id":"http://arxiv.org/abs/2511.20170v1","updated":"2025-11-25T10:50:06Z","published":"2025-11-25T10:50:06Z","title":"AdaCap: An Adaptive Contrastive Approach for Small-Data Neural Networks","summary":"Neural networks struggle on small tabular datasets, where tree-based models remain dominant. We introduce Adaptive Contrastive Approach (AdaCap), a training scheme that combines a permutation-based contrastive loss with a Tikhonov-based closed-form output mapping. Across 85 real-world regression datasets and multiple architectures, AdaCap yields consistent and statistically significant improvements in the small-sample regime, particularly for residual models. A meta-predictor trained on dataset characteristics (size, skewness, noise) accurately anticipates when AdaCap is beneficial. These results show that AdaCap acts as a targeted regularization mechanism, strengthening neural networks precisely where they are most fragile. All results and code are publicly available at https://github.com/BrunoBelucci/adacap.","authors":["Bruno Belucci","Karim Lounici","Katia Meziani"],"pdf_url":"","comment":"Submitted to ESANN 2026"},{"id":"http://arxiv.org/abs/2511.20168v1","updated":"2025-11-25T10:47:05Z","published":"2025-11-25T10:47:05Z","title":"On the Limits of Momentum in Decentralized and Federated Optimization","summary":"Recent works have explored the use of momentum in local methods to enhance distributed SGD. This is particularly appealing in Federated Learning (FL), where momentum intuitively appears as a solution to mitigate the effects of statistical heterogeneity. Despite recent progress in this direction, it is still unclear if momentum can guarantee convergence under unbounded heterogeneity in decentralized scenarios, where only some workers participate at each round. In this work we analyze momentum under cyclic client participation, and theoretically prove that it remains inevitably affected by statistical heterogeneity. Similarly to SGD, we prove that decreasing step-sizes do not help either: in fact, any schedule decreasing faster than $Θ\\left(1/t\\right)$ leads to convergence to a constant value that depends on the initialization and the heterogeneity bound. Numerical results corroborate the theory, and deep learning experiments confirm its relevance for realistic settings.","authors":["Riccardo Zaccone","Sai Praneeth Karimireddy","Carlo Masone"],"pdf_url":"","comment":"Accepted at the 17th Workshop on Optimization for Machine Learning (OPT@NeurIPS2025)"},{"id":"http://arxiv.org/abs/2501.11655v2","updated":"2025-11-25T10:30:53Z","published":"2025-01-20T18:38:51Z","title":"KKL Observer Synthesis for Nonlinear Systems via Physics-Informed Learning","summary":"This paper proposes a novel learning approach for designing Kazantzis-Kravaris/Luenberger (KKL) observers for autonomous nonlinear systems. The design of a KKL observer involves finding an injective map that transforms the system state into a higher-dimensional observer state, whose dynamics is linear and stable. The observer's state is then mapped back to the original system coordinates via the inverse map to obtain the state estimate. However, finding this transformation and its inverse is quite challenging. We propose learning the forward mapping using a physics-informed neural network, and then learning its inverse mapping with a conventional feedforward neural network. Theoretical guarantees for the robustness of state estimation against approximation error and system uncertainties are provided, including non-asymptotic learning guarantees that link approximation quality to finite sample sizes. The effectiveness of the proposed approach is demonstrated through numerical simulations on benchmark examples, showing superior generalization capability outside the training domain compared to state-of-the-art methods.","authors":["M. Umar B. Niazi","John Cao","Matthieu Barreau","Karl Henrik Johansson"],"pdf_url":"","comment":"27 pages, 7 figures, submitted to Automatica"},{"id":"http://arxiv.org/abs/2511.20141v1","updated":"2025-11-25T10:02:21Z","published":"2025-11-25T10:02:21Z","title":"IDAP++: Advancing Divergence-Based Pruning via Filter-Level and Layer-Level Optimization","summary":"This paper presents a novel approach to neural network compression that addresses redundancy at both the filter and architectural levels through a unified framework grounded in information flow analysis. Building on the concept of tensor flow divergence, which quantifies how information is transformed across network layers, we develop a two-stage optimization process. The first stage employs iterative divergence-aware pruning to identify and remove redundant filters while preserving critical information pathways. The second stage extends this principle to higher-level architecture optimization by analyzing layer-wise contributions to information propagation and selectively eliminating entire layers that demonstrate minimal impact on network performance. The proposed method naturally adapts to diverse architectures, including convolutional networks, transformers, and hybrid designs, providing a consistent metric for comparing the structural importance across different layer types. Experimental validation across multiple modern architectures and datasets reveals that this combined approach achieves substantial model compression while maintaining competitive accuracy. The presented approach achieves parameter reduction results that are globally comparable to those of state-of-the-art solutions and outperforms them across a wide range of modern neural network architectures, from convolutional models to transformers. The results demonstrate how flow divergence serves as an effective guiding principle for both filter-level and layer-level optimization, offering practical benefits for deployment in resource-constrained environments.","authors":["Aleksei Samarin","Artem Nazarenko","Egor Kotenko","Valentin Malykh","Alexander Savelev","Aleksei Toropov"],"pdf_url":"","comment":"65 pages, 4 figures, 38 tables"},{"id":"http://arxiv.org/abs/2511.20138v1","updated":"2025-11-25T09:59:56Z","published":"2025-11-25T09:59:56Z","title":"From data to concepts via wiring diagrams","summary":"A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.","authors":["Jason Lo","Mohammadnima Jafari"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2112.07436v3","updated":"2025-11-25T09:56:05Z","published":"2021-12-14T14:48:08Z","title":"Graph Kernel Neural Networks","summary":"The convolution operator at the core of many modern neural architectures can effectively be seen as performing a dot product between an input matrix and a filter. While this is readily applicable to data such as images, which can be represented as regular grids in the Euclidean space, extending the convolution operator to work on graphs proves more challenging, due to their irregular structure. In this paper, we propose to use graph kernels, i.e. kernel functions that compute an inner product on graphs, to extend the standard convolution operator to the graph domain. This allows us to define an entirely structural model that does not require computing the embedding of the input graph. Our architecture allows to plug-in any type of graph kernels and has the added benefit of providing some interpretability in terms of the structural masks that are learned during the training process, similarly to what happens for convolutional masks in traditional convolutional neural networks. We perform an extensive ablation study to investigate the model hyper-parameters' impact and show that our model achieves competitive performance on standard graph classification and regression datasets.","authors":["Luca Cosmo","Giorgia Minello","Alessandro Bicciato","Michael Bronstein","Emanuele Rodolà","Luca Rossi","Andrea Torsello"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20109v1","updated":"2025-11-25T09:27:33Z","published":"2025-11-25T09:27:33Z","title":"CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science Workflows","summary":"Climate science demands automated workflows to transform comprehensive questions into data-driven statements across massive, heterogeneous datasets. However, generic LLM agents and static scripting pipelines lack climate-specific context and flexibility, thus, perform poorly in practice. We present ClimateAgent, an autonomous multi-agent framework that orchestrates end-to-end climate data analytic workflows. ClimateAgent decomposes user questions into executable sub-tasks coordinated by an Orchestrate-Agent and a Plan-Agent; acquires data via specialized Data-Agents that dynamically introspect APIs to synthesize robust download scripts; and completes analysis and reporting with a Coding-Agent that generates Python code, visualizations, and a final report with a built-in self-correction loop. To enable systematic evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves, sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85, ClimateAgent achieves 100% task completion and a report quality score of 8.32, outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results demonstrate that our multi-agent orchestration with dynamic API awareness and self-correcting execution substantially advances reliable, end-to-end automation for climate science analytic tasks.","authors":["Hyeonjae Kim","Chenyue Li","Wen Deng","Mengxi Jin","Wen Huang","Mengqian Lu","Binhang Yuan"],"pdf_url":"","comment":"30 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.20105v1","updated":"2025-11-25T09:26:13Z","published":"2025-11-25T09:26:13Z","title":"Multivariate Forecasting of Bitcoin Volatility with Gradient Boosting: Deterministic, Probabilistic, and Feature Importance Perspectives","summary":"This study investigates the application of the Light Gradient Boosting Machine (LGBM) model for both deterministic and probabilistic forecasting of Bitcoin realized volatility. Utilizing a comprehensive set of 69 predictors -- encompassing market, behavioral, and macroeconomic indicators -- we evaluate the performance of LGBM-based models and compare them with both econometric and machine learning baselines. For probabilistic forecasting, we explore two quantile-based approaches: direct quantile regression using the pinball loss function, and a residual simulation method that transforms point forecasts into predictive distributions. To identify the main drivers of volatility, we employ gain-based and permutation feature importance techniques, consistently highlighting the significance of trading volume, lagged volatility measures, investor attention, and market capitalization. The results demonstrate that LGBM models effectively capture the nonlinear and high-variance characteristics of cryptocurrency markets while providing interpretable insights into the underlying volatility dynamics.","authors":["Grzegorz Dudek","Mateusz Kasprzyk","Paweł Pełka"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20104v1","updated":"2025-11-25T09:25:33Z","published":"2025-11-25T09:25:33Z","title":"The Devil in the Details: Emergent Misalignment, Format and Coherence in Open-Weights LLMs","summary":"Prior work has shown that fine-tuning models on a narrow domain with misaligned data can lead to broad misalignment - a phenomenon termed \"emergent misalignment\" (Betley et al. 2025). While all tested models were susceptible to emergent misalignment, some models showed more resistance than others. Specifically the Qwen-2.5 family proved to be relatively resistant, while GPT-4o exhibited the strongest misalignment. In this paper we evaluate if current-generation open-weights models exhibit similar resistance to the Qwen-2.5 family and measure misalignment robustness over a range of model architectures and scales.\n  We replicate the effect across nine modern open-weights models (Gemma 3 and Qwen 3 families, 1B-32B parameters). Models fine-tuned on insecure code generation show a 0.68% misalignment rate (compared to 0.07% for base models), matching the lower end of prior open-model results but dramatically lower than GPT-4o's 20%.\n  We identify a critical format-dependent vulnerability: requiring JSON output doubles misalignment rates compared to natural language prompts (0.96% vs 0.42%). This suggests that structural constraints may bypass safety training by reducing the model's 'degrees of freedom' to refuse. These findings confirm emergent misalignment as a reproducible phenomenon in modern open-weights models, with rates substantially lower than observed in proprietary systems.","authors":["Craig Dickson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20099v1","updated":"2025-11-25T09:17:32Z","published":"2025-11-25T09:17:32Z","title":"QiMeng-CRUX: Narrowing the Gap between Natural Language and Verilog via Core Refined Understanding eXpression","summary":"Large language models (LLMs) have shown promising capabilities in hardware description language (HDL) generation. However, existing approaches often rely on free-form natural language descriptions that are often ambiguous, redundant, and unstructured, which poses significant challenges for downstream Verilog code generation. We treat hardware code generation as a complex transformation from an open-ended natural language space to a domain-specific, highly constrained target space. To bridge this gap, we introduce Core Refined Understanding eXpression (CRUX), a structured intermediate space that captures the essential semantics of user intent while organizing the expression for precise Verilog code generation. We further design a two-stage training framework, comprising Joint Expression Modeling and Dual-Space Optimization, to enhance the quality of both CRUX and Verilog code. Experiments across multiple Verilog generation benchmarks demonstrate that our model, CRUX-V, achieves state-of-the-art performance among general models, particularly under challenging design tasks. Furthermore, the CRUX space proves transferable and beneficial when used as input prompts for other code models, highlighting its effectiveness in narrowing the gap between free-form natural language descriptions and precise Verilog generation.","authors":["Lei Huang","Rui Zhang","Jiaming Guo","Yang Zhang","Di Huang","Shuyao Cheng","Pengwei Jin","Chongxiao Li","Zidong Du","Xing Hu","Qi Guo","Yunji Chen"],"pdf_url":"","comment":"Accepted by the AAAI26 Conference Main Track"},{"id":"http://arxiv.org/abs/2511.11602v2","updated":"2025-11-25T09:15:43Z","published":"2025-10-31T18:17:38Z","title":"Aspiration-based Perturbed Learning Automata in Games with Noisy Utility Measurements. Part A: Stochastic Stability in Non-zero-Sum Games","summary":"Reinforcement-based learning has attracted considerable attention both in modeling human behavior as well as in engineering, for designing measurement- or payoff-based optimization schemes. Such learning schemes exhibit several advantages, especially in relation to filtering out noisy observations. However, they may exhibit several limitations when applied in a distributed setup. In multi-player weakly-acyclic games, and when each player applies an independent copy of the learning dynamics, convergence to (usually desirable) pure Nash equilibria cannot be guaranteed. Prior work has only focused on a small class of games, namely potential and coordination games. To address this main limitation, this paper introduces a novel payoff-based learning scheme for distributed optimization, namely aspiration-based perturbed learning automata (APLA). In this class of dynamics, and contrary to standard reinforcement-based learning schemes, each player's probability distribution for selecting actions is reinforced both by repeated selection and an aspiration factor that captures the player's satisfaction level. We provide a stochastic stability analysis of APLA in multi-player positive-utility games under the presence of noisy observations. This is the first part of the paper that characterizes stochastic stability in generic non-zero-sum games by establishing equivalence of the induced infinite-dimensional Markov chain with a finite dimensional one. In the second part, stochastic stability is further specialized to weakly acyclic games.","authors":["Georgios C. Chasparis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18660v2","updated":"2025-11-25T09:14:27Z","published":"2025-11-24T00:15:46Z","title":"Subtract the Corruption: Training-Data-Free Corrective Machine Unlearning using Task Arithmetic","summary":"Corrupted training data are ubiquitous. Corrective Machine Unlearning (CMU) seeks to remove the influence of such corruption post-training. Prior CMU typically assumes access to identified corrupted training samples (a \"forget set\"). However, in many real-world scenarios the training data are no longer accessible. We formalize source-free CMU, where the original training data are unavailable and, consequently, no forget set of identified corrupted training samples can be specified. Instead, we assume a small proxy (surrogate) set of corrupted samples that reflect the suspected corruption type without needing to be the original training samples. In this stricter setting, methods relying on forget set are ineffective or narrow in scope. We introduce Corrective Unlearning in Task Space (CUTS), a lightweight weight space correction method guided by the proxy set using task arithmetic principles. CUTS treats the clean and the corruption signal as distinct tasks. Specifically, we briefly fine-tune the corrupted model on the proxy to amplify the corruption mechanism in the weight space, compute the difference between the corrupted and fine-tuned weights as a proxy task vector, and subtract a calibrated multiple of this vector to cancel the corruption. Without access to clean data or a forget set, CUTS recovers a large fraction of the lost utility under label noise and, for backdoor triggers, nearly eliminates the attack with minimal damage to utility, outperforming state-of-the-art specialized CMU methods in source-free setting.","authors":["Mostafa Mozafari","Farooq Ahmad Wani","Maria Sofia Bucarelli","Fabrizio Silvestri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17628v2","updated":"2025-11-25T08:57:01Z","published":"2025-11-19T02:06:30Z","title":"Rectifying Distribution Shift in Cascaded Precipitation Nowcasting","summary":"Precipitation nowcasting, which aims to provide high spatio-temporal resolution precipitation forecasts by leveraging current radar observations, is a core task in regional weather forecasting. Recently, the cascaded architecture has emerged as the mainstream paradigm for deep learning-based precipitation nowcasting. This paradigm involves a deterministic model to predict posterior mean, followed by a probabilistic model to generate local stochasticity. However, existing methods commonly overlook the conflation of the systematic distribution shift in deterministic predictions and the local stochasticity. As a result, the distribution shift of the deterministic component contaminates the predictions of the probabilistic component, leading to inaccuracies in precipitation patterns and intensity, particularly over longer lead times. To address this issue, we introduce RectiCast, a two-stage framework that explicitly decouples the rectification of mean-field shift from the generation of local stochasticity via a dual Flow Matching model. In the first stage, a deterministic model generates the posterior mean. In the second stage, we introduce a Rectifier to explicitly learn the distribution shift and produce a rectified mean. Subsequently, a Generator focuses on modeling the local stochasticity conditioned on the rectified mean. Experiments on two radar datasets demonstrate that RectiCast achieves significant performance improvements over existing state-of-the-art methods.","authors":["Fanbo Ju","Haiyuan Shi","Qingjian Ni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.17811v2","updated":"2025-11-25T08:48:19Z","published":"2025-08-25T09:04:20Z","title":"MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting","summary":"Surface reconstruction has been widely studied in computer vision and graphics. However, existing surface reconstruction works struggle to recover accurate scene geometry when the input views are extremely sparse. To address this issue, we propose MeshSplat, a generalizable sparse-view surface reconstruction framework via Gaussian Splatting. Our key idea is to leverage 2DGS as a bridge, which connects novel view synthesis to learned geometric priors and then transfers these priors to achieve surface reconstruction. Specifically, we incorporate a feed-forward network to predict per-view pixel-aligned 2DGS, which enables the network to synthesize novel view images and thus eliminates the need for direct 3D ground-truth supervision. To improve the accuracy of 2DGS position and orientation prediction, we propose a Weighted Chamfer Distance Loss to regularize the depth maps, especially in overlapping areas of input views, and also a normal prediction network to align the orientation of 2DGS with normal vectors predicted by a monocular normal estimator. Extensive experiments validate the effectiveness of our proposed improvement, demonstrating that our method achieves state-of-the-art performance in generalizable sparse-view mesh reconstruction tasks. Project Page: https://hanzhichang.github.io/meshsplat_web","authors":["Hanzhi Chang","Ruijie Zhu","Wenjie Chang","Mulin Yu","Yanzhe Liang","Jiahao Lu","Zhuoyuan Li","Tianzhu Zhang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20066v1","updated":"2025-11-25T08:39:21Z","published":"2025-11-25T08:39:21Z","title":"SOMBRL: Scalable and Optimistic Model-Based RL","summary":"We address the challenge of efficient exploration in model-based reinforcement learning (MBRL), where the system dynamics are unknown and the RL agent must learn directly from online interactions. We propose Scalable and Optimistic MBRL (SOMBRL), an approach based on the principle of optimism in the face of uncertainty. SOMBRL learns an uncertainty-aware dynamics model and greedily maximizes a weighted sum of the extrinsic reward and the agent's epistemic uncertainty. SOMBRL is compatible with any policy optimizers or planners, and under common regularity assumptions on the system, we show that SOMBRL has sublinear regret for nonlinear dynamics in the (i) finite-horizon, (ii) discounted infinite-horizon, and (iii) non-episodic settings. Additionally, SOMBRL offers a flexible and scalable solution for principled exploration. We evaluate SOMBRL on state-based and visual-control environments, where it displays strong performance across all tasks and baselines. We also evaluate SOMBRL on a dynamic RC car hardware and show SOMBRL outperforms the state-of-the-art, illustrating the benefits of principled exploration for MBRL.","authors":["Bhavya Sukhija","Lenart Treven","Carmelo Sferrazza","Florian Dörfler","Pieter Abbeel","Andreas Krause"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10533v4","updated":"2025-11-25T08:21:28Z","published":"2025-08-14T11:10:07Z","title":"Mitigating Exponential Mixed Frequency Growth through Frequency Selection","summary":"Quantum machine learning research has expanded rapidly due to potential computational advantages over classical methods. Angle encoding has emerged as a popular choice as feature map (FM) for embedding classical data into quantum models due to its simplicity and natural generation of truncated Fourier series, providing universal function approximation capabilities. Efficient FMs within quantum circuits can exploit exponential scaling of Fourier frequencies, with multi-dimensional inputs introducing additional exponential growth through mixed-frequency terms. Despite this promising expressive capability, practical implementation faces significant challenges. Through controlled experiments with white-box target functions, we demonstrate that training failures can occur even when all relevant frequencies are theoretically accessible. We illustrate how two primary known causes lead to unsuccessful optimization: insufficient trainable parameters relative to the model's frequency content, and limitations imposed by the ansatz's dynamic lie algebra dimension, but also uncover an additional parameter burden: the necessity of controlling non-unique frequencies within the model. To address this, we propose near-zero weight initialization to suppress unnecessary duplicate frequencies. For target functions with a priori frequency knowledge, we introduce frequency selection as a practical solution that reduces parameter requirements and mitigates the exponential growth that would otherwise render problems intractable due to parameter insufficiency. Our frequency selection approach achieved near-optimal performance (median $R^2 \\approx 0.95$) with 78\\% of the parameters needed by the best standard approach in 10 randomly chosen target functions.","authors":["Michael Poppel","David Bucher","Maximilian Zorn","Nico Kraus","Philipp Altmann","Jonas Stein","Claudia Linnhoff-Popien"],"pdf_url":"","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2505.11749v3","updated":"2025-11-25T08:19:47Z","published":"2025-05-16T23:15:02Z","title":"Missing Data Imputation by Reducing Mutual Information with Rectified Flows","summary":"This paper introduces a novel iterative method for missing data imputation that sequentially reduces the mutual information between data and the corresponding missingness mask. Inspired by GAN-based approaches that train generators to decrease the predictability of missingness patterns, our method explicitly targets this reduction in mutual information. Specifically, our algorithm iteratively minimizes the KL divergence between the joint distribution of the imputed data and missingness mask, and the product of their marginals from the previous iteration. We show that the optimal imputation under this framework can be achieved by solving an ODE whose velocity field minimizes a rectified flow training objective. We further illustrate that some existing imputation techniques can be interpreted as approximate special cases of our mutual-information-reducing framework. Comprehensive experiments on synthetic and real-world datasets validate the efficacy of our proposed approach, demonstrating its superior imputation performance. Our implementation is available at https://github.com/yujhml/MIRI-Imputation.","authors":["Jiahao Yu","Qizhen Ying","Leyang Wang","Ziyue Jiang","Song Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20048v1","updated":"2025-11-25T08:15:17Z","published":"2025-11-25T08:15:17Z","title":"Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design","summary":"LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.","authors":["Zixiao Huang","Wen Zeng","Tianyu Fu","Tengxuan Liu","Yizhou Sun","Ke Hong","Xinhao Yang","Chengchun Liu","Yan Li","Quanlu Zhang","Guohao Dai","Zhenhua Zhu","Yu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.20629v2","updated":"2025-11-25T08:12:03Z","published":"2025-05-27T02:16:06Z","title":"Unified Text-Image-to-Video Generation: A Training-Free Approach to Flexible Visual Conditioning","summary":"Text-image-to-video (TI2V) generation is a critical problem for controllable video generation using both semantic and visual conditions. Most existing methods typically add visual conditions to text-to-video (T2V) foundation models by finetuning, which is costly in resources and only limited to a few pre-defined conditioning settings. To tackle these constraints, we introduce a unified formulation for TI2V generation with flexible visual conditioning. Furthermore, we propose an innovative training-free approach, dubbed FlexTI2V, that can condition T2V foundation models on an arbitrary amount of images at arbitrary positions. Specifically, we firstly invert the condition images to noisy representation in a latent space. Then, in the denoising process of T2V models, our method uses a novel random patch swapping strategy to incorporate visual features into video representations through local image patches. To balance creativity and fidelity, we use a dynamic control mechanism to adjust the strength of visual conditioning to each video frame. Extensive experiments validate that our method surpasses previous training-free image conditioning methods by a notable margin. Our method can also generalize to both UNet-based and transformer-based architectures.","authors":["Bolin Lai","Sangmin Lee","Xu Cao","Xiang Li","James M. Rehg"],"pdf_url":"","comment":"18 pages, 10 figures, 8 tables"},{"id":"http://arxiv.org/abs/2511.20044v1","updated":"2025-11-25T08:11:41Z","published":"2025-11-25T08:11:41Z","title":"RED-F: Reconstruction-Elimination based Dual-stream Contrastive Forecasting for Multivariate Time Series Anomaly Prediction","summary":"The proactive prediction of anomalies (AP) in mul- tivariate time series (MTS) is a critical challenge to ensure system dependability. The difficulty lies in identifying subtle anomaly precursors concealed within normal signals. However, existing unsupervised methods, trained exclusively on normal data, demonstrate a fundamental propensity to reconstruct normal patterns. Consequently, when confronted with weak precursors, their predictions are dominated by the normal pattern, submerging the very signal required for prediction. To contend with the limitation, we propose RED-F, a Reconstruction- Elimination based Dual-stream Contrastive Forecasting frame- work, comprising the Reconstruction-Elimination Model (REM) and the Dual-stream Contrastive Forecasting Model (DFM). The REM utilizes a hybrid time-frequency mechanism to mitigate the precursor, generating a purified, normal-pattern baseline. The DFM then receives this purified baseline and the original sequence which retains the precursor as parallel inputs. At the core of our framework, RED-F employs a contrastive forecast that transforms the difficult task of absolute signal detection into a simpler, more robust task of relative trajectory comparison by computing the divergence between these two predictive streams. This contrastive mechanism serves to amplify the faint precursor signal. Furthermore, the DFM is trained with a novel Multi-Series Prediction (MSP) objective, which leverages distant future con- text to enhance its predictive sensitivity. Extensive experiments on six real-world datasets demonstrate the superior capability of RED-F in anomaly prediction tasks.","authors":["PengYu Chen","Xiaohou Shi","Yuan Chang","Yan Sun","Sajal K. Das"],"pdf_url":"","comment":"13 pages, 12 figures"},{"id":"http://arxiv.org/abs/2511.20041v1","updated":"2025-11-25T08:10:56Z","published":"2025-11-25T08:10:56Z","title":"MFM-point: Multi-scale Flow Matching for Point Cloud Generation","summary":"In recent years, point cloud generation has gained significant attention in 3D generative modeling. Among existing approaches, point-based methods directly generate point clouds without relying on other representations such as latent features, meshes, or voxels. These methods offer low training cost and algorithmic simplicity, but often underperform compared to representation-based approaches. In this paper, we propose MFM-Point, a multi-scale Flow Matching framework for point cloud generation that substantially improves the scalability and performance of point-based methods while preserving their simplicity and efficiency. Our multi-scale generation algorithm adopts a coarse-to-fine generation paradigm, enhancing generation quality and scalability without incurring additional training or inference overhead. A key challenge in developing such a multi-scale framework lies in preserving the geometric structure of unordered point clouds while ensuring smooth and consistent distributional transitions across resolutions. To address this, we introduce a structured downsampling and upsampling strategy that preserves geometry and maintains alignment between coarse and fine resolutions. Our experimental results demonstrate that MFM-Point achieves best-in-class performance among point-based methods and challenges the best representation-based methods. In particular, MFM-point demonstrates strong results in multi-category and high-resolution generation tasks.","authors":["Petr Molodyk","Jaemoo Choi","David W. Romero","Ming-Yu Liu","Yongxin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20038v1","updated":"2025-11-25T08:08:39Z","published":"2025-11-25T08:08:39Z","title":"Softmax Transformers are Turing-Complete","summary":"Hard attention Chain-of-Thought (CoT) transformers are known to be Turing-complete. However, it is an open problem whether softmax attention Chain-of-Thought (CoT) transformers are Turing-complete. In this paper, we prove a stronger result that length-generalizable softmax CoT transformers are Turing-complete. More precisely, our Turing-completeness proof goes via the CoT extension of the Counting RASP (C-RASP), which correspond to softmax CoT transformers that admit length generalization. We prove Turing-completeness for CoT C-RASP with causal masking over a unary alphabet (more generally, for letter-bounded languages). While we show this is not Turing-complete for arbitrary languages, we prove that its extension with relative positional encoding is Turing-complete for arbitrary languages. We empirically validate our theory by training transformers for languages requiring complex (non-linear) arithmetic reasoning.","authors":["Hongjian Jiang","Michael Hahn","Georg Zetzsche","Anthony Widjaja Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.04979v2","updated":"2025-11-25T08:05:43Z","published":"2025-11-07T04:38:25Z","title":"Scaling Up ROC-Optimizing Support Vector Machines","summary":"The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the area under the ROC curve (AUC) and has become an attractive alternative of the conventional binary classification under the presence of class imbalance. However, its practical use is limited by high computational cost, as training involves evaluating all $O(n^2)$. To overcome this limitation, we develop a scalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby substantially reducing computational complexity. We further extend the framework to nonlinear classification through a low-rank kernel approximation, enabling efficient training in reproducing kernel Hilbert spaces. Theoretical analysis establishes an error bound that justifies the proposed approximation, and empirical results on both synthetic and real datasets demonstrate that the proposed method achieves comparable AUC performance to the original ROC-SVM with drastically reduced training time.","authors":["Gimun Bae","Seung Jun Shin"],"pdf_url":"","comment":"15 pages, Accepted in Stat"},{"id":"http://arxiv.org/abs/2506.18165v3","updated":"2025-11-25T07:56:48Z","published":"2025-06-22T20:41:31Z","title":"Non-equilibrium Annealed Adjoint Sampler","summary":"Recently, there has been significant progress in learning-based diffusion samplers, which aim to sample from a given unnormalized density. Many of these approaches formulate the sampling task as a stochastic optimal control (SOC) problem using a canonical uninformative reference process, which limits their ability to efficiently guide trajectories toward the target distribution. In this work, we propose the Non-Equilibrium Annealed Adjoint Sampler (NAAS), a novel SOC-based diffusion framework that employs annealed reference dynamics as a non-stationary base SDE. This annealing structure provides a natural progression toward the target distribution and generates informative reference trajectories, thereby enhancing the stability and efficiency of learning the control. Owing to our SOC formulation, our framework can incorporate a variety of SOC solvers, thereby offering high flexibility in algorithmic design. As one instantiation, we employ a lean adjoint system inspired by adjoint matching, enabling efficient and scalable training. We demonstrate the effectiveness of NAAS across a range of tasks, including sampling from classical energy landscapes and molecular Boltzmann distributions.","authors":["Jaemoo Choi","Yongxin Chen","Molei Tao","Guan-Horng Liu"],"pdf_url":"","comment":"26 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.20030v1","updated":"2025-11-25T07:56:40Z","published":"2025-11-25T07:56:40Z","title":"Cross-Contrastive Clustering for Multimodal Attributed Graphs with Dual Graph Filtering","summary":"Multimodal Attributed Graphs (MMAGs) are an expressive data model for representing the complex interconnections among entities that associate attributes from multiple data modalities (text, images, etc.). Clustering over such data finds numerous practical applications in real scenarios, including social community detection, medical data analytics, etc. However, as revealed by our empirical studies, existing multi-view clustering solutions largely rely on the high correlation between attributes across various views and overlook the unique characteristics (e.g., low modality-wise correlation and intense feature-wise noise) of multimodal attributes output by large pre-trained language and vision models in MMAGs, leading to suboptimal clustering performance.\n  Inspired by foregoing empirical observations and our theoretical analyses with graph signal processing, we propose the Dual Graph Filtering (DGF) scheme, which innovatively incorporates a feature-wise denoising component into node representation learning, thereby effectively overcoming the limitations of traditional graph filters adopted in the extant multi-view graph clustering approaches. On top of that, DGF includes a tri-cross contrastive training strategy that employs instance-level contrastive learning across modalities, neighborhoods, and communities for learning robust and discriminative node representations. Our comprehensive experiments on eight benchmark MMAG datasets exhibit that DGF is able to outperform a wide range of state-of-the-art baselines consistently and significantly in terms of clustering quality measured against ground-truth labels.","authors":["Haoran Zheng","Renchi Yang","Hongtao Wang","Jianliang Xu"],"pdf_url":"","comment":"Accepted by SIGKDD 2026. The code is available at https://github.com/HaoranZ99/DGF"},{"id":"http://arxiv.org/abs/2505.20192v3","updated":"2025-11-25T07:50:07Z","published":"2025-05-26T16:38:06Z","title":"FunReason: Enhancing Large Language Models' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement","summary":"The integration of large language models (LLMs) with function calling has emerged as a crucial capability for enhancing their practical utility in real-world applications. However, effectively combining reasoning processes with accurate function execution remains a significant challenge. Traditional training approaches often struggle to balance the detailed reasoning steps with the precision of function calls, leading to suboptimal performance. To address these limitations, we introduce FunReason, a novel framework that enhances LLMs' function calling capabilities through an automated data refinement strategy and a Self-Refinement Multiscale Loss (SRML) approach. FunReason leverages LLMs' natural reasoning abilities to generate high-quality training examples, focusing on query parseability, reasoning coherence, and function call precision. The SRML approach dynamically balances the contribution of reasoning processes and function call accuracy during training, addressing the inherent trade-off between these two critical aspects. FunReason achieves performance comparable to GPT-4o while effectively mitigating catastrophic forgetting during fine-tuning. FunReason provides a comprehensive solution for enhancing LLMs' function calling capabilities by introducing a balanced training methodology and a data refinement pipeline. For code and dataset, please refer to our repository at GitHub https://github.com/BingguangHao/FunReason","authors":["Bingguang Hao","ZengZhuang Xu","Maolin Wang","Yuntao Wen","Yicheng Chen","Cunyin Peng","Long Chen","Dong Wang","Xiangyu Zhao","Jinjie Gu","Chenyi Zhuang","Ji Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.13902v3","updated":"2025-11-25T07:43:03Z","published":"2025-05-20T04:06:43Z","title":"An Asymptotic Equation Linking WAIC and WBIC in Singular Models","summary":"In statistical learning, models are classified as regular or singular depending on whether the mapping from parameters to probability distributions is injective. Most models with hierarchical structures or latent variables are singular, for which conventional criteria such as the Akaike Information Criterion and the Bayesian Information Criterion are inapplicable due to the breakdown of normal approximations for the likelihood and posterior. To address this, the Widely Applicable Information Criterion (WAIC) and the Widely Applicable Bayesian Information Criterion (WBIC) have been proposed. Since WAIC and WBIC are computed using posterior distributions at different temperature settings, separate posterior sampling is generally required. In this paper, we theoretically derive an asymptotic equation that links WAIC and WBIC, despite their dependence on different posteriors. This equation yields an asymptotically unbiased expression of WAIC in terms of the posterior distribution used for WBIC. The result clarifies the structural relationship between these criteria within the framework of singular learning theory, and deepens understanding of their asymptotic behavior. This theoretical contribution provides a foundation for future developments in the computational efficiency of model selection in singular models.","authors":["Naoki Hayashi","Takuro Kutsuna","Sawa Takamuku"],"pdf_url":"","comment":"14pages, accepted in ICONIP2025 and published in Neural Information Processing (Lecture Notes in Computer Science)"},{"id":"http://arxiv.org/abs/2511.14301v2","updated":"2025-11-25T07:42:59Z","published":"2025-11-18T09:56:16Z","title":"Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense Evasion","summary":"Transformer models are foundational to natural language processing (NLP) applications, yet remain vulnerable to backdoor attacks introduced through poisoned data, which implant hidden behaviors during training. To strengthen the ability to prevent such compromises, recent research has focused on designing increasingly stealthy attacks to stress-test existing defenses, pairing backdoor behaviors with stylized artifact or token-level perturbation triggers. However, this trend diverts attention from the harder and more realistic case: making the model respond to semantic triggers such as specific names or entities, where a successful backdoor could manipulate outputs tied to real people or events in deployed systems. Motivated by this growing disconnect, we introduce SteganoBackdoor, bringing stealth techniques back into line with practical threat models. Leveraging innocuous properties from natural-language steganography, SteganoBackdoor applies a gradient-guided data optimization process to transform semantic trigger seeds into steganographic carriers that embed a high backdoor payload, remain fluent, and exhibit no representational resemblance to the trigger. Across diverse experimental settings, SteganoBackdoor achieves over 99% attack success at an order-of-magnitude lower data-poisoning rate than prior approaches while maintaining unparalleled evasion against a comprehensive suite of data-level defenses. By revealing this practical and covert attack, SteganoBackdoor highlights an urgent blind spot in current defenses and demands immediate attention to adversarial data defenses and real-world threat modeling.","authors":["Eric Xue","Ruiyi Zhang","Zijun Zhang","Pengtao Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08276v2","updated":"2025-11-25T07:39:28Z","published":"2025-06-09T22:43:30Z","title":"LEANN: A Low-Storage Vector Index","summary":"Embedding-based vector search underpins many important applications, such as recommendation and retrieval-augmented generation (RAG). It relies on vector indices to enable efficient search. However, these indices require storing high-dimensional embeddings and large index metadata, whose total size can be several times larger than the original data (e.g., text chunks). Such high storage overhead makes it difficult, or even impractical, to deploy vector search on personal devices or large-scale datasets. To tackle this problem, we propose LEANN, a storage-efficient index for vector search that recomputes embeddings on the fly instead of storing them, and compresses state-of-the-art proximity graph indices while preserving search accuracy. LEANN delivers high-quality vector search while using only a fraction of the storage (e.g., 5% of the original data) and supporting storage-efficient index construction and updates. On real-world benchmarks, LEANN reduces index size by up to 50x compared with conventional indices, while maintaining SOTA accuracy and comparable latency for RAG applications.","authors":["Yichuan Wang","Zhifei Li","Shu Liu","Yongji Wu","Ziming Mao","Yilong Zhao","Xiao Yan","Zhiying Xu","Yang Zhou","Ion Stoica","Sewon Min","Matei Zaharia","Joseph E. Gonzalez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.16274v2","updated":"2025-11-25T07:36:10Z","published":"2025-07-22T06:39:07Z","title":"STAlloc: Enhancing Memory Efficiency in Large-Scale Model Training with Spatio-Temporal Planning","summary":"The rapid scaling of large language models (LLMs) has significantly increased GPU memory pressure, which is further aggravated by training optimization techniques such as virtual pipeline and recomputation that disrupt tensor lifespans and introduce considerable memory fragmentation. Such fragmentation stems from the use of online GPU memory allocators in popular deep learning frameworks like PyTorch, which disregard tensor lifespans. As a result, this inefficiency can waste as much as 43% of memory and trigger out-of-memory errors, undermining the effectiveness of optimization methods. To address this, we introduce STAlloc, a GPU memory allocator for deep learning frameworks that reduces fragmentation by exploiting the spatial and temporal regularity in memory allocation behaviors of training workloads. STAlloc introduces a novel paradigm that combines offline planning with online allocation. The offline planning leverages spatio-temporal regularities to generate a near-optimal allocation plan, while the online allocation handles complex and dynamic models such as Mixture-of-Experts (MoE). Built as a pluggable PyTorch memory allocator, STAlloc reduces fragmentation ratio on average by 85.1% (up to 100%) across both dense and MoE models, with negligible overhead. This enables more efficient, high-throughput training configurations and improves throughput performance by up to 32.5%.","authors":["Zixiao Huang","Junhao Hu","Hao Lin","Chunyang Zhu","Yueran Tang","Quanlu Zhang","Zhen Guo","Zhenhua Li","Shengen Yan","Zhenhua Zhu","Guohao Dai","Yu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10764v4","updated":"2025-11-25T07:35:02Z","published":"2025-10-12T19:05:04Z","title":"Optimally Deep Networks - Adapting Model Depth to Datasets for Superior Efficiency","summary":"Deep neural networks (DNNs) have provided brilliant performance across various tasks. However, this success often comes at the cost of unnecessarily large model sizes, high computational demands, and substantial memory footprints. Typically, powerful architectures are trained at full depths but not all datasets or tasks require such high model capacity. Training big and deep architectures on relatively low-complexity datasets frequently leads to wasted computation, unnecessary energy consumption, and excessive memory usage, which in turn makes deployment of models on resource-constrained devices impractical. To address this problem, we introduce the concept of Optimally Deep Networks (ODNs), which provides a balance between model depth and task complexity. Specifically, we propose a NAS like training strategy called progressive depth expansion, which begins by training neural networks at shallower depths and incrementally increases their depth as the earlier blocks converge, continuing this process until the target accuracy is reached. ODNs use only the optimal depth for the tasks at hand, removing redundant layers. This cuts down future training and inference costs, lowers the model memory footprint, enhances computational efficiency, and facilitates deployment on edge devices. Empirical results show that the optimal depths of ResNet-18 and ResNet-34 for MNIST and SVHN, achieve up to 98.64 % and 96.44 % reduction in memory footprint, while maintaining a competitive accuracy of 99.31 % and 96.08 %, respectively.","authors":["Shaharyar Ahmed Khan Tareen","Filza Khan Tareen"],"pdf_url":"","comment":"6 pages, 4 figures, 1 table, 2 equations, 1 algorithm"},{"id":"http://arxiv.org/abs/2511.20015v1","updated":"2025-11-25T07:32:49Z","published":"2025-11-25T07:32:49Z","title":"iRadioDiff: Physics-Informed Diffusion Model for Indoor Radio Map Construction and Localization","summary":"Radio maps (RMs) serve as environment-aware electromagnetic (EM) representations that connect scenario geometry and material properties to the spatial distribution of signal strength, enabling localization without costly in-situ measurements. However, constructing high-fidelity indoor RMs remains challenging due to the prohibitive latency of EM solvers and the limitations of learning-based methods, which often rely on sparse measurements or assumptions of homogeneous material, which are misaligned with the heterogeneous and multipath-rich nature of indoor environments. To overcome these challenges, we propose iRadioDiff, a sampling-free diffusion-based framework for indoor RM construction. iRadioDiff is conditioned on access point (AP) positions, and physics-informed prompt encoded by material reflection and transmission coefficients. It further incorporates multipath-critical priors, including diffraction points, strong transmission boundaries, and line-of-sight (LoS) contours, to guide the generative process via conditional channels and boundary-weighted objectives. This design enables accurate modeling of nonstationary field discontinuities and efficient construction of physically consistent RMs. Experiments demonstrate that iRadioDiff achieves state-of-the-art performance in indoor RM construction and received signal strength based indoor localization, which offers effective generalization across layouts and material configurations. Code is available at https://github.com/UNIC-Lab/iRadioDiff.","authors":["Xiucheng Wang","Tingwei Yuan","Yang Cao","Nan Cheng","Ruijin Sun","Weihua Zhuang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.05718v3","updated":"2025-11-25T07:32:45Z","published":"2024-12-07T18:31:16Z","title":"RLZero: Direct Policy Inference from Language Without In-Domain Supervision","summary":"The reward hypothesis states that all goals and purposes can be understood as the maximization of a received scalar reward signal. However, in practice, defining such a reward signal is notoriously difficult, as humans are often unable to predict the optimal behavior corresponding to a reward function. Natural language offers an intuitive alternative for instructing reinforcement learning (RL) agents, yet previous language-conditioned approaches either require costly supervision or test-time training given a language instruction. In this work, we present a new approach that uses a pretrained RL agent trained using only unlabeled, offline interactions--without task-specific supervision or labeled trajectories--to get zero-shot test-time policy inference from arbitrary natural language instructions. We introduce a framework comprising three steps: imagine, project, and imitate. First, the agent imagines a sequence of observations corresponding to the provided language description using video generative models. Next, these imagined observations are projected into the target environment domain. Finally, an agent pretrained in the target environment with unsupervised RL instantly imitates the projected observation sequence through a closed-form solution. To the best of our knowledge, our method, RLZero, is the first approach to show direct language-to-behavior generation abilities on a variety of tasks and environments without any in-domain supervision. We further show that components of RLZero can be used to generate policies zero-shot from cross-embodied videos, such as those available on YouTube, even for complex embodiments like humanoids.","authors":["Harshit Sikchi","Siddhant Agarwal","Pranaya Jajoo","Samyak Parajuli","Caleb Chuck","Max Rudolph","Peter Stone","Amy Zhang","Scott Niekum"],"pdf_url":"","comment":"NeurIPS 2025, 26 pages"},{"id":"http://arxiv.org/abs/2511.17585v2","updated":"2025-11-25T07:18:32Z","published":"2025-11-16T05:31:11Z","title":"PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis","summary":"Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by integrating textual, acoustic, and visual signals. Although multimodal fusion is designed to leverage cross-modal complementarity, real-world scenarios often exhibit modality competition: dominant modalities tend to overshadow weaker ones, leading to suboptimal performance. In this paper, we propose PaSE, a novel Prototype-aligned Calibration and Shapley-optimized Equilibrium framework, which enhances collaboration while explicitly mitigating modality competition. PaSE first applies Prototype-guided Calibration Learning (PCL) to refine unimodal representations and align them through an Entropic Optimal Transport mechanism that ensures semantic consistency. To further stabilize optimization, we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion module is first used to extract shared representations, followed by Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients according to the contribution of each modality. Extensive experiments on IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance and effectively alleviates modality competition.","authors":["Kang He","Boyu Chen","Yuzhe Ding","Fei Li","Chong Teng","Donghong Ji"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20004v1","updated":"2025-11-25T07:14:50Z","published":"2025-11-25T07:14:50Z","title":"Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting","summary":"This work investigates the zero-shot forecasting capability of time-series foundation models for Leaf Area Index (LAI) forecasting in agricultural monitoring. Using the HiQ dataset (U.S., 2000-2022), we systematically compare statistical baselines, a fully supervised LSTM, and the Sundial foundation model under multiple evaluation protocols. We find that Sundial, in the zero-shot setting, can outperform a fully trained LSTM provided that the input context window is sufficiently long-specifically, when covering more than one or two full seasonal cycles. This demonstrates, for the first time, that a general-purpose foundation model can surpass specialized supervised models on remote-sensing time series prediction without any task-specific tuning. These results highlight the strong potential of pretrained time-series foundation models to serve as effective plug-and-play forecasters in agricultural and environmental applications.","authors":["Peining Zhang","Hongchen Qin","Haochen Zhang","Ziqi Guo","Guiling Wang","Jinbo Bi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.24160v2","updated":"2025-11-25T07:13:49Z","published":"2025-10-28T07:57:14Z","title":"Identifiable learning of dissipative dynamics","summary":"Complex dissipative systems appear across science and engineering, from polymers and active matter to learning algorithms. These systems operate far from equilibrium, where energy dissipation and time irreversibility govern their behavior but are difficult to quantify from data. Here, we introduce a universal and identifiable neural framework that learns dissipative stochastic dynamics directly from trajectories while ensuring interpretability, expressiveness, and uniqueness. Our method identifies a unique energy landscape, separates reversible from irreversible motion, and allows direct computation of the entropy production, providing a principled measure of irreversibility and deviations from equilibrium. Applications to polymer stretching in elongational flow and to stochastic gradient Langevin dynamics reveal new insights, including super-linear scaling of barrier heights and sub-linear scaling of entropy production rates with the strain rate, and the suppression of irreversibility with increasing batch size. Our methodology thus establishes a general, data-driven framework for discovering and interpreting non-equilibrium dynamics.","authors":["Aiqing Zhu","Beatrice W. Soh","Grigorios A. Pavliotis","Qianxiao Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19998v1","updated":"2025-11-25T07:04:44Z","published":"2025-11-25T07:04:44Z","title":"REWA: Witness-Overlap Theory -- Foundations for Composable Binary Similarity Systems","summary":"REWA introduces a general theory of similarity based on witness-overlap structures. We show that whenever similarity between concepts can be expressed as monotone witness overlap -- whether arising from graph neighborhoods, causal relations, temporal structure, topological features, symbolic patterns, or embedding-based neighborhoods -- it admits a reduction to compact encodings with provable ranking preservation guarantees. REWA systems consist of: (1) finite witness sets $W(v)$, (2) semi-random bit assignments generated from each witness, and (3) monotonicity of expected similarity in the overlap $Δ(u, v) = |W(u) \\cap W(v)|$. We prove that under an overlap-gap condition on the final witness sets -- independent of how they were constructed -- top-$k$ rankings are preserved using $m = O(\\log(|V|/δ))$ bits. The witness-set formulation is compositional: any sequence of structural, temporal, causal, topological, information-theoretic, or learned transformations can be combined into pipelines that terminate in discrete witness sets. The theory applies to the final witness overlap, enabling modular construction of similarity systems from reusable primitives. This yields a vast design space: millions of composable similarity definitions inherit logarithmic encoding complexity. REWA subsumes and unifies Bloom filters, minhash, LSH bitmaps, random projections, sketches, and hierarchical filters as special cases. It provides a principled foundation for similarity systems whose behavior is governed by witness overlap rather than hash-function engineering. This manuscript presents the axioms, the main reducibility theorem, complete proofs with explicit constants, and a detailed discussion of compositional design, limitations, and future extensions including multi-bit encodings, weighted witnesses, and non-set representations.","authors":["Nikit Phadke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19996v1","updated":"2025-11-25T07:02:56Z","published":"2025-11-25T07:02:56Z","title":"RankOOD - Class Ranking-based Out-of-Distribution Detection","summary":"We propose RankOOD, a rank-based Out-of-Distribution (OOD) detection approach based on training a model with the Placket-Luce loss, which is now extensively used for preference alignment tasks in foundational models. Our approach is based on the insight that with a deep learning model trained using the Cross Entropy Loss, in-distribution (ID) class prediction induces a ranking pattern for each ID class prediction. The RankOOD framework formalizes the insight by first extracting a rank list for each class using an initial classifier and then uses another round of training with the Plackett-Luce loss, where the class rank, a fixed permutation for each class, is the predicted variable. An OOD example may get assigned with high probability to an ID example, but the probability of it respecting the ranking classification is likely to be small. RankOOD, achieves SOTA performance on the near-ODD TinyImageNet evaluation benchmark, reducing FPR95 by 4.3%.","authors":["Dishanika Denipitiyage","Naveen Karunanayake","Suranga Seneviratne","Sanjay Chawla"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.04774v3","updated":"2025-11-25T07:01:57Z","published":"2025-11-06T19:48:53Z","title":"SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud Microservices","summary":"Large-scale networked services rely on deep soft-ware stacks and microservice orchestration, which increase instruction footprints and create frontend stalls that inflate tail latency and energy. We revisit instruction prefetching for these cloud workloads and present a design that aligns with SLO driven and self optimizing systems. Building on the Entangling Instruction Prefetcher (EIP), we introduce a Compressed Entry that captures up to eight destinations around a base using 36 bits by exploiting spatial clustering, and a Hierarchical Metadata Storage scheme that keeps only L1 resident and frequently queried entries on chip while virtualizing bulk metadata into lower levels. We further add a lightweight Online ML Controller that scores prefetch profitability using context features and a bandit adjusted threshold. On data center applications, our approach preserves EIP like speedups with smaller on chip state and improves efficiency for networked services in the ML era.","authors":["Zerui Bao","Di Zhu","Liu Jiang","Shiqi Sheng","Ziwei Wang","Haoyun Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19986v1","updated":"2025-11-25T06:54:04Z","published":"2025-11-25T06:54:04Z","title":"On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on Edge Devices","summary":"Sparsity is essential for deploying large models on resource constrained edge platforms. However, optimizing sparsity patterns for individual tasks in isolation ignores the significant I/O overhead incurred during frequent task switching. We introduce an on-demand multi-task sparsity framework specifically designed to minimize switching costs by maximizing parameter reuse. Unlike monolithic approaches, we decompose weights into reusable block-granular units and align sparse structures across tasks to maximize overlap. By dynamically loading only the small differential set of blocks required for the next task, our method effectively mitigates the cold-start latency inherent in traditional monolithic approaches.Experiments on a real-world autonomous driving platform demonstrate that our framework achieves superior switching efficiency, accelerating task switching by over 6.6X on average compared to existing sparsity methods.","authors":["Lianming Huang","Haibo Hu","Qiao Li","Nan Guan","Chun Jason Xue"],"pdf_url":"","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2511.20650v1","updated":"2025-11-25T18:59:53Z","published":"2025-11-25T18:59:53Z","title":"MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities","summary":"Traditional object detection models in medical imaging operate within a closed-set paradigm, limiting their ability to detect objects of novel labels. Open-vocabulary object detection (OVOD) addresses this limitation but remains underexplored in medical imaging due to dataset scarcity and weak text-image alignment. To bridge this gap, we introduce MedROV, the first Real-time Open Vocabulary detection model for medical imaging. To enable open-vocabulary learning, we curate a large-scale dataset, Omnis, with 600K detection samples across nine imaging modalities and introduce a pseudo-labeling strategy to handle missing annotations from multi-source datasets. Additionally, we enhance generalization by incorporating knowledge from a large pre-trained foundation model. By leveraging contrastive learning and cross-modal representations, MedROV effectively detects both known and novel structures. Experimental results demonstrate that MedROV outperforms the previous state-of-the-art foundation model for medical image detection with an average absolute improvement of 40 mAP50, and surpasses closed-set detectors by more than 3 mAP50, while running at 70 FPS, setting a new benchmark in medical detection. Our source code, dataset, and trained model are available at https://github.com/toobatehreem/MedROV.","authors":["Tooba Tehreem Sheikh","Jean Lahoud","Rao Muhammad Anwer","Fahad Shahbaz Khan","Salman Khan","Hisham Cholakkal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20640v1","updated":"2025-11-25T18:57:25Z","published":"2025-11-25T18:57:25Z","title":"MotionV2V: Editing Motion in a Video","summary":"While generative video models have achieved remarkable fidelity and consistency, applying these capabilities to video editing remains a complex challenge. Recent research has explored motion controllability as a means to enhance text-to-video generation or image animation; however, we identify precise motion control as a promising yet under-explored paradigm for editing existing videos. In this work, we propose modifying video motion by directly editing sparse trajectories extracted from the input. We term the deviation between input and output trajectories a \"motion edit\" and demonstrate that this representation, when coupled with a generative backbone, enables powerful video editing capabilities. To achieve this, we introduce a pipeline for generating \"motion counterfactuals\", video pairs that share identical content but distinct motion, and we fine-tune a motion-conditioned video diffusion architecture on this dataset. Our approach allows for edits that start at any timestamp and propagate naturally. In a four-way head-to-head user study, our model achieves over 65 percent preference against prior work. Please see our project page: https://ryanndagreat.github.io/MotionV2V","authors":["Ryan Burgert","Charles Herrmann","Forrester Cole","Michael S Ryoo","Neal Wadhwa","Andrey Voynov","Nataniel Ruiz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20639v1","updated":"2025-11-25T18:56:57Z","published":"2025-11-25T18:56:57Z","title":"Latent Collaboration in Multi-Agent Systems","summary":"Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.","authors":["Jiaru Zou","Xiyuan Yang","Ruizhong Qiu","Gaotang Li","Katherine Tieu","Pan Lu","Ke Shen","Hanghang Tong","Yejin Choi","Jingrui He","James Zou","Mengdi Wang","Ling Yang"],"pdf_url":"","comment":"Project: https://github.com/Gen-Verse/LatentMAS"},{"id":"http://arxiv.org/abs/2511.20629v1","updated":"2025-11-25T18:49:21Z","published":"2025-11-25T18:49:21Z","title":"MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models","summary":"Reinforcement learning from human feedback (RLHF) with reward models has advanced alignment of generative models to human aesthetic and perceptual preferences. However, jointly optimizing multiple rewards often incurs an alignment tax, improving one dimension while degrading others. To address this, we introduce two complementary methods: MapReduce LoRA and Reward-aware Token Embedding (RaTE). MapReduce LoRA trains preference-specific LoRA experts in parallel and iteratively merges them to refine a shared base model; RaTE learns reward-specific token embeddings that compose at inference for flexible preference control. Experiments on Text-to-Image generation (Stable Diffusion 3.5 Medium and FLUX.1-dev) show improvements of 36.1%, 4.6%, and 55.7%, and 32.7%, 4.3%, and 67.1% on GenEval, PickScore, and OCR, respectively. On Text-to-Video generation (HunyuanVideo), visual and motion quality improve by 48.1% and 90.0%, respectively. On the language task, Helpful Assistant, with Llama-2 7B, helpful and harmless improve by 43.4% and 136.7%, respectively. Our framework sets a new state-of-the-art multi-preference alignment recipe across modalities.","authors":["Chieh-Yun Chen","Zhonghao Wang","Qi Chen","Zhifan Ye","Min Shi","Yue Zhao","Yinan Zhao","Hui Qu","Wei-An Lin","Yiru Shen","Ajinkya Kale","Irfan Essa","Humphrey Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20627v1","updated":"2025-11-25T18:48:19Z","published":"2025-11-25T18:48:19Z","title":"Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems","summary":"The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.","authors":["Anastasia Mavridou","Divya Gopinath","Corina S. Păsăreanu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20626v1","updated":"2025-11-25T18:48:05Z","published":"2025-11-25T18:48:05Z","title":"ROOT: Robust Orthogonalized Optimizer for Neural Network Training","summary":"The optimization of large language models (LLMs) remains a critical challenge, particularly as model scaling exacerbates sensitivity to algorithmic imprecision and training instability. Recent advances in optimizers have improved convergence efficiency through momentum orthogonalization, but suffer from two key robustness limitations: dimensional fragility in orthogonalization precision and vulnerability to outlier-induced noise. To address these robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer that enhances training stability through dual robustness mechanisms. First, we develop a dimension-robust orthogonalization scheme using adaptive Newton iterations with fine-grained coefficients tailored to specific matrix sizes, ensuring consistent precision across diverse architectural configurations. Second, we introduce an optimization-robust framework via proximal optimization that suppresses outlier noise while preserving meaningful gradient directions. Extensive experiments demonstrate that ROOT achieves significantly improved robustness, with faster convergence and superior final performance compared to both Muon and Adam-based optimizers, particularly in noisy and non-convex scenarios. Our work establishes a new paradigm for developing robust and precise optimizers capable of handling the complexities of modern large-scale model training. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/ROOT.","authors":["Wei He","Kai Han","Hang Zhou","Hanting Chen","Zhicheng Liu","Xinghao Chen","Yunhe Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20623v1","updated":"2025-11-25T18:46:14Z","published":"2025-11-25T18:46:14Z","title":"Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development","summary":"The widespread use of Large Language Models (LLMs) raises critical concerns regarding the unauthorized inclusion of copyrighted content in training data. Existing detection frameworks, such as DE-COP, are computationally intensive, and largely inaccessible to independent creators. As legal scrutiny increases, there is a pressing need for a scalable, transparent, and user-friendly solution. This paper introduce an open-source copyright detection platform that enables content creators to verify whether their work was used in LLM training datasets. Our approach enhances existing methodologies by facilitating ease of use, improving similarity detection, optimizing dataset validation, and reducing computational overhead by 10-30% with efficient API calls. With an intuitive user interface and scalable backend, this framework contributes to increasing transparency in AI development and ethical compliance, facilitating the foundation for further research in responsible AI development and copyright enforcement.","authors":["David Szczecina","Senan Gaffori","Edmond Li"],"pdf_url":"","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.20621v1","updated":"2025-11-25T18:44:22Z","published":"2025-11-25T18:44:22Z","title":"DiFR: Inference Verification Despite Nondeterminism","summary":"As demand for LLM inference grows, it is becoming increasingly important that providers and their customers can verify that inference processes are performed correctly, without errors or tampering. However, re-running the same inference process twice often leads to different results due to benign numerical noise, making it difficult to distinguish legitimate variation from actual problems. To address this problem, we introduce Token-DiFR (Token-Divergence-From-Reference), a method for verifying inference outputs by comparing generated tokens against predictions made by a trusted reference implementation conditioned on the same random seed. Sampling seed synchronization tightly constrains valid outputs, leaving providers minimal room to deviate from correct inference, which allows output tokens themselves to serve as auditable evidence of correctness at zero additional cost to the provider. Token-DiFR reliably identifies sampling errors, simulated bugs, and model quantization, detecting 4-bit quantization with AUC $>$ 0.999 within 300 output tokens. For applications requiring sample-efficient forward-pass verification, we additionally introduce Activation-DiFR, a scheme that uses random orthogonal projections to compress activations into compact fingerprints for subsequent verification. Activation-DiFR detects 4-bit quantization with AUC $>$ 0.999 using just 2 output tokens, while reducing communication overhead by 25-75% relative to existing methods. We release an open-source integration with vLLM to accelerate practical deployment of verifiable inference.","authors":["Adam Karvonen","Daniel Reuter","Roy Rinberg","Luke Marks","Adrià Garriga-Alonso","Keri Warr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.14993v3","updated":"2025-11-25T18:43:50Z","published":"2024-09-23T13:16:09Z","title":"Multi-modal Generative AI: Multi-modal LLMs, Diffusions, and the Unification","summary":"Multi-modal generative AI (Artificial Intelligence) has attracted increasing attention from both academia and industry. Particularly, two dominant families of techniques have emerged: i) Multi-modal large language models (LLMs) demonstrate impressive ability for multi-modal understanding; and ii) Diffusion models exhibit remarkable multi-modal powers in terms of multi-modal generation. Therefore, this paper provides a comprehensive overview of multi-modal generative AI, including multi-modal LLMs, diffusions, and the unification for understanding and generation. To lay a solid foundation for unified models, we first provide a detailed review of both multi-modal LLMs and diffusion models respectively, including their probabilistic modeling procedure, multi-modal architecture design, and advanced applications to image/video LLMs as well as text-to-image/video generation. Furthermore, we explore the emerging efforts toward unified models for understanding and generation. To achieve the unification of understanding and generation, we investigate key designs including autoregressive-based and diffusion-based modeling, as well as dense and Mixture-of-Experts (MoE) architectures. We then introduce several strategies for unified models, analyzing their potential advantages and disadvantages. In addition, we summarize the common datasets widely used for multi-modal generative AI pretraining. Last but not least, we present several challenging future research directions which may contribute to the ongoing advancement of multi-modal generative AI.","authors":["Xin Wang","Yuwei Zhou","Bin Huang","Hong Chen","Wenwu Zhu"],"pdf_url":"","comment":"21 pages, 10 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.20615v1","updated":"2025-11-25T18:40:48Z","published":"2025-11-25T18:40:48Z","title":"Evaluating the Performance of Deep Learning Models in Whole-body Dynamic 3D Posture Prediction During Load-reaching Activities","summary":"This study aimed to explore the application of deep neural networks for whole-body human posture prediction during dynamic load-reaching activities. Two time-series models were trained using bidirectional long short-term memory (BLSTM) and transformer architectures. The dataset consisted of 3D full-body plug-in gait dynamic coordinates from 20 normal-weight healthy male individuals each performing 204 load-reaching tasks from different load positions while adapting various lifting and handling techniques. The model inputs consisted of the 3D position of the hand-load position, lifting (stoop, full-squat and semi-squat) and handling (one- and two-handed) techniques, body weight and height, and the 3D coordinate data of the body posture from the first 25% of the task duration. These inputs were used by the models to predict body coordinates during the remaining 75% of the task period. Moreover, a novel method was proposed to improve the accuracy of the previous and present posture prediction networks by enforcing constant body segment lengths through the optimization of a new cost function. The results indicated that the new cost function decreased the prediction error of the models by approximately 8% and 21% for the arm and leg models, respectively. We indicated that utilizing the transformer architecture, with a root-mean-square-error of 47.0 mm, exhibited ~58% more accurate long-term performance than the BLSTM-based model. This study merits the use of neural networks that capture time series dependencies in 3D motion frames, providing a unique approach for understanding and predict motion dynamics during manual material handling activities.","authors":["Seyede Niloofar Hosseini","Ali Mojibi","Mahdi Mohseni","Navid Arjmand","Alireza Taheri"],"pdf_url":"","comment":"10 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2511.20613v1","updated":"2025-11-25T18:40:22Z","published":"2025-11-25T18:40:22Z","title":"Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning","summary":"The rapid proliferation of Large Language Models (LLMs) has revolutionized AI-assisted code generation. This rapid development of LLMs has outpaced our ability to properly benchmark them. Prevailing benchmarks emphasize unit-test pass rates and syntactic correctness. Such metrics understate the difficulty of many real-world problems that require planning, optimization, and strategic interaction. We introduce a multi-agent reasoning-driven benchmark based on a real-world logistics optimization problem (Auction, Pickup, and Delivery Problem) that couples competitive auctions with capacity-constrained routing. The benchmark requires building agents that can (i) bid strategically under uncertainty and (ii) optimize planners that deliver tasks while maximizing profit. We evaluate 40 LLM-coded agents (by a wide range of state-of-the-art LLMs under multiple prompting methodologies, including vibe coding) against 17 human-coded agents developed before the advent of LLMs. Our results over 12 double all-play-all tournaments and $\\sim 40$k matches demonstrate (i) a clear superiority of human(graduate students)-coded agents: the top 5 spots are consistently won by human-coded agents, (ii) the majority of LLM-coded agents (33 out of 40) are beaten by very simple baselines, and (iii) given the best human solution as an input and prompted to improve upon, the best performing LLM makes the solution significantly worse instead of improving it. Our results highlight a gap in LLMs' ability to produce code that works competitively in the real-world, and motivate new evaluations that emphasize reasoning-driven code synthesis in real-world scenarios.","authors":["Panayiotis Danassis","Naman Goel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20610v1","updated":"2025-11-25T18:37:55Z","published":"2025-11-25T18:37:55Z","title":"Building a Foundation Model for Trajectory from Scratch","summary":"Foundation models are transformative in artificial intelligence, but building them from scratch, especially for mobility trajectories, is not yet clear or documented. This tutorial bridges this gap by demonstrating the steps and code of a minimal implementation of a trajectory-focused foundation model starting from GPT-2. Through a concise, step-by-step, code-driven process, we demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare representative trajectory foundation models, such as TrajFM and TrajGPT, highlighting their architectural innovations and differences. Additionally, we introduce complementary techniques from related domains, like TimesFM's patching approach. Targeted at researchers and practitioners, this tutorial aims to explain the concepts and terminology of foundation models, at the implementation level. We find it timely and indispensable to create this educational material in order to support the SIGSPATIAL community in building and evaluating mobility foundation models, enhancing both research clarity and peer-review effectiveness in mobility AI.","authors":["Gaspard Merten","Mahmoud Sakr","Gilles Dejaegere"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20604v1","updated":"2025-11-25T18:33:24Z","published":"2025-11-25T18:33:24Z","title":"On Evaluating LLM Alignment by Evaluating LLMs as Judges","summary":"Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.","authors":["Yixin Liu","Pengfei Liu","Arman Cohan"],"pdf_url":"","comment":"NeurIPS 2025 Camera Ready"},{"id":"http://arxiv.org/abs/2511.20601v1","updated":"2025-11-25T18:30:55Z","published":"2025-11-25T18:30:55Z","title":"The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to Autocorrelation in Blood Glucose Forecasting","summary":"Deep sequence models for blood glucose forecasting consistently fail to leverage clinically informative drivers--insulin, meals, and activity--despite well-understood physiological mechanisms. We term this Driver-Blindness and formalize it via $Δ_{\\text{drivers}}$, the performance gain of multivariate models over matched univariate baselines. Across the literature, $Δ_{\\text{drivers}}$ is typically near zero. We attribute this to three interacting factors: architectural biases favoring autocorrelation (C1), data fidelity gaps that render drivers noisy and confounded (C2), and physiological heterogeneity that undermines population-level models (C3). We synthesize strategies that partially mitigate Driver-Blindness--including physiological feature encoders, causal regularization, and personalization--and recommend that future work routinely report $Δ_{\\text{drivers}}$ to prevent driver-blind models from being considered state-of-the-art.","authors":["Heman Shakeri"],"pdf_url":"","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2511.20597v1","updated":"2025-11-25T18:28:35Z","published":"2025-11-25T18:28:35Z","title":"BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents","summary":"The integration of artificial intelligence (AI) agents into web browsers introduces security challenges that go beyond traditional web application threat models. Prior work has identified prompt injection as a new attack vector for web agents, yet the resulting impact within real-world environments remains insufficiently understood.\n  In this work, we examine the landscape of prompt injection attacks and synthesize a benchmark of attacks embedded in realistic HTML payloads. Our benchmark goes beyond prior work by emphasizing injections that can influence real-world actions rather than mere text outputs, and by presenting attack payloads with complexity and distractor frequency similar to what real-world agents encounter. We leverage this benchmark to conduct a comprehensive empirical evaluation of existing defenses, assessing their effectiveness across a suite of frontier AI models. We propose a multi-layered defense strategy comprising both architectural and model-based defenses to protect against evolving prompt injection attacks. Our work offers a blueprint for designing practical, secure web agents through a defense-in-depth approach.","authors":["Kaiyuan Zhang","Mark Tenenholtz","Kyle Polley","Jerry Ma","Denis Yarats","Ninghui Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20590v1","updated":"2025-11-25T18:19:40Z","published":"2025-11-25T18:19:40Z","title":"EnergyTwin: A Multi-Agent System for Simulating and Coordinating Energy Microgrids","summary":"Microgrids are deployed to reduce purchased grid energy, limit exposure to volatile tariffs, and ensure service continuity during disturbances. This requires coordinating heterogeneous distributed energy resources across multiple time scales and under variable conditions. Among existing tools, typically, power-system simulators capture physical behaviour but assume centralized control, while multi-agent frameworks model decentralized decision-making but represent energy with no physical grounding. In this context, the EnergyTwin is introduced, an agent-based microgrid simulation environment that couples physically grounded models with forecast-informed, rolling-horizon planning, and negotiations. Each asset is modeled as an agent, interacting with a central agent that obtains forecasts, formulates predictions, and allocates energy through contract-based interactions. EnergyTwin targets tertiary-layer decision making and is extensible for digital-twin use. Its feasibility was evaluated in a university campus microgrid scenario where multiple planning strategies were compared. Achieved results show that forecast-driven rolling-horizon planning increases local energy self-sufficiency, maintains higher battery reserves, and reduces exposure to low-resilience operating states. They demonstrate also potential of EnergyTwin as platform supporting research on resilient, negotiation-driven microgrids.","authors":["Jakub Muszyński","Ignacy Walużenicz","Patryk Zan","Zofia Wrona","Maria Ganzha","Marcin Paprzycki","Costin Bădică"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20586v1","updated":"2025-11-25T18:15:36Z","published":"2025-11-25T18:15:36Z","title":"PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic","summary":"Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \\emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \\emph{Trust Nodes} and \\emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \\emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \\emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.","authors":["Koffi Ismael Ouattara","Ioannis Krontiris","Theo Dimitrakos","Dennis Eisermann","Frank Kargl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20570v1","updated":"2025-11-25T18:05:05Z","published":"2025-11-25T18:05:05Z","title":"Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics","summary":"Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.","authors":["Tasha Kim","Oiwi Parker Jones"],"pdf_url":"","comment":"Embodied and Safe-Assured Robotic Systems workshop at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20551v1","updated":"2025-11-25T17:48:04Z","published":"2025-11-25T17:48:04Z","title":"Time-Domain Linear Model-based Framework for Passive Acoustic Mapping of Cavitation Activity","summary":"Passive acoustic mapping enables the spatial mapping and temporal monitoring of cavitation activity, playing a crucial role in therapeutic ultrasound applications. Most conventional beamforming methods, whether implemented in the time or frequency domains, suffer from limited axial resolution due to the absence of a reference emission onset time. While frequency-domain methods, the most efficient of which are based on the cross-spectral matrix, require long signals for accurate estimation, time-domain methods typically achieve lower spatial resolution. To address these limitations, we propose a linear model-based beamforming framework fully formulated in the time domain. The linear forward model relates a discretized spatiotemporal distribution of cavitation activity to the temporal signals recorded by a probe, explicitly accounting for time-of-flight delays dictated by the acquisition geometry. This model is then inverted using regularization techniques that exploit prior knowledge of cavitation activity in both spatial and temporal domains. Experimental results show that the proposed framework achieves enhanced or competitive cavitation map quality while using only 20\\% of the data typically required by frequency-domain methods. This highlights the substantial gain in data efficiency and the flexibility of our spatiotemporal regularization to adapt to diverse passive cavitation scenarios, outperforming state-of-the-art techniques.","authors":["Tatiana Gelvez-Barrera","Barbara Nicolas","Denis Kouamé","Bruno Gilles","Adrian Basarab"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20549v1","updated":"2025-11-25T17:47:11Z","published":"2025-11-25T17:47:11Z","title":"Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning","summary":"Diffusion Models have emerged as a leading class of generative models, yet their iterative sampling process remains computationally expensive. Timestep distillation is a promising technique to accelerate generation, but it often requires extensive training and leads to image quality degradation. Furthermore, fine-tuning these distilled models for specific objectives, such as aesthetic appeal or user preference, using Reinforcement Learning (RL) is notoriously unstable and easily falls into reward hacking. In this work, we introduce Flash-DMD, a novel framework that enables fast convergence with distillation and joint RL-based refinement. Specifically, we first propose an efficient timestep-aware distillation strategy that significantly reduces training cost with enhanced realism, outperforming DMD2 with only $2.1\\%$ its training cost. Second, we introduce a joint training scheme where the model is fine-tuned with an RL objective while the timestep distillation training continues simultaneously. We demonstrate that the stable, well-defined loss from the ongoing distillation acts as a powerful regularizer, effectively stabilizing the RL training process and preventing policy collapse. Extensive experiments on score-based and flow matching models show that our proposed Flash-DMD not only converges significantly faster but also achieves state-of-the-art generation quality in the few-step sampling regime, outperforming existing methods in visual quality, human preference, and text-image alignment metrics. Our work presents an effective paradigm for training efficient, high-fidelity, and stable generative models. Codes are coming soon.","authors":["Guanjie Chen","Shirui Huang","Kai Liu","Jianchen Zhu","Xiaoye Qu","Peng Chen","Yu Cheng","Yifu Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20544v1","updated":"2025-11-25T17:44:50Z","published":"2025-11-25T17:44:50Z","title":"New York Smells: A Large Multimodal Dataset for Olfaction","summary":"While olfaction is central to how animals perceive the world, this rich chemical sensory modality remains largely inaccessible to machines. One key bottleneck is the lack of diverse, multimodal olfactory training data collected in natural settings. We present New York Smells, a large dataset of paired image and olfactory signals captured ``in the wild.'' Our dataset contains 7,000 smell-image pairs from 3,500 distinct objects across indoor and outdoor environments, with approximately 70$\\times$ more objects than existing olfactory datasets. Our benchmark has three tasks: cross-modal smell-to-image retrieval, recognizing scenes, objects, and materials from smell alone, and fine-grained discrimination between grass species. Through experiments on our dataset, we find that visual data enables cross-modal olfactory representation learning, and that our learned olfactory representations outperform widely-used hand-crafted features.","authors":["Ege Ozguroglu","Junbang Liang","Ruoshi Liu","Mia Chiquier","Michael DeTienne","Wesley Wei Qian","Alexandra Horowitz","Andrew Owens","Carl Vondrick"],"pdf_url":"","comment":"Project website at https://smell.cs.columbia.edu"},{"id":"http://arxiv.org/abs/2511.20541v1","updated":"2025-11-25T17:42:11Z","published":"2025-11-25T17:42:11Z","title":"Automated Monitoring of Cultural Heritage Artifacts Using Semantic Segmentation","summary":"This paper addresses the critical need for automated crack detection in the preservation of cultural heritage through semantic segmentation. We present a comparative study of U-Net architectures, using various convolutional neural network (CNN) encoders, for pixel-level crack identification on statues and monuments. A comparative quantitative evaluation is performed on the test set of the OmniCrack30k dataset [1] using popular segmentation metrics including Mean Intersection over Union (mIoU), Dice coefficient, and Jaccard index. This is complemented by an out-of-distribution qualitative evaluation on an unlabeled test set of real-world cracked statues and monuments. Our findings provide valuable insights into the capabilities of different CNN- based encoders for fine-grained crack segmentation. We show that the models exhibit promising generalization capabilities to unseen cultural heritage contexts, despite never having been explicitly trained on images of statues or monuments.","authors":["Andrea Ranieri","Giorgio Palmieri","Silvia Biasotti"],"pdf_url":"","comment":"Keywords: Cultural Heritage, Monitoring, Deep Learning, U-Nets, Semantic Segmentation"},{"id":"http://arxiv.org/abs/2511.20540v1","updated":"2025-11-25T17:41:15Z","published":"2025-11-25T17:41:15Z","title":"Proceedings Twentieth Conference on Theoretical Aspects of Rationality and Knowledge","summary":"The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a conference that aims to bring together researchers from a wide variety of fields, including computer science, artificial intelligence, game theory, decision theory, philosophy, logic, linguistics, and cognitive science. Its goal is to further our understanding of interdisciplinary issues involving reasoning about rationality and knowledge.\n  Previous conferences have been held biennially around the world since 1986, on the initiative of Joe Halpern (Cornell University). Topics of interest include, but are not limited to, semantic models for knowledge, belief, uncertainty, awareness, bounded rationality, common sense epistemic reasoning, epistemic logic, epistemic game theory, knowledge and action, applications of reasoning about knowledge and other mental states, belief revision, computational social choice, algorithmic game theory, and foundations of multi-agent systems.\n  Information about TARK is available at http://www.tark.org/.\n  These proceedings contain the papers that have been accepted for presentation at the Twentieth Conference on Theoretical Aspects of Rationality and Knowledge (TARK 2025), held July 14--16, 2025, at Heinrich-Heine-Universität, Düsseldorf, Germany. The conference website can be found at https://ccc.cs.uni-duesseldorf.de/tark-2025/.","authors":["Adam Bjorndahl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20532v1","updated":"2025-11-25T17:34:38Z","published":"2025-11-25T17:34:38Z","title":"MIMIC-MJX: Neuromechanical Emulation of Animal Behavior","summary":"The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.","authors":["Charles Y. Zhang","Yuanjia Yang","Aidan Sirbu","Elliott T. T. Abe","Emil Wärnberg","Eric J. Leonardis","Diego E. Aldarondo","Adam Lee","Aaditya Prasad","Jason Foat","Kaiwen Bian","Joshua Park","Rusham Bhatt","Hutton Saunders","Akira Nagamori","Ayesha R. Thanawalla","Kee Wui Huang","Fabian Plum","Hendrik K. Beck","Steven W. Flavell","David Labonte","Blake A. Richards","Bingni W. Brunton","Eiman Azim","Bence P. Ölveczky","Talmo D. Pereira"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20531v1","updated":"2025-11-25T17:34:32Z","published":"2025-11-25T17:34:32Z","title":"Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models","summary":"Visual Language Models (VLMs) are powerful generative tools but often produce factually in- accurate outputs due to a lack of robust reason- ing capabilities. While extensive research has been conducted on integrating external knowl- edge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seam- lessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leverag- ing structured knowledge graphs for multi-hop verification using image-captioning task to il- lustrate our framework. Our approach enables systematic reasoning across multiple steps, in- cluding visual entity recognition, knowledge graph traversal, and fact-based caption refine- ment. We evaluate the framework using hi- erarchical, triple-based and bullet-point based knowledge representations, analyzing their ef- fectiveness in factual accuracy and logical infer- ence. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions re- vealing key insights into reasoning patterns and failure modes. This work demonstrates the po- tential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.","authors":["Shamima Hossain"],"pdf_url":"","comment":"Accepted as poster at NewInML Workshop ICML, 2025"},{"id":"http://arxiv.org/abs/2511.18780v2","updated":"2025-11-25T17:33:32Z","published":"2025-11-24T05:27:05Z","title":"ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection","summary":"Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation.Our code is available at https://github.com/Ruize-Ma/ConceptGuard.","authors":["Ruize Ma","Minghong Cai","Yilei Jiang","Jiaming Han","Yi Feng","Yingshui Tan","Xiaoyong Zhu","Bo Zhang","Bo Zheng","Xiangyu Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20526v1","updated":"2025-11-25T17:31:25Z","published":"2025-11-25T17:31:25Z","title":"Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam","summary":"Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist Licensing Examination (2017-2021), and to discuss the implications of these performance differences for AI-enabled formative evaluation. Methods: A total of 2,306 multiple-choice (text-only) questions were compiled from official exams, training materials, and public databases. Questions containing tables or images were excluded. Each item was input in its original Chinese format, and model responses were evaluated for exact accuracy. Pearson's Chi-squared test was used to compare overall performance, and Fisher's exact test was applied to year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p < 0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1, particularly in foundational and clinical synthesis modules. While year-by-year multiple-choice performance also favored DeepSeek-R1, this performance gap did not reach statistical significance in any specific unit-year (all p > 0.05). Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and semantic demands of the pharmacist licensure exam. These findings suggest that domain-specific models warrant further investigation for this context, while also reinforcing the necessity of human oversight in legally and ethically sensitive contexts.","authors":["Xinran Wang","Boran Zhu","Shujuan Zhou","Ziwen Long","Dehua Zhou","Shu Zhang"],"pdf_url":"","comment":"15 pages, 4 figures"},{"id":"http://arxiv.org/abs/2310.15074v4","updated":"2025-11-25T17:28:34Z","published":"2023-10-23T16:32:18Z","title":"MGAS: Multi-Granularity Architecture Search for Trade-Off Between Model Effectiveness and Efficiency","summary":"Neural architecture search (NAS) has gained significant traction in automating the design of neural networks. To reduce search time, differentiable architecture search (DAS) reframes the traditional paradigm of discrete candidate sampling and evaluation into a differentiable optimization over a super-net, followed by discretization. However, most existing DAS methods primarily focus on optimizing the coarse-grained operation-level topology, while neglecting finer-grained structures such as filter-level and weight-level patterns. This limits their ability to balance model performance with model size. Additionally, many methods compromise search quality to save memory during the search process. To tackle these issues, we propose Multi-Granularity Differentiable Architecture Search (MG-DARTS), a unified framework which aims to discover both effective and efficient architectures from scratch by comprehensively yet memory-efficiently exploring a multi-granularity search space. Specifically, we improve the existing DAS methods in two aspects. First, we adaptively adjust the retention ratios of searchable units across different granularity levels through adaptive pruning, which is achieved by learning granularity-specific discretization functions along with the evolving architecture. Second, we decompose the super-net optimization and discretization into multiple stages, each operating on a sub-net, and introduce progressive re-evaluation to enable re-pruning and regrowth of previous units, thereby mitigating potential bias. Extensive experiments on CIFAR-10, CIFAR-100 and ImageNet demonstrate that MG-DARTS outperforms other state-of-the-art methods in achieving a better trade-off between model accuracy and parameter efficiency. Codes are available at https://github.com/lxy12357/MG_DARTS.","authors":["Xiaoyun Liu","Divya Saxena","Jiannong Cao","Yuqing Zhao","Penghui Ruan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01772v3","updated":"2025-11-25T17:27:39Z","published":"2025-08-03T14:12:42Z","title":"LoRA-based methods on Unet for transfer learning in Subarachnoid Hematoma Segmentation","summary":"Aneurysmal subarachnoid hemorrhage (SAH) is a life-threatening neurological emergency with mortality rates exceeding 30%. Transfer learning from related hematoma types represents a potentially valuable but underexplored approach. Although Unet architectures remain the gold standard for medical image segmentation due to their effectiveness on limited datasets, Low-Rank Adaptation (LoRA) methods for parameter-efficient transfer learning have been rarely applied to convolutional neural networks in medical imaging contexts. We implemented a Unet architecture pre-trained on computed tomography scans from 124 traumatic brain injury patients across multiple institutions, then fine-tuned on 30 aneurysmal SAH patients from the University of Michigan Health System using 3-fold cross-validation. We developed a novel CP-LoRA method based on tensor CP-decomposition and introduced DoRA variants (DoRA-C, convDoRA, CP-DoRA) that decompose weight matrices into magnitude and directional components. We compared these approaches against existing LoRA methods (LoRA-C, convLoRA) and standard fine-tuning strategies across different modules on a multi-view Unet model. LoRA-based methods consistently outperformed standard Unet fine-tuning. Performance varied by hemorrhage volume, with all methods showing improved accuracy for larger volumes. CP-LoRA achieved comparable performance to existing methods while using significantly fewer parameters. Over-parameterization with higher ranks consistently yielded better performance than strictly low-rank adaptations. This study demonstrates that transfer learning between hematoma types is feasible and that LoRA-based methods significantly outperform conventional Unet fine-tuning for aneurysmal SAH segmentation.","authors":["Cristian Minoccheri","Matthew Hodgman","Haoyuan Ma","Rameez Merchant","Emily Wittrup","Craig Williamson","Kayvan Najarian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05865v2","updated":"2025-11-25T17:27:33Z","published":"2025-11-08T05:38:18Z","title":"CGCE: Classifier-Guided Concept Erasure in Generative Models","summary":"Recent advancements in large-scale generative models have enabled the creation of high-quality images and videos, but have also raised significant safety concerns regarding the generation of unsafe content. To mitigate this, concept erasure methods have been developed to remove undesirable concepts from pre-trained models. However, existing methods remain vulnerable to adversarial attacks that can regenerate the erased content. Moreover, achieving robust erasure often degrades the model's generative quality for safe, unrelated concepts, creating a difficult trade-off between safety and performance. To address this challenge, we introduce Classifier-Guided Concept Erasure (CGCE), an efficient plug-and-play framework that provides robust concept erasure for diverse generative models without altering their original weights. CGCE uses a lightweight classifier operating on text embeddings to first detect and then refine prompts containing undesired concepts. This approach is highly scalable, allowing for multi-concept erasure by aggregating guidance from several classifiers. By modifying only unsafe embeddings at inference time, our method prevents harmful content generation while preserving the model's original quality on benign prompts. Extensive experiments show that CGCE achieves state-of-the-art robustness against a wide range of red-teaming attacks. Our approach also maintains high generative utility, demonstrating a superior balance between safety and performance. We showcase the versatility of CGCE through its successful application to various modern T2I and T2V models, establishing it as a practical and effective solution for safe generative AI.","authors":["Viet Nguyen","Vishal M. Patel"],"pdf_url":"","comment":"26 pages, 17 figures"},{"id":"http://arxiv.org/abs/2503.14421v2","updated":"2025-11-25T17:20:44Z","published":"2025-03-18T16:55:07Z","title":"ExDDV: A New Dataset for Explainable Deepfake Detection in Video","summary":"The ever growing realism and quality of generated videos makes it increasingly harder for humans to spot deepfake content, who need to rely more and more on automatic deepfake detectors. However, deepfake detectors are also prone to errors, and their decisions are not explainable, leaving humans vulnerable to deepfake-based fraud and misinformation. To this end, we introduce ExDDV, the first dataset and benchmark for Explainable Deepfake Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that are manually annotated with text descriptions (to explain the artifacts) and clicks (to point out the artifacts). We evaluate a number of vision-language models on ExDDV, performing experiments with various fine-tuning and in-context learning strategies. Our results show that text and click supervision are both required to develop robust explainable models for deepfake videos, which are able to localize and describe the observed artifacts. Our novel dataset and code to reproduce the results are available at https://github.com/vladhondru25/ExDDV.","authors":["Vlad Hondru","Eduard Hogea","Darian Onchis","Radu Tudor Ionescu"],"pdf_url":"","comment":"Accepted at WACV 2026"},{"id":"http://arxiv.org/abs/2511.20513v1","updated":"2025-11-25T17:19:10Z","published":"2025-11-25T17:19:10Z","title":"DesignPref: Capturing Personal Preferences in Visual Design Generation","summary":"Generative models, such as large language models and text-to-image diffusion models, are increasingly used to create visual designs like user interfaces (UIs) and presentation slides. Finetuning and benchmarking these generative models have often relied on datasets of human-annotated design preferences. Yet, due to the subjective and highly personalized nature of visual design, preference varies widely among individuals. In this paper, we study this problem by introducing DesignPref, a dataset of 12k pairwise comparisons of UI design generation annotated by 20 professional designers with multi-level preference ratings. We found that among trained designers, substantial levels of disagreement exist (Krippendorff's alpha = 0.25 for binary preferences). Natural language rationales provided by these designers indicate that disagreements stem from differing perceptions of various design aspect importance and individual preferences. With DesignPref, we demonstrate that traditional majority-voting methods for training aggregated judge models often do not accurately reflect individual preferences. To address this challenge, we investigate multiple personalization strategies, particularly fine-tuning or incorporating designer-specific annotations into RAG pipelines. Our results show that personalized models consistently outperform aggregated baseline models in predicting individual designers' preferences, even when using 20 times fewer examples. Our work provides the first dataset to study personalized visual design evaluation and support future research into modeling individual design taste.","authors":["Yi-Hao Peng","Jeffrey P. Bigham","Jason Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20510v1","updated":"2025-11-25T17:17:54Z","published":"2025-11-25T17:17:54Z","title":"FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization","summary":"Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a \"vocabulary selection\" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.","authors":["Yuto Suzuki","Paul Awolade","Daniel V. LaBarbera","Farnoush Banaei-Kashani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20507v1","updated":"2025-11-25T17:16:38Z","published":"2025-11-25T17:16:38Z","title":"The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models","summary":"Large language models (LLMs) have emerged as a candidate \"model organism\" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.","authors":["Nathan Roll","Jill Kries","Flora Jin","Catherine Wang","Ann Marie Finley","Meghan Sumner","Cory Shain","Laura Gwilliams"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20500v1","updated":"2025-11-25T17:07:41Z","published":"2025-11-25T17:07:41Z","title":"From One Attack Domain to Another: Contrastive Transfer Learning with Siamese Networks for APT Detection","summary":"Advanced Persistent Threats (APT) pose a major cybersecurity challenge due to their stealth, persistence, and adaptability. Traditional machine learning detectors struggle with class imbalance, high dimensional features, and scarce real world traces. They often lack transferability-performing well in the training domain but degrading in novel attack scenarios. We propose a hybrid transfer framework that integrates Transfer Learning, Explainable AI (XAI), contrastive learning, and Siamese networks to improve cross-domain generalization. An attention-based autoencoder supports knowledge transfer across domains, while Shapley Additive exPlanations (SHAP) select stable, informative features to reduce dimensionality and computational cost. A Siamese encoder trained with a contrastive objective aligns source and target representations, increasing anomaly separability and mitigating feature drift. We evaluate on real-world traces from the DARPA Transparent Computing (TC) program and augment with synthetic attack scenarios to test robustness. Across source to target transfers, the approach delivers improved detection scores with classical and deep baselines, demonstrating a scalable, explainable, and transferable solution for APT detection.","authors":["Sidahmed Benabderrahmane","Talal Rahwan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20497v1","updated":"2025-11-25T17:04:02Z","published":"2025-11-25T17:04:02Z","title":"Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic","summary":"To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.","authors":["Van Tran","Shinan Liu","Tian Li","Nick Feamster"],"pdf_url":"","comment":"14 pages, 13 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2511.20490v1","updated":"2025-11-25T16:56:25Z","published":"2025-11-25T16:56:25Z","title":"MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology","summary":"Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.","authors":["Kiril Vasilev","Alexandre Misrahi","Eeshaan Jain","Phil F Cheng","Petros Liakopoulos","Olivier Michielin","Michael Moor","Charlotte Bunne"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20480v1","updated":"2025-11-25T16:42:12Z","published":"2025-11-25T16:42:12Z","title":"Ranking-Enhanced Anomaly Detection Using Active Learning-Assisted Attention Adversarial Dual AutoEncoders","summary":"Advanced Persistent Threats (APTs) pose a significant challenge in cybersecurity due to their stealthy and long-term nature. Modern supervised learning methods require extensive labeled data, which is often scarce in real-world cybersecurity environments. In this paper, we propose an innovative approach that leverages AutoEncoders for unsupervised anomaly detection, augmented by active learning to iteratively improve the detection of APT anomalies. By selectively querying an oracle for labels on uncertain or ambiguous samples, we minimize labeling costs while improving detection rates, enabling the model to improve its detection accuracy with minimal data while reducing the need for extensive manual labeling. We provide a detailed formulation of the proposed Attention Adversarial Dual AutoEncoder-based anomaly detection framework and show how the active learning loop iteratively enhances the model. The framework is evaluated on real-world imbalanced provenance trace databases produced by the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004\\% of the data. The datasets span multiple operating systems, including Android, Linux, BSD, and Windows, and cover two attack scenarios. The results have shown significant improvements in detection rates during active learning and better performance compared to other existing approaches.","authors":["Sidahmed Benabderrahmane","James Cheney","Talal Rahwan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20471v1","updated":"2025-11-25T16:34:59Z","published":"2025-11-25T16:34:59Z","title":"Universe of Thoughts: Enabling Creative Reasoning with Large Language Models","summary":"Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \\textit{combinational}, \\textit{exploratory}, and \\textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \\textit{Universe of Thoughts} (or \\textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.","authors":["Yuto Suzuki","Farnoush Banaei-Kashani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20470v1","updated":"2025-11-25T16:34:07Z","published":"2025-11-25T16:34:07Z","title":"Efficient and Fast Generative-Based Singing Voice Separation using a Latent Diffusion Model","summary":"Extracting individual elements from music mixtures is a valuable tool for music production and practice. While neural networks optimized to mask or transform mixture spectrograms into the individual source(s) have been the leading approach, the source overlap and correlation in music signals poses an inherent challenge. Also, accessing all sources in the mixture is crucial to train these systems, while complicated. Attempts to address these challenges in a generative fashion exist, however, the separation performance and inference efficiency remain limited. In this work, we study the potential of diffusion models to advance toward bridging this gap, focusing on generative singing voice separation relying only on corresponding pairs of isolated vocals and mixtures for training. To align with creative workflows, we leverage latent diffusion: the system generates samples encoded in a compact latent space, and subsequently decodes these into audio. This enables efficient optimization and faster inference. Our system is trained using only open data. We outperform existing generative separation systems, and level the compared non-generative systems on a list of signal quality measures and on interference removal. We provide a noise robustness study on the latent encoder, providing insights on its potential for the task. We release a modular toolkit for further research on the topic.","authors":["Genís Plaja-Roglans","Yun-Ning Hung","Xavier Serra","Igor Pereira"],"pdf_url":"","comment":"Accepted for oral presentation at IJCNN 2025"},{"id":"http://arxiv.org/abs/2511.20468v1","updated":"2025-11-25T16:33:42Z","published":"2025-11-25T16:33:42Z","title":"DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs","summary":"Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed","authors":["Yuanhao Li","Mingshan Liu","Hongbo Wang","Yiding Zhang","Yifei Ma","Wei Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20459v1","updated":"2025-11-25T16:25:44Z","published":"2025-11-25T16:25:44Z","title":"Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts","summary":"Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.","authors":["Mosab Rezaei","Mina Rajaei Moghadam","Abdul Rahman Shaikh","Hamed Alhoori","Reva Freedman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.00979v2","updated":"2025-11-25T16:18:38Z","published":"2025-06-01T12:20:22Z","title":"IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and Video AIGC Detection","summary":"The rapid development of Artificial Intelligence Generated Content (AIGC) techniques has enabled the creation of high-quality synthetic content, but it also raises significant security concerns. Current detection methods face two major limitations: (1) the lack of multidimensional explainable datasets for generated images and videos. Existing open-source datasets (e.g., WildFake, GenVideo) rely on oversimplified binary annotations, which restrict the explainability and trustworthiness of trained detectors. (2) Prior MLLM-based forgery detectors (e.g., FakeVLM) exhibit insufficiently fine-grained interpretability in their step-by-step reasoning, which hinders reliable localization and explanation. To address these challenges, we introduce Ivy-Fake, the first large-scale multimodal benchmark for explainable AIGC detection. It consists of over 106K richly annotated training samples (images and videos) and 5,000 manually verified evaluation examples, sourced from multiple generative models and real world datasets through a carefully designed pipeline to ensure both diversity and quality. Furthermore, we propose Ivy-xDetector, a reinforcement learning model based on Group Relative Policy Optimization (GRPO), capable of producing explainable reasoning chains and achieving robust performance across multiple synthetic content detection benchmarks. Extensive experiments demonstrate the superiority of our dataset and confirm the effectiveness of our approach. Notably, our method improves performance on GenImage from 86.88% to 96.32%, surpassing prior state-of-the-art methods by a clear margin.","authors":["Changjiang Jiang","Wenhui Dong","Zhonghao Zhang","Chenyang Si","Fengchang Yu","Wei Peng","Xinbin Yuan","Yifei Bi","Ming Zhao","Zian Zhou","Caifeng Shan"],"pdf_url":"","comment":"30 pages"},{"id":"http://arxiv.org/abs/2511.20439v1","updated":"2025-11-25T16:12:32Z","published":"2025-11-25T16:12:32Z","title":"Object-Centric Vision Token Pruning for Vision Language Models","summary":"In Vision Language Models (VLMs), vision tokens are quantity-heavy yet information-dispersed compared with language tokens, thus consume too much unnecessary computation. Pruning redundant vision tokens for high VLM inference efficiency has been continuously studied but all existing methods resort to indirect and non-guaranteed ways. We propose OC-VTP, a direct and guaranteed approach to select the most representative vision tokens for high-efficiency yet accuracy-preserving VLM inference. Our OC-VTP requires merely light-weight pre-training of a small object-centric vision token pruner, which can then be inserted into existing VLMs, without fine-tuning of any models on any datasets. It is gauranteed that the most representative vision tokens are kept by minimizing the error in reconstructing the original unpruned tokens from the selected ones. Across any vision pruning ratios, i.e., inference efficiency, our OC-VTP consistently helps mainstream VLMs to preserve the highest inference accuracy. Our pruning also demonstrates interesting interpretability. Our codes are available at https://github.com/GarryLarry010131/OC-VTP.","authors":["Guangyuan Li","Rongzhen Zhao","Jinhong Deng","Yanbo Wang","Joni Pajarinen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20426v1","updated":"2025-11-25T15:52:58Z","published":"2025-11-25T15:52:58Z","title":"Block Cascading: Training Free Acceleration of Block-Causal Video Models","summary":"Block-causal video generation faces a stark speed-quality trade-off: small 1.3B models manage only 16 FPS while large 14B models crawl at 4.5 FPS, forcing users to choose between responsiveness and quality. Block Cascading significantly mitigates this trade-off through training-free parallelization. Our key insight: future video blocks do not need fully denoised current blocks to begin generation. By starting block generation with partially denoised context from predecessors, we transform sequential pipelines into parallel cascades where multiple blocks denoise simultaneously. With 5 GPUs exploiting temporal parallelism, we achieve ~2x acceleration across all model scales: 1.3B models accelerate from 16 to 30 FPS, 14B models from 4.5 to 12.5 FPS. Beyond inference speed, Block Cascading eliminates overhead from KV-recaching (of ~200ms) during context switches for interactive generation. Extensive evaluations validated against multiple block-causal pipelines demonstrate no significant loss in generation quality when switching from block-causal to Block Cascading pipelines for inference. Project Page: https://hmrishavbandy.github.io/block_cascading_page/","authors":["Hmrishav Bandyopadhyay","Nikhil Pinnaparaju","Rahim Entezari","Jim Scott","Yi-Zhe Song","Varun Jampani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.08015v2","updated":"2025-11-25T15:51:29Z","published":"2025-09-08T23:08:23Z","title":"CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models","summary":"Generative models of 3D cardiovascular anatomy can synthesize informative structures for clinical research and medical device evaluation, but face a trade-off between geometric controllability and realism. We propose CardioComposer: a programmable, inference-time framework for generating multi-class anatomical label maps based on interpretable ellipsoidal primitives. These primitives represent geometric attributes such as the size, shape, and position of discrete substructures. We specifically develop differentiable measurement functions based on voxel-wise geometric moments, enabling loss-based gradient guidance during diffusion model sampling. We demonstrate that these losses can constrain individual geometric attributes in a disentangled manner and provide compositional control over multiple substructures. Finally, we show that our method is compatible with a wide array of anatomical systems containing non-convex substructures, spanning cardiac, vascular, and skeletal organs.","authors":["Karim Kadry","Shoaib Goraya","Ajay Manicka","Abdalla Abdelwahed","Naravich Chutisilp","Farhad Nezami","Elazer Edelman"],"pdf_url":"","comment":"10 pages, 16 figures"},{"id":"http://arxiv.org/abs/2501.17690v4","updated":"2025-11-25T15:50:33Z","published":"2025-01-29T14:58:48Z","title":"Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment","summary":"We introduce a novel segmentation-aware joint training framework called generative reinforcement network (GRN) that integrates segmentation loss feedback to optimize both image generation and segmentation performance in a single stage. An image enhancement technique called segmentation-guided enhancement (SGE) is also developed, where the generator produces images tailored specifically for the segmentation model. Two variants of GRN were also developed, including GRN for sample-efficient learning (GRN-SEL) and GRN for semi-supervised learning (GRN-SSL). GRN's performance was evaluated using a dataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The annotations included six anatomical structures: dermis, superficial fat, superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and muscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up to 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient (DSC) compared to models trained on fully labeled datasets. GRN-SEL alone reduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling requirements by 70%, and GRN-SSL alone by 60%, all while maintaining performance comparable to fully supervised models. These findings suggest the effectiveness of the GRN framework in optimizing segmentation performance with significantly less labeled data, offering a scalable and efficient solution for ultrasound image analysis and reducing the burdens associated with data annotation.","authors":["Zixue Zeng","Xiaoyan Zhao","Matthew Cartier","Tong Yu","Jing Wang","Xin Meng","Zhiyu Sheng","Maryam Satarpour","John M Cormack","Allison Bean","Ryan Nussbaum","Maya Maurer","Emily Landis-Walkenhorst","Dinesh Kumbhare","Kang Kim","Ajay Wasan","Jiantao Pu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20422v1","updated":"2025-11-25T15:48:49Z","published":"2025-11-25T15:48:49Z","title":"VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning","summary":"Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.","authors":["Bo Pang","Chenxi Xu","Jierui Ren","Guoping Wang","Sheng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.23506v3","updated":"2025-11-25T15:47:59Z","published":"2025-10-27T16:40:17Z","title":"Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale Verifier","summary":"The recent advancement of Multimodal Large Language Models (MLLMs) is transforming human-computer interaction (HCI) from surface-level exchanges into more nuanced and emotionally intelligent communication. To realize this shift, emotion understanding becomes essential allowing systems to capture subtle cues underlying user intent. Furthermore, providing faithful explanations for predicted emotions is crucial to ensure interpretability and build user trust. However, current MLLM-based methods often generate emotion explanations that diverge from the target labels and sometimes even contradict their own predicted emotions. This inconsistency poses a critical risk for misunderstanding and erodes reliability in interactive settings. To address this, we propose a novel approach: the Emotional Rationale Verifier (ERV) and an Explanation Reward. Our method guides the model to produce reasoning that is explicitly consistent with the target emotion during multimodal emotion recognition without modifying the model architecture or requiring additional paired video-description annotations. Our method significantly improves faithful explanation-prediction consistency and explanation emotion accuracy on the MAFW and DFEW datasets. Through extensive experiments and human evaluations, we show that our approach not only enhances alignment between explanation and prediction but also empowers MLLMs to deliver emotionally coherent, trustworthy interactions, marking a key step toward truly human-like HCI systems.","authors":["Hyeongseop Rha","Jeong Hun Yeo","Yeonju Kim","Yong Man Ro"],"pdf_url":"","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2511.20418v1","updated":"2025-11-25T15:42:33Z","published":"2025-11-25T15:42:33Z","title":"StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections","summary":"Multi-object tracking (MOT) is one of the most challenging tasks in computer vision, where it is important to correctly detect objects and associate these detections across frames. Current approaches mainly focus on tracking objects in each frame of a video stream, making it almost impossible to run the model under conditions of limited computing resources. To address this issue, we propose StableTrack, a novel approach that stabilizes the quality of tracking on low-frequency detections. Our method introduces a new two-stage matching strategy to improve the cross-frame association between low-frequency detections. We propose a novel Bbox-Based Distance instead of the conventional Mahalanobis distance, which allows us to effectively match objects using the Re-ID model. Furthermore, we integrate visual tracking into the Kalman Filter and the overall tracking pipeline. Our method outperforms current state-of-the-art trackers in the case of low-frequency detections, achieving $\\textit{11.6%}$ HOTA improvement at $\\textit{1}$ Hz on MOT17-val, while keeping up with the best approaches on the standard MOT17, MOT20, and DanceTrack benchmarks with full-frequency detections.","authors":["Matvei Shelukhan","Timur Mamedov","Karina Kvanchiani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20406v1","updated":"2025-11-25T15:34:46Z","published":"2025-11-25T15:34:46Z","title":"Short-Range Oversquashing","summary":"Message Passing Neural Networks (MPNNs) are widely used for learning on graphs, but their ability to process long-range information is limited by the phenomenon of oversquashing. This limitation has led some researchers to advocate Graph Transformers as a better alternative, whereas others suggest that it can be mitigated within the MPNN framework, using virtual nodes or other rewiring techniques.\n  In this work, we demonstrate that oversquashing is not limited to long-range tasks, but can also arise in short-range problems. This observation allows us to disentangle two distinct mechanisms underlying oversquashing: (1) the bottleneck phenomenon, which can arise even in low-range settings, and (2) the vanishing gradient phenomenon, which is closely associated with long-range tasks.\n  We further show that the short-range bottleneck effect is not captured by existing explanations for oversquashing, and that adding virtual nodes does not resolve it. In contrast, transformers do succeed in such tasks, positioning them as the more compelling solution to oversquashing, compared to specialized MPNNs.","authors":["Yaaqov Mishayev","Yonatan Sverdlov","Tal Amir","Nadav Dym"],"pdf_url":"","comment":"Accepted to Learning on Graphs (LoG) 2025. Version identical to the camera-ready paper"},{"id":"http://arxiv.org/abs/2505.12366v4","updated":"2025-11-25T15:34:10Z","published":"2025-05-18T11:08:32Z","title":"DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization","summary":"The recent success and openness of DeepSeek-R1 have brought widespread attention to Group Relative Policy Optimization (GRPO) as a reinforcement learning method for large reasoning models (LRMs). In this work, we analyze the GRPO objective under a binary reward setting and reveal an inherent limitation of question-level difficulty bias. We also identify a connection between GRPO and traditional discriminative methods in supervised learning. Motivated by these insights, we introduce a new Discriminative Constrained Optimization (DisCO) framework for reinforcing LRMs, grounded in the principle of discriminative learning. The main differences between DisCO and GRPO and its recent variants are: (1) it replaces the group relative objective with a discriminative objective defined by a scoring function; (2) it abandons clipping-based surrogates in favor of non-clipping RL surrogate objectives used as scoring functions; (3) it employs a simple yet effective constrained optimization approach to enforce the KL divergence constraint. As a result, DisCO offers notable advantages over GRPO and its variants: (i) it completely eliminates difficulty bias by adopting discriminative objectives; (ii) it addresses the entropy instability in GRPO and its variants through the use of non-clipping scoring functions and a constrained optimization approach, yielding long and stable training dynamics; (iii) it allows the incorporation of advanced discriminative learning techniques to address data imbalance, where a significant number of questions have more negative than positive generated answers during training. Our experiments on enhancing the mathematical reasoning capabilities of SFT-finetuned models show that DisCO significantly outperforms GRPO and its improved variants such as DAPO, achieving average gains of 7\\% over GRPO and 6\\% over DAPO across six benchmark tasks for an 1.5B model.","authors":["Gang Li","Ming Lin","Tomer Galanti","Zhengzhong Tu","Tianbao Yang"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20403v1","updated":"2025-11-25T15:33:00Z","published":"2025-11-25T15:33:00Z","title":"LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework","summary":"Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.","authors":["Andrea Lops","Fedelucio Narducci","Azzurra Ragone","Michelantonio Trizio","Claudio Barto"],"pdf_url":"","comment":"Accepted at 40th IEEE/ACM International Conference on Automated Software Engineering"},{"id":"http://arxiv.org/abs/2511.20399v1","updated":"2025-11-25T15:26:47Z","published":"2025-11-25T15:26:47Z","title":"BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali","summary":"Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.","authors":["Abdullah Al Sefat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26536v2","updated":"2025-11-25T15:21:05Z","published":"2025-09-30T17:09:32Z","title":"OceanGym: A Benchmark Environment for Underwater Embodied Agents","summary":"We introduce OceanGym, the first comprehensive benchmark for ocean underwater embodied agents, designed to advance AI in one of the most demanding real-world environments. Unlike terrestrial or aerial domains, underwater settings present extreme perceptual and decision-making challenges, including low visibility, dynamic ocean currents, making effective agent deployment exceptionally difficult. OceanGym encompasses eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), which integrates perception, memory, and sequential decision-making. Agents are required to comprehend optical and sonar data, autonomously explore complex environments, and accomplish long-horizon objectives under these harsh conditions. Extensive experiments reveal substantial gaps between state-of-the-art MLLM-driven agents and human experts, highlighting the persistent difficulty of perception, planning, and adaptability in ocean underwater environments. By providing a high-fidelity, rigorously designed platform, OceanGym establishes a testbed for developing robust embodied AI and transferring these capabilities to real-world autonomous ocean underwater vehicles, marking a decisive step toward intelligent agents capable of operating in one of Earth's last unexplored frontiers. The code and data are available at https://github.com/OceanGPT/OceanGym.","authors":["Yida Xue","Mingjun Mao","Xiangyuan Ru","Yuqi Zhu","Baochang Ren","Shuofei Qiao","Mengru Wang","Shumin Deng","Xinyu An","Ningyu Zhang","Ying Chen","Huajun Chen"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2510.18866v2","updated":"2025-11-25T15:07:32Z","published":"2025-10-21T17:58:17Z","title":"LightMem: Lightweight and Efficient Memory-Augmented Generation","summary":"Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at https://github.com/zjunlp/LightMem.","authors":["Jizhan Fang","Xinle Deng","Haoming Xu","Ziyan Jiang","Yuqi Tang","Ziwen Xu","Shumin Deng","Yunzhi Yao","Mengru Wang","Shuofei Qiao","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2505.21740v3","updated":"2025-11-25T15:00:53Z","published":"2025-05-27T20:29:50Z","title":"Counterfactual Simulatability of LLM Explanations for Generation Tasks","summary":"LLMs can be unpredictable, as even slight alterations to the prompt can cause the output to change in unexpected ways. Thus, the ability of models to accurately explain their behavior is critical, especially in high-stakes settings. One approach for evaluating explanations is counterfactual simulatability, how well an explanation allows users to infer the model's output on related counterfactuals. Counterfactual simulatability has been previously studied for yes/no question answering tasks. We provide a general framework for extending this method to generation tasks, using news summarization and medical suggestion as example use cases. We find that while LLM explanations do enable users to better predict LLM outputs on counterfactuals in the summarization setting, there is significant room for improvement for medical suggestion. Furthermore, our results suggest that the evaluation for counterfactual simulatability may be more appropriate for skill-based tasks as opposed to knowledge-based tasks.","authors":["Marvin Limpijankit","Yanda Chen","Melanie Subbiah","Nicholas Deas","Kathleen McKeown"],"pdf_url":"","comment":"INLG25"},{"id":"http://arxiv.org/abs/2506.06836v2","updated":"2025-11-25T14:56:02Z","published":"2025-06-07T15:27:30Z","title":"Harnessing Vision-Language Models for Time Series Anomaly Detection","summary":"Time-series anomaly detection (TSAD) has played a vital role in a variety of fields, including healthcare, finance, and sensor-based condition monitoring. Prior methods, which mainly focus on training domain-specific models on numerical data, lack the visual-temporal understanding capacity that human experts have to identify contextual anomalies. To fill this gap, we explore a solution based on vision language models (VLMs). Recent studies have shown the ability of VLMs for visual understanding tasks, yet their direct application to time series has fallen short on both accuracy and efficiency. To harness the power of VLMs for TSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening stage built on a relatively lightweight pre-trained vision encoder, which leverages 2D time series representations to accurately localize candidate anomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal context and VLM's visual understanding capacity to refine the detection upon the candidates provided by ViT4TS. We show that without any time-series training, VLM4TS outperforms time-series pre-trained and from-scratch baselines in most cases, yielding a 24.6% improvement in F1-max score over the best baseline. Moreover, VLM4TS also consistently outperforms existing language model-based TSAD methods and is on average 36x more efficient in token usage.","authors":["Zelin He","Sarah Alnegheimish","Matthew Reimherr"],"pdf_url":"","comment":"Accepted at AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2511.20359v1","updated":"2025-11-25T14:39:17Z","published":"2025-11-25T14:39:17Z","title":"From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations","summary":"Image manipulation localization (IML) faces a fundamental trade-off between minimizing annotation cost and achieving fine-grained localization accuracy. Existing fully-supervised IML methods depend heavily on dense pixel-level mask annotations, which limits scalability to large datasets or real-world deployment.In contrast, the majority of existing weakly-supervised IML approaches are based on image-level labels, which greatly reduce annotation effort but typically lack precise spatial localization. To address this dilemma, we propose BoxPromptIML, a novel weakly-supervised IML framework that effectively balances annotation cost and localization performance. Specifically, we propose a coarse region annotation strategy, which can generate relatively accurate manipulation masks at lower cost. To improve model efficiency and facilitate deployment, we further design an efficient lightweight student model, which learns to perform fine-grained localization through knowledge distillation from a fixed teacher model based on the Segment Anything Model (SAM). Moreover, inspired by the human subconscious memory mechanism, our feature fusion module employs a dual-guidance strategy that actively contextualizes recalled prototypical patterns with real-time observational cues derived from the input. Instead of passive feature extraction, this strategy enables a dynamic process of knowledge recollection, where long-term memory is adapted to the specific context of the current image, significantly enhancing localization accuracy and robustness. Extensive experiments across both in-distribution and out-of-distribution datasets show that BoxPromptIML outperforms or rivals fully-supervised models, while maintaining strong generalization, low annotation cost, and efficient deployment characteristics.","authors":["Zhiqing Guo","Dongdong Xi","Songlin Li","Gaobo Yang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20347v1","updated":"2025-11-25T14:25:19Z","published":"2025-11-25T14:25:19Z","title":"Soft Adaptive Policy Optimization","summary":"Reinforcement learning (RL) plays an increasingly important role in enhancing the reasoning capabilities of large language models (LLMs), yet stable and performant policy optimization remains challenging. Token-level importance ratios often exhibit high variance-a phenomenon exacerbated in Mixture-of-Experts models-leading to unstable updates. Existing group-based policy optimization methods, such as GSPO and GRPO, alleviate this problem via hard clipping, making it difficult to maintain both stability and effective learning. We propose Soft Adaptive Policy Optimization (SAPO), which replaces hard clipping with a smooth, temperature-controlled gate that adaptively attenuates off-policy updates while preserving useful learning signals. Compared with GSPO and GRPO, SAPO is both sequence-coherent and token-adaptive. Like GSPO, SAPO maintains sequence-level coherence, but its soft gating forms a continuous trust region that avoids the brittle hard clipping band used in GSPO. When a sequence contains a few highly off-policy tokens, GSPO suppresses all gradients for that sequence, whereas SAPO selectively down-weights only the offending tokens and preserves the learning signal from the near-on-policy ones, improving sample efficiency. Relative to GRPO, SAPO replaces hard token-level clipping with smooth, temperature-controlled scaling, enabling more informative and stable updates. Empirical results on mathematical reasoning benchmarks indicate that SAPO exhibits improved training stability and higher Pass@1 performance under comparable training budgets. Moreover, we employ SAPO to train the Qwen3-VL model series, demonstrating that SAPO yields consistent performance gains across diverse tasks and different model sizes. Overall, SAPO provides a more reliable, scalable, and effective optimization strategy for RL training of LLMs.","authors":["Chang Gao","Chujie Zheng","Xiong-Hui Chen","Kai Dang","Shixuan Liu","Bowen Yu","An Yang","Shuai Bai","Jingren Zhou","Junyang Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.15236v3","updated":"2025-11-25T14:24:38Z","published":"2024-10-20T00:00:56Z","title":"Jailbreaking and Mitigation of Vulnerabilities in Large Language Models","summary":"Large Language Models (LLMs) have transformed artificial intelligence by advancing natural language understanding and generation, enabling applications across fields beyond healthcare, software engineering, and conversational systems. Despite these advancements in the past few years, LLMs have shown considerable vulnerabilities, particularly to prompt injection and jailbreaking attacks. This review analyzes the state of research on these vulnerabilities and presents available defense strategies. We roughly categorize attack approaches into prompt-based, model-based, multimodal, and multilingual, covering techniques such as adversarial prompting, backdoor injections, and cross-modality exploits. We also review various defense mechanisms, including prompt filtering, transformation, alignment techniques, multi-agent defenses, and self-regulation, evaluating their strengths and shortcomings. We also discuss key metrics and benchmarks used to assess LLM safety and robustness, noting challenges like the quantification of attack success in interactive contexts and biases in existing datasets. Identifying current research gaps, we suggest future directions for resilient alignment strategies, advanced defenses against evolving attacks, automation of jailbreak detection, and consideration of ethical and societal impacts. This review emphasizes the need for continued research and cooperation within the AI community to enhance LLM security and ensure their safe deployment.","authors":["Benji Peng","Keyu Chen","Qian Niu","Ziqian Bi","Ming Liu","Pohsun Feng","Tianyang Wang","Lawrence K. Q. Yan","Yizhu Wen","Yichao Zhang","Caitlyn Heqi Yin","Xinyuan Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11512v2","updated":"2025-11-25T14:24:21Z","published":"2025-10-13T15:19:07Z","title":"LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference","summary":"Intuitive physics understanding in video diffusion models plays an essential role in building general-purpose physically plausible world simulators, yet accurately evaluating such capacity remains a challenging task due to the difficulty in disentangling physics correctness from visual appearance in generation. To the end, we introduce LikePhys, a training-free method that evaluates intuitive physics in video diffusion models by distinguishing physically valid and impossible videos using the denoising objective as an ELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs. By testing on our constructed benchmark of twelve scenarios spanning over four physics domains, we show that our evaluation metric, Plausibility Preference Error (PPE), demonstrates strong alignment with human preference, outperforming state-of-the-art evaluator baselines. We then systematically benchmark intuitive physics understanding in current video diffusion models. Our study further analyses how model design and inference settings affect intuitive physics understanding and highlights domain-specific capacity variations across physical laws. Empirical results show that, despite current models struggling with complex and chaotic dynamics, there is a clear trend of improvement in physics understanding as model capacity and inference settings scale.","authors":["Jianhao Yuan","Fabio Pizzati","Francesco Pinto","Lars Kunze","Ivan Laptev","Paul Newman","Philip Torr","Daniele De Martini"],"pdf_url":"","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2506.04704v5","updated":"2025-11-25T14:16:10Z","published":"2025-06-05T07:26:34Z","title":"HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model","summary":"Despite emerging efforts to enhance the safety of Vision-Language Models (VLMs), current approaches face two main shortcomings. 1) Existing safety-tuning datasets and benchmarks only partially consider how image-text interactions can yield harmful content, often overlooking contextually unsafe outcomes from seemingly benign pairs. This narrow coverage leaves VLMs vulnerable to jailbreak attacks in unseen configurations. 2) Prior methods rely primarily on data-centric tuning, with limited architectural innovations to intrinsically strengthen safety. We address these gaps by introducing a holistic safety dataset and benchmark, \\textbf{HoliSafe}, that spans all five safe/unsafe image-text combinations, providing a more robust basis for both training and evaluation (HoliSafe-Bench). We further propose a novel modular framework for enhancing VLM safety with a visual guard module (VGM) designed to assess the harmfulness of input images for VLMs. This module endows VLMs with a dual functionality: they not only learn to generate safer responses but can also provide an interpretable harmfulness classification to justify their refusal decisions. A significant advantage of this approach is its modularity; the VGM is designed as a plug-in component, allowing for seamless integration with diverse pre-trained VLMs across various scales. Experiments show that Safe-VLM with VGM, trained on our HoliSafe, achieves state-of-the-art safety performance across multiple VLM benchmarks. Additionally, the HoliSafe-Bench itself reveals critical vulnerabilities in existing VLM models. We hope that HoliSafe and VGM will spur further research into robust and interpretable VLM safety, expanding future avenues for multimodal alignment.","authors":["Youngwan Lee","Kangsan Kim","Kwanyong Park","Ilcahe Jung","Soojin Jang","Seanie Lee","Yong-Ju Lee","Sung Ju Hwang"],"pdf_url":"","comment":"Project page: https://youngwanlee.github.io/holisafe"},{"id":"http://arxiv.org/abs/2511.20333v1","updated":"2025-11-25T14:10:44Z","published":"2025-11-25T14:10:44Z","title":"NNGPT: Rethinking AutoML with Large Language Models","summary":"Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.","authors":["Roman Kochnev","Waleed Khalid","Tolgay Atinc Uzun","Xi Zhang","Yashkumar Sanjaybhai Dhameliya","Furui Qin","Chandini Vysyaraju","Raghuvir Duvvuri","Avi Goyal","Dmitry Ignatov","Radu Timofte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20332v1","updated":"2025-11-25T14:09:44Z","published":"2025-11-25T14:09:44Z","title":"3D Motion Perception of Binocular Vision Target with PID-CNN","summary":"This article trained a network for perceiving three-dimensional motion information of binocular vision target, which can provide real-time three-dimensional coordinate, velocity, and acceleration, and has a basic spatiotemporal perception capability. Understood the ability of neural networks to fit nonlinear problems from the perspective of PID. Considered a single-layer neural network as using a second-order difference equation and a nonlinearity to describe a local problem. Multilayer networks gradually transform the raw representation to the desired representation through multiple such combinations. Analysed some reference principles for designing neural networks. Designed a relatively small PID convolutional neural network, with a total of 17 layers and 413 thousand parameters. Implemented a simple but practical feature reuse method by concatenation and pooling. The network was trained and tested using the simulated randomly moving ball datasets, and the experimental results showed that the prediction accuracy was close to the upper limit that the input image resolution can represent. Analysed the experimental results and errors, as well as the existing shortcomings and possible directions for improvement. Finally, discussed the advantages of high-dimensional convolution in improving computational efficiency and feature space utilization. As well as the potential advantages of using PID information to implement memory and attention mechanisms.","authors":["Shi Jiazhao","Pan Pan","Shi Haotian"],"pdf_url":"","comment":"7 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2508.21380v2","updated":"2025-11-25T13:55:48Z","published":"2025-08-29T07:51:45Z","title":"Iterative Inference in a Chess-Playing Neural Network","summary":"Do neural networks build their representations through smooth, gradual refinement, or via more complex computational processes? We investigate this by extending the logit lens to analyze the policy network of Leela Chess Zero, a superhuman chess engine. Although playing strength and puzzle-solving ability improve consistently across layers, capability progression occurs in distinct computational phases with move preferences undergoing continuous reevaluation--move rankings remain poorly correlated with final outputs until late, and correct puzzle solutions found in middle layers are sometimes overridden. This late-layer reversal is accompanied by concept preference analyses showing final layers prioritize safety over aggression, suggesting a mechanism by which heuristic priors can override tactical solutions.","authors":["Elias Sandmann","Sebastian Lapuschkin","Wojciech Samek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20321v1","updated":"2025-11-25T13:54:10Z","published":"2025-11-25T13:54:10Z","title":"Active Inference in Discrete State Spaces from First Principles","summary":"We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.","authors":["Patrick Kenny"],"pdf_url":"","comment":"56 pages"},{"id":"http://arxiv.org/abs/2511.20315v1","updated":"2025-11-25T13:52:46Z","published":"2025-11-25T13:52:46Z","title":"Geometry of Decision Making in Language Models","summary":"Large Language Models (LLMs) show strong generalization across diverse tasks, yet the internal decision-making processes behind their predictions remain opaque. In this work, we study the geometry of hidden representations in LLMs through the lens of \\textit{intrinsic dimension} (ID), focusing specifically on decision-making dynamics in a multiple-choice question answering (MCQA) setting. We perform a large-scale study, with 28 open-weight transformer models and estimate ID across layers using multiple estimators, while also quantifying per-layer performance on MCQA tasks. Our findings reveal a consistent ID pattern across models: early layers operate on low-dimensional manifolds, middle layers expand this space, and later layers compress it again, converging to decision-relevant representations. Together, these results suggest LLMs implicitly learn to project linguistic inputs onto structured, low-dimensional manifolds aligned with task-specific decisions, providing new geometric insights into how generalization and reasoning emerge in language models.","authors":["Abhinav Joshi","Divyanshu Bhatt","Ashutosh Modi"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20312v1","updated":"2025-11-25T13:49:48Z","published":"2025-11-25T13:49:48Z","title":"Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries","summary":"Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.","authors":["Alexander Beiser","Flavio Martinelli","Wulfram Gerstner","Johanni Brea"],"pdf_url":"","comment":"Proceedings of the III edition of the Workshop on Unifying Representations in Neural Models (UniReps 2025)"},{"id":"http://arxiv.org/abs/2410.05130v3","updated":"2025-11-25T13:44:03Z","published":"2024-10-07T15:34:14Z","title":"Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents","summary":"Recent research has explored the use of Large Language Models (LLMs) for tackling complex graph reasoning tasks. However, due to the intricacies of graph structures and the inherent limitations of LLMs in handling long text, current approaches often fail to deliver satisfactory accuracy, even on small-scale graphs and simple tasks. To address these challenges, we introduce GraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent collaboration strategy for explicit and precise graph reasoning. Inspired by distributed graph computation theory, our framework decomposes graph problems into smaller, node-centric tasks that are distributed among multiple agents. The agents collaborate to solve the overall problem, significantly reducing the amount of information and complexity handled by a single LLM, thus enhancing the accuracy of graph reasoning. By simply increasing the number of agents, GraphAgent-Reasoner can efficiently scale to accommodate larger graphs with over 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework demonstrates near-perfect accuracy on polynomial-time graph reasoning tasks, significantly outperforming the best available models, both closed-source and fine-tuned open-source variants. Our framework also demonstrates the capability to handle real-world graph reasoning applications such as webpage importance analysis.","authors":["Yuwei Hu","Runlin Lei","Xinyi Huang","Zhewei Wei","Yongchao Liu"],"pdf_url":"","comment":"Accepted by AAAI 2026 Workshop WMAC"},{"id":"http://arxiv.org/abs/2511.20305v1","updated":"2025-11-25T13:43:44Z","published":"2025-11-25T13:43:44Z","title":"RIS-Assisted Downlink Pinching-Antenna Systems: GNN-Enabled Optimization Approaches","summary":"This paper investigates a reconfigurable intelligent surface (RIS)-assisted multi-waveguide pinching-antenna (PA) system (PASS) for multi-user downlink information transmission, motivated by the unknown impact of the integration of emerging PASS and RIS on wireless communications. First, we formulate sum rate (SR) and energy efficiency (EE) maximization problems in a unified framework, subject to constraints on the movable region of PAs, total power budget, and tunable phase of RIS elements. Then, by leveraging a graph-structured topology of the RIS-assisted PASS, a novel three-stage graph neural network (GNN) is proposed, which learns PA positions based on user locations, and RIS phase shifts according to composite channel conditions at the first two stages, respectively, and finally determines beamforming vectors. Specifically, the proposed GNN is achieved through unsupervised training, together with three implementation strategies for its integration with convex optimization, thus offering trade-offs between inference time and solution optimality. Extensive numerical results are provided to validate the effectiveness of the proposed GNN, and to support its unique attributes of viable generalization capability, good performance reliability, and real-time applicability. Moreover, the impact of key parameters on RIS-assisted PASS is illustrated and analyzed.","authors":["Changpeng He","Yang Lu","Yanqing Xu","Chong-Yung Chi","Bo Ai","Arumugam Nallanathan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20297v1","updated":"2025-11-25T13:34:54Z","published":"2025-11-25T13:34:54Z","title":"Improving Language Agents through BREW","summary":"Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.","authors":["Shashank Kirtania","Param Biyani","Priyanshu Gupta","Yasharth Bajpai","Roshni Iyer","Sumit Gulwani","Gustavo Soares"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20296v1","updated":"2025-11-25T13:31:53Z","published":"2025-11-25T13:31:53Z","title":"Prompting Lipschitz-constrained network for multiple-in-one sparse-view CT reconstruction","summary":"Despite significant advancements in deep learning-based sparse-view computed tomography (SVCT) reconstruction algorithms, these methods still encounter two primary limitations: (i) It is challenging to explicitly prove that the prior networks of deep unfolding algorithms satisfy Lipschitz constraints due to their empirically designed nature. (ii) The substantial storage costs of training a separate model for each setting in the case of multiple views hinder practical clinical applications. To address these issues, we elaborate an explicitly provable Lipschitz-constrained network, dubbed LipNet, and integrate an explicit prompt module to provide discriminative knowledge of different sparse sampling settings, enabling the treatment of multiple sparse view configurations within a single model. Furthermore, we develop a storage-saving deep unfolding framework for multiple-in-one SVCT reconstruction, termed PromptCT, which embeds LipNet as its prior network to ensure the convergence of its corresponding iterative algorithm. In simulated and real data experiments, PromptCT outperforms benchmark reconstruction algorithms in multiple-in-one SVCT reconstruction, achieving higher-quality reconstructions with lower storage costs. On the theoretical side, we explicitly demonstrate that LipNet satisfies boundary property, further proving its Lipschitz continuity and subsequently analyzing the convergence of the proposed iterative algorithms. The data and code are publicly available at https://github.com/shibaoshun/PromptCT.","authors":["Baoshun Shi","Ke Jiang","Qiusheng Lian","Xinran Yu","Huazhu Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.15511v2","updated":"2025-11-25T13:27:15Z","published":"2024-03-22T03:54:04Z","title":"Multiple-Input Auto-Encoder Guided Feature Selection for IoT Intrusion Detection Systems","summary":"While intrusion detection systems (IDSs) benefit from the diversity and generalization of IoT data features, the data diversity (e.g., the heterogeneity and high dimensions of data) also makes it difficult to train effective machine learning models in IoT IDSs. This also leads to potentially redundant/noisy features that may decrease the accuracy of the detection engine in IDSs. This paper first introduces a novel neural network architecture called Multiple-Input Auto-Encoder (MIAE). MIAE consists of multiple sub-encoders that can process inputs from different sources with different characteristics. The MIAE model is trained in an unsupervised learning mode to transform the heterogeneous inputs into lower-dimensional representation, which helps classifiers distinguish between normal behaviour and different types of attacks. To distil and retain more relevant features but remove less important/redundant ones during the training process, we further design and embed a feature selection layer right after the representation layer of MIAE resulting in a new model called MIAEFS. This layer learns the importance of features in the representation vector, facilitating the selection of informative features from the representation vector. The results on three IDS datasets, i.e., NSLKDD, UNSW-NB15, and IDS2017, show the superior performance of MIAE and MIAEFS compared to other methods, e.g., conventional classifiers, dimensionality reduction models, unsupervised representation learning methods with different input dimensions, and unsupervised feature selection models. Moreover, MIAE and MIAEFS combined with the Random Forest (RF) classifier achieve accuracy of 96.5% in detecting sophisticated attacks, e.g., Slowloris. The average running time for detecting an attack sample using RF with the representation of MIAE and MIAEFS is approximate 1.7E-6 seconds, whilst the model size is lower than 1 MB.","authors":["Phai Vu Dinh","Diep N. Nguyen","Dinh Thai Hoang","Quang Uy Nguyen","Eryk Dutkiewicz","Son Pham Bao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20293v1","updated":"2025-11-25T13:25:59Z","published":"2025-11-25T13:25:59Z","title":"Forgetting by Pruning: Data Deletion in Join Cardinality Estimation","summary":"Machine unlearning in learned cardinality estimation (CE) systems presents unique challenges due to the complex distributional dependencies in multi-table relational data. Specifically, data deletion, a core component of machine unlearning, faces three critical challenges in learned CE models: attribute-level sensitivity, inter-table propagation and domain disappearance leading to severe overestimation in multi-way joins. We propose Cardinality Estimation Pruning (CEP), the first unlearning framework specifically designed for multi-table learned CE systems. CEP introduces Distribution Sensitivity Pruning, which constructs semi-join deletion results and computes sensitivity scores to guide parameter pruning, and Domain Pruning, which removes support for value domains entirely eliminated by deletion. We evaluate CEP on state-of-the-art architectures NeuroCard and FACE across IMDB and TPC-H datasets. Results demonstrate CEP consistently achieves the lowest Q-error in multi-table scenarios, particularly under high deletion ratios, often outperforming full retraining. Furthermore, CEP significantly reduces convergence iterations, incurring negligible computational overhead of 0.3%-2.5% of fine-tuning time.","authors":["Chaowei He","Yuanjun Liu","Qingzhi Ma","Shenyuan Ren","Xizhao Luo","Lei Zhao","An Liu"],"pdf_url":"","comment":"AAAI26"},{"id":"http://arxiv.org/abs/2511.20285v1","updated":"2025-11-25T13:13:56Z","published":"2025-11-25T13:13:56Z","title":"SMoG: Schema Matching on Graph","summary":"Schema matching is a critical task in data integration, par- ticularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suf- fer from hallucination and lack of up-to-date domain knowl- edge. Knowledge Graphs (KGs) offer a solution by pro- viding structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iter- ative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question An- swering (KGQA). SMoG enhances explainability and relia- bility by generating human-verifiable query paths while sig- nificantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world med- ical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effec- tiveness and efficiency in KG-augmented schema matching.","authors":["Mingyu Jeon","Jaeyoung Suh","Suwan Cho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20284v1","updated":"2025-11-25T13:11:23Z","published":"2025-11-25T13:11:23Z","title":"Can LLMs Make (Personalized) Access Control Decisions?","summary":"Precise access control decisions are crucial to the security of both traditional applications and emerging agent-based systems. Typically, these decisions are made by users during app installation or at runtime. Due to the increasing complexity and automation of systems, making these access control decisions can add a significant cognitive load on users, often overloading them and leading to suboptimal or even arbitrary access control decisions. To address this problem, we propose to leverage the processing and reasoning capabilities of large language models (LLMs) to make dynamic, context-aware decisions aligned with the user's security preferences. For this purpose, we conducted a user study, which resulted in a dataset of 307 natural-language privacy statements and 14,682 access control decisions made by users. We then compare these decisions against those made by two versions of LLMs: a general and a personalized one, for which we also gathered user feedback on 1,446 of its decisions.\n  Our results show that in general, LLMs can reflect users' preferences well, achieving up to 86\\% accuracy when compared to the decision made by the majority of users. Our study also reveals a crucial trade-off in personalizing such a system: while providing user-specific privacy preferences to the LLM generally improves agreement with individual user decisions, adhering to those preferences can also violate some security best practices. Based on our findings, we discuss design and risk considerations for implementing a practical natural-language-based access control system that balances personalization, security, and utility.","authors":["Friederike Groschupp","Daniele Lain","Aritra Dhar","Lara Magdalena Lazier","Srdjan Čapkun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.16786v2","updated":"2025-11-25T13:07:39Z","published":"2025-10-19T10:32:18Z","title":"More with Less: An Empirical Study of Turn-Control Strategies for Efficient Coding Agents","summary":"LLM-powered coding agents, which operate in iterative loops (turns) to solve software engineering tasks, are becoming increasingly powerful. However, their practical deployment is hindered by significant and unpredictable costs. This challenge arises from a combination of factors: quadratically growing token counts with each turn, the high price of models, the large number of turns required for real-world tasks, and the tendency of agents to take inefficient or unnecessary actions. While existing research focuses on optimizing individual turns, the strategic control of the total number of turns remains an underexplored area for managing agent performance and cost. To address this gap, we conduct a comprehensive empirical study on SWE-bench using three state-of-the-art models and evaluate the impact of three distinct turn-control strategies: an unrestricted baseline, a fixed-turn limit with reminders, and a novel dynamic-turn strategy that grants extensions on-demand. Our findings first reveal a fundamental trade-off in the unrestricted setting, where no single model excels across performance, cost, and turn efficiency. We then show that a fixed-turn limit, specifically at the 75th percentile of the baseline, serves as a \"sweet spot\", substantially reducing costs (by 24%-68%) with minimal impact on solve rates. Most significantly, the dynamic-turn strategy consistently outperforms fixed-limit approaches, achieving comparable or better solve rates while further reducing costs by an additional 12%-24% by intelligently allocating resources only to tasks that need them. This work provides the first systematic analysis of turn-control strategies, offering simple yet effective guidelines for developers to balance cost and efficacy. We demonstrate that dynamic resource allocation is a superior, easy-to-implement approach for deploying powerful yet economically viable coding agents.","authors":["Pengfei Gao","Chao Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20277v1","updated":"2025-11-25T13:05:40Z","published":"2025-11-25T13:05:40Z","title":"HVAdam: A Full-Dimension Adaptive Optimizer","summary":"Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer's ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity\n  , allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad's hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.","authors":["Yiheng Zhang","Shaowu Wu","Yuanzhuo Xu","Jiajun Wu","Shang Xu","Steve Drew","Xiaoguang Niu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20273v1","updated":"2025-11-25T12:59:15Z","published":"2025-11-25T12:59:15Z","title":"Beyond Components: Singular Vector-Based Interpretability of Transformer Circuits","summary":"Transformer-based language models exhibit complex and distributed behavior, yet their internal computations remain poorly understood. Existing mechanistic interpretability methods typically treat attention heads and multilayer perceptron layers (MLPs) (the building blocks of a transformer architecture) as indivisible units, overlooking possibilities of functional substructure learned within them. In this work, we introduce a more fine-grained perspective that decomposes these components into orthogonal singular directions, revealing superposed and independent computations within a single head or MLP. We validate our perspective on widely used standard tasks like Indirect Object Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that previously identified canonical functional heads, such as the name mover, encode multiple overlapping subfunctions aligned with distinct singular directions. Nodes in a computational graph, that are previously identified as circuit elements show strong activation along specific low-rank directions, suggesting that meaningful computations reside in compact subspaces. While some directions remain challenging to interpret fully, our results highlight that transformer computations are more distributed, structured, and compositional than previously assumed. This perspective opens new avenues for fine-grained mechanistic interpretability and a deeper understanding of model internals.","authors":["Areeb Ahmad","Abhinav Joshi","Ashutosh Modi"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2406.12841v4","updated":"2025-11-25T12:43:13Z","published":"2024-06-18T17:57:11Z","title":"Demystifying Higher-Order Graph Neural Networks","summary":"Higher-order graph neural networks (HOGNNs) and the related architectures from Topological Deep Learning are an important class of GNN models that harness polyadic relations between vertices beyond plain edges. They have been used to eliminate issues such as over-smoothing or over-squashing, to significantly enhance the accuracy of GNN predictions, to improve the expressiveness of GNN architectures, and for numerous other goals. A plethora of HOGNN models have been introduced, and they come with diverse neural architectures, and even with different notions of what the \"higher-order\" means. This richness makes it very challenging to appropriately analyze and compare HOGNN models, and to decide in what scenario to use specific ones. To alleviate this, we first design an in-depth taxonomy and a blueprint for HOGNNs. This facilitates designing models that maximize performance. Then, we use our taxonomy to analyze and compare the available HOGNN models. The outcomes of our analysis are synthesized in a set of insights that help to select the most beneficial GNN model in a given scenario, and a comprehensive list of challenges and opportunities for further research into more powerful HOGNNs.","authors":["Maciej Besta","Florian Scheidl","Lukas Gianinazzi","Grzegorz Kwasniewski","Shachar Klaiman","Jürgen Müller","Torsten Hoefler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.13334v5","updated":"2025-11-25T12:39:17Z","published":"2024-10-17T08:46:09Z","title":"BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models","summary":"Although large language models (LLMs) demonstrate impressive proficiency in various tasks, they present potential safety risks, such as `jailbreaks', where malicious inputs can coerce LLMs into generating harmful content bypassing safety alignments. In this paper, we delve into the ethical biases in LLMs and examine how those biases could be exploited for jailbreaks. Notably, these biases result in a jailbreaking success rate in GPT-4o models that differs by 20\\% between non-binary and cisgender keywords and by 16\\% between white and black keywords, even when the other parts of the prompts are identical. We introduce the concept of BiasJailbreak, highlighting the inherent risks posed by these safety-induced biases. BiasJailbreak generates biased keywords automatically by asking the target LLM itself, and utilizes the keywords to generate harmful output. Additionally, we propose an efficient defense method BiasDefense, which prevents jailbreak attempts by injecting defense prompts prior to generation. BiasDefense stands as an appealing alternative to Guard Models, such as Llama-Guard, that require additional inference cost after text generation. Our findings emphasize that ethical biases in LLMs can actually lead to generating unsafe output, and suggest a method to make the LLMs more secure and unbiased. To enable further research and improvements, we open-source our code and artifacts of BiasJailbreak, providing the community with tools to better understand and mitigate safety-induced biases in LLMs.","authors":["Isack Lee","Haebin Seong"],"pdf_url":"","comment":"Accepted as a workshop paper at AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20257v1","updated":"2025-11-25T12:36:27Z","published":"2025-11-25T12:36:27Z","title":"Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling","summary":"Accurate and interpretable air pollution forecasting is crucial for public health, but most models face a trade-off between performance and interpretability. This study proposes a physics-guided, interpretable-by-design spatiotemporal learning framework. The model decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules. The first is a physics-guided transport kernel with directed weights conditioned on wind and geography (advection). The second is an explainable attention mechanism that learns local responses and attributes future concentrations to specific historical lags and exogenous drivers. Evaluated on a comprehensive dataset from the Stockholm region, our model consistently outperforms state-of-the-art baselines across multiple forecasting horizons. Our model's integration of high predictive performance and spatiotemporal interpretability provides a more reliable foundation for operational air-quality management in real-world applications.","authors":["Zhiguo Zhang","Xiaoliang Ma","Daniel Schlesinger"],"pdf_url":"","comment":"Accepted to 2025 IEEE International Conference on Big Data"},{"id":"http://arxiv.org/abs/2511.18958v2","updated":"2025-11-25T12:33:40Z","published":"2025-11-24T10:19:58Z","title":"Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation","summary":"As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation. We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both high- and low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.","authors":["Qisen Chai","Yansong Wang","Junjie Huang","Tao Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20254v1","updated":"2025-11-25T12:29:10Z","published":"2025-11-25T12:29:10Z","title":"XiCAD: Camera Activation Detection in the Da Vinci Xi User Interface","summary":"Purpose: Robot-assisted minimally invasive surgery relies on endoscopic video as the sole intraoperative visual feedback. The DaVinci Xi system overlays a graphical user interface (UI) that indicates the state of each robotic arm, including the activation of the endoscope arm. Detecting this activation provides valuable metadata such as camera movement information, which can support downstream surgical data science tasks including tool tracking, skill assessment, or camera control automation.\n  Methods: We developed a lightweight pipeline based on a ResNet18 convolutional neural network to automatically identify the position of the camera tile and its activation state within the DaVinci Xi UI. The model was fine-tuned on manually annotated data from the SurgToolLoc dataset and evaluated across three public datasets comprising over 70,000 frames.\n  Results: The model achieved F1-scores between 0.993 and 1.000 for the binary detection of active cameras and correctly localized the camera tile in all cases without false multiple-camera detections.\n  Conclusion: The proposed pipeline enables reliable, real-time extraction of camera activation metadata from surgical videos, facilitating automated preprocessing and analysis for diverse downstream applications. All code, trained models, and annotations are publicly available.","authors":["Alexander C. Jenke","Gregor Just","Claas de Boer","Martin Wagner","Sebastian Bodenstedt","Stefanie Speidel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.15577v2","updated":"2025-11-25T12:28:01Z","published":"2025-08-21T13:51:45Z","title":"LFaB: Low fidelity as Bias for Active Learning in the chemical configuration space","summary":"Active learning promises to provide an optimal training sample selection procedure in the construction of machine learning models. It often relies on minimizing the model's variance, which is assumed to decrease the prediction error. Still, it is frequently even less efficient than pure random sampling. Motivated by the bias-variance decomposition, we propose to minimize the model's bias instead of its variance. By doing so, we are able to almost exactly match the best-case error over all possible greedy sample selection procedures for a relevant application. Our bias approximation is based on using cheap to calculate low fidelity data as known from $Δ$-ML or multifidelity machine learning. We exemplify our approach for a wider class of applications in quantum chemistry including predicting excitation energies and ab initio potential energy surfaces. Here, the proposed method reduces training data consumption by up to an order of magnitude compared to standard active learning.","authors":["Vivin Vinod","Peter Zaspel"],"pdf_url":"","comment":"SI included in main"},{"id":"http://arxiv.org/abs/2511.20250v1","updated":"2025-11-25T12:25:20Z","published":"2025-11-25T12:25:20Z","title":"Uplifting Table Tennis: A Robust, Real-World Application for 3D Trajectory and Spin Estimation","summary":"Obtaining the precise 3D motion of a table tennis ball from standard monocular videos is a challenging problem, as existing methods trained on synthetic data struggle to generalize to the noisy, imperfect ball and table detections of the real world. This is primarily due to the inherent lack of 3D ground truth trajectories and spin annotations for real-world video. To overcome this, we propose a novel two-stage pipeline that divides the problem into a front-end perception task and a back-end 2D-to-3D uplifting task. This separation allows us to train the front-end components with abundant 2D supervision from our newly created TTHQ dataset, while the back-end uplifting network is trained exclusively on physically-correct synthetic data. We specifically re-engineer the uplifting model to be robust to common real-world artifacts, such as missing detections and varying frame rates. By integrating a ball detector and a table keypoint detector, our approach transforms a proof-of-concept uplifting method into a practical, robust, and high-performing end-to-end application for 3D table tennis trajectory and spin analysis.","authors":["Daniel Kienzle","Katja Ludwig","Julian Lorenz","Shin'ichi Satoh","Rainer Lienhart"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.18428v2","updated":"2025-11-25T12:20:37Z","published":"2024-12-24T13:42:44Z","title":"Multi-Modal Data Exploration via Language Agents","summary":"International enterprises, organizations, and hospitals collect large amounts of multi-modal data stored in databases, text documents, images, and videos. While there has been recent progress in the separate fields of multi-modal data exploration as well as in database systems that automatically translate natural language questions to database query languages, the research challenge of querying both structured databases and unstructured modalities (e.g., texts, images) in natural language remains largely unexplored. In this paper, we propose M$^2$EX -a system that enables multi-modal data exploration via language agents. Our approach is based on the following research contributions: (1) Our system is inspired by a real-world use case that enables users to explore multi-modal information systems. (2) M$^2$EX leverages an LLM-based agentic AI framework to decompose a natural language question into subtasks such as text-to-SQL generation and image analysis and to orchestrate modality-specific experts in an efficient query plan. (3) Experimental results on multi-modal datasets, encompassing relational data, text, and images, demonstrate that our system outperforms state-of-the-art multi-modal exploration systems, excelling in both accuracy and various performance metrics, including query latency, API costs, and planning efficiency, thanks to the more effective utilization of the reasoning capabilities of LLMs.","authors":["Farhad Nooralahzadeh","Yi Zhang","Jonathan Furst","Kurt Stockinger"],"pdf_url":"","comment":"Accepted to the IJCNLP AACL 2025 Findings"},{"id":"http://arxiv.org/abs/2511.20236v1","updated":"2025-11-25T12:09:36Z","published":"2025-11-25T12:09:36Z","title":"Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints","summary":"Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.","authors":["Szymon Bobek","Łukasz Bałec","Grzegorz J. Nalepa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20234v1","updated":"2025-11-25T12:07:25Z","published":"2025-11-25T12:07:25Z","title":"Leveraging weights signals - Predicting and improving generalizability in reinforcement learning","summary":"Generalizability of Reinforcement Learning (RL) agents (ability to perform on environments different from the ones they have been trained on) is a key problem as agents have the tendency to overfit to their training environments. In order to address this problem and offer a solution to increase the generalizability of RL agents, we introduce a new methodology to predict the generalizability score of RL agents based on the internal weights of the agent's neural networks. Using this prediction capability, we propose some changes in the Proximal Policy Optimization (PPO) loss function to boost the generalization score of the agents trained with this upgraded version. Experimental results demonstrate that our improved PPO algorithm yields agents with stronger generalizability compared to the original version.","authors":["Olivier Moulin","Vincent Francois-lavet","Paul Elbers","Mark Hoogendoorn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20224v1","updated":"2025-11-25T11:53:57Z","published":"2025-11-25T11:53:57Z","title":"DUO-TOK: Dual-Track Semantic Music Tokenizer for Vocal-Accompaniment Generation","summary":"Duo-Tok is a source-aware dual-codebook tokenizer for vocal-accompaniment music that targets the growing tension between reconstruction quality and language-model (LM) learnability in modern lyrics-to-song systems. Existing codecs either prioritize high-fidelity reconstruction with difficult-to-model acoustic tokens or compress aggressively into semantic tokens that are LM-friendly but lossy, and they rarely make the tokenizer itself aware of dual-track structure. Duo-Tok follows a four-stage, SSL-centered pipeline: we first pretrain a BEST-RQ-style encoder on large-scale audio, then stabilize and factorize the representation with Gaussian replacement noise and multi-task supervision, before freezing the encoder to learn SimVQ-based dual codebooks with hard routing for vocals and accompaniment, and finally training latent diffusion decoders on top of the discrete tokens. Duo-Tok at 0.75 kbps shifts the empirical reconstruction-generation Pareto frontier, achieving the best music-tagging AP and the lowest vocabulary-normalized LM perplexity among compared codecs while maintaining reconstruction quality comparable to state-of-the-art music tokenizers.","authors":["Rui Lin","Zhiyue Wu","Jiahe Le","Kangdi Wang","Weixiong Chen","Junyu Dai","Tao Jiang"],"pdf_url":"","comment":"17 pages, 5 figures, 8 tables. Project page: https://eps-acoustic-revolution-lab.github.io/DUO_TOK/"},{"id":"http://arxiv.org/abs/2508.06982v2","updated":"2025-11-25T11:52:52Z","published":"2025-08-09T13:29:39Z","title":"WeatherDiffusion: Controllable Weather Editing in Intrinsic Space","summary":"We present WeatherDiffusion, a diffusion-based framework for controllable weather editing in intrinsic space. Our framework includes two components based on diffusion priors: an inverse renderer that estimates material properties, scene geometry, and lighting as intrinsic maps from an input image, and a forward renderer that utilizes these geometry and material maps along with a text prompt that describes specific weather conditions to generate a final image. The intrinsic maps enhance controllability compared to traditional pixel-space editing approaches.We propose an intrinsic map-aware attention mechanism that improves spatial correspondence and decomposition quality in large outdoor scenes. For forward rendering, we leverage CLIP-space interpolation of weather prompts to achieve fine-grained weather control. We also introduce a synthetic and a real-world dataset, containing 38k and 18k images under various weather conditions, each with intrinsic map annotations. WeatherDiffusion outperforms state-of-the-art pixel-space editing approaches, weather restoration methods, and rendering-based methods, showing promise for downstream tasks such as autonomous driving, enhancing the robustness of detection and segmentation in challenging weather scenarios.","authors":["Yixin Zhu","Zuoliang Zhu","Jian Yang","Miloš Hašan","Jin Xie","Beibei Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.18847v2","updated":"2025-11-25T11:46:58Z","published":"2025-08-26T09:25:32Z","title":"ConfTuner: Training Large Language Models to Express Their Confidence Verbally","summary":"Large Language Models (LLMs) are increasingly deployed in high-stakes domains such as science, law, and healthcare, where accurate expressions of uncertainty are essential for reliability and trust. However, current LLMs are often observed to generate incorrect answers with high confidence, a phenomenon known as \"overconfidence\". Recent efforts have focused on calibrating LLMs' verbalized confidence: i.e., their expressions of confidence in text form, such as \"I am 80% confident that...\". Existing approaches either rely on prompt engineering or fine-tuning with heuristically generated uncertainty estimates, both of which have limited effectiveness and generalizability. Motivated by the notion of proper scoring rules for calibration in classical machine learning models, we introduce ConfTuner, a simple and efficient fine-tuning method that introduces minimal overhead and does not require ground-truth confidence scores or proxy confidence estimates. ConfTuner relies on a new loss function, tokenized Brier score, which we theoretically prove to be a proper scoring rule, intuitively meaning that it \"correctly incentivizes the model to report its true probability of being correct\". ConfTuner improves calibration across diverse reasoning tasks and generalizes to black-box models such as GPT-4o. Our results further show that better-calibrated confidence enables downstream gains in self-correction and model cascade, advancing the development of trustworthy LLM systems. The code is available at https://github.com/liushiliushi/ConfTuner.","authors":["Yibo Li","Miao Xiong","Jiaying Wu","Bryan Hooi"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.20216v1","updated":"2025-11-25T11:42:28Z","published":"2025-11-25T11:42:28Z","title":"CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents","summary":"Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.","authors":["Haebin Seong","Sungmin Kim","Minchan Kim","Yongjun Cho","Myunchul Joe","Suhwan Choi","Jaeyoon Jung","Jiyong Youn","Yoonshik Kim","Samwoo Seong","Yubeen Park","Youngjae Yu","Yunsung Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20211v1","updated":"2025-11-25T11:34:51Z","published":"2025-11-25T11:34:51Z","title":"OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA Generation","summary":"Generative models have excelled in RGB synthesis, but real-world applications require RGBA manipulation. This has led to a fragmented landscape: specialized, single-task models handle alpha but lack versatility, while unified multi-task frameworks are confined to the RGB domain. To bridge this critical gap, we propose OmniAlpha, the first unified, multi-task generative framework for sequence-to-sequence RGBA image generation and editing. Its architecture features MSRoPE-BiL, a novel RoPE method with a bi-directionally extendable layer axis for its Diffusion Transformer (DiT) backbone, enabling the concurrent processing of multiple input and target RGBA layers. To power this framework, we introduce AlphaLayers, a new dataset of 1,000 high-quality, multi-layer triplets, built via a novel automated synthesis and filter pipeline. Jointly training OmniAlpha on this dataset across a comprehensive suite of 21 diverse tasks, extensive experiments demonstrate that our unified approach consistently outperforms strong, specialized baselines. Most notably, OmniAlpha achieves a dramatic 84.8% relative reduction in SAD for mask-free matting on AIM-500 and wins over 90% of human preferences in layer-conditioned completion. Our work proves that a unified, multi-task model can learn a superior shared representation for RGBA, paving the way for more powerful, layer-aware generative systems.","authors":["Hao Yu","Jiabo Zhan","Zile Wang","Jinglin Wang","Huaisong Zhang","Hongyu Li","Xinrui Chen","Yongxian Wei","Chun Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.01423v3","updated":"2025-11-25T11:29:35Z","published":"2024-06-03T15:24:15Z","title":"Value Improved Actor Critic Algorithms","summary":"To learn approximately optimal acting policies for decision problems, modern Actor Critic algorithms rely on deep Neural Networks (DNNs) to parameterize the acting policy and greedification operators to iteratively improve it. The reliance on DNNs suggests an improvement that is gradient based, which is per step much less greedy than the improvement possible by greedier operators such as the greedy update used by Q-learning algorithms. On the other hand, slow changes to the policy can also be beneficial for the stability of the learning process, resulting in a tradeoff between greedification and stability. To better address this tradeoff, we propose to decouple the acting policy from the policy evaluated by the critic. This allows the agent to separately improve the critic's policy (e.g. value improvement) with greedier updates while maintaining the slow gradient-based improvement to the parameterized acting policy. We investigate the convergence of this approach using the popular analysis scheme of generalized Policy Iteration in the finite-horizon domain. Empirically, incorporating value-improvement into the popular off-policy actor-critic algorithms TD3 and SAC significantly improves or matches performance over their respective baselines, across different environments from the DeepMind continuous control domain, with negligible compute and implementation cost.","authors":["Yaniv Oren","Moritz A. Zanger","Pascal R. van der Vaart","Mustafa Mert Celikok","Matthijs T. J. Spaan","Wendelin Bohmer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.15691v3","updated":"2025-11-25T11:27:22Z","published":"2025-10-17T14:35:03Z","title":"Exploring the Synergy of Quantitative Factors and Newsflow Representations from Large Language Models for Stock Return Prediction","summary":"In quantitative investing, return prediction supports various tasks, including stock selection, portfolio optimization, and risk management. Quantitative factors, such as valuation, quality, and growth, capture various characteristics of stocks. Unstructured data, like news and transcripts, has attracted growing attention, driven by recent advances in large language models (LLMs). This paper examines effective methods for leveraging multimodal factors and newsflow in return prediction and stock selection. First, we introduce a fusion learning framework to learn a unified representation from factors and newsflow representations generated by an LLM. Within this framework, we compare three methods of different architectural complexities: representation combination, representation summation, and attentive representations. Next, building on the limitation of fusion learning observed in empirical comparison, we explore the mixture model that adaptively combines predictions made by single modalities and their fusion. To mitigate the training instability of the mixture model, we introduce a decoupled training approach with theoretical insights. Finally, our experiments on real investment universes yield several insights into effective multimodal modeling of factors and news for stock return prediction and selection.","authors":["Tian Guo","Emmanuel Hauptmann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20200v1","updated":"2025-11-25T11:24:14Z","published":"2025-11-25T11:24:14Z","title":"Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025","summary":"This report presents the solution and results of our team MSRA\\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution","authors":["Yitian Huang","Yuxuan Lei","Jianxun Lian","Hao Liao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20196v1","updated":"2025-11-25T11:22:45Z","published":"2025-11-25T11:22:45Z","title":"Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning","summary":"Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but can inadvertently memorize privacy-sensitive information. Although existing unlearning methods can remove such knowledge, they fail to achieve benign forgetting because they often degrade the model's general image understanding performance. To address this, we propose the Sculpted Memory Forgetting Adapter (SMFA), which confines forgetting to targeted memory regions while preserving overall capabilities. SMFA first fine-tunes the model to replace sensitive responses with refusals, yielding a memory forgetting adapter, and then applies a retaining anchor-guided masking mechanism to prevent interference with unrelated knowledge and understanding ability. To systematically evaluate selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark designed to jointly assess the removal of sensitive knowledge and retention of general visual understanding. Extensive experiments show that, unlike prior methods, SMFA achieves precise and controllable unlearning while maintaining the model's foundational image understanding.","authors":["Zhen Zeng","Leijiang Gu","Zhangling Duan","Feng Li","Zenglin Shi","Cees G. M. Snoek","Meng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.14228v3","updated":"2025-11-25T11:20:07Z","published":"2025-03-18T13:05:41Z","title":"Panoramic Distortion-Aware Tokenization for Person Detection and Localization in Overhead Fisheye Images","summary":"Person detection in overhead fisheye images is challenging due to person rotation and small persons. Prior work has mainly addressed person rotation, leaving the small-person problem underexplored. We remap fisheye images to equirectangular panoramas to handle rotation and exploit panoramic geometry to handle small persons more effectively. Conventional detection methods tend to favor larger persons because they dominate the attention maps, causing smaller persons to be missed. In hemispherical equirectangular panoramas, we find that apparent person height decreases approximately linearly with the vertical angle near the top of the image. Using this finding, we introduce panoramic distortion-aware tokenization to enhance the detection of small persons. This tokenization procedure divides panoramic features using self-similar figures that enable the determination of optimal divisions without gaps, and we leverage the maximum significance values in each tile of the token groups to preserve the significance areas of smaller persons. We propose a transformer-based person detection and localization method that combines panoramic-image remapping and the tokenization procedure. Extensive experiments demonstrated that our method outperforms conventional methods on large-scale datasets.","authors":["Nobuhiko Wakai","Satoshi Sato","Yasunori Ishii","Takayoshi Yamashita"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20179v1","updated":"2025-11-25T11:00:39Z","published":"2025-11-25T11:00:39Z","title":"Human-computer interactions predict mental health","summary":"Scalable assessments of mental illness, the leading driver of disability worldwide, remain a critical roadblock toward accessible and equitable care. Here, we show that human-computer interactions encode multiple dimensions of self-reported mental health and their changes over time.\n  We introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA to predict 1.3 million mental-health self-reports from 20,000 cursor and touchscreen recordings recorded in 9,000 online participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, generalizes across contexts, and achieves near-ceiling accuracy when predicting group-level mental health. The model translates from general to clinical populations, identifies individuals living with mental illness, and captures signatures of psychological function that are not conveyed by language.\n  Our results demonstrate how everyday human-computer interactions can power passive, reliable, dynamic, and maximally scalable mental health assessments. The ability to decode mental states at zero marginal cost sets new benchmarks for precision medicine and public health, while raising important questions about privacy, agency, and autonomy online.","authors":["Veith Weilnhammer","Jefferson Ortega","David Whitney"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.08706v3","updated":"2025-11-25T10:51:57Z","published":"2024-11-13T15:50:32Z","title":"Searching Latent Program Spaces","summary":"General intelligence requires systems that acquire new skills efficiently and generalize beyond their training distributions. Although program synthesis approaches have strong generalization power, they face scaling issues due to the large combinatorial spaces that quickly render them impractical, requiring human-generated DSLs or pre-trained priors to narrow this search space. On the other hand, deep learning methods have had high successes, but they lack structured test-time adaptation and rely on heavy stochastic sampling or expensive gradient updates for fine-tuning. In this work, we propose the Latent Program Network (LPN), a novel architecture that builds in test-time search directly into neural models. LPN learns a latent space of implicit programs -- neurally mapping inputs to outputs -- through which it can search using gradients at test time. LPN combines the adaptability of symbolic approaches and the scalability of neural methods. It searches through a compact latent space at test time and bypasses the need for pre-defined domain-specific languages. On a range of programming-by-examples tasks, LPN either outperforms or matches performance compared to in-context learning and test-time training methods. Tested on the ARC-AGI benchmark, we demonstrate that LPN can both learn a compact program space and search through it at test time to adapt to novel tasks. LPN doubles its performance on out-of-distribution tasks when test-time search is switched on.","authors":["Matthew V Macfarlane","Clement Bonnet"],"pdf_url":"","comment":"NeurIPS 2025 spotlight. Code available at https://github.com/clement-bonnet/lpn"},{"id":"http://arxiv.org/abs/2511.20172v1","updated":"2025-11-25T10:51:43Z","published":"2025-11-25T10:51:43Z","title":"Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management","summary":"The rapid increase in LLM model sizes and the growing demand for long-context inference have made memory a critical bottleneck in GPU-accelerated serving systems. Although high-bandwidth memory (HBM) on GPUs offers fast access, its limited capacity necessitates reliance on host memory (CPU DRAM) to support larger working sets such as the KVCache. However, the maximum DRAM capacity is constrained by the limited number of memory channels per CPU socket. To overcome this limitation, current systems often adopt RDMA-based disaggregated memory pools, which introduce significant challenges including high access latency, complex communication protocols, and synchronization overhead. Fortunately, the emerging CXL technology introduces new opportunities in KVCache design. In this paper, we propose Beluga, a novel memory architecture that enables GPUs and CPUs to access a shared, large-scale memory pool through CXL switches. By supporting native load/store access semantics over the CXL fabric, our design delivers near-local memory latency, while reducing programming complexity and minimizing synchronization overhead. We conduct a systematic characterization of a commercial CXL switch-based memory pool and propose a set of design guidelines. Based on Beluga, we design and implement Beluga-KVCache, a system tailored for managing the large-scale KVCache in LLM inference. Beluga-KVCache achieves an 89.6% reduction in Time-To-First-Token (TTFT) and 7.35x throughput improvement in the vLLM inference engine compared to RDMA-based solutions. To the best of our knowledge, Beluga is the first system that enables GPUs to directly access large-scale memory pools through CXL switches, marking a significant step toward low-latency, shared access to vast memory resources by GPUs.","authors":["Xinjun Yang","Qingda Hu","Junru Li","Feifei Li","Yuqi Zhou","Yicong Zhu","Qiuru Lin","Jian Dai","Yang Kong","Jiayu Zhang","Guoqiang Xu","Qiang Liu"],"pdf_url":"","comment":"13 pages, accepted by SIGMOD'26"},{"id":"http://arxiv.org/abs/2511.18491v2","updated":"2025-11-25T10:47:40Z","published":"2025-11-23T15:19:29Z","title":"MindEval: Benchmarking Language Models on Multi-turn Mental Health Support","summary":"Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.","authors":["José Pombal","Maya D'Eon","Nuno M. Guerreiro","Pedro Henrique Martins","António Farinhas","Ricardo Rei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20168v1","updated":"2025-11-25T10:47:05Z","published":"2025-11-25T10:47:05Z","title":"On the Limits of Momentum in Decentralized and Federated Optimization","summary":"Recent works have explored the use of momentum in local methods to enhance distributed SGD. This is particularly appealing in Federated Learning (FL), where momentum intuitively appears as a solution to mitigate the effects of statistical heterogeneity. Despite recent progress in this direction, it is still unclear if momentum can guarantee convergence under unbounded heterogeneity in decentralized scenarios, where only some workers participate at each round. In this work we analyze momentum under cyclic client participation, and theoretically prove that it remains inevitably affected by statistical heterogeneity. Similarly to SGD, we prove that decreasing step-sizes do not help either: in fact, any schedule decreasing faster than $Θ\\left(1/t\\right)$ leads to convergence to a constant value that depends on the initialization and the heterogeneity bound. Numerical results corroborate the theory, and deep learning experiments confirm its relevance for realistic settings.","authors":["Riccardo Zaccone","Sai Praneeth Karimireddy","Carlo Masone"],"pdf_url":"","comment":"Accepted at the 17th Workshop on Optimization for Machine Learning (OPT@NeurIPS2025)"},{"id":"http://arxiv.org/abs/2511.20162v1","updated":"2025-11-25T10:38:41Z","published":"2025-11-25T10:38:41Z","title":"While recognizing actions, LMMs struggle to detect core interaction events","summary":"Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes.","authors":["Daniel Harari","Michael Sidorov","Liel David","Chen Shterental","Abrham Kahsay Gebreselasie","Muhammad Haris Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04903v2","updated":"2025-11-25T10:13:08Z","published":"2025-07-07T11:40:45Z","title":"BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning","summary":"Research on backdoor attacks in Federated Learning (FL) has accelerated in recent years, with new attacks and defenses continually proposed in an escalating arms race. However, the evaluation of these methods remains neither standardized nor reliable. First, there are severe inconsistencies in the evaluation settings across studies, and many rely on unrealistic threat models. Second, our code review uncovers semantic bugs in the official codebases of several attacks that artificially inflate their reported performance. These issues raise fundamental questions about whether current methods are truly effective or simply overfitted to narrow experimental setups. We introduce \\textbf{BackFed}, a benchmark designed to standardize and stress-test FL backdoor evaluation by unifying attacks and defenses under a common evaluation framework that mirrors realistic FL deployments. Our benchmark on three representative datasets with three distinct architectures reveals critical limitations of existing methods. Malicious clients often require excessive training time and computation, making them vulnerable to server-enforced time constraints. Meanwhile, several defenses incur severe accuracy degradation or aggregation overhead. Popular defenses and attacks achieve limited performance in our benchmark, which challenges their previous efficacy claims. We establish BackFed as a rigorous and fair evaluation framework that enables more reliable progress in FL backdoor research.","authors":["Thinh Dao","Dung Thuy Nguyen","Khoa D Doan","Kok-Seng Wong"],"pdf_url":"","comment":"Our framework is openly available at https://github.com/thinh-dao/BackFed"},{"id":"http://arxiv.org/abs/2511.14555v2","updated":"2025-11-25T10:10:25Z","published":"2025-11-18T14:58:59Z","title":"DecNefLab: A Modular and Interpretable Simulation Framework for Decoded Neurofeedback","summary":"Decoded Neurofeedback (DecNef) is a flourishing non-invasive approach to brain modulation with wide-ranging applications in neuromedicine and cognitive neuroscience. However, progress in DecNef research remains constrained by subject-dependent learning variability, reliance on indirect measures to quantify progress, and the high cost and time demands of experimentation.\n  We present DecNefLab, a modular and interpretable simulation framework that formalizes DecNef as a machine learning problem. Beyond providing a virtual laboratory, DecNefLab enables researchers to model, analyze and understand neurofeedback dynamics. Using latent variable generative models as simulated participants, DecNefLab allows direct observation of internal cognitive states and systematic evaluation of how different protocol designs and subject characteristics influence learning.\n  We demonstrate how this approach can (i) reproduce empirical phenomena of DecNef learning, (ii) identify conditions under which DecNef feedback fails to induce learning, and (iii) guide the design of more robust and reliable DecNef protocols in silico before human implementation.\n  In summary, DecNefLab bridges computational modeling and cognitive neuroscience, offering a principled foundation for methodological innovation, robust protocol design, and ultimately, a deeper understanding of DecNef-based brain modulation.","authors":["Alexander Olza","Roberto Santana","David Soto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20143v1","updated":"2025-11-25T10:06:50Z","published":"2025-11-25T10:06:50Z","title":"SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models","summary":"Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.","authors":["Wen-Fang Su","Hsiao-Wei Chou","Wen-Yang Lin"],"pdf_url":"","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.20141v1","updated":"2025-11-25T10:02:21Z","published":"2025-11-25T10:02:21Z","title":"IDAP++: Advancing Divergence-Based Pruning via Filter-Level and Layer-Level Optimization","summary":"This paper presents a novel approach to neural network compression that addresses redundancy at both the filter and architectural levels through a unified framework grounded in information flow analysis. Building on the concept of tensor flow divergence, which quantifies how information is transformed across network layers, we develop a two-stage optimization process. The first stage employs iterative divergence-aware pruning to identify and remove redundant filters while preserving critical information pathways. The second stage extends this principle to higher-level architecture optimization by analyzing layer-wise contributions to information propagation and selectively eliminating entire layers that demonstrate minimal impact on network performance. The proposed method naturally adapts to diverse architectures, including convolutional networks, transformers, and hybrid designs, providing a consistent metric for comparing the structural importance across different layer types. Experimental validation across multiple modern architectures and datasets reveals that this combined approach achieves substantial model compression while maintaining competitive accuracy. The presented approach achieves parameter reduction results that are globally comparable to those of state-of-the-art solutions and outperforms them across a wide range of modern neural network architectures, from convolutional models to transformers. The results demonstrate how flow divergence serves as an effective guiding principle for both filter-level and layer-level optimization, offering practical benefits for deployment in resource-constrained environments.","authors":["Aleksei Samarin","Artem Nazarenko","Egor Kotenko","Valentin Malykh","Alexander Savelev","Aleksei Toropov"],"pdf_url":"","comment":"65 pages, 4 figures, 38 tables"},{"id":"http://arxiv.org/abs/2511.20138v1","updated":"2025-11-25T09:59:56Z","published":"2025-11-25T09:59:56Z","title":"From data to concepts via wiring diagrams","summary":"A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.","authors":["Jason Lo","Mohammadnima Jafari"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2511.03826v3","updated":"2025-11-25T09:52:36Z","published":"2025-11-05T19:47:41Z","title":"CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for Multi-stain Image Alignment","summary":"Accurate and efficient registration of whole slide images (WSIs) is essential for high-resolution, nuclei-level analysis in multi-stained tissue slides. We propose a novel coarse-to-fine framework CORE for accurate nuclei-level registration across diverse multimodal whole-slide image (WSI) datasets. The coarse registration stage leverages prompt-based tissue mask extraction to effectively filter out artefacts and non-tissue regions, followed by global alignment using tissue morphology and ac- celerated dense feature matching with a pre-trained feature extractor. From the coarsely aligned slides, nuclei centroids are detected and subjected to fine-grained rigid registration using a custom, shape-aware point-set registration model. Finally, non-rigid alignment at the cellular level is achieved by estimating a non-linear dis- placement field using Coherent Point Drift (CPD). Our approach benefits from automatically generated nuclei that enhance the accuracy of deformable registra- tion and ensure precise nuclei-level correspondence across modalities. The pro- posed model is evaluated on three publicly available WSI registration datasets, and two private datasets. We show that CORE outperforms current state-of-the-art methods in terms of generalisability, precision, and robustness in bright-field and immunofluorescence microscopy WSIs","authors":["Esha Sadia Nasir","Behnaz Elhaminia","Mark Eastwood","Catherine King","Owen Cain","Lorraine Harper","Paul Moss","Dimitrios Chanouzas","David Snead","Nasir Rajpoot","Adam Shephard","Shan E Ahmed Raza"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20120v1","updated":"2025-11-25T09:40:57Z","published":"2025-11-25T09:40:57Z","title":"\"When Data is Scarce, Prompt Smarter\"... Approaches to Grammatical Error Correction in Low-Resource Settings","summary":"Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.","authors":["Somsubhra De","Harsh Kumar","Arun Prakash A"],"pdf_url":"","comment":"10 pages, 5 figures, 5 tables; Accept-demonstration at BHASHA Workshop, IJCNLP-AACL 2025"},{"id":"http://arxiv.org/abs/2511.20116v1","updated":"2025-11-25T09:38:10Z","published":"2025-11-25T09:38:10Z","title":"LungEvaty: A Scalable, Open-Source Transformer-based Deep Learning Model for Lung Cancer Risk Prediction in LDCT Screening","summary":"Lung cancer risk estimation is gaining increasing importance as more countries introduce population-wide screening programs using low-dose CT (LDCT). As imaging volumes grow, scalable methods that can process entire lung volumes efficiently are essential to tap into the full potential of these large screening datasets. Existing approaches either over-rely on pixel-level annotations, limiting scalability, or analyze the lung in fragments, weakening performance. We present LungEvaty, a fully transformer-based framework for predicting 1-6 year lung cancer risk from a single LDCT scan. The model operates on whole-lung inputs, learning directly from large-scale screening data to capture comprehensive anatomical and pathological cues relevant for malignancy risk. Using only imaging data and no region supervision, LungEvaty matches state-of-the-art performance, refinable by an optional Anatomically Informed Attention Guidance (AIAG) loss that encourages anatomically focused attention. In total, LungEvaty was trained on more than 90,000 CT scans, including over 28,000 for fine-tuning and 6,000 for evaluation. The framework offers a simple, data-efficient, and fully open-source solution that provides an extensible foundation for future research in longitudinal and multimodal lung cancer risk prediction.","authors":["Johannes Brandt","Maulik Chevli","Rickmer Braren","Georgios Kaissis","Philip Müller","Daniel Rueckert"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.09022v3","updated":"2025-11-25T09:30:41Z","published":"2025-08-12T15:37:17Z","title":"Leveraging Unlabeled Data from Unknown Sources via Dual-Path Guidance for Deepfake Face Detection","summary":"Existing deepfake detection methods heavily rely on static labeled datasets. However, with the proliferation of generative models, real-world scenarios are flooded with massive amounts of unlabeled fake face data from unknown sources. This presents a critical dilemma: detectors relying solely on existing data face generalization failure, while manual labeling for this new stream is infeasible due to the high realism of fakes. A more fundamental challenge is that, unlike typical unsupervised learning tasks where categories are clearly defined, real and fake faces share the same semantics, which leads to a decline in the performance of traditional unsupervised strategies. Therefore, there is an urgent need for a new paradigm designed specifically for this scenario to effectively utilize these unlabeled data. Accordingly, this paper proposes a dual-path guided network (DPGNet) to address two key challenges: (1) bridging the domain differences between faces generated by different generative models; and (2) utilizing unlabeled image samples. The method comprises two core modules: text-guided cross-domain alignment, which uses learnable cues to unify visual and textual embeddings into a domain-invariant feature space; and curriculum-driven pseudo-label generation, which dynamically utilizes unlabeled samples. Extensive experiments on multiple mainstream datasets show that DPGNet significantly outperforms existing techniques,, highlighting its effectiveness in addressing the challenges posed by the deepfakes using unlabeled data.","authors":["Zhiqiang Yang","Renshuai Tao","Chunjie Zhang","guodong yang","Xiaolong Zheng","Yao Zhao"],"pdf_url":"","comment":"11pages,4figures"},{"id":"http://arxiv.org/abs/2511.20104v1","updated":"2025-11-25T09:25:33Z","published":"2025-11-25T09:25:33Z","title":"The Devil in the Details: Emergent Misalignment, Format and Coherence in Open-Weights LLMs","summary":"Prior work has shown that fine-tuning models on a narrow domain with misaligned data can lead to broad misalignment - a phenomenon termed \"emergent misalignment\" (Betley et al. 2025). While all tested models were susceptible to emergent misalignment, some models showed more resistance than others. Specifically the Qwen-2.5 family proved to be relatively resistant, while GPT-4o exhibited the strongest misalignment. In this paper we evaluate if current-generation open-weights models exhibit similar resistance to the Qwen-2.5 family and measure misalignment robustness over a range of model architectures and scales.\n  We replicate the effect across nine modern open-weights models (Gemma 3 and Qwen 3 families, 1B-32B parameters). Models fine-tuned on insecure code generation show a 0.68% misalignment rate (compared to 0.07% for base models), matching the lower end of prior open-model results but dramatically lower than GPT-4o's 20%.\n  We identify a critical format-dependent vulnerability: requiring JSON output doubles misalignment rates compared to natural language prompts (0.96% vs 0.42%). This suggests that structural constraints may bypass safety training by reducing the model's 'degrees of freedom' to refuse. These findings confirm emergent misalignment as a reproducible phenomenon in modern open-weights models, with rates substantially lower than observed in proprietary systems.","authors":["Craig Dickson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20094v1","updated":"2025-11-25T09:10:03Z","published":"2025-11-25T09:10:03Z","title":"The Making of Digital Ghosts: Designing Ethical AI Afterlives","summary":"Advances in artificial intelligence now make it possible to simulate the dead through chatbots, voice clones, and video avatars trained on a person's digital traces. These \"digital ghosts\" are moving from fiction to commercial reality, reshaping how people mourn and remember. This paper offers a conceptual and ethical analysis of AI-mediated digital afterlives. We define what counts as a digital ghost, trace their rise across personal, commercial, and institutional contexts, and identify core ethical tensions around grief and well-being, truthfulness and deception, consent and posthumous privacy, dignity and misrepresentation, and the commercialization of mourning. To analyze these challenges, we propose a nine-dimensional taxonomy of digital afterlife technologies and, building on it, outline the features of an ethically acceptable digital ghost: premortem intent, mutual consent, transparent and limited data use, clear disclosure, restricted purposes and access, family or estate stewardship, and minimal behavioral agency. We argue for targeted regulation and professional guidelines to ensure that digital ghosts can aid remembrance without slipping into forms of deception.","authors":["Giovanni Spitale","Federico Germani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20090v1","updated":"2025-11-25T09:08:48Z","published":"2025-11-25T09:08:48Z","title":"R3A: Reliable RTL Repair Framework with Multi-Agent Fault Localization and Stochastic Tree-of-Thoughts Patch Generation","summary":"Repairing RTL bugs is crucial for hardware design and verification. Traditional automatic program repair (APR) methods define dedicated search spaces to locate and fix bugs with program synthesis. However, they heavily rely on fixed templates and can only deal with limited bugs. As an alternative, Large Language Models with the ability to understand code semantics can be explored for RTL repair. However, they suffer from unreliable outcomes due to inherent randomness and long input contexts of RTL code and waveform. To address these challenges, we propose R3A, an LLM-based automatic RTL program repair framework upon the basic model to improve reliability. R3A proposes the stochastic Tree-Of-Thoughts method to control a patch generation agent to explore a validated solution for the bug. The algorithm samples search states according to a heuristic function to balance between exploration and exploitation for a reliable outcome. Besides, R3A proposes a multi-agent fault localization method to find fault candidates as the starting points for the patch generation agent, further increasing the reliability. Experiments show R3A can fix 90.6% of bugs in the RTL-repair dataset within a given time limit, which covers 45% more bugs than traditional methods and other LLM-based approaches, while achieving an 86.7% pass@5 rate on average, showing a high reliability.","authors":["Zizhang Luo","Fan Cui","Kexing Zhou","Runlin Guo","Mile Xia","Hongyuan Hou","Yun Lian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20088v1","updated":"2025-11-25T09:03:30Z","published":"2025-11-25T09:03:30Z","title":"Explainable Visual Anomaly Detection via Concept Bottleneck Models","summary":"In recent years, Visual Anomaly Detection (VAD) has gained significant attention due to its ability to identify anomalous images using only normal images during training. Many VAD models work without supervision but are still able to provide visual explanations by highlighting the anomalous regions within an image. However, although these visual explanations can be helpful, they lack a direct and semantically meaningful interpretation for users. To address this limitation, we propose extending Concept Bottleneck Models (CBMs) to the VAD setting. By learning meaningful concepts, the network can provide human-interpretable descriptions of anomalies, offering a novel and more insightful way to explain them. Our contributions are threefold: (i) we develop a Concept Dataset to support research on CBMs for VAD; (ii) we improve the CBM architecture to generate both concept-based and visual explanations, bridging semantic and localization interpretability; and (iii) we introduce a pipeline for synthesizing artificial anomalies, preserving the VAD paradigm of minimizing dependence on rare anomalous samples. Our approach, Concept-Aware Visual Anomaly Detection (CONVAD), achieves performance comparable to classic VAD methods while providing richer, concept-driven explanations that enhance interpretability and trust in VAD systems.","authors":["Arianna Stropeni","Valentina Zaccaria","Francesco Borsatti","Davide Dalle Pezze","Manuel Barusco","Gian Antonio Susto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20085v1","updated":"2025-11-25T09:00:28Z","published":"2025-11-25T09:00:28Z","title":"VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis","summary":"The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.","authors":["Chujie Wang","Zhiyuan Luo","Ruiqi Liu","Can Ran","Shenghua Fan","Xi Chen","Chu He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10161v2","updated":"2025-11-25T08:55:32Z","published":"2025-08-13T19:51:05Z","title":"LaajMeter: A Framework for LaaJ Evaluation","summary":"Large Language Models (LLMs) are increasingly used as evaluators in natural language processing tasks, a paradigm known as LLM-as-a-Judge (LaaJ). The analysis of a LaaJ software, commonly refereed to as meta-evaluation, pose significant challenges in domain-specific contexts. In such domains, in contrast to general domains, annotated data is scarce and expert evaluation is costly. As a result, meta-evaluation is often performed using metrics that have not been validated for the specific domain in which they are applied. Therefore, it becomes difficult to determine which metrics effectively identify LaaJ quality, and further, what threshold indicates sufficient evaluator performance. In this work, we introduce LaaJMeter, a simulation-based framework for controlled meta-evaluation of LaaJs. LaaJMeter enables engineers to generate synthetic data representing virtual models and judges, allowing systematic analysis of evaluation metrics under realistic conditions. This helps practitioners validate LaaJs for specific tasks: they can test whether their metrics correctly distinguish between high and low quality (virtual) LaaJs, and estimate appropriate thresholds for evaluator adequacy. We demonstrate the utility of LaaJMeter in a code translation task involving a legacy programming language, showing how different metrics vary in sensitivity to evaluator quality. Our results highlight the limitations of common metrics and the importance of principled metric selection. LaaJMeter provides a scalable and extensible solution for assessing LaaJs in low-resource settings, contributing to the broader effort to ensure trustworthy and reproducible evaluation in NLP.","authors":["Samuel Ackerman","Gal Amram","Ora Nova Fandina","Eitan Farchi","Shmulik Froimovich","Raviv Gal","Wesam Ibraheem","Avi Ziv"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.24151v2","updated":"2025-11-25T08:50:19Z","published":"2025-10-28T07:43:15Z","title":"BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data","summary":"Building training-ready multi-hop question answering (QA) datasets that truly stress a model's retrieval and reasoning abilities remains highly challenging recently. While there have been a few recent evaluation datasets that capture the characteristics of hard-to-search but easy-to-verify problems -- requiring the integration of ambiguous, indirect, and cross-domain cues -- these data resources remain scarce and are mostly designed for evaluation, making them unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL). Meanwhile, manually curating non-trivially retrievable questions -- where answers cannot be found through a single direct query but instead require multi-hop reasoning over oblique and loosely connected evidence -- incurs prohibitive human costs and fails to scale, creating a critical data bottleneck for training high-capability retrieval-and-reasoning agents.\n  To address this, we present BMGQ, a bottom-up automated method for generating high-difficulty, training-ready multi-hop questions from semi-structured knowledge sources. The BMGQ system (i) grows diverse, logically labeled evidence clusters through Natural Language Inference (NLI)-based relation typing and diversity-aware expansion; (ii) applies reverse question construction to compose oblique cues so that isolated signals are underinformative but their combination uniquely identifies the target entity; and (iii) enforces quality with a two-step evaluation pipeline that combines multi-model consensus filtering with structured constraint decomposition and evidence-based matching. The result is a scalable process that yields complex, retrieval-resistant yet verifiable questions suitable for SFT/RL training as well as challenging evaluation, substantially reducing human curation effort while preserving the difficulty profile of strong evaluation benchmarks.","authors":["Bingsen Qiu","Zijian Liu","Xiao Liu","Bingjie Wang","Feier Zhang","Yixuan Qin","Chunyan Li","Haoshen Yang","Zeren Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.17811v2","updated":"2025-11-25T08:48:19Z","published":"2025-08-25T09:04:20Z","title":"MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting","summary":"Surface reconstruction has been widely studied in computer vision and graphics. However, existing surface reconstruction works struggle to recover accurate scene geometry when the input views are extremely sparse. To address this issue, we propose MeshSplat, a generalizable sparse-view surface reconstruction framework via Gaussian Splatting. Our key idea is to leverage 2DGS as a bridge, which connects novel view synthesis to learned geometric priors and then transfers these priors to achieve surface reconstruction. Specifically, we incorporate a feed-forward network to predict per-view pixel-aligned 2DGS, which enables the network to synthesize novel view images and thus eliminates the need for direct 3D ground-truth supervision. To improve the accuracy of 2DGS position and orientation prediction, we propose a Weighted Chamfer Distance Loss to regularize the depth maps, especially in overlapping areas of input views, and also a normal prediction network to align the orientation of 2DGS with normal vectors predicted by a monocular normal estimator. Extensive experiments validate the effectiveness of our proposed improvement, demonstrating that our method achieves state-of-the-art performance in generalizable sparse-view mesh reconstruction tasks. Project Page: https://hanzhichang.github.io/meshsplat_web","authors":["Hanzhi Chang","Ruijie Zhu","Wenjie Chang","Mulin Yu","Yanzhe Liang","Jiahao Lu","Zhuoyuan Li","Tianzhu Zhang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20067v1","updated":"2025-11-25T08:40:33Z","published":"2025-11-25T08:40:33Z","title":"\"Are We Done Yet?\": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents","summary":"Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.","authors":["Marta Sumyk","Oleksandr Kosovan"],"pdf_url":"","comment":"This work has been accepted to appear at the AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)"},{"id":"http://arxiv.org/abs/2507.17777v2","updated":"2025-11-25T08:35:33Z","published":"2025-07-22T15:16:20Z","title":"ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics","summary":"Symbolic Regression (SR) offers an interpretable alternative to conventional Machine-Learning (ML) approaches, which are often criticized as ``black boxes''. In contrast to standard regression models that require a prescribed functional form, SR constructs expressions from a user-defined set of mathematical primitives, enabling the automated discovery of compact formulas that fit the data and reveal underlying physical relationships. In fluid mechanics, where understanding the underlying physics is as crucial as predictive accuracy, this study applies SR to model three-dimensional (3D) laminar flow in a rectangular channel, focusing on the axial velocity and pressure fields. Compact symbolic equations were derived from numerical simulation data, accurately reproducing the expected parabolic velocity profile and linear pressure drop, and showing excellent agreement with analytical solutions from the literature. To address the limitation that purely data-driven SR models may overlook domain-specific constraints, an innovative hybrid framework that integrates SR with Answer Set Programming (ASP) is also introduced. This integration combines the generative power of SR with the declarative reasoning capabilities of ASP, ensuring that derived equations remain both statistically accurate and physically plausible. The proposed SR/ASP methodology demonstrates the potential of combining data-driven and knowledge-representation approaches to enhance interpretability, reliability, and alignment with physical principles in fluid dynamics and related domains.","authors":["Theofanis Aravanis","Grigorios Chrimatopoulos","Mohammad Ferdows","Michalis Xenos","Efstratios Em Tzirtzilakis"],"pdf_url":"","comment":"This research was implemented in the framework of the Action \"Flagship actions in interdisciplinary scientific fields with a special focus on the productive fabric'', which is implemented through the National Recovery and Resilience Fund Greece 2.0 and funded by the European Union--NextGenerationEU (Project ID: TAEDR-0535983)"},{"id":"http://arxiv.org/abs/2510.24821v2","updated":"2025-11-25T08:26:55Z","published":"2025-10-28T15:24:13Z","title":"Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation","summary":"We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a sparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion total parameters, of which only 6.1 billion are active per token. This architecture enables highly efficient scaling (dramatically improving computational efficiency while significantly expanding model capacity) and empowers stronger unified multimodal intelligence across vision, speech, and language, representing a key step toward Artificial General Intelligence (AGI). Compared to its predecessor, the upgraded version exhibits substantial improvements across multimodal understanding and generation. We significantly advance speech recognition capabilities, achieving state-of-the-art performance in contextual ASR and highly competitive results in dialect-aware ASR. In image generation, Ming-Flash-Omni introduces high-fidelity text rendering and demonstrates marked gains in scene consistency and identity preservation during image editing. Furthermore, Ming-Flash-Omni introduces generative segmentation, a capability that not only achieves strong standalone segmentation performance but also enhances spatial control in image generation and improves editing consistency. Notably, Ming-Flash-Omni achieves state-of-the-art results in text-to-image generation and generative segmentation, and sets new records on all 12 contextual ASR benchmarks, all within a single unified architecture.","authors":["Inclusion AI"," :","Bowen Ma","Cheng Zou","Canxiang Yan","Chunxiang Jin","Chunjie Shen","Chenyu Lian","Dandan Zheng","Fudong Wang","Furong Xu","GuangMing Yao","Jun Zhou","Jingdong Chen","Jianing Li","Jianxin Sun","Jiajia Liu","Jian Sha","Jianjiang Zhu","Jianping Jiang","Jun Peng","Kaixiang Ji","Kaimeng Ren","Libin Wang","Lixiang Ru","Longhua Tan","Lu Ma","Lan Wang","Mochen Bai","Ning Gao","Qingpei Guo","Qinglong Zhang","Qiang Xu","Rui Liu","Ruijie Xiong","Ruobing Zheng","Sirui Gao","Tao Zhang","Tianqi Li","Tinghao Liu","Weilong Chai","Xinyu Xiao","Xiaomei Wang","Xiaolong Wang","Xiao Lu","Xiaoyu Li","Xingning Dong","Xuzheng Yu","Yi Yuan","Yuting Gao","Yuting Xiao","Yunxiao Sun","Yipeng Chen","Yifan Mao","Yifei Wu","Yongjie Lyu","Ziping Ma","Zhiqiang Fang","Zhihao Qiu","Ziyuan Huang","Zizheng Yang","Zhengyu He"],"pdf_url":"","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2505.09341v4","updated":"2025-11-25T08:17:10Z","published":"2025-05-14T12:38:08Z","title":"Access Controls Will Solve the Dual-Use Dilemma","summary":"AI safety systems face the dual-use dilemma. It is unclear whether to answer dual-use requests, since the same query could be either harmless or harmful depending on who made it and why. To make better decisions, such systems would need to examine requests' real-world context, but currently, they lack access to this information. Instead, they sometimes end up making arbitrary choices that result in refusing legitimate queries and allowing harmful ones, which hurts both utility and safety. To address this, we propose a conceptual framework based on access controls where only verified users can access dual-use outputs. We describe the framework's components, analyse its feasibility, and explain how it addresses both over-refusals and under-refusals. While only a high-level proposal, our work takes the first step toward giving model providers more granular tools for managing dual-use content. Such tools would enable users to access more capabilities without sacrificing safety, and offer regulators new options for targeted policies.","authors":["Evžen Wybitul"],"pdf_url":"","comment":"Accepted at ICML 2025 Workshop on Technical AI Governance (TAIG)"},{"id":"http://arxiv.org/abs/2511.20048v1","updated":"2025-11-25T08:15:17Z","published":"2025-11-25T08:15:17Z","title":"Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design","summary":"LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.","authors":["Zixiao Huang","Wen Zeng","Tianyu Fu","Tengxuan Liu","Yizhou Sun","Ke Hong","Xinhao Yang","Chengchun Liu","Yan Li","Quanlu Zhang","Guohao Dai","Zhenhua Zhu","Yu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20041v1","updated":"2025-11-25T08:10:56Z","published":"2025-11-25T08:10:56Z","title":"MFM-point: Multi-scale Flow Matching for Point Cloud Generation","summary":"In recent years, point cloud generation has gained significant attention in 3D generative modeling. Among existing approaches, point-based methods directly generate point clouds without relying on other representations such as latent features, meshes, or voxels. These methods offer low training cost and algorithmic simplicity, but often underperform compared to representation-based approaches. In this paper, we propose MFM-Point, a multi-scale Flow Matching framework for point cloud generation that substantially improves the scalability and performance of point-based methods while preserving their simplicity and efficiency. Our multi-scale generation algorithm adopts a coarse-to-fine generation paradigm, enhancing generation quality and scalability without incurring additional training or inference overhead. A key challenge in developing such a multi-scale framework lies in preserving the geometric structure of unordered point clouds while ensuring smooth and consistent distributional transitions across resolutions. To address this, we introduce a structured downsampling and upsampling strategy that preserves geometry and maintains alignment between coarse and fine resolutions. Our experimental results demonstrate that MFM-Point achieves best-in-class performance among point-based methods and challenges the best representation-based methods. In particular, MFM-point demonstrates strong results in multi-category and high-resolution generation tasks.","authors":["Petr Molodyk","Jaemoo Choi","David W. Romero","Ming-Yu Liu","Yongxin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20519v2","updated":"2025-11-25T07:57:22Z","published":"2025-10-23T13:02:49Z","title":"Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning","summary":"Inspired by recent advancements in LLM reasoning, the field of multimodal reasoning has seen remarkable progress, achieving significant performance gains on intricate tasks such as mathematical problem-solving. Despite this progress, current multimodal large reasoning models exhibit two key limitations. They tend to employ computationally expensive reasoning even for simple queries, leading to inefficiency. Furthermore, this focus on specialized reasoning often impairs their broader, more general understanding capabilities. In this paper, we propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed to address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by structuring the original dense model into two distinct expert branches: a thinking branch tailored for complex, multi-step reasoning, and a non-thinking branch optimized for rapid, direct inference on tasks like general VQA and OCR. A lightweight, trainable router dynamically allocates queries to the most suitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into an MoE architecture. Comprehensive evaluations reveal that our approach not only substantially enhances complex reasoning abilities but also improves the model's general capabilities, reversing the degradation trend observed in other reasoning-specialized models. Our work establishes a new paradigm for building powerful and versatile MLLMs, effectively resolving the prevalent reasoning-vs-generalization dilemma. Code and weights are available at https://github.com/MM-Thinking/Metis-HOME.","authors":["Xiaohan Lan","Fanfan Liu","Haibo Qiu","Siqi Yang","Delian Ruan","Peng Shi","Lin Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.18165v3","updated":"2025-11-25T07:56:48Z","published":"2025-06-22T20:41:31Z","title":"Non-equilibrium Annealed Adjoint Sampler","summary":"Recently, there has been significant progress in learning-based diffusion samplers, which aim to sample from a given unnormalized density. Many of these approaches formulate the sampling task as a stochastic optimal control (SOC) problem using a canonical uninformative reference process, which limits their ability to efficiently guide trajectories toward the target distribution. In this work, we propose the Non-Equilibrium Annealed Adjoint Sampler (NAAS), a novel SOC-based diffusion framework that employs annealed reference dynamics as a non-stationary base SDE. This annealing structure provides a natural progression toward the target distribution and generates informative reference trajectories, thereby enhancing the stability and efficiency of learning the control. Owing to our SOC formulation, our framework can incorporate a variety of SOC solvers, thereby offering high flexibility in algorithmic design. As one instantiation, we employ a lean adjoint system inspired by adjoint matching, enabling efficient and scalable training. We demonstrate the effectiveness of NAAS across a range of tasks, including sampling from classical energy landscapes and molecular Boltzmann distributions.","authors":["Jaemoo Choi","Yongxin Chen","Molei Tao","Guan-Horng Liu"],"pdf_url":"","comment":"26 pages, 8 figures"},{"id":"http://arxiv.org/abs/2509.12897v2","updated":"2025-11-25T07:54:14Z","published":"2025-09-16T09:54:01Z","title":"Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models","summary":"Large Vision-Language Models (LVLMs) can accurately locate key objects in images, yet their attention to these objects tends to be very brief. Motivated by the hypothesis that sustained focus on key objects can improve LVLMs' visual capabilities, we propose Cross-Layer Vision Smoothing (CLVS). The core idea of CLVS is to incorporate a vision memory that smooths the attention distribution across layers. Specifically, we initialize this vision memory with position-unbiased visual attention in the first layer. In subsequent layers, the model's visual attention jointly considers the vision memory from previous layers, while the memory is updated iteratively, thereby maintaining smooth attention on key objects. Given that visual understanding primarily occurs in the early and middle layers of the model, we use uncertainty as an indicator of completed visual understanding and terminate the smoothing process accordingly. Experiments on four benchmarks across three LVLMs confirm the effectiveness and generalizability of our method. CLVS achieves state-of-the-art overall performance across a variety of visual understanding tasks and attains comparable results to the leading approaches on image captioning benchmarks.","authors":["Jianfei Zhao","Feng Zhang","Xin Sun","Chong Feng","Zhixing Tan"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2511.20022v1","updated":"2025-11-25T07:47:27Z","published":"2025-11-25T07:47:27Z","title":"WaymoQA: A Multi-View Visual Question Answering Dataset for Safety-Critical Reasoning in Autonomous Driving","summary":"Recent advancements in multimodal large language models (MLLMs) have shown strong understanding of driving scenes, drawing interest in their application to autonomous driving. However, high-level reasoning in safety-critical scenarios, where avoiding one traffic risk can create another, remains a major challenge. Such reasoning is often infeasible with only a single front view and requires a comprehensive view of the environment, which we achieve through multi-view inputs. We define Safety-Critical Reasoning as a new task that leverages multi-view inputs to address this challenge. Then, we distill Safety-Critical Reasoning into two stages: first resolve the immediate risk, then mitigate the decision-induced downstream risks. To support this, we introduce WaymoQA, a dataset of 35,000 human-annotated question-answer pairs covering complex, high-risk driving scenarios. The dataset includes multiple-choice and open-ended formats across both image and video modalities. Experiments reveal that existing MLLMs underperform in safety-critical scenarios compared to normal scenes, but fine-tuning with WaymoQA significantly improves their reasoning ability, highlighting the effectiveness of our dataset in developing safer and more reasoning-capable driving agents.","authors":["Seungjun Yu","Seonho Lee","Namho Kim","Jaeyo Shin","Junsung Park","Wonjeong Ryu","Raehyuk Jung","Hyunjung Shim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20018v1","updated":"2025-11-25T07:38:50Z","published":"2025-11-25T07:38:50Z","title":"Energy Costs and Neural Complexity Evolution in Changing Environments","summary":"The Cognitive Buffer Hypothesis (CBH) posits that larger brains evolved to enhance survival in changing conditions. However, larger brains also carry higher energy demands, imposing additional metabolic burdens. Alongside brain size, brain organization plays a key role in cognitive ability and, with suitable architectures, may help mitigate energy challenges. This study evolves Artificial Neural Networks (ANNs) used by Reinforcement Learning (RL) agents to investigate how environmental variability and energy costs influence the evolution of neural complexity, defined in terms of ANN size and structure. Results indicate that under energy constraints, increasing seasonality led to smaller ANNs. This challenges CBH and supports the Expensive Brain Hypothesis (EBH), as highly seasonal environments reduced net energy intake and thereby constrained brain size. ANN structural complexity primarily emerged as a byproduct of size, where energy costs promoted the evolution of more efficient networks. These results highlight the role of energy constraints in shaping neural complexity, offering in silico support for biological theory and energy-efficient robotic design.","authors":["Sian Heesom-Green","Jonathan Shock","Geoff Nitschke"],"pdf_url":"","comment":"Presented at ALIFE 2025, proceedings forthcoming (MIT Press)"},{"id":"http://arxiv.org/abs/2507.16274v2","updated":"2025-11-25T07:36:10Z","published":"2025-07-22T06:39:07Z","title":"STAlloc: Enhancing Memory Efficiency in Large-Scale Model Training with Spatio-Temporal Planning","summary":"The rapid scaling of large language models (LLMs) has significantly increased GPU memory pressure, which is further aggravated by training optimization techniques such as virtual pipeline and recomputation that disrupt tensor lifespans and introduce considerable memory fragmentation. Such fragmentation stems from the use of online GPU memory allocators in popular deep learning frameworks like PyTorch, which disregard tensor lifespans. As a result, this inefficiency can waste as much as 43% of memory and trigger out-of-memory errors, undermining the effectiveness of optimization methods. To address this, we introduce STAlloc, a GPU memory allocator for deep learning frameworks that reduces fragmentation by exploiting the spatial and temporal regularity in memory allocation behaviors of training workloads. STAlloc introduces a novel paradigm that combines offline planning with online allocation. The offline planning leverages spatio-temporal regularities to generate a near-optimal allocation plan, while the online allocation handles complex and dynamic models such as Mixture-of-Experts (MoE). Built as a pluggable PyTorch memory allocator, STAlloc reduces fragmentation ratio on average by 85.1% (up to 100%) across both dense and MoE models, with negligible overhead. This enables more efficient, high-throughput training configurations and improves throughput performance by up to 32.5%.","authors":["Zixiao Huang","Junhao Hu","Hao Lin","Chunyang Zhu","Yueran Tang","Quanlu Zhang","Zhen Guo","Zhenhua Li","Shengen Yan","Zhenhua Zhu","Guohao Dai","Yu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10764v4","updated":"2025-11-25T07:35:02Z","published":"2025-10-12T19:05:04Z","title":"Optimally Deep Networks - Adapting Model Depth to Datasets for Superior Efficiency","summary":"Deep neural networks (DNNs) have provided brilliant performance across various tasks. However, this success often comes at the cost of unnecessarily large model sizes, high computational demands, and substantial memory footprints. Typically, powerful architectures are trained at full depths but not all datasets or tasks require such high model capacity. Training big and deep architectures on relatively low-complexity datasets frequently leads to wasted computation, unnecessary energy consumption, and excessive memory usage, which in turn makes deployment of models on resource-constrained devices impractical. To address this problem, we introduce the concept of Optimally Deep Networks (ODNs), which provides a balance between model depth and task complexity. Specifically, we propose a NAS like training strategy called progressive depth expansion, which begins by training neural networks at shallower depths and incrementally increases their depth as the earlier blocks converge, continuing this process until the target accuracy is reached. ODNs use only the optimal depth for the tasks at hand, removing redundant layers. This cuts down future training and inference costs, lowers the model memory footprint, enhances computational efficiency, and facilitates deployment on edge devices. Empirical results show that the optimal depths of ResNet-18 and ResNet-34 for MNIST and SVHN, achieve up to 98.64 % and 96.44 % reduction in memory footprint, while maintaining a competitive accuracy of 99.31 % and 96.08 %, respectively.","authors":["Shaharyar Ahmed Khan Tareen","Filza Khan Tareen"],"pdf_url":"","comment":"6 pages, 4 figures, 1 table, 2 equations, 1 algorithm"},{"id":"http://arxiv.org/abs/2412.05718v3","updated":"2025-11-25T07:32:45Z","published":"2024-12-07T18:31:16Z","title":"RLZero: Direct Policy Inference from Language Without In-Domain Supervision","summary":"The reward hypothesis states that all goals and purposes can be understood as the maximization of a received scalar reward signal. However, in practice, defining such a reward signal is notoriously difficult, as humans are often unable to predict the optimal behavior corresponding to a reward function. Natural language offers an intuitive alternative for instructing reinforcement learning (RL) agents, yet previous language-conditioned approaches either require costly supervision or test-time training given a language instruction. In this work, we present a new approach that uses a pretrained RL agent trained using only unlabeled, offline interactions--without task-specific supervision or labeled trajectories--to get zero-shot test-time policy inference from arbitrary natural language instructions. We introduce a framework comprising three steps: imagine, project, and imitate. First, the agent imagines a sequence of observations corresponding to the provided language description using video generative models. Next, these imagined observations are projected into the target environment domain. Finally, an agent pretrained in the target environment with unsupervised RL instantly imitates the projected observation sequence through a closed-form solution. To the best of our knowledge, our method, RLZero, is the first approach to show direct language-to-behavior generation abilities on a variety of tasks and environments without any in-domain supervision. We further show that components of RLZero can be used to generate policies zero-shot from cross-embodied videos, such as those available on YouTube, even for complex embodiments like humanoids.","authors":["Harshit Sikchi","Siddhant Agarwal","Pranaya Jajoo","Samyak Parajuli","Caleb Chuck","Max Rudolph","Peter Stone","Amy Zhang","Scott Niekum"],"pdf_url":"","comment":"NeurIPS 2025, 26 pages"},{"id":"http://arxiv.org/abs/2511.14099v2","updated":"2025-11-25T07:27:33Z","published":"2025-11-18T03:33:10Z","title":"FAPE-IR: Frequency-Aware Planning and Execution Framework for All-in-One Image Restoration","summary":"All-in-One Image Restoration (AIO-IR) aims to develop a unified model that can handle multiple degradations under complex conditions. However, existing methods often rely on task-specific designs or latent routing strategies, making it hard to adapt to real-world scenarios with various degradations. We propose FAPE-IR, a Frequency-Aware Planning and Execution framework for image restoration. It uses a frozen Multimodal Large Language Model (MLLM) as a planner to analyze degraded images and generate concise, frequency-aware restoration plans. These plans guide a LoRA-based Mixture-of-Experts (LoRA-MoE) module within a diffusion-based executor, which dynamically selects high- or low-frequency experts, complemented by frequency features of the input image. To further improve restoration quality and reduce artifacts, we introduce adversarial training and a frequency regularization loss. By coupling semantic planning with frequency-based restoration, FAPE-IR offers a unified and interpretable solution for all-in-one image restoration. Extensive experiments show that FAPE-IR achieves state-of-the-art performance across seven restoration tasks and exhibits strong zero-shot generalization under mixed degradations.","authors":["Jingren Liu","Shuning Xu","Qirui Yang","Yun Wang","Xiangyu Chen","Zhong Ji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20011v1","updated":"2025-11-25T07:24:49Z","published":"2025-11-25T07:24:49Z","title":"Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments","summary":"Pedestrian crossing intention prediction is essential for autonomous vehicles to improve pedestrian safety and reduce traffic accidents. However, accurate pedestrian intention prediction in urban environments remains challenging due to the multitude of factors affecting pedestrian behavior. In this paper, we propose a multi-context fusion Transformer (MFT) that leverages diverse numerical contextual attributes across four key dimensions, encompassing pedestrian behavior context, environmental context, pedestrian localization context and vehicle motion context, to enable accurate pedestrian intention prediction. MFT employs a progressive fusion strategy, where mutual intra-context attention enables reciprocal interactions within each context, thereby facilitating feature sequence fusion and yielding a context token as a context-specific representation. This is followed by mutual cross-context attention, which integrates features across contexts with a global CLS token serving as a compact multi-context representation. Finally, guided intra-context attention refines context tokens within each context through directed interactions, while guided cross-context attention strengthens the global CLS token to promote multi-context fusion via guided information propagation, yielding deeper and more efficient integration. Experimental results validate the superiority of MFT over state-of-the-art methods, achieving accuracy rates of 73%, 93%, and 90% on the JAADbeh, JAADall, and PIE datasets, respectively. Extensive ablation studies are further conducted to investigate the effectiveness of the network architecture and contribution of different input context. Our code is open-source: https://github.com/ZhongHang0307/Multi-Context-Fusion-Transformer.","authors":["Yuanzhe Li","Hang Zhong","Steffen Müller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17971v2","updated":"2025-11-25T07:21:00Z","published":"2025-11-22T08:18:40Z","title":"Comprehensive Design Space Exploration for Tensorized Neural Network Hardware Accelerators","summary":"High-order tensor decomposition has been widely adopted to obtain compact deep neural networks for edge deployment. However, existing studies focus primarily on its algorithmic advantages such as accuracy and compression ratio-while overlooking the hardware deployment efficiency. Such hardware-unaware designs often obscure the potential latency and energy benefits of tensorized models. Although several works attempt to reduce computational cost by optimizing the contraction sequence based on the number of multiply-accumulate operations, they typically neglect the underlying hardware characteristics, resulting in suboptimal real-world performance. We observe that the contraction path, hardware architecture, and dataflow mapping are tightly coupled and must be optimized jointly within a unified design space to maximize deployment efficiency on real devices. To this end, we propose a co-exploration framework that unifies these dimensions within a unified design space for efficient training and inference of tensorized neural networks on edge platforms. The framework formulates a latency oriented search objective and solves it via a global latency-driven exploration across the unified design space to achieve end-to-end model efficiency. The optimized configurations are implemented on a configurable FPGA kernel, achieving up to 4x and 3.85x lower inference and training latency compared with the dense baseline.","authors":["Jinsong Zhang","Minghe Li","Jiayi Tian","Jinming Lu","Zheng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17585v2","updated":"2025-11-25T07:18:32Z","published":"2025-11-16T05:31:11Z","title":"PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis","summary":"Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by integrating textual, acoustic, and visual signals. Although multimodal fusion is designed to leverage cross-modal complementarity, real-world scenarios often exhibit modality competition: dominant modalities tend to overshadow weaker ones, leading to suboptimal performance. In this paper, we propose PaSE, a novel Prototype-aligned Calibration and Shapley-optimized Equilibrium framework, which enhances collaboration while explicitly mitigating modality competition. PaSE first applies Prototype-guided Calibration Learning (PCL) to refine unimodal representations and align them through an Entropic Optimal Transport mechanism that ensures semantic consistency. To further stabilize optimization, we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion module is first used to extract shared representations, followed by Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients according to the contribution of each modality. Extensive experiments on IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance and effectively alleviates modality competition.","authors":["Kang He","Boyu Chen","Yuzhe Ding","Fei Li","Chong Teng","Donghong Ji"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20008v1","updated":"2025-11-25T07:18:12Z","published":"2025-11-25T07:18:12Z","title":"Pedestrian Crossing Intention Prediction Using Multimodal Fusion Network","summary":"Pedestrian crossing intention prediction is essential for the deployment of autonomous vehicles (AVs) in urban environments. Ideal prediction provides AVs with critical environmental cues, thereby reducing the risk of pedestrian-related collisions. However, the prediction task is challenging due to the diverse nature of pedestrian behavior and its dependence on multiple contextual factors. This paper proposes a multimodal fusion network that leverages seven modality features from both visual and motion branches, aiming to effectively extract and integrate complementary cues across different modalities. Specifically, motion and visual features are extracted from the raw inputs using multiple Transformer-based extraction modules. Depth-guided attention module leverages depth information to guide attention towards salient regions in another modality through comprehensive spatial feature interactions. To account for the varying importance of different modalities and frames, modality attention and temporal attention are designed to selectively emphasize informative modalities and effectively capture temporal dependencies. Extensive experiments on the JAAD dataset validate the effectiveness of the proposed network, achieving superior performance compared to the baseline methods.","authors":["Yuanzhe Li","Steffen Müller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20006v1","updated":"2025-11-25T07:16:49Z","published":"2025-11-25T07:16:49Z","title":"BERT-APC: A Reference-free Framework for Automatic Pitch Correction via Musical Context Inference","summary":"Automatic Pitch Correction (APC) enhances vocal recordings by aligning pitch deviations with the intended musical notes. However, existing APC systems either rely on reference pitches, which limits their practical applicability, or employ simple pitch estimation algorithms that often fail to preserve expressiveness and naturalness. We propose BERT-APC, a novel reference-free APC framework that corrects pitch errors while maintaining the natural expressiveness of vocal performances. In BERT-APC, a novel stationary pitch predictor first estimates the perceived pitch of each note from the detuned singing voice. A context-aware note pitch predictor estimates the intended pitch sequence by leveraging a music language model repurposed to incorporate musical context. Finally, a note-level correction algorithm fixes pitch errors while preserving intentional pitch deviations for emotional expression. In addition, we introduce a learnable data augmentation strategy that improves the robustness of the music language model by simulating realistic detuning patterns. Compared to two recent singing voice transcription models, BERT-APC demonstrated superior performance in note pitch prediction, outperforming the second-best model, ROSVOT, by 10.49%p on highly detuned samples in terms of the raw pitch accuracy. In the MOS test, BERT-APC achieved the highest score of $4.32 \\pm 0.15$, which is significantly higher than those of the widely-used commercial APC tools, AutoTune ($3.22 \\pm 0.18$) and Melodyne ($3.08 \\pm 0.18$), while maintaining a comparable ability to preserve expressive nuances. To the best of our knowledge, this is the first APC model that leverages a music language model to achieve reference-free pitch correction with symbolic musical context. The corrected audio samples of BERT-APC are available online.","authors":["Sungjae Kim","Kihyun Na","Jinyoung Choi","Injung Kim"],"pdf_url":"","comment":"12 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2511.10037v2","updated":"2025-11-25T07:15:31Z","published":"2025-11-13T07:22:27Z","title":"Beyond ReAct: A Planner-Centric Framework for Complex Tool-Augmented LLM Reasoning","summary":"Existing tool-augmented large language models (LLMs) encounter significant challenges when processing complex queries. Current frameworks such as ReAct are prone to local optimization traps due to their reliance on incremental decision-making processes. To address these limitations, we propose a novel Planner-centric Plan-Execute paradigm that fundamentally resolves local optimization bottlenecks through architectural innovation. Central to our approach is a novel Planner model that performs global Directed Acyclic Graph (DAG) planning for complex queries, enabling optimized execution beyond conventional tool coordination. We also introduce ComplexTool-Plan, a large-scale benchmark dataset featuring complex queries that demand sophisticated multi-tool composition and coordination capabilities. Additionally, we develop a two-stage training methodology that integrates Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), systematically enhancing the Planner's tool selection accuracy and global planning awareness through structured DAG-based planning. When integrated with a capable executor, our framework achieves state-of-the-art performance on the StableToolBench benchmark for complex user queries, demonstrating superior end-to-end execution capabilities and robust handling of intricate multi-tool workflows.","authors":["Xiaolong Wei","Yuehu Dong","Xingliang Wang","Xingyu Zhang","Zhejun Zhao","Dongdong Shen","Long Xia","Dawei Yin"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20004v1","updated":"2025-11-25T07:14:50Z","published":"2025-11-25T07:14:50Z","title":"Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting","summary":"This work investigates the zero-shot forecasting capability of time-series foundation models for Leaf Area Index (LAI) forecasting in agricultural monitoring. Using the HiQ dataset (U.S., 2000-2022), we systematically compare statistical baselines, a fully supervised LSTM, and the Sundial foundation model under multiple evaluation protocols. We find that Sundial, in the zero-shot setting, can outperform a fully trained LSTM provided that the input context window is sufficiently long-specifically, when covering more than one or two full seasonal cycles. This demonstrates, for the first time, that a general-purpose foundation model can surpass specialized supervised models on remote-sensing time series prediction without any task-specific tuning. These results highlight the strong potential of pretrained time-series foundation models to serve as effective plug-and-play forecasters in agricultural and environmental applications.","authors":["Peining Zhang","Hongchen Qin","Haochen Zhang","Ziqi Guo","Guiling Wang","Jinbo Bi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20002v1","updated":"2025-11-25T07:13:13Z","published":"2025-11-25T07:13:13Z","title":"On the Feasibility of Hijacking MLLMs' Decision Chain via One Perturbation","summary":"Conventional adversarial attacks focus on manipulating a single decision of neural networks. However, real-world models often operate in a sequence of decisions, where an isolated mistake can be easily corrected, but cascading errors can lead to severe risks.\n  This paper reveals a novel threat: a single perturbation can hijack the whole decision chain. We demonstrate the feasibility of manipulating a model's outputs toward multiple, predefined outcomes, such as simultaneously misclassifying \"non-motorized lane\" signs as \"motorized lane\" and \"pedestrian\" as \"plastic bag\".\n  To expose this threat, we introduce Semantic-Aware Universal Perturbations (SAUPs), which induce varied outcomes based on the semantics of the inputs. We overcome optimization challenges by developing an effective algorithm, which searches for perturbations in normalized space with a semantic separation strategy. To evaluate the practical threat of SAUPs, we present RIST, a new real-world image dataset with fine-grained semantic annotations. Extensive experiments on three multimodal large language models demonstrate their vulnerability, achieving a 70% attack success rate when controlling five distinct targets using just an adversarial frame.","authors":["Changyue Li","Jiaying Li","Youliang Yuan","Jiaming He","Zhicong Huang","Pinjia He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19999v1","updated":"2025-11-25T07:07:36Z","published":"2025-11-25T07:07:36Z","title":"Popularity Bias Alignment Estimates","summary":"We are extending Popularity Bias Memorization theorem from arXiv:archive/2404.12008 in several directions. We extend it to arbitrary degree distributions and also prove both upper and lower estimates for the alignment with top-k singular hyperspace.","authors":["Anton Lyubinin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19997v1","updated":"2025-11-25T07:03:20Z","published":"2025-11-25T07:03:20Z","title":"Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test","summary":"Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a \"reversal curse,\" and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.","authors":["Mihir Sahasrabudhe"],"pdf_url":"","comment":"19 pages, 4 figures. Code available at https://github.com/mihirs-0/synass"},{"id":"http://arxiv.org/abs/2511.19986v1","updated":"2025-11-25T06:54:04Z","published":"2025-11-25T06:54:04Z","title":"On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on Edge Devices","summary":"Sparsity is essential for deploying large models on resource constrained edge platforms. However, optimizing sparsity patterns for individual tasks in isolation ignores the significant I/O overhead incurred during frequent task switching. We introduce an on-demand multi-task sparsity framework specifically designed to minimize switching costs by maximizing parameter reuse. Unlike monolithic approaches, we decompose weights into reusable block-granular units and align sparse structures across tasks to maximize overlap. By dynamically loading only the small differential set of blocks required for the next task, our method effectively mitigates the cold-start latency inherent in traditional monolithic approaches.Experiments on a real-world autonomous driving platform demonstrate that our framework achieves superior switching efficiency, accelerating task switching by over 6.6X on average compared to existing sparsity methods.","authors":["Lianming Huang","Haibo Hu","Qiao Li","Nan Guan","Chun Jason Xue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19982v1","updated":"2025-11-25T06:51:15Z","published":"2025-11-25T06:51:15Z","title":"EmoFeedback2: Reinforcement of Continuous Emotional Image Generation via LVLM-based Reward and Textual Feedback","summary":"Continuous emotional image generation (C-EICG) is emerging rapidly due to its ability to produce images aligned with both user descriptions and continuous emotional values. However, existing approaches lack emotional feedback from generated images, limiting the control of emotional continuity. Additionally, their simple alignment between emotions and naively generated texts fails to adaptively adjust emotional prompts according to image content, leading to insufficient emotional fidelity. To address these concerns, we propose a novel generation-understanding-feedback reinforcement paradigm (EmoFeedback2) for C-EICG, which exploits the reasoning capability of the fine-tuned large vision-language model (LVLM) to provide reward and textual feedback for generating high-quality images with continuous emotions. Specifically, we introduce an emotion-aware reward feedback strategy, where the LVLM evaluates the emotional values of generated images and computes the reward against target emotions, guiding the reinforcement fine-tuning of the generative model and enhancing the emotional continuity of images. Furthermore, we design a self-promotion textual feedback framework, in which the LVLM iteratively analyzes the emotional content of generated images and adaptively produces refinement suggestions for the next-round prompt, improving the emotional fidelity with fine-grained content. Extensive experimental results demonstrate that our approach effectively generates high-quality images with the desired emotions, outperforming existing state-of-the-art methods in our custom dataset. The code and dataset will be released soon.","authors":["Jingyang Jia","Kai Shu","Gang Yang","Long Xing","Xun Chen","Aiping Liu"],"pdf_url":"","comment":null}]},"2025-11-26T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2511.21690v1","updated":"2025-11-26T18:59:55Z","published":"2025-11-26T18:59:55Z","title":"TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos","summary":"Learning new robot tasks on new platforms and in new scenes from only a handful of demonstrations remains challenging. While videos of other embodiments - humans and different robots - are abundant, differences in embodiment, camera, and environment hinder their direct use. We address the small-data problem by introducing a unifying, symbolic representation - a compact 3D \"trace-space\" of scene-level trajectories - that enables learning from cross-embodiment, cross-environment, and cross-task videos. We present TraceGen, a world model that predicts future motion in trace-space rather than pixel space, abstracting away appearance while retaining the geometric structure needed for manipulation. To train TraceGen at scale, we develop TraceForge, a data pipeline that transforms heterogeneous human and robot videos into consistent 3D traces, yielding a corpus of 123K videos and 1.8M observation-trace-language triplets. Pretraining on this corpus produces a transferable 3D motion prior that adapts efficiently: with just five target robot videos, TraceGen attains 80% success across four tasks while offering 50-600x faster inference than state-of-the-art video-based world models. In the more challenging case where only five uncalibrated human demonstration videos captured on a handheld phone are available, it still reaches 67.5% success on a real robot, highlighting TraceGen's ability to adapt across embodiments without relying on object detectors or heavy pixel-space generation.","authors":["Seungjae Lee","Yoonkyo Jung","Inkook Chun","Yao-Chih Lee","Zikui Cai","Hongjia Huang","Aayush Talreja","Tan Dat Dao","Yongyuan Liang","Jia-Bin Huang","Furong Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21666v1","updated":"2025-11-26T18:39:44Z","published":"2025-11-26T18:39:44Z","title":"Uncertainty Quantification for Visual Object Pose Estimation","summary":"Quantifying the uncertainty of an object's pose estimate is essential for robust control and planning. Although pose estimation is a well-studied robotics problem, attaching statistically rigorous uncertainty is not well understood without strict distributional assumptions. We develop distribution-free pose uncertainty bounds about a given pose estimate in the monocular setting. Our pose uncertainty only requires high probability noise bounds on pixel detections of 2D semantic keypoints on a known object. This noise model induces an implicit, non-convex set of pose uncertainty constraints. Our key contribution is SLUE (S-Lemma Uncertainty Estimation), a convex program to reduce this set to a single ellipsoidal uncertainty bound that is guaranteed to contain the true object pose with high probability. SLUE solves a relaxation of the minimum volume bounding ellipsoid problem inspired by the celebrated S-lemma. It requires no initial guess of the bound's shape or size and is guaranteed to contain the true object pose with high probability. For tighter uncertainty bounds at the same confidence, we extend SLUE to a sum-of-squares relaxation hierarchy which is guaranteed to converge to the minimum volume ellipsoidal uncertainty bound for a given set of keypoint constraints. We show this pose uncertainty bound can easily be projected to independent translation and axis-angle orientation bounds. We evaluate SLUE on two pose estimation datasets and a real-world drone tracking scenario. Compared to prior work, SLUE generates substantially smaller translation bounds and competitive orientation bounds. We release code at https://github.com/MIT-SPARK/PoseUncertaintySets.","authors":["Lorenzo Shaikewitz","Charis Georgiou","Luca Carlone"],"pdf_url":"","comment":"18 pages, 9 figures. Code available: https://github.com/MIT-SPARK/PoseUncertaintySets"},{"id":"http://arxiv.org/abs/2507.14731v2","updated":"2025-11-26T17:05:48Z","published":"2025-07-19T19:40:53Z","title":"X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots","summary":"Existing navigation methods are primarily designed for specific robot embodiments, limiting their generalizability across diverse robot platforms. In this paper, we introduce X-Nav, a novel framework for end-to-end cross-embodiment navigation where a single unified policy can be deployed across various embodiments for both wheeled and quadrupedal robots. X-Nav consists of two learning stages: 1) multiple expert policies are trained using deep reinforcement learning with privileged observations on a wide range of randomly generated robot embodiments; and 2) a single general policy is distilled from the expert policies via navigation action chunking with transformer (Nav-ACT). The general policy directly maps visual and proprioceptive observations to low-level control commands, enabling generalization to novel robot embodiments. Simulated experiments demonstrated that X-Nav achieved zero-shot transfer to both unseen embodiments and photorealistic environments. A scalability study showed that the performance of X-Nav improves when trained with an increasing number of randomly generated embodiments. An ablation study confirmed the design choices of X-Nav. Furthermore, real-world experiments were conducted to validate the generalizability of X-Nav in real-world environments.","authors":["Haitong Wang","Aaron Hao Tan","Angus Fung","Goldie Nejat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21584v1","updated":"2025-11-26T17:01:41Z","published":"2025-11-26T17:01:41Z","title":"Model-Based Policy Adaptation for Closed-Loop End-to-End Autonomous Driving","summary":"End-to-end (E2E) autonomous driving models have demonstrated strong performance in open-loop evaluations but often suffer from cascading errors and poor generalization in closed-loop settings. To address this gap, we propose Model-based Policy Adaptation (MPA), a general framework that enhances the robustness and safety of pretrained E2E driving agents during deployment. MPA first generates diverse counterfactual trajectories using a geometry-consistent simulation engine, exposing the agent to scenarios beyond the original dataset. Based on this generated data, MPA trains a diffusion-based policy adapter to refine the base policy's predictions and a multi-step Q value model to evaluate long-term outcomes. At inference time, the adapter proposes multiple trajectory candidates, and the Q value model selects the one with the highest expected utility. Experiments on the nuScenes benchmark using a photorealistic closed-loop simulator demonstrate that MPA significantly improves performance across in-domain, out-of-domain, and safety-critical scenarios. We further investigate how the scale of counterfactual data and inference-time guidance strategies affect overall effectiveness.","authors":["Haohong Lin","Yunzhi Zhang","Wenhao Ding","Jiajun Wu","Ding Zhao"],"pdf_url":"","comment":"Published at NeurIPS 2025: https://openreview.net/forum?id=4OLbpaTKJe"},{"id":"http://arxiv.org/abs/2511.21557v1","updated":"2025-11-26T16:29:24Z","published":"2025-11-26T16:29:24Z","title":"VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation","summary":"Vision Language Action models have significantly advanced general purpose robotic manipulation by harnessing large scale pretrained vision and language representations. Among existing approaches, a majority of current VLA systems employ parallel two finger grippers as their default end effectors. However, such grippers face inherent limitations in handling certain real world tasks such as wiping glass surfaces or opening drawers without handles due to insufficient contact area or lack of adhesion. To overcome these challenges, we present a low cost, integrated hardware design that combines a mechanical two finger gripper with a vacuum suction unit, enabling dual mode manipulation within a single end effector. Our system supports flexible switching or synergistic use of both modalities, expanding the range of feasible tasks. We validate the efficiency and practicality of our design within two state of the art VLA frameworks: DexVLA and Pi0. Experimental results demonstrate that with the proposed hybrid end effector, robots can successfully perform multiple complex tasks that are infeasible for conventional two finger grippers alone. All hardware designs and controlling systems will be released.","authors":["Hui Zhou","Siyuan Huang","Minxing Li","Hao Zhang","Lue Fan","Shaoshuai Shi"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2511.21542v1","updated":"2025-11-26T16:14:20Z","published":"2025-11-26T16:14:20Z","title":"$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion","summary":"Vision-Language-Action (VLA) models offer a unified framework for robotic manipulation by integrating visual perception, language understanding, and control generation. Yet existing VLA models still struggle to generalize across diverse tasks, scenes, and camera viewpoints, and often produce coarse or unstable actions. We introduce E0, a continuized discrete diffusion framework that formulates action generation as iterative denoising over quantized action tokens. Compared with continuous diffusion policies, E0 offers two key advantages: (1) discrete action tokens align naturally with the symbolic structure of pretrained VLM/VLA backbones, enabling stronger semantic conditioning; and 2. discrete diffusion matches the true quantized nature of real-world robot control-whose hardware constraints (e.g., encoder resolution, control frequency, actuation latency) inherently discretize continuous signals-and therefore benefits from a Bayes-optimal denoiser that models the correct discrete action distribution, leading to stronger generalization. Compared with discrete autoregressive and mask-based discrete diffusion models, E0 supports a significantly larger and finer-grained action vocabulary and avoids the distributional mismatch introduced by masking-based corruptions-yielding more accurate fine-grained action control. We further introduce a spherical viewpoint perturbation augmentation method to improve robustness to camera shifts without additional data. Experiments on LIBERO, VLABench, and ManiSkill show that E0 achieves state-of-the-art performance across 14 diverse environments, outperforming strong baselines by 10.7% on average. Real-world evaluation on a Franka arm confirms that E0 delivers precise, robust, and transferable manipulation, establishing discrete diffusion as a promising direction for generalizable VLA policy learning.","authors":["Zhihao Zhan","Jiaying Zhou","Likui Zhang","Qinhan Lv","Hao Liu","Jusheng Zhang","Weizheng Li","Ziliang Chen","Tianshui Chen","Keze Wang","Liang Lin","Guangrun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21531v1","updated":"2025-11-26T15:59:55Z","published":"2025-11-26T15:59:55Z","title":"Predictive Safety Shield for Dyna-Q Reinforcement Learning","summary":"Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.","authors":["Jin Pin","Krasowski Hanna","Vanneaux Elena"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.17846v2","updated":"2025-11-26T15:20:20Z","published":"2024-05-28T05:50:25Z","title":"Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs","summary":"Safety limitations in service robotics across various industries have raised significant concerns about the need for robust mechanisms ensuring that robots adhere to safe practices, thereby preventing actions that might harm humans or cause property damage. Despite advances, including the integration of Knowledge Graphs (KGs) with Large Language Models (LLMs), challenges in ensuring consistent safety in autonomous robot actions persist. In this paper, we propose a novel integration of Large Language Models with Embodied Robotic Control Prompts (ERCPs) and Embodied Knowledge Graphs (EKGs) to enhance the safety framework for service robots. ERCPs are designed as predefined instructions that ensure LLMs generate safe and precise responses. These responses are subsequently validated by EKGs, which provide a comprehensive knowledge base ensuring that the actions of the robot are continuously aligned with safety protocols, thereby promoting safer operational practices in varied contexts. Our experimental setup involved diverse real-world tasks, where robots equipped with our framework demonstrated significantly higher compliance with safety standards compared to traditional methods. This integration fosters secure human-robot interactions and positions our methodology at the forefront of AI-driven safety innovations in service robotics.","authors":["Yong Qi","Gabriel Kyebambo","Siyuan Xie","Wei Shen","Shenghui Wang","Bitao Xie","Bin He","Zhipeng Wang","Shuo Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07387v3","updated":"2025-11-26T14:06:48Z","published":"2025-08-10T15:27:23Z","title":"MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control","summary":"Navigating unknown environments with a single RGB camera is challenging, as the lack of depth information prevents reliable collision-checking. While some methods use estimated depth to build collision maps, we found that depth estimates from vision foundation models are too noisy for zero-shot navigation in cluttered environments. We propose an alternative approach: instead of using noisy estimated depth for direct collision-checking, we use it as a rich context input to a learned collision model. This model predicts the distribution of minimum obstacle clearance that the robot can expect for a given control sequence. At inference, these predictions inform a risk-aware MPC planner that minimizes estimated collision risk. We proposed a joint learning pipeline that co-trains the collision model and risk metric using both safe and unsafe trajectories. Crucially, our joint-training ensures well calibrated uncertainty in our collision model that improves navigation in highly cluttered environments. Consequently, real-world experiments show reductions in collision-rate and improvements in goal reaching and speed over several strong baselines.","authors":["Basant Sharma","Prajyot Jadhav","Pranjal Paul","K. Madhava Krishna","Arun Kumar Singh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21366v1","updated":"2025-11-26T13:12:21Z","published":"2025-11-26T13:12:21Z","title":"Hybrid Control for Robotic Nut Tightening Task","summary":"An autonomous robotic nut tightening system for a serial manipulator equipped with a parallel gripper is proposed. The system features a hierarchical motion-primitive-based planner and a control-switching scheme that alternates between force and position control. Extensive simulations demonstrate the system's robustness to variance in initial conditions. Additionally, the proposed controller tightens threaded screws 14% faster than the baseline while applying 40 times less contact force on manipulands. For the benefit of the research community, the system's implementation is open-sourced.","authors":["Dmitri Kovalenko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21314v1","updated":"2025-11-26T12:00:58Z","published":"2025-11-26T12:00:58Z","title":"Scalable Multisubject Vital Sign Monitoring With mmWave FMCW Radar and FPGA Prototyping","summary":"In this work, we introduce an innovative approach to estimate the vital signs of multiple human subjects simultaneously in a non-contact way using a Frequency Modulated Continuous Wave (FMCW) radar-based system. Traditional vital sign monitoring methods often face significant limitations, including subject discomfort with wearable devices, challenges in calibration, and the risk of infection transmission through contact measurement devices. To address these issues, this research is motivated by the need for versatile, non-contact vital monitoring solutions applicable in various critical scenarios. This work also explores the challenges of extending this capability to an arbitrary number of subjects, including hardware and theoretical limitations. Supported by rigorous experimental results and discussions, the paper illustrates the system's potential to redefine vital sign monitoring. An FPGA-based implementation is also presented as proof of concept for a hardware-based and portable solution, improving upon previous works by offering 2.7x faster execution and 18.4% less Look-Up Table (LUT) utilization, as well as providing over 7400x acceleration compared to its software counterpart.","authors":["Jewel Benny","Narahari N. Moudhgalya","Mujeev Khan","Hemant Kumar Meena","Mohd Wajid","Abhishek Srivastava"],"pdf_url":"","comment":"Published in IEEE Sensors Journal"},{"id":"http://arxiv.org/abs/2511.21312v1","updated":"2025-11-26T11:59:09Z","published":"2025-11-26T11:59:09Z","title":"Neural NMPC through Signed Distance Field Encoding for Collision Avoidance","summary":"This paper introduces a neural Nonlinear Model Predictive Control (NMPC) framework for mapless, collision-free navigation in unknown environments with Aerial Robots, using onboard range sensing. We leverage deep neural networks to encode a single range image, capturing all the available information about the environment, into a Signed Distance Function (SDF). The proposed neural architecture consists of two cascaded networks: a convolutional encoder that compresses the input image into a low-dimensional latent vector, and a Multi-Layer Perceptron that approximates the corresponding spatial SDF. This latter network parametrizes an explicit position constraint used for collision avoidance, which is embedded in a velocity-tracking NMPC that outputs thrust and attitude commands to the robot. First, a theoretical analysis of the contributed NMPC is conducted, verifying recursive feasibility and stability properties under fixed observations. Subsequently, we evaluate the open-loop performance of the learning-based components as well as the closed-loop performance of the controller in simulations and experiments. The simulation study includes an ablation study, comparisons with two state-of-the-art local navigation methods, and an assessment of the resilience to drifting odometry. The real-world experiments are conducted in forest environments, demonstrating that the neural NMPC effectively performs collision avoidance in cluttered settings against an adversarial reference velocity input and drifting position estimates.","authors":["Martin Jacquet","Marvin Harms","Kostas Alexis"],"pdf_url":"","comment":"accepted for publication in IJRR"},{"id":"http://arxiv.org/abs/2511.01493v2","updated":"2025-11-26T11:12:19Z","published":"2025-11-03T12:00:15Z","title":"Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues","summary":"Guiding an agent to a specific target in indoor environments based solely on RGB inputs and a floor plan is a promising yet challenging problem. Although existing methods have made significant progress, two challenges remain unresolved. First, the modality gap between egocentric RGB observations and the floor plan hinders the integration of visual and spatial information for both local obstacle avoidance and global planning. Second, accurate localization is critical for navigation performance, but remains challenging at deployment in unseen environments due to the lack of explicit geometric alignment between RGB inputs and floor plans. We propose a novel diffusion-based policy, denoted as GlocDiff, which integrates global path planning from the floor plan with local depth-aware features derived from RGB observations. The floor plan offers explicit global guidance, while the depth features provide implicit geometric cues, collectively enabling precise prediction of optimal navigation directions and robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation during training to enhance robustness against pose estimation errors, and we find that combining this with a relatively stable VO module during inference results in significantly improved navigation performance. Extensive experiments on the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in achieving superior navigation performance, and the success of real-world deployments also highlights its potential for widespread practical applications.","authors":["Wei Huang","Jiaxin Li","Zang Wan","Huijun Di","Wei Liang","Zhu Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21280v1","updated":"2025-11-26T11:11:59Z","published":"2025-11-26T11:11:59Z","title":"Improvement of Collision Avoidance in Cut-In Maneuvers Using Time-to-Collision Metrics","summary":"This paper proposes a new strategy for collision avoidance system leveraging Time-to-Collision (TTC) metrics for handling cut-in scenarios, which are particularly challenging for autonomous vehicles (AVs). By integrating a deep learning with TTC calculations, the system predicts potential collisions and determines appropriate evasive actions compared to traditional TTC -based approaches.","authors":["Jamal Raiyn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21264v1","updated":"2025-11-26T10:42:10Z","published":"2025-11-26T10:42:10Z","title":"Sampling-Based Optimization with Parallelized Physics Simulator for Bimanual Manipulation","summary":"In recent years, dual-arm manipulation has become an area of strong interest in robotics, with end-to-end learning emerging as the predominant strategy for solving bimanual tasks. A critical limitation of such learning-based approaches, however, is their difficulty in generalizing to novel scenarios, especially within cluttered environments. This paper presents an alternative paradigm: a sampling-based optimization framework that utilizes a GPU-accelerated physics simulator as its world model. We demonstrate that this approach can solve complex bimanual manipulation tasks in the presence of static obstacles. Our contribution is a customized Model Predictive Path Integral Control (MPPI) algorithm, \\textbf{guided by carefully designed task-specific cost functions,} that uses GPU-accelerated MuJoCo for efficiently evaluating robot-object interaction. We apply this method to solve significantly more challenging versions of tasks from the PerAct$^{2}$ benchmark, such as requiring the point-to-point transfer of a ball through an obstacle course. Furthermore, we establish that our method achieves real-time performance on commodity GPUs and facilitates successful sim-to-real transfer by leveraging unique features within MuJoCo. The paper concludes with a statistical analysis of the sample complexity and robustness, quantifying the performance of our approach. The project website is available at: https://sites.google.com/view/bimanualakslabunitartu .","authors":["Iryna Hurova","Alinjar Dan","Karl Kruusamäe","Arun Kumar Singh"],"pdf_url":"","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.21255v1","updated":"2025-11-26T10:38:53Z","published":"2025-11-26T10:38:53Z","title":"Design and Measurements of mmWave FMCW Radar Based Non-Contact Multi-Patient Heart Rate and Breath Rate Monitoring System","summary":"Recent developments in mmWave radar technologies have enabled the truly non-contact heart-rate (HR) and breath-rate (BR) measurement approaches, which provides a great ease in patient monitoring. Additionally, these technologies also provide opportunities to simultaneously detect HR and BR of multiple patients, which has become increasingly important for efficient mass monitoring scenarios. In this work, a frequency modulated continuous wave (FMCW) mmWave radar based truly non-contact multiple patient HR and BR monitoring system has been presented. Furthermore, a novel approach is also proposed, which combines multiple processing methods using a least squares solution to improve measurement accuracy, generalization, and handle measurement error. The proposed system has been developed using Texas Instruments' FMCW radar and experimental results with multiple subjects are also presented, which show >97% and >93% accuracy in the measured BR and HR values, respectively.","authors":["Jewel Benny","Pranjal Mahajan","Srayan Sankar Chatterjee","Mohd Wajid","Abhishek Srivastava"],"pdf_url":"","comment":"Presented at BioCAS 2023"},{"id":"http://arxiv.org/abs/2511.18157v2","updated":"2025-11-26T09:37:48Z","published":"2025-11-22T18:52:34Z","title":"scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python","summary":"Three-dimensional rigid-body transforms, i.e. rotations and translations, are central to modern differentiable machine learning pipelines in robotics, vision, and simulation. However, numerically robust and mathematically correct implementations, particularly on SO(3), are error-prone due to issues such as axis conventions, normalizations, composition consistency and subtle errors that only appear in edge cases. SciPy's spatial$.$transform module is a rigorously tested Python implementation. However, it historically only supported NumPy, limiting adoption in GPU-accelerated and autodiff-based workflows. We present a complete overhaul of SciPy's spatial$.$transform functionality that makes it compatible with any array library implementing the Python array API, including JAX, PyTorch, and CuPy. The revised implementation preserves the established SciPy interface while enabling GPU/TPU execution, JIT compilation, vectorized batching, and differentiation via native autodiff of the chosen backend. We demonstrate how this foundation supports differentiable scientific computing through two case studies: (i) scalability of 3D transforms and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation for accurate integration of rotational dynamics. Our contributions have been merged into SciPy main and will ship in the next release, providing a framework-agnostic, production-grade basis for 3D spatial math in differentiable systems and ML.","authors":["Martin Schuck","Alexander von Rohr","Angela P. Schoellig"],"pdf_url":"","comment":"Accepted as oral at the 1st Workshop on Differentiable Systems and Scientific Machine Learning @ EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21203v1","updated":"2025-11-26T09:33:03Z","published":"2025-11-26T09:33:03Z","title":"Transformer Driven Visual Servoing and Dual Arm Impedance Control for Fabric Texture Matching","summary":"In this paper, we propose a method to align and place a fabric piece on top of another using a dual-arm manipulator and a grayscale camera, so that their surface textures are accurately matched. We propose a novel control scheme that combines Transformer-driven visual servoing with dualarm impedance control. This approach enables the system to simultaneously control the pose of the fabric piece and place it onto the underlying one while applying tension to keep the fabric piece flat. Our transformer-based network incorporates pretrained backbones and a newly introduced Difference Extraction Attention Module (DEAM), which significantly enhances pose difference prediction accuracy. Trained entirely on synthetic images generated using rendering software, the network enables zero-shot deployment in real-world scenarios without requiring prior training on specific fabric textures. Real-world experiments demonstrate that the proposed system accurately aligns fabric pieces with different textures.","authors":["Fuyuki Tokuda","Akira Seino","Akinari Kobayashi","Kai Tang","Kazuhiro Kosuge"],"pdf_url":"","comment":"8 pages, 11 figures. Accepted to IEEE Robotics and Automation Letters (RA-L)"},{"id":"http://arxiv.org/abs/2511.21189v1","updated":"2025-11-26T09:11:52Z","published":"2025-11-26T09:11:52Z","title":"Dual Preintegration for Relative State Estimation","summary":"Relative State Estimation perform mutually localization between two mobile agents undergoing six-degree-of-freedom motion. Based on the principle of circular motion, the estimation accuracy is sensitive to nonlinear rotations of the reference platform, particularly under large inter-platform distances. This phenomenon is even obvious for linearized kinematics, because cumulative linearization errors significantly degrade precision. In virtual reality (VR) applications, this manifests as substantial positional errors in 6-DoF controller tracking during rapid rotations of the head-mounted display. The linearization errors introduce drift in the estimate and render the estimator inconsistent. In the field of odometry, IMU preintegration is proposed as a kinematic observation to enable efficient relinearization, thus mitigate linearized error. Building on this theory, we propose dual preintegration, a novel observation integrating IMU preintegration from both platforms. This method serves as kinematic constraints for consecutive relative state and supports efficient relinearization. We also perform observability analysis of the state and analytically formulate the accordingly null space. Algorithm evaluation encompasses both simulations and real-world experiments. Multiple nonlinear rotations on the reference platform are simulated to compare the precision of the proposed method with that of other state-of-the-art (SOTA) algorithms. The field test compares the proposed method and SOTA algorithms in the application of VR controller tracking from the perspectives of bias observability, nonlinear rotation, and background texture. The results demonstrate that the proposed method is more precise and robust than the SOTA algorithms.","authors":["Ruican Xia","Hailong Pei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.02062v3","updated":"2025-11-26T09:00:14Z","published":"2024-11-04T13:05:11Z","title":"Heterogeneous Multi-robot Task Allocation for Long-Endurance Missions in Dynamic Scenarios","summary":"We present a framework for Multi-Robot Task Allocation (MRTA) in heterogeneous teams performing long-endurance missions in dynamic scenarios. Given the limited battery of robots, especially for aerial vehicles, we allow for robot recharges and the possibility of fragmenting and/or relaying certain tasks. We also address tasks that must be performed by a coalition of robots in a coordinated manner. Given these features, we introduce a new class of heterogeneous MRTA problems which we analyze theoretically and optimally formulate as a Mixed-Integer Linear Program. We then contribute a heuristic algorithm to compute approximate solutions and integrate it into a mission planning and execution architecture capable of reacting to unexpected events by repairing or recomputing plans online. Our experimental results show the relevance of our newly formulated problem in a realistic use case for inspection with aerial robots. We assess the performance of our heuristic solver in comparison with other variants and with exact optimal solutions in small-scale scenarios. In addition, we evaluate the ability of our replanning framework to repair plans online.","authors":["Alvaro Calvo","Jesus Capitan"],"pdf_url":"","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.19031v2","updated":"2025-11-26T08:49:54Z","published":"2025-11-24T12:05:13Z","title":"Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors","summary":"Monocular Simultaneous Localization and Mapping (SLAM) aims to estimate a robot's pose while simultaneously reconstructing an unknown 3D scene using a single camera. While existing monocular SLAM systems generate detailed 3D geometry through dense scene representations, they are computationally expensive due to the need for iterative optimization. To address this challenge, MASt3R-SLAM utilizes learned 3D reconstruction priors, enabling more efficient and accurate estimation of both 3D structures and camera poses. However, MASt3R-SLAM is limited to single-agent operation. In this paper, we extend MASt3R-SLAM to introduce the first multi-agent monocular dense SLAM system. Each agent performs local SLAM using a 3D reconstruction prior, and their individual maps are fused into a globally consistent map through a loop-closure-based map fusion mechanism. Our approach improves computational efficiency compared to state-of-the-art methods, while maintaining similar mapping accuracy when evaluated on real-world datasets.","authors":["Yuchen Zhou","Haihang Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04384v3","updated":"2025-11-26T08:45:32Z","published":"2025-07-06T13:14:35Z","title":"Rapid and Safe Trajectory Planning over Diverse Scenes through Diffusion Composition","summary":"Safe trajectory planning in complex environments must balance stringent collision avoidance with real-time efficiency, which is a long-standing challenge in robotics. In this work, we present a diffusion-based trajectory planning framework that is both rapid and safe. First, we introduce a scene-agnostic, MPC-based data generation pipeline that efficiently produces large volumes of kinematically feasible trajectories. Building on this dataset, our integrated diffusion planner maps raw onboard sensor inputs directly to kinematically feasible trajectories, enabling efficient inference while maintaining strong collision avoidance. To generalize to diverse, previously unseen scenarios, we compose diffusion models at test time, enabling safe behavior without additional training. We further propose a lightweight, rule-based safety filter that, from the candidate set, selects the trajectory meeting safety and kinematic-feasibility requirements. Across seen and unseen settings, the proposed method delivers real-time-capable inference with high safety and stability. Experiments on an F1TENTH vehicle demonstrate practicality on real hardware. Project page: https://rstp-comp-diffuser.github.io/.","authors":["Wule Mao","Zhouheng Li","Yunhao Luo","Yilun Du","Lei Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21169v1","updated":"2025-11-26T08:29:51Z","published":"2025-11-26T08:29:51Z","title":"Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation","summary":"Humanoid robots, with their human-like morphology, hold great potential for industrial applications. However, existing loco-manipulation methods primarily focus on dexterous manipulation, falling short of the combined requirements for dexterity and proactive force interaction in high-load industrial scenarios. To bridge this gap, we propose a reinforcement learning-based framework with a decoupled three-stage training pipeline, consisting of an upper-body policy, a lower-body policy, and a delta-command policy. To accelerate upper-body training, a heuristic reward function is designed. By implicitly embedding forward kinematics priors, it enables the policy to converge faster and achieve superior performance. For the lower body, a force-based curriculum learning strategy is developed, enabling the robot to actively exert and regulate interaction forces with the environment.","authors":["Kaiyan Xiao","Zihan Xu","Cheng Zhe","Chengju Liu","Qijun Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21161v1","updated":"2025-11-26T08:20:20Z","published":"2025-11-26T08:20:20Z","title":"MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments","summary":"The development of embodied agents for complex commercial environments is hindered by a critical gap in existing robotics datasets and benchmarks, which primarily focus on household or tabletop settings with short-horizon tasks. To address this limitation, we introduce MarketGen, a scalable simulation platform with automatic scene generation for complex supermarket environments. MarketGen features a novel agent-based Procedural Content Generation (PCG) framework. It uniquely supports multi-modal inputs (text and reference images) and integrates real-world design principles to automatically generate complete, structured, and realistic supermarkets. We also provide an extensive and diverse 3D asset library with a total of 1100+ supermarket goods and parameterized facilities assets. Building on this generative foundation, we propose a novel benchmark for assessing supermarket agents, featuring two daily tasks in a supermarket: (1) Checkout Unloading: long-horizon tabletop tasks for cashier agents, and (2) In-Aisle Item Collection: complex mobile manipulation tasks for salesperson agents. We validate our platform and benchmark through extensive experiments, including the deployment of a modular agent system and successful sim-to-real transfer. MarketGen provides a comprehensive framework to accelerate research in embodied AI for complex commercial applications.","authors":["Xu Hu","Yiyang Feng","Junran Peng","Jiawei He","Liyi Chen","Chuanchen Luo","Xucheng Yin","Qing Li","Zhaoxiang Zhang"],"pdf_url":"","comment":"Project Page: https://xuhu0529.github.io/MarketGen"},{"id":"http://arxiv.org/abs/2501.02874v3","updated":"2025-11-26T08:17:54Z","published":"2025-01-06T09:35:36Z","title":"Steering Flexible Linear Objects in Planar Environments by Two Robot Hands Using Euler's Elastica Solutions","summary":"The manipulation of flexible objects such as cables, wires and fresh food items by robot hands forms a special challenge in robot grasp mechanics. This paper considers the steering of flexible linear objects in planar environments by two robot hands. The flexible linear object, modeled as an elastic non-stretchable rod, is manipulated by varying the gripping endpoint positions while keeping equal endpoint tangents. The flexible linear object shape has a closed form solution in terms of the grasp endpoint positions and tangents, called Euler's elastica. This paper obtains the elastica solutions under the optimal control framework, then uses the elastica solutions to obtain closed-form criteria for non self-intersection, stability and obstacle avoidance of the flexible linear object. The new tools are incorporated into a planning scheme for steering flexible linear objects in planar environments populated by sparsely spaced obstacles. The scheme is fully implemented and demonstrated with detailed examples.","authors":["Aharon Levin","Elon Rimon","Amir Shapiro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.05717v11","updated":"2025-11-26T08:17:06Z","published":"2024-07-08T08:21:22Z","title":"A New Framework for Nonlinear Kalman Filters","summary":"The Kalman filter (KF) is a state estimation algorithm that optimally combines system knowledge and measurements to minimize the mean squared error of the estimated states. While KF was initially designed for linear systems, numerous extensions of it, such as extended Kalman filter (EKF), unscented Kalman filter (UKF), cubature Kalman filter (CKF), etc., have been proposed for nonlinear systems over the last sixty years. Although different types of nonlinear KFs have different pros and cons, they all use the same framework of linear KF. Yet, according to our theoretical and empirical analysis, the framework tends to give overconfident and less accurate state estimations when the measurement functions are nonlinear. Therefore, in this study, we designed a new framework that can be combined with any existing type of nonlinear KFs and showed theoretically and empirically that the new framework estimates the states and covariance more accurately than the old one. The new framework was tested on four different nonlinear KFs and five different tasks, showcasing its ability to reduce estimation errors by several orders of magnitude in low-measurement-noise conditions. The codes are available at https://github.com/Shida-Jiang/A-new-framework-for-nonlinear-Kalman-filters","authors":["Shida Jiang","Junzhe Shi","Scott Moura"],"pdf_url":"","comment":"Massive revisions throughout the entire paper. More simulation results are added, and the mathematical expressions have become more rigorous and precise"},{"id":"http://arxiv.org/abs/2511.21149v1","updated":"2025-11-26T08:10:59Z","published":"2025-11-26T08:10:59Z","title":"Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning","summary":"Non-contact manipulation has emerged as a transformative approach across various industrial fields. However, current flexible 2D and 3D non-contact manipulation techniques are often limited to microscopic scales, typically controlling objects in the milligram range. In this paper, we present a magnetic levitation system, termed Maglev-Pentabot, designed to address this limitation. The Maglev-Pentabot leverages deep reinforcement learning (DRL) to develop complex control strategies for manipulating objects in the gram range. Specifically, we propose an electromagnet arrangement optimized through numerical analysis to maximize controllable space. Additionally, an action remapping method is introduced to address sample sparsity issues caused by the strong nonlinearity in magnetic field intensity, hence allowing the DRL controller to converge. Experimental results demonstrate flexible manipulation capabilities, and notably, our system can generalize to transport tasks it has not been explicitly trained for. Furthermore, our approach can be scaled to manipulate heavier objects using larger electromagnets, offering a reference framework for industrial-scale robotic applications.","authors":["Guoming Huang","Qingyi Zhou","Dianjing Liu","Shuai Zhang","Ming Zhou","Zongfu Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18579v2","updated":"2025-11-26T07:41:17Z","published":"2025-11-23T18:44:47Z","title":"Connectivity-Preserving Multi-Agent Area Coverage via Optimal-Transport-Based Density-Driven Optimal Control (D2OC)","summary":"Multi-agent systems play a central role in area coverage tasks across search-and-rescue, environmental monitoring, and precision agriculture. Achieving non-uniform coverage, where spatial priorities vary across the domain, requires coordinating agents while respecting dynamic and communication constraints. Density-driven approaches can distribute agents according to a prescribed reference density, but existing methods do not ensure connectivity. This limitation often leads to communication loss, reduced coordination, and degraded coverage performance.\n  This letter introduces a connectivity-preserving extension of the Density-Driven Optimal Control (D2OC) framework. The coverage objective, defined using the Wasserstein distance between the agent distribution and the reference density, admits a convex quadratic program formulation. Communication constraints are incorporated through a smooth connectivity penalty, which maintains strict convexity, supports distributed implementation, and preserves inter-agent communication without imposing rigid formations.\n  Simulation studies show that the proposed method consistently maintains connectivity, improves convergence speed, and enhances non-uniform coverage quality compared with density-driven schemes that do not incorporate explicit connectivity considerations.","authors":["Kooktae Lee","Ethan Brook"],"pdf_url":"","comment":"Under review in IEEE Control Systems Letters (LCSS). 6 pages"},{"id":"http://arxiv.org/abs/2511.21135v1","updated":"2025-11-26T07:36:01Z","published":"2025-11-26T07:36:01Z","title":"SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation","summary":"Embodied navigation that adheres to social norms remains an open research challenge. Our \\textbf{SocialNav} is a foundational model for socially-aware navigation with a hierarchical \"brain-action\" architecture, capable of understanding high-level social norms and generating low-level, socially compliant trajectories. To enable such dual capabilities, we construct the SocNav Dataset, a large-scale collection of 7 million samples, comprising (1) a Cognitive Activation Dataset providing social reasoning signals such as chain-of-thought explanations and social traversability prediction, and (2) an Expert Trajectories Pyramid aggregating diverse navigation demonstrations from internet videos, simulated environments, and real-world robots. A multi-stage training pipeline is proposed to gradually inject and refine navigation intelligence: we first inject general navigation skills and social norms understanding into the model via imitation learning, and then refine such skills through a deliberately designed Socially-Aware Flow Exploration GRPO (SAFE-GRPO), the first flow-based reinforcement learning framework for embodied navigation that explicitly rewards socially compliant behaviors. SocialNav achieves +38% success rate and +46% social compliance rate compared to the state-of-the-art method, demonstrating strong gains in both navigation performance and social compliance. Our project page: https://amap-eai.github.io/SocialNav/","authors":["Ziyi Chen","Yingnan Guo","Zedong Chu","Minghua Luo","Yanfen Shen","Mingchao Sun","Junjun Hu","Shichao Xie","Kuan Yang","Pei Shi","Zhining Gu","Lu Liu","Honglin Han","Xiaolong Wu","Mu Xu","Yu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20431v2","updated":"2025-11-26T06:45:15Z","published":"2025-11-25T16:03:38Z","title":"BRIC: Bridging Kinematic Plans and Physical Control at Test Time","summary":"We propose BRIC, a novel test-time adaptation (TTA) framework that enables long-term human motion generation by resolving execution discrepancies between diffusion-based kinematic motion planners and reinforcement learning-based physics controllers. While diffusion models can generate diverse and expressive motions conditioned on text and scene context, they often produce physically implausible outputs, leading to execution drift during simulation. To address this, BRIC dynamically adapts the physics controller to noisy motion plans at test time, while preserving pre-trained skills via a loss function that mitigates catastrophic forgetting. In addition, BRIC introduces a lightweight test-time guidance mechanism that steers the diffusion model in the signal space without updating its parameters. By combining both adaptation strategies, BRIC ensures consistent and physically plausible long-term executions across diverse environments in an effective and efficient manner. We validate the effectiveness of BRIC on a variety of long-term tasks, including motion composition, obstacle avoidance, and human-scene interaction, achieving state-of-the-art performance across all tasks.","authors":["Dohun Lim","Minji Kim","Jaewoon Lim","Sungchan Kim"],"pdf_url":"","comment":"Accepted to AAAI'26"},{"id":"http://arxiv.org/abs/2511.21083v1","updated":"2025-11-26T06:03:03Z","published":"2025-11-26T06:03:03Z","title":"Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry","summary":"Visual-Inertial Odometry (VIO) is a critical component for robust ego-motion estimation, enabling foundational capabilities such as autonomous navigation in robotics and real-time 6-DoF tracking for augmented reality. Existing methods face a well-known trade-off: filter-based approaches are efficient but prone to drift, while optimization-based methods, though accurate, rely on computationally prohibitive Visual-Inertial Bundle Adjustment (VIBA) that is difficult to run on resource-constrained platforms. Rather than removing VIBA altogether, we aim to reduce how often and how heavily it must be invoked. To this end, we cast two key design choices in modern VIO, when to run the visual frontend and how strongly to trust its output, as sequential decision problems, and solve them with lightweight reinforcement learning (RL) agents. Our framework introduces a lightweight, dual-pronged RL policy that serves as our core contribution: (1) a Select Agent intelligently gates the entire VO pipeline based only on high-frequency IMU data; and (2) a composite Fusion Agent that first estimates a robust velocity state via a supervised network, before an RL policy adaptively fuses the full (p, v, q) state. Experiments on the EuRoC MAV and TUM-VI datasets show that, in our unified evaluation, the proposed method achieves a more favorable accuracy-efficiency-memory trade-off than prior GPU-based VO/VIO systems: it attains the best average ATE while running up to 1.77 times faster and using less GPU memory. Compared to classical optimization-based VIO systems, our approach maintains competitive trajectory accuracy while substantially reducing computational load.","authors":["Feiyang Pan","Shenghe Zheng","Chunyan Yin","Guangbin Dou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21053v1","updated":"2025-11-26T04:44:27Z","published":"2025-11-26T04:44:27Z","title":"AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios","summary":"Referring Multi-Object Tracking (RMOT) aims to achieve precise object detection and tracking through natural language instructions, representing a fundamental capability for intelligent robotic systems. However, current RMOT research remains mostly confined to ground-level scenarios, which constrains their ability to capture broad-scale scene contexts and perform comprehensive tracking and path planning. In contrast, Unmanned Aerial Vehicles (UAVs) leverage their expansive aerial perspectives and superior maneuverability to enable wide-area surveillance. Moreover, UAVs have emerged as critical platforms for Embodied Intelligence, which has given rise to an unprecedented demand for intelligent aerial systems capable of natural language interaction. To this end, we introduce AerialMind, the first large-scale RMOT benchmark in UAV scenarios, which aims to bridge this research gap. To facilitate its construction, we develop an innovative semi-automated collaborative agent-based labeling assistant (COALA) framework that significantly reduces labor costs while maintaining annotation quality. Furthermore, we propose HawkEyeTrack (HETrack), a novel method that collaboratively enhances vision-language representation learning and improves the perception of UAV scenarios. Comprehensive experiments validated the challenging nature of our dataset and the effectiveness of our method.","authors":["Chenglizhao Chen","Shaofeng Liang","Runwei Guan","Xiaolou Sun","Haocheng Zhao","Haiyun Jiang","Tao Huang","Henghui Ding","Qing-Long Han"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.19655v2","updated":"2025-11-26T03:20:17Z","published":"2025-11-24T19:43:03Z","title":"Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection","summary":"Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.","authors":["Shantanu Rahman","Nayeb Hasin","Mainul Islam","Golam Sarowar"],"pdf_url":"","comment":"49 pages, 23 figures"},{"id":"http://arxiv.org/abs/2511.20992v1","updated":"2025-11-26T02:47:33Z","published":"2025-11-26T02:47:33Z","title":"Dataset Poisoning Attacks on Behavioral Cloning Policies","summary":"Behavior Cloning (BC) is a popular framework for training sequential decision policies from expert demonstrations via supervised learning. As these policies are increasingly being deployed in the real world, their robustness and potential vulnerabilities are an important concern. In this work, we perform the first analysis of the efficacy of clean-label backdoor attacks on BC policies. Our backdoor attacks poison a dataset of demonstrations by injecting a visual trigger to create a spurious correlation that can be exploited at test time. We evaluate how policy vulnerability scales with the fraction of poisoned data, the strength of the trigger, and the trigger type. We also introduce a novel entropy-based test-time trigger attack that substantially degrades policy performance by identifying critical states where test-time triggering of the backdoor is expected to be most effective at degrading performance. We empirically demonstrate that BC policies trained on even minimally poisoned datasets exhibit deceptively high, near-baseline task performance despite being highly vulnerable to backdoor trigger attacks during deployment. Our results underscore the urgent need for more research into the robustness of BC policies, particularly as large-scale datasets are increasingly used to train policies for real-world cyber-physical systems. Videos and code are available at https://sites.google.com/view/dataset-poisoning-in-bc.","authors":["Akansha Kalra","Soumil Datta","Ethan Gilmore","Duc La","Guanhong Tao","Daniel S. Brown"],"pdf_url":"","comment":"Accepted at EAI SmartSP 2025"},{"id":"http://arxiv.org/abs/2509.01010v2","updated":"2025-11-26T02:47:08Z","published":"2025-08-31T22:13:42Z","title":"Analytical Solvers for Common Algebraic Equations Arising in Kinematics Problems","summary":"This paper presents analytical solvers for four common types of algebraic equations encountered in robot kinematics: single trigonometric equations, single-angle trigonometric systems, two-angle trigonometric systems, and bilinear two-angle systems. These equations arise frequently in the kinematics problems, particularly in robot kinematics. We provide detailed solution methods, including closed-form expressions, numerical algorithms, and robustness considerations. The solvers are designed to handle general coefficients, manage singularities, and enumerate all real solutions efficiently. These solvers are implemented in Python packages and can be reproduced by prompting Language Lanuage Models. Sampe prompts are also provided in the public code space Github repo. These prompts can generate a working solver code with one single prompt in coding agent such as OpenAI's Codex 5.1. This work serves as a foundation for developing complete inverse kinematics solvers for various robot architectures. Extensive validation and benchmarking demonstrate the effectiveness and reliability of the proposed methods.","authors":["Hai-Jun Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06374v2","updated":"2025-11-26T01:42:54Z","published":"2025-09-08T06:59:46Z","title":"MAPF-HD: Multi-Agent Path Finding in High-Density Environments","summary":"Multi-agent path finding (MAPF) involves planning efficient paths for multiple agents to move simultaneously while avoiding collisions. In typical warehouse environments, agents are often sparsely distributed along aisles; however, increasing the agent density can improve space efficiency. When the agent density is high, it becomes necessary to optimize the paths not only for goal-assigned agents but also for those obstructing them. This study proposes a novel MAPF framework for high-density environments (MAPF-HD). Several studies have explored MAPF in similar settings using integer linear programming (ILP). However, ILP-based methods require substantial computation time to optimize all agent paths simultaneously. Even in small grid-based environments with fewer than $100$ cells, these computations can take tens to hundreds of seconds. Such high computational costs render these methods impractical for large-scale applications such as automated warehouses and valet parking. To address these limitations, we introduce the phased null-agent swapping (PHANS) method. PHANS employs a heuristic approach to incrementally swap positions between agents and empty vertices. This method solves the MAPF-HD problem within a few seconds, even in large environments containing more than $700$ cells. The proposed method has the potential to improve efficiency in various real-world applications such as warehouse logistics, traffic management, and crowd control. The implementation is available at https://github.com/ToyotaCRDL/MAPF-in-High-Density-Envs.","authors":["Hiroya Makino","Seigo Ito"],"pdf_url":"","comment":"9 pages, 12 figures"},{"id":"http://arxiv.org/abs/2510.11539v2","updated":"2025-11-26T01:22:03Z","published":"2025-10-13T15:39:21Z","title":"Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization","summary":"Accurate state estimation is critical for legged and aerial robots operating in dynamic, uncertain environments. A key challenge lies in specifying process and measurement noise covariances, which are typically unknown or manually tuned. In this work, we introduce a bi-level optimization framework that jointly calibrates covariance matrices and kinematic parameters in an estimator-in-the-loop manner. The upper level treats noise covariances and model parameters as optimization variables, while the lower level executes a full-information estimator. Differentiating through the estimator allows direct optimization of trajectory-level objectives, resulting in accurate and consistent state estimates. We validate our approach on quadrupedal and humanoid robots, demonstrating significantly improved estimation accuracy and uncertainty calibration compared to hand-tuned baselines. Our method unifies state estimation, sensor, and kinematics calibration into a principled, data-driven framework applicable across diverse robotic platforms.","authors":["Denglin Cheng","Jiarong Kang","Xiaobin Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20937v1","updated":"2025-11-26T00:06:02Z","published":"2025-11-26T00:06:02Z","title":"ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction","summary":"Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.","authors":["Qineng Wang","Wenlong Huang","Yu Zhou","Hang Yin","Tianwei Bao","Jianwen Lyu","Weiyu Liu","Ruohan Zhang","Jiajun Wu","Li Fei-Fei","Manling Li"],"pdf_url":"","comment":"Preprint version"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2511.21691v1","updated":"2025-11-26T18:59:56Z","published":"2025-11-26T18:59:56Z","title":"Canvas-to-Image: Compositional Image Generation with Multimodal Controls","summary":"While modern diffusion models excel at generating high-quality and diverse images, they still struggle with high-fidelity compositional and multimodal control, particularly when users simultaneously specify text prompts, subject references, spatial arrangements, pose constraints, and layout annotations. We introduce Canvas-to-Image, a unified framework that consolidates these heterogeneous controls into a single canvas interface, enabling users to generate images that faithfully reflect their intent. Our key idea is to encode diverse control signals into a single composite canvas image that the model can directly interpret for integrated visual-spatial reasoning. We further curate a suite of multi-task datasets and propose a Multi-Task Canvas Training strategy that optimizes the diffusion model to jointly understand and integrate heterogeneous controls into text-to-image generation within a unified learning paradigm. This joint training enables Canvas-to-Image to reason across multiple control modalities rather than relying on task-specific heuristics, and it generalizes well to multi-control scenarios during inference. Extensive experiments show that Canvas-to-Image significantly outperforms state-of-the-art methods in identity preservation and control adherence across challenging benchmarks, including multi-person composition, pose-controlled composition, layout-constrained generation, and multi-control generation.","authors":["Yusuf Dalva","Guocheng Gordon Qian","Maya Goldenberg","Tsai-Shien Chen","Kfir Aberman","Sergey Tulyakov","Pinar Yanardag","Kuan-Chieh Jackson Wang"],"pdf_url":"","comment":"24 pages; webpage: https://snap-research.github.io/canvas-to-image/"},{"id":"http://arxiv.org/abs/2511.21690v1","updated":"2025-11-26T18:59:55Z","published":"2025-11-26T18:59:55Z","title":"TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos","summary":"Learning new robot tasks on new platforms and in new scenes from only a handful of demonstrations remains challenging. While videos of other embodiments - humans and different robots - are abundant, differences in embodiment, camera, and environment hinder their direct use. We address the small-data problem by introducing a unifying, symbolic representation - a compact 3D \"trace-space\" of scene-level trajectories - that enables learning from cross-embodiment, cross-environment, and cross-task videos. We present TraceGen, a world model that predicts future motion in trace-space rather than pixel space, abstracting away appearance while retaining the geometric structure needed for manipulation. To train TraceGen at scale, we develop TraceForge, a data pipeline that transforms heterogeneous human and robot videos into consistent 3D traces, yielding a corpus of 123K videos and 1.8M observation-trace-language triplets. Pretraining on this corpus produces a transferable 3D motion prior that adapts efficiently: with just five target robot videos, TraceGen attains 80% success across four tasks while offering 50-600x faster inference than state-of-the-art video-based world models. In the more challenging case where only five uncalibrated human demonstration videos captured on a handheld phone are available, it still reaches 67.5% success on a real robot, highlighting TraceGen's ability to adapt across embodiments without relying on object detectors or heavy pixel-space generation.","authors":["Seungjae Lee","Yoonkyo Jung","Inkook Chun","Yao-Chih Lee","Zikui Cai","Hongjia Huang","Aayush Talreja","Tan Dat Dao","Yongyuan Liang","Jia-Bin Huang","Furong Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21688v1","updated":"2025-11-26T18:59:39Z","published":"2025-11-26T18:59:39Z","title":"G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning","summary":"Vision-Language Models (VLMs) still lack robustness in spatial intelligence, demonstrating poor performance on spatial understanding and reasoning tasks. We attribute this gap to the absence of a visual geometry learning process capable of reconstructing 3D space from 2D images. We present G$^2$VLM, a geometry grounded vision-language model that bridges two fundamental aspects of spatial intelligence: spatial 3D reconstruction and spatial understanding. G$^2$VLM natively leverages learned 3D visual geometry features to directly predict 3D attributes and enhance spatial reasoning tasks via in-context learning and interleaved reasoning. Our unified design is highly scalable for spatial understanding: it trains on abundant multi-view image and video data, while simultaneously leveraging the benefits of 3D visual priors that are typically only derived from hard-to-collect annotations. Experimental results demonstrate G$^2$VLM is proficient in both tasks, achieving comparable results to state-of-the-art feed-forward 3D reconstruction models and achieving better or competitive results across spatial understanding and reasoning tasks. By unifying a semantically strong VLM with low-level 3D vision tasks, we hope G$^2$VLM can serve as a strong baseline for the community and unlock more future applications, such as 3D scene editing.","authors":["Wenbo Hu","Jingli Lin","Yilin Long","Yunlong Ran","Lihan Jiang","Yifan Wang","Chenming Zhu","Runsen Xu","Tai Wang","Jiangmiao Pang"],"pdf_url":"","comment":"code are released at https://github.com/InternRobotics/G2VLM"},{"id":"http://arxiv.org/abs/2511.21681v1","updated":"2025-11-26T18:57:01Z","published":"2025-11-26T18:57:01Z","title":"Seeing without Pixels: Perception from Camera Trajectories","summary":"Can one perceive a video's content without seeing its pixels, just from the camera trajectory-the path it carves through space? This paper is the first to systematically investigate this seemingly implausible question. Towards this end, we propose a contrastive learning framework to train CamFormer, a dedicated encoder that projects camera pose trajectories into a joint embedding space, aligning them with natural language. We find that, contrary to its apparent simplicity, the camera trajectory is a remarkably informative signal to uncover video content. In other words, \"how you move\" can indeed reveal \"what you are doing\" (egocentric) or \"observing\" (exocentric). We demonstrate the versatility of our learned CamFormer embeddings on a diverse suite of downstream tasks, ranging from cross-modal alignment to classification and temporal analysis. Importantly, our representations are robust across diverse camera pose estimation methods, including both high-fidelity multi-sensored and standard RGB-only estimators. Our findings establish camera trajectory as a lightweight, robust, and versatile modality for perceiving video content.","authors":["Zihui Xue","Kristen Grauman","Dima Damen","Andrew Zisserman","Tengda Han"],"pdf_url":"","comment":"Project website: https://sites.google.com/view/seeing-without-pixels"},{"id":"http://arxiv.org/abs/2511.21673v1","updated":"2025-11-26T18:51:46Z","published":"2025-11-26T18:51:46Z","title":"Revolutionizing Glioma Segmentation & Grading Using 3D MRI - Guided Hybrid Deep Learning Models","summary":"Gliomas are brain tumor types that have a high mortality rate which means early and accurate diagnosis is important for therapeutic intervention for the tumors. To address this difficulty, the proposed research will develop a hybrid deep learning model which integrates U-Net based segmentation and a hybrid DenseNet-VGG classification network with multihead attention and spatial-channel attention capabilities. The segmentation model will precisely demarcate the tumors in a 3D volume of MRI data guided by spatial and contextual information. The classification network which combines a branch of both DenseNet and VGG, will incorporate the demarcated tumor on which features with attention mechanisms would be focused on clinically relevant features. High-dimensional 3D MRI data could successfully be utilized in the model through preprocessing steps which are normalization, resampling, and data augmentation. Through a variety of measures the framework is evaluated: measures of performance in segmentation are Dice coefficient and Mean Intersection over Union (IoU) and measures of performance in classification are accuracy precision, recall, and F1-score. The hybrid framework that has been proposed has demonstrated through physical testing that it has the capability of obtaining a Dice coefficient of 98% in tumor segmentation, and 99% on classification accuracy, outperforming traditional CNN models and attention-free methods. Utilizing multi-head attention mechanisms enhances notions of priority in aspects of the tumor that are clinically significant, and enhances interpretability and accuracy. The results suggest a great potential of the framework in facilitating the timely and reliable diagnosis and grading of glioma by clinicians is promising, allowing for better planning of patient treatment.","authors":["Pandiyaraju V","Sreya Mynampati","Abishek Karthik","Poovarasan L","D. Saraswathi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21666v1","updated":"2025-11-26T18:39:44Z","published":"2025-11-26T18:39:44Z","title":"Uncertainty Quantification for Visual Object Pose Estimation","summary":"Quantifying the uncertainty of an object's pose estimate is essential for robust control and planning. Although pose estimation is a well-studied robotics problem, attaching statistically rigorous uncertainty is not well understood without strict distributional assumptions. We develop distribution-free pose uncertainty bounds about a given pose estimate in the monocular setting. Our pose uncertainty only requires high probability noise bounds on pixel detections of 2D semantic keypoints on a known object. This noise model induces an implicit, non-convex set of pose uncertainty constraints. Our key contribution is SLUE (S-Lemma Uncertainty Estimation), a convex program to reduce this set to a single ellipsoidal uncertainty bound that is guaranteed to contain the true object pose with high probability. SLUE solves a relaxation of the minimum volume bounding ellipsoid problem inspired by the celebrated S-lemma. It requires no initial guess of the bound's shape or size and is guaranteed to contain the true object pose with high probability. For tighter uncertainty bounds at the same confidence, we extend SLUE to a sum-of-squares relaxation hierarchy which is guaranteed to converge to the minimum volume ellipsoidal uncertainty bound for a given set of keypoint constraints. We show this pose uncertainty bound can easily be projected to independent translation and axis-angle orientation bounds. We evaluate SLUE on two pose estimation datasets and a real-world drone tracking scenario. Compared to prior work, SLUE generates substantially smaller translation bounds and competitive orientation bounds. We release code at https://github.com/MIT-SPARK/PoseUncertaintySets.","authors":["Lorenzo Shaikewitz","Charis Georgiou","Luca Carlone"],"pdf_url":"","comment":"18 pages, 9 figures. Code available: https://github.com/MIT-SPARK/PoseUncertaintySets"},{"id":"http://arxiv.org/abs/2511.21663v1","updated":"2025-11-26T18:37:54Z","published":"2025-11-26T18:37:54Z","title":"Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models","summary":"In recent years, Vision-Language-Action (VLA) models in embodied intelligence have developed rapidly. However, existing adversarial attack methods require costly end-to-end training and often generate noticeable perturbation patches. To address these limitations, we propose ADVLA, a framework that directly applies adversarial perturbations on features projected from the visual encoder into the textual feature space. ADVLA efficiently disrupts downstream action predictions under low-amplitude constraints, and attention guidance allows the perturbations to be both focused and sparse. We introduce three strategies that enhance sensitivity, enforce sparsity, and concentrate perturbations. Experiments demonstrate that under an $L_{\\infty}=4/255$ constraint, ADVLA combined with Top-K masking modifies less than 10% of the patches while achieving an attack success rate of nearly 100%. The perturbations are concentrated on critical regions, remain almost imperceptible in the overall image, and a single-step iteration takes only about 0.06 seconds, significantly outperforming conventional patch-based attacks. In summary, ADVLA effectively weakens downstream action predictions of VLA models under low-amplitude and locally sparse conditions, avoiding the high training costs and conspicuous perturbations of traditional patch attacks, and demonstrates unique effectiveness and practical value for attacking VLA feature spaces.","authors":["Naifu Zhang","Wei Tao","Xi Xiao","Qianpu Sun","Yuxin Zheng","Wentao Mo","Peiqiang Wang","Nan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21662v1","updated":"2025-11-26T18:35:17Z","published":"2025-11-26T18:35:17Z","title":"Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following","summary":"Large multimodal models (LMMs) are increasingly adopted as judges in multimodal evaluation systems due to their strong instruction following and consistency with human preferences. However, their ability to follow diverse, fine-grained evaluation criteria remains underexplored. We develop Multi-Crit, a benchmark for evaluating multimodal judges on their capacity to follow pluralistic criteria and produce reliable criterion-level judgments. Covering both open-ended generation and verifiable reasoning tasks, Multi-Crit is built through a rigorous data curation pipeline that gathers challenging response pairs with multi-criterion human annotations. It further introduces three novel metrics for systematically assessing pluralistic adherence, criterion-switching flexibility, and the ability to recognize criterion-level preference conflicts. Comprehensive analysis of 25 LMMs reveals that 1) proprietary models still struggle to maintain consistent adherence to pluralistic criteria--especially in open-ended evaluation; 2) open-source models lag further behind in flexibly following diverse criteria; and 3) critic fine-tuning with holistic judgment signals enhances visual grounding but fails to generalize to pluralistic criterion-level judgment. Additional analyses on reasoning fine-tuning, test-time scaling, and boundary consistency between open-source and proprietary models further probe the limits of current multimodal judges. As a pioneering study, Multi-Crit lays the foundation for building reliable and steerable multimodal AI evaluation.","authors":["Tianyi Xiong","Yi Ge","Ming Li","Zuolong Zhang","Pranav Kulkarni","Kaishen Wang","Qi He","Zeying Zhu","Chenxi Liu","Ruibo Chen","Tong Zheng","Yanshuo Chen","Xiyao Wang","Renrui Zhang","Wenhu Chen","Heng Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16595v2","updated":"2025-11-26T18:30:04Z","published":"2025-11-20T17:48:21Z","title":"TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding","summary":"We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.","authors":["Boshen Xu","Zihan Xiao","Jiaze Li","Jianzhong Ju","Zhenbo Luo","Jian Luan","Qin Jin"],"pdf_url":"","comment":"Project page: https://xuboshen.github.io/TimeViper; Code: https://github.com/xiaomi-research/timeviper"},{"id":"http://arxiv.org/abs/2511.21653v1","updated":"2025-11-26T18:25:41Z","published":"2025-11-26T18:25:41Z","title":"CaFlow: Enhancing Long-Term Action Quality Assessment with Causal Counterfactual Flow","summary":"Action Quality Assessment (AQA) predicts fine-grained execution scores from action videos and is widely applied in sports, rehabilitation, and skill evaluation. Long-term AQA, as in figure skating or rhythmic gymnastics, is especially challenging since it requires modeling extended temporal dynamics while remaining robust to contextual confounders. Existing approaches either depend on costly annotations or rely on unidirectional temporal modeling, making them vulnerable to spurious correlations and unstable long-term representations. To this end, we propose CaFlow, a unified framework that integrates counterfactual de-confounding with bidirectional time-conditioned flow. The Causal Counterfactual Regularization (CCR) module disentangles causal and confounding features in a self-supervised manner and enforces causal robustness through counterfactual interventions, while the BiT-Flow module models forward and backward dynamics with a cycle-consistency constraint to produce smoother and more coherent representations. Extensive experiments on multiple long-term AQA benchmarks demonstrate that CaFlow achieves state-of-the-art performance. Code is available at https://github.com/Harrison21/CaFlow","authors":["Ruisheng Han","Kanglei Zhou","Shuang Chen","Amir Atapour-Abarghouei","Hubert P. H. Shum"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21652v1","updated":"2025-11-26T18:24:11Z","published":"2025-11-26T18:24:11Z","title":"Continual Error Correction on Low-Resource Devices","summary":"The proliferation of AI models in everyday devices has highlighted a critical challenge: prediction errors that degrade user experience. While existing solutions focus on error detection, they rarely provide efficient correction mechanisms, especially for resource-constrained devices. We present a novel system enabling users to correct AI misclassifications through few-shot learning, requiring minimal computational resources and storage. Our approach combines server-side foundation model training with on-device prototype-based classification, enabling efficient error correction through prototype updates rather than model retraining. The system consists of two key components: (1) a server-side pipeline that leverages knowledge distillation to transfer robust feature representations from foundation models to device-compatible architectures, and (2) a device-side mechanism that enables ultra-efficient error correction through prototype adaptation. We demonstrate our system's effectiveness on both image classification and object detection tasks, achieving over 50% error correction in one-shot scenarios on Food-101 and Flowers-102 datasets while maintaining minimal forgetting (less than 0.02%) and negligible computational overhead. Our implementation, validated through an Android demonstration app, proves the system's practicality in real-world scenarios.","authors":["Kirill Paramonov","Mete Ozay","Aristeidis Mystakidis","Nikolaos Tsalikidis","Dimitrios Sotos","Anastasios Drosou","Dimitrios Tzovaras","Hyunjun Kim","Kiseok Chang","Sangdok Mo","Namwoong Kim","Woojong Yoo","Jijoong Moon","Umberto Michieli"],"pdf_url":"","comment":"ACM MMSys 2025"},{"id":"http://arxiv.org/abs/2511.21635v1","updated":"2025-11-26T18:07:14Z","published":"2025-11-26T18:07:14Z","title":"Mechanisms of Non-Monotonic Scaling in Vision Transformers","summary":"Deeper Vision Transformers often perform worse than shallower ones, which challenges common scaling assumptions. Through a systematic empirical analysis of ViT-S, ViT-B, and ViT-L on ImageNet, we identify a consistent three-phase Cliff-Plateau-Climb pattern that governs how representations evolve with depth. We observe that better performance is associated with progressive marginalization of the [CLS] token, originally designed as a global aggregation hub, in favor of distributed consensus among patch tokens. We quantify patterns of information mixing with an Information Scrambling Index, and show that in ViT-L the information-task tradeoff emerges roughly 10 layers later than in ViT-B, and that these additional layers correlate with increased information diffusion rather than improved task performance. Taken together, these results suggest that transformer architectures in this regime may benefit more from carefully calibrated depth that executes clean phase transitions than from simply increasing parameter count. The Information Scrambling Index provides a useful diagnostic for existing models and suggests a potential design target for future architectures. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb.","authors":["Anantha Padmanaban Krishna Kumar"],"pdf_url":"","comment":"16 pages total (11 pages main text, 1 pages references, 4 pages appendix), 5 figures, 11 tables. Code available at https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb"},{"id":"http://arxiv.org/abs/2511.21631v1","updated":"2025-11-26T17:59:08Z","published":"2025-11-26T17:59:08Z","title":"Qwen3-VL Technical Report","summary":"We introduce Qwen3-VL, the most capable vision-language model in the Qwen series to date, achieving superior performance across a broad range of multimodal benchmarks. It natively supports interleaved contexts of up to 256K tokens, seamlessly integrating text, images, and video. The model family includes both dense (2B/4B/8B/32B) and mixture-of-experts (30B-A3B/235B-A22B) variants to accommodate diverse latency-quality trade-offs. Qwen3-VL delivers three core pillars: (i) markedly stronger pure-text understanding, surpassing comparable text-only backbones in several cases; (ii) robust long-context comprehension with a native 256K-token window for both text and interleaved multimodal inputs, enabling faithful retention, retrieval, and cross-referencing across long documents and videos; and (iii) advanced multimodal reasoning across single-image, multi-image, and video tasks, demonstrating leading performance on comprehensive evaluations such as MMMU and visual-math benchmarks (e.g., MathVista and MathVision). Architecturally, we introduce three key upgrades: (i) an enhanced interleaved-MRoPE for stronger spatial-temporal modeling across images and video; (ii) DeepStack integration, which effectively leverages multi-level ViT features to tighten vision-language alignment; and (iii) text-based time alignment for video, evolving from T-RoPE to explicit textual timestamp alignment for more precise temporal grounding. Under comparable token budgets and latency constraints, Qwen3-VL achieves superior performance in both dense and Mixture-of-Experts (MoE) architectures. We envision Qwen3-VL serving as a foundational engine for image-grounded reasoning, agentic decision-making, and multimodal code intelligence in real-world workflows.","authors":["Shuai Bai","Yuxuan Cai","Ruizhe Chen","Keqin Chen","Xionghui Chen","Zesen Cheng","Lianghao Deng","Wei Ding","Chang Gao","Chunjiang Ge","Wenbin Ge","Zhifang Guo","Qidong Huang","Jie Huang","Fei Huang","Binyuan Hui","Shutong Jiang","Zhaohai Li","Mingsheng Li","Mei Li","Kaixin Li","Zicheng Lin","Junyang Lin","Xuejing Liu","Jiawei Liu","Chenglong Liu","Yang Liu","Dayiheng Liu","Shixuan Liu","Dunjie Lu","Ruilin Luo","Chenxu Lv","Rui Men","Lingchen Meng","Xuancheng Ren","Xingzhang Ren","Sibo Song","Yuchong Sun","Jun Tang","Jianhong Tu","Jianqiang Wan","Peng Wang","Pengfei Wang","Qiuyue Wang","Yuxuan Wang","Tianbao Xie","Yiheng Xu","Haiyang Xu","Jin Xu","Zhibo Yang","Mingkun Yang","Jianxin Yang","An Yang","Bowen Yu","Fei Zhang","Hang Zhang","Xi Zhang","Bo Zheng","Humen Zhong","Jingren Zhou","Fan Zhou","Jing Zhou","Yuanzhi Zhu","Ke Zhu"],"pdf_url":"","comment":"42 pages"},{"id":"http://arxiv.org/abs/2511.21625v1","updated":"2025-11-26T17:51:59Z","published":"2025-11-26T17:51:59Z","title":"Active Learning for GCN-based Action Recognition","summary":"Despite the notable success of graph convolutional networks (GCNs) in skeleton-based action recognition, their performance often depends on large volumes of labeled data, which are frequently scarce in practical settings. To address this limitation, we propose a novel label-efficient GCN model. Our work makes two primary contributions. First, we develop a novel acquisition function that employs an adversarial strategy to identify a compact set of informative exemplars for labeling. This selection process balances representativeness, diversity, and uncertainty. Second, we introduce bidirectional and stable GCN architectures. These enhanced networks facilitate a more effective mapping between the ambient and latent data spaces, enabling a better understanding of the learned exemplar distribution. Extensive evaluations on two challenging skeleton-based action recognition benchmarks reveal significant improvements achieved by our label-efficient GCNs compared to prior work.","authors":["Hichem Sahbi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21606v1","updated":"2025-11-26T17:26:00Z","published":"2025-11-26T17:26:00Z","title":"ReSAM: Refine, Requery, and Reinforce: Self-Prompting Point-Supervised Segmentation for Remote Sensing Images","summary":"Interactive segmentation models such as the Segment Anything Model (SAM) have demonstrated remarkable generalization on natural images, but perform suboptimally on remote sensing imagery (RSI) due to severe domain shift and the scarcity of dense annotations. To address this, we propose a self-prompting, point-supervised framework that adapts SAM to RSIs using only sparse point annotations. Our method employs a Refine-Requery-Reinforce loop, where coarse pseudo-masks are generated from initial points (Refine), improved with self-constructed box prompts (Requery), and embeddings are aligned across iterations to reduce confirmation bias (Reinforce). Without relying on full-mask supervision, our approach progressively enhances SAM's segmentation quality and domain robustness through self-guided prompt adaptation . We evaluate our proposed method on three RSI benchmark datasets, including WHU, HRSID, and NWPU VHR-10, showing that our method consistently surpasses pretrained SAM and recent point-supervised segmentation methods. Our results demonstrate that self-prompting and semantic alignment provide an efficient path towards scalable, point-level adaptation of foundation segmentation models for remote sensing applications.","authors":["M. Naseer Subhani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21592v1","updated":"2025-11-26T17:09:03Z","published":"2025-11-26T17:09:03Z","title":"MoGAN: Improving Motion Quality in Video Diffusion via Few-Step Motion Adversarial Post-Training","summary":"Video diffusion models achieve strong frame-level fidelity but still struggle with motion coherence, dynamics and realism, often producing jitter, ghosting, or implausible dynamics. A key limitation is that the standard denoising MSE objective provides no direct supervision on temporal consistency, allowing models to achieve low loss while still generating poor motion. We propose MoGAN, a motion-centric post-training framework that improves motion realism without reward models or human preference data. Built atop a 3-step distilled video diffusion model, we train a DiT-based optical-flow discriminator to differentiate real from generated motion, combined with a distribution-matching regularizer to preserve visual fidelity. With experiments on Wan2.1-T2V-1.3B, MoGAN substantially improves motion quality across benchmarks. On VBench, MoGAN boosts motion score by +7.3% over the 50-step teacher and +13.3% over the 3-step DMD model. On VideoJAM-Bench, MoGAN improves motion score by +7.4% over the teacher and +8.8% over DMD, while maintaining comparable or even better aesthetic and image-quality scores. A human study further confirms that MoGAN is preferred for motion quality (52% vs. 38% for the teacher; 56% vs. 29% for DMD). Overall, MoGAN delivers significantly more realistic motion without sacrificing visual fidelity or efficiency, offering a practical path toward fast, high-quality video generation. Project webpage is: https://xavihart.github.io/mogan.","authors":["Haotian Xue","Qi Chen","Zhonghao Wang","Xun Huang","Eli Shechtman","Jinrong Xie","Yongxin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21582v1","updated":"2025-11-26T16:56:42Z","published":"2025-11-26T16:56:42Z","title":"Deep Learning-Based Multiclass Classification of Oral Lesions with Stratified Augmentation","summary":"Oral cancer is highly common across the globe and is mostly diagnosed during the later stages due to the close visual similarity to benign, precancerous, and malignant lesions in the oral cavity. Implementing computer aided diagnosis systems early on has the potential to greatly improve clinical outcomes. This research intends to use deep learning to build a multiclass classifier for sixteen different oral lesions. To overcome the challenges of limited and imbalanced datasets, the proposed technique combines stratified data splitting and advanced data augmentation and oversampling to perform the classification. The experimental results, which achieved 83.33 percent accuracy, 89.12 percent precision, and 77.31 percent recall, demonstrate the superiority of the suggested model over state of the art methods now in use. The suggested model effectively conveys the effectiveness of oversampling and augmentation strategies in situations where the minority class classification performance is noteworthy. As a first step toward trustworthy computer aided diagnostic systems for the early detection of oral cancer in clinical settings, the suggested framework shows promise.","authors":["Joy Naoum","Revana Salama","Ali Hamdi"],"pdf_url":"","comment":"12 pages, 3 figures,"},{"id":"http://arxiv.org/abs/2511.21579v1","updated":"2025-11-26T16:53:05Z","published":"2025-11-26T16:53:05Z","title":"Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy","summary":"The synthesis of synchronized audio-visual content is a key challenge in generative AI, with open-source models facing challenges in robust audio-video alignment. Our analysis reveals that this issue is rooted in three fundamental challenges of the joint diffusion process: (1) Correspondence Drift, where concurrently evolving noisy latents impede stable learning of alignment; (2) inefficient global attention mechanisms that fail to capture fine-grained temporal cues; and (3) the intra-modal bias of conventional Classifier-Free Guidance (CFG), which enhances conditionality but not cross-modal synchronization. To overcome these challenges, we introduce Harmony, a novel framework that mechanistically enforces audio-visual synchronization. We first propose a Cross-Task Synergy training paradigm to mitigate drift by leveraging strong supervisory signals from audio-driven video and video-driven audio generation tasks. Then, we design a Global-Local Decoupled Interaction Module for efficient and precise temporal-style alignment. Finally, we present a novel Synchronization-Enhanced CFG (SyncCFG) that explicitly isolates and amplifies the alignment signal during inference. Extensive experiments demonstrate that Harmony establishes a new state-of-the-art, significantly outperforming existing methods in both generation fidelity and, critically, in achieving fine-grained audio-visual synchronization.","authors":["Teng Hu","Zhentao Yu","Guozhen Zhang","Zihan Su","Zhengguang Zhou","Youliang Zhang","Yuan Zhou","Qinglin Lu","Ran Yi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21575v1","updated":"2025-11-26T16:50:06Z","published":"2025-11-26T16:50:06Z","title":"Enhanced Landmark Detection Model in Pelvic Fluoroscopy using 2D/3D Registration Loss","summary":"Automated landmark detection offers an efficient approach for medical professionals to understand patient anatomic structure and positioning using intra-operative imaging. While current detection methods for pelvic fluoroscopy demonstrate promising accuracy, most assume a fixed Antero-Posterior view of the pelvis. However, orientation often deviates from this standard view, either due to repositioning of the imaging unit or of the target structure itself. To address this limitation, we propose a novel framework that incorporates 2D/3D landmark registration into the training of a U-Net landmark prediction model. We analyze the performance difference by comparing landmark detection accuracy between the baseline U-Net, U-Net trained with Pose Estimation Loss, and U-Net fine-tuned with Pose Estimation Loss under realistic intra-operative conditions where patient pose is variable.","authors":["Chou Mo","Yehyun Suh","J. Ryan Martin","Daniel Moyer"],"pdf_url":"","comment":"9 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2511.21574v1","updated":"2025-11-26T16:49:38Z","published":"2025-11-26T16:49:38Z","title":"Multimodal Robust Prompt Distillation for 3D Point Cloud Models","summary":"Adversarial attacks pose a significant threat to learning-based 3D point cloud models, critically undermining their reliability in security-sensitive applications. Existing defense methods often suffer from (1) high computational overhead and (2) poor generalization ability across diverse attack types. To bridge these gaps, we propose a novel yet efficient teacher-student framework, namely Multimodal Robust Prompt Distillation (MRPD) for distilling robust 3D point cloud model. It learns lightweight prompts by aligning student point cloud model's features with robust embeddings from three distinct teachers: a vision model processing depth projections, a high-performance 3D model, and a text encoder. To ensure a reliable knowledge transfer, this distillation is guided by a confidence-gated mechanism which dynamically balances the contribution of all input modalities. Notably, since the distillation is all during the training stage, there is no additional computational cost at inference. Extensive experiments demonstrate that MRPD substantially outperforms state-of-the-art defense methods against a wide range of white-box and black-box attacks, while even achieving better performance on clean data. Our work presents a new, practical paradigm for building robust 3D vision systems by efficiently harnessing multimodal knowledge.","authors":["Xiang Gu","Liming Lu","Xu Zheng","Anan Du","Yongbin Zhou","Shuchao Pang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21565v1","updated":"2025-11-26T16:38:29Z","published":"2025-11-26T16:38:29Z","title":"UAVLight: A Benchmark for Illumination-Robust 3D Reconstruction in Unmanned Aerial Vehicle (UAV) Scenes","summary":"Illumination inconsistency is a fundamental challenge in multi-view 3D reconstruction. Variations in sunlight direction, cloud cover, and shadows break the constant-lighting assumption underlying both classical multi-view stereo (MVS) and structure from motion (SfM) pipelines and recent neural rendering methods, leading to geometry drift, color inconsistency, and shadow imprinting. This issue is especially critical in UAV-based reconstruction, where long flight durations and outdoor environments make lighting changes unavoidable. However, existing datasets either restrict capture to short time windows, thus lacking meaningful illumination diversity, or span months and seasons, where geometric and semantic changes confound the isolated study of lighting robustness. We introduce UAVLight, a controlled-yet-real benchmark for illumination-robust 3D reconstruction. Each scene is captured along repeatable, geo-referenced flight paths at multiple fixed times of day, producing natural lighting variation under consistent geometry, calibration, and viewpoints. With standardized evaluation protocols across lighting conditions, UAVLight provides a reliable foundation for developing and benchmarking reconstruction methods that are consistent, faithful, and relightable in real outdoor environments.","authors":["Kang Du","Xue Liao","Junpeng Xia","Chaozheng Guo","Yi Gu","Yirui Guan","Duotun Wang"," ShengHuang","Zeyu Wang"],"pdf_url":"","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.18255v2","updated":"2025-11-26T16:28:59Z","published":"2025-11-23T02:58:10Z","title":"Sequence-Adaptive Video Prediction in Continuous Streams using Diffusion Noise Optimization","summary":"In this work, we investigate diffusion-based video prediction models, which forecast future video frames, for continuous video streams. In this context, the models observe continuously new training samples, and we aim to leverage this to improve their predictions. We thus propose an approach that continuously adapts a pre-trained diffusion model to a video stream. Since fine-tuning the parameters of a large diffusion model is too expensive, we refine the diffusion noise during inference while keeping the model parameters frozen, allowing the model to adaptively determine suitable sampling noise. We term the approach Sequence Adaptive Video Prediction with Diffusion Noise Optimization (SAVi-DNO). To validate our approach, we introduce a new evaluation setting on the Ego4D dataset, focusing on simultaneous adaptation and evaluation on long continuous videos. Empirical results demonstrate improved performance based on FVD, SSIM, and PSNR metrics on long videos of Ego4D and OpenDV-YouTube, as well as videos of UCF-101 and SkyTimelapse, showcasing SAVi-DNO's effectiveness.","authors":["Sina Mokhtarzadeh Azar","Emad Bahrami","Enrico Pallotta","Gianpiero Francesca","Radu Timofte","Juergen Gall"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06283v2","updated":"2025-11-26T16:22:26Z","published":"2025-11-09T08:37:18Z","title":"TinyChemVL: Advancing Chemical Vision-Language Models via Efficient Visual Token Reduction and Complex Reaction Tasks","summary":"While Vision Language Models (VLMs) have demonstrated remarkable capabilities in general visual understanding, their application in the chemical domain has been limited, with previous works predominantly focusing on text and thus overlooking critical visual information, such as molecular structures. Current approaches that directly adopt standard VLMs for chemical tasks suffer from two primary issues: (i) computational inefficiency of processing entire chemical images with non-informative backgrounds. (ii) a narrow scope on molecular-level tasks that restricts progress in chemical reasoning. In this work, we propose \\textbf{TinyChemVL}, an efficient and powerful chemical VLM that leverages visual token reduction and reaction-level tasks to improve model efficiency and reasoning capacity. Also, we propose \\textbf{ChemRxn-V}, a reaction-level benchmark for assessing vision-based reaction recognition and prediction tasks. Directly predicting reaction products from molecular images poses a non-trivial challenge, as it requires models to integrate both recognition and reasoning capacities. Our results demonstrate that with only 4B parameters, TinyChemVL achieves superior performance on both molecular and reaction tasks while demonstrating faster inference and training speeds compared to existing models. Notably, TinyChemVL outperforms ChemVLM while utilizing only 1/16th of the visual tokens. This work builds efficient yet powerful VLMs for chemical domains by co-designing model architecture and task complexity.","authors":["Xuanle Zhao","Shuxin Zeng","Xinyuan Cai","Xiang Cheng","Duzhen Zhang","Xiuyi Chen","Bo Xu"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.21541v1","updated":"2025-11-26T16:14:18Z","published":"2025-11-26T16:14:18Z","title":"Video Generation Models Are Good Latent Reward Models","summary":"Reward feedback learning (ReFL) has proven effective for aligning image generation with human preferences. However, its extension to video generation faces significant challenges. Existing video reward models rely on vision-language models designed for pixel-space inputs, confining ReFL optimization to near-complete denoising steps after computationally expensive VAE decoding. This pixel-space approach incurs substantial memory overhead and increased training time, and its late-stage optimization lacks early-stage supervision, refining only visual quality rather than fundamental motion dynamics and structural coherence. In this work, we show that pre-trained video generation models are naturally suited for reward modeling in the noisy latent space, as they are explicitly designed to process noisy latent representations at arbitrary timesteps and inherently preserve temporal information through their sequential modeling capabilities. Accordingly, we propose Process Reward Feedback Learning~(PRFL), a framework that conducts preference optimization entirely in latent space, enabling efficient gradient backpropagation throughout the full denoising chain without VAE decoding. Extensive experiments demonstrate that PRFL significantly improves alignment with human preferences, while achieving substantial reductions in memory consumption and training time compared to RGB ReFL.","authors":["Xiaoyue Mi","Wenqing Yu","Jiesong Lian","Shibo Jie","Ruizhe Zhong","Zijun Liu","Guozhen Zhang","Zixiang Zhou","Zhiyong Xu","Yuan Zhou","Qinglin Lu","Fan Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.22105v2","updated":"2025-11-26T16:07:32Z","published":"2025-05-28T08:32:55Z","title":"Adapting Segment Anything Model for Power Transmission Corridor Hazard Segmentation","summary":"Power transmission corridor hazard segmentation (PTCHS) aims to separate transmission equipment and surrounding hazards from complex background, conveying great significance to maintaining electric power transmission safety. Recently, the Segment Anything Model (SAM) has emerged as a foundational vision model and pushed the boundaries of segmentation tasks. However, SAM struggles to deal with the target objects in complex transmission corridor scenario, especially those with fine structure. In this paper, we propose ELE-SAM, adapting SAM for the PTCHS task. Technically, we develop a Context-Aware Prompt Adapter to achieve better prompt tokens via incorporating global-local features and focusing more on key regions. Subsequently, to tackle the hazard objects with fine structure in complex background, we design a High-Fidelity Mask Decoder by leveraging multi-granularity mask features and then scaling them to a higher resolution. Moreover, to train ELE-SAM and advance this field, we construct the ELE-40K benchmark, the first large-scale and real-world dataset for PTCHS including 44,094 image-mask pairs. Experimental results for ELE-40K demonstrate the superior performance that ELE-SAM outperforms the baseline model with the average 16.8% mIoU and 20.6% mBIoU performance improvement. Moreover, compared with the state-of-the-art method on HQSeg-44K, the average 2.9% mIoU and 3.8% mBIoU absolute improvements further validate the effectiveness of our method on high-quality generic object segmentation. The source code and dataset are available at https://github.com/Hhaizee/ELE-SAM.","authors":["Hang Chen","Maoyuan Ye","Peng Yang","Haibin He","Juhua Liu","Bo Du"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.19386v2","updated":"2025-11-26T16:02:59Z","published":"2025-05-26T01:04:02Z","title":"Force Prompting: Video Generation Models Can Learn and Generalize Physics-based Control Signals","summary":"Recent advances in video generation models have sparked interest in world models capable of simulating realistic environments. While navigation has been well-explored, physically meaningful interactions that mimic real-world forces remain largely understudied. In this work, we investigate using physical forces as a control signal for video generation and propose force prompts which enable users to interact with images through both localized point forces, such as poking a plant, and global wind force fields, such as wind blowing on fabric. We demonstrate that these force prompts can enable videos to respond realistically to physical control signals by leveraging the visual and motion prior in the original pretrained model, without using any 3D asset or physics simulator at inference. The primary challenge of force prompting is the difficulty in obtaining high quality paired force-video training data, both in the real world due to the difficulty of obtaining force signals, and in synthetic data due to limitations in the visual quality and domain diversity of physics simulators. Our key finding is that video generation models can generalize remarkably well when adapted to follow physical force conditioning from videos synthesized by Blender, even with limited demonstrations of few objects. Our method can generate videos which simulate forces across diverse geometries, settings, and materials. We also try to understand the source of this generalization and perform ablations that reveal two key elements: visual diversity and the use of specific text keywords during training. Our approach is trained on only around 15k training examples for a single day on four A100 GPUs, and outperforms existing methods on force adherence and physics realism, bringing world models closer to real-world physics interactions. We release all datasets, code, weights, and interactive video demos at our project page.","authors":["Nate Gillman","Charles Herrmann","Michael Freeman","Daksh Aggarwal","Evan Luo","Deqing Sun","Chen Sun"],"pdf_url":"","comment":"Camera ready version (NeurIPS 2025). Code and interactive demos at https://force-prompting.github.io/"},{"id":"http://arxiv.org/abs/2408.10901v4","updated":"2025-11-26T16:00:49Z","published":"2024-08-20T14:43:53Z","title":"A Gray-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse","summary":"Recent advancements in Latent Diffusion Models (LDMs) have revolutionized image synthesis and manipulation, raising significant concerns about data misappropriation and intellectual property infringement. While adversarial attacks have been extensively explored as a protective measure against such misuse of generative AI, current approaches are severely limited by their heavy reliance on model-specific knowledge and substantial computational costs. Drawing inspiration from the posterior collapse phenomenon observed in VAE training, we propose the Posterior Collapse Attack (PCA), a novel framework for protecting images from unauthorized manipulation. Through comprehensive theoretical analysis and empirical validation, we identify two distinct collapse phenomena during VAE inference: diffusion collapse and concentration collapse. Based on this discovery, we design a unified loss function that can flexibly achieve both types of collapse through parameter adjustment, each corresponding to different protection objectives in preventing image manipulation. Our method significantly reduces dependence on model-specific knowledge by requiring access to only the VAE encoder, which constitutes less than 4\\% of LDM parameters. Notably, PCA achieves prompt-invariant protection by operating on the VAE encoder before text conditioning occurs, eliminating the need for empty prompt optimization required by existing methods. This minimal requirement enables PCA to maintain adequate transferability across various VAE-based LDM architectures while effectively preventing unauthorized image editing. Extensive experiments show PCA outperforms existing techniques in protection effectiveness, computational efficiency (runtime and VRAM), and generalization across VAE-based LDM variants. Our code is available at https://github.com/ZhongliangGuo/PosteriorCollapseAttack.","authors":["Zhongliang Guo","Chun Tong Lei","Lei Fang","Shuai Zhao","Yifei Qian","Jingyu Lin","Zeyu Wang","Cunjian Chen","Ognjen Arandjelović","Chun Pong Lau"],"pdf_url":"","comment":"15 pages, 9 figures, 9 tables"},{"id":"http://arxiv.org/abs/2511.21533v1","updated":"2025-11-26T16:00:38Z","published":"2025-11-26T16:00:38Z","title":"Bangla Sign Language Translation: Dataset Creation Challenges, Benchmarking and Prospects","summary":"Bangla Sign Language Translation (BdSLT) has been severely constrained so far as the language itself is very low resource. Standard sentence level dataset creation for BdSLT is of immense importance for developing AI based assistive tools for deaf and hard of hearing people of Bangla speaking community. In this paper, we present a dataset, IsharaKhobor , and two subset of it for enabling research. We also present the challenges towards developing the dataset and present some way forward by benchmarking with landmark based raw and RQE embedding. We do some ablation on vocabulary restriction and canonicalization of the same within the dataset, which resulted in two more datasets, IsharaKhobor_small and IsharaKhobor_canonical_small. The dataset is publicly available at: www.kaggle.com/datasets/hasanssl/isharakhobor [1].","authors":["Husne Ara Rubaiyeat","Hasan Mahmud","Md Kamrul Hasan"],"pdf_url":"","comment":"14 pages, 8 tables"},{"id":"http://arxiv.org/abs/2511.21530v1","updated":"2025-11-26T15:58:44Z","published":"2025-11-26T15:58:44Z","title":"The Age-specific Alzheimer 's Disease Prediction with Characteristic Constraints in Nonuniform Time Span","summary":"Alzheimer's disease is a debilitating disorder marked by a decline in cognitive function. Timely identification of the disease is essential for the development of personalized treatment strategies that aim to mitigate its progression. The application of generated images for the prediction of Alzheimer's disease poses challenges, particularly in accurately representing the disease's characteristics when input sequences are captured at irregular time intervals. This study presents an innovative methodology for sequential image generation, guided by quantitative metrics, to maintain the essential features indicative of disease progression. Furthermore, an age-scaling factor is integrated into the process to produce age-specific MRI images, facilitating the prediction of advanced stages of the disease. The results obtained from the ablation study suggest that the inclusion of quantitative metrics significantly improves the accuracy of MRI image synthesis. Furthermore, the application of age-scaled pixel loss contributed to the enhanced iterative generation of MRI images. In terms of long-term disease prognosis, the Structural Similarity Index reached a peak value of 0.882, indicating a substantial degree of similarity in the synthesized images.","authors":["Xin Hong","Kaifeng Huang"],"pdf_url":"","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2505.06370v2","updated":"2025-11-26T15:56:33Z","published":"2025-05-09T18:25:59Z","title":"LMLCC-Net: A Semi-Supervised Deep Learning Model for Lung Nodule Malignancy Prediction from CT Scans using a Novel Hounsfield Unit-Based Intensity Filtering","summary":"Lung cancer is the leading cause of patient mortality in the world. Early diagnosis of malignant pulmonary nodules in CT images can have a significant impact on reducing disease mortality and morbidity. In this work, we propose LMLCC-Net, a novel deep learning framework for classifying nodules from CT scan images using a 3D CNN, considering Hounsfield Unit (HU)-based intensity filtering. Benign and malignant nodules have significant differences in their intensity profile of HU, which was not exploited in the literature. Our method considers the intensity pattern as well as the texture for the prediction of malignancies. LMLCC-Net extracts features from multiple branches that each use a separate learnable HU-based intensity filtering stage. Various combinations of branches and learnable ranges of filters were explored to finally produce the best-performing model. In addition, we propose a semi-supervised learning scheme for labeling ambiguous cases and also developed a lightweight model to classify the nodules. The experimental evaluations are carried out on the LUNA16 dataset. The proposed LMLCC-Net was evaluated using the LUNA16 dataset. Our proposed method achieves a classification accuracy of 91.96%, a sensitivity of 92.94%, and an area under the curve of 94.07%, showing improved performance compared to existing methods The proposed method can have a significant impact in helping radiologists in the classification of pulmonary nodules and improving patient care.","authors":["Tasnia Binte Mamun","Adhora Madhuri","Nusaiba Sobir","Taufiq Hasan"],"pdf_url":"","comment":"12 pages, 9 figures, 7 tables"},{"id":"http://arxiv.org/abs/2511.21523v1","updated":"2025-11-26T15:52:56Z","published":"2025-11-26T15:52:56Z","title":"EoS-FM: Can an Ensemble of Specialist Models act as a Generalist Feature Extractor?","summary":"Recent advances in foundation models have shown great promise in domains such as natural language processing and computer vision, and similar efforts are now emerging in the Earth Observation community. These models aim to generalize across tasks with limited supervision, reducing the need for training separate models for each task. However, current strategies, which largely focus on scaling model size and dataset volume, require prohibitive computational and data resources, limiting accessibility to only a few large institutions. Moreover, this paradigm of ever-larger models stands in stark contrast with the principles of sustainable and environmentally responsible AI, as it leads to immense carbon footprints and resource inefficiency. In this work, we present a novel and efficient alternative: an Ensemble-of-Specialists framework for building Remote Sensing Foundation Models (RSFMs). Our method decomposes the training process into lightweight, task-specific ConvNeXtV2 specialists that can be frozen and reused. This modular approach offers strong advantages in efficiency, interpretability, and extensibility. Moreover, it naturally supports federated training, pruning, and continuous specialist integration, making it particularly well-suited for collaborative and resource-constrained settings. Our framework sets a new direction for building scalable and efficient RSFMs.","authors":["Pierre Adorni","Minh-Tan Pham","Stéphane May","Sébastien Lefèvre"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21519v1","updated":"2025-11-26T15:50:03Z","published":"2025-11-26T15:50:03Z","title":"Self-Paced Learning for Images of Antinuclear Antibodies","summary":"Antinuclear antibody (ANA) testing is a crucial method for diagnosing autoimmune disorders, including lupus, Sjögren's syndrome, and scleroderma. Despite its importance, manual ANA detection is slow, labor-intensive, and demands years of training. ANA detection is complicated by over 100 coexisting antibody types, resulting in vast fluorescent pattern combinations. Although machine learning and deep learning have enabled automation, ANA detection in real-world clinical settings presents unique challenges as it involves multi-instance, multi-label (MIML) learning. In this paper, a novel framework for ANA detection is proposed that handles the complexities of MIML tasks using unaltered microscope images without manual preprocessing. Inspired by human labeling logic, it identifies consistent ANA sub-regions and assigns aggregated labels accordingly. These steps are implemented using three task-specific components: an instance sampler, a probabilistic pseudo-label dispatcher, and self-paced weight learning rate coefficients. The instance sampler suppresses low-confidence instances by modeling pattern confidence, while the dispatcher adaptively assigns labels based on instance distinguishability. Self-paced learning adjusts training according to empirical label observations. Our framework overcomes limitations of traditional MIML methods and supports end-to-end optimization. Extensive experiments on one ANA dataset and three public medical MIML benchmarks demonstrate the superiority of our framework. On the ANA dataset, our model achieves up to +7.0% F1-Macro and +12.6% mAP gains over the best prior method, setting new state-of-the-art results. It also ranks top-2 across all key metrics on public datasets, reducing Hamming loss and one-error by up to 18.2% and 26.9%, respectively. The source code can be accessed at https://github.com/fletcherjiang/ANA-SelfPacedLearning.","authors":["Yiyang Jiang","Guangwu Qian","Jiaxin Wu","Qi Huang","Qing Li","Yongkang Wu","Xiao-Yong Wei"],"pdf_url":"","comment":"IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2511.21507v1","updated":"2025-11-26T15:40:58Z","published":"2025-11-26T15:40:58Z","title":"Generalized Design Choices for Deepfake Detectors","summary":"The effectiveness of deepfake detection methods often depends less on their core design and more on implementation details such as data preprocessing, augmentation strategies, and optimization techniques. These factors make it difficult to fairly compare detectors and to understand which factors truly contribute to their performance. To address this, we systematically investigate how different design choices influence the accuracy and generalization capabilities of deepfake detection models, focusing on aspects related to training, inference, and incremental updates. By isolating the impact of individual factors, we aim to establish robust, architecture-agnostic best practices for the design and development of future deepfake detection systems. Our experiments identify a set of design choices that consistently improve deepfake detection and enable state-of-the-art performance on the AI-GenBench benchmark.","authors":["Lorenzo Pellegrini","Serafino Pandolfini","Davide Maltoni","Matteo Ferrara","Marco Prati","Marco Ramilli"],"pdf_url":"","comment":"12 pages, 9 figures, 10 tables, code available: https://github.com/MI-BioLab/AI-GenBench"},{"id":"http://arxiv.org/abs/2511.19516v2","updated":"2025-11-26T15:38:35Z","published":"2025-11-24T03:11:08Z","title":"Connecting the Dots: Training-Free Visual Grounding via Agentic Reasoning","summary":"Visual grounding, the task of linking textual queries to specific regions within images, plays a pivotal role in vision-language integration. Existing methods typically rely on extensive task-specific annotations and fine-tuning, limiting their ability to generalize effectively to novel or out-of-distribution scenarios. To address these limitations, we introduce GroundingAgent, a novel agentic visual grounding framework that operates without any task-specific fine-tuning. GroundingAgent employs a structured, iterative reasoning mechanism that integrates pretrained open-vocabulary object detectors, multimodal large language models (MLLMs), and large language models (LLMs) to progressively refine candidate regions through joint semantic and spatial analyses. Remarkably, GroundingAgent achieves an average zero-shot grounding accuracy of 65.1 % on widely-used benchmarks (RefCOCO, RefCOCO+, RefCOCOg), entirely without fine-tuning. Furthermore, by substituting MLLM-generated captions with the original query texts, the accuracy at the selection stage alone reaches approximately 90 %, closely matching supervised performance and underscoring the critical role of LLM reasoning capabilities. GroundingAgent also offers strong interpretability, transparently illustrating each reasoning step and providing clear insights into its decision-making process.","authors":["Liqin Luo","Guangyao Chen","Xiawu Zheng","Yongxing Dai","Yixiong Zou","Yonghong Tian"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.21503v1","updated":"2025-11-26T15:38:10Z","published":"2025-11-26T15:38:10Z","title":"CanKD: Cross-Attention-based Non-local operation for Feature-based Knowledge Distillation","summary":"We propose Cross-Attention-based Non-local Knowledge Distillation (CanKD), a novel feature-based knowledge distillation framework that leverages cross-attention mechanisms to enhance the knowledge transfer process. Unlike traditional self-attention-based distillation methods that align teacher and student feature maps independently, CanKD enables each pixel in the student feature map to dynamically consider all pixels in the teacher feature map. This non-local knowledge transfer more thoroughly captures pixel-wise relationships, improving feature representation learning. Our method introduces only an additional loss function to achieve superior performance compared with existing attention-guided distillation methods. Extensive experiments on object detection and image segmentation tasks demonstrate that CanKD outperforms state-of-the-art feature and hybrid distillation methods. These experimental results highlight CanKD's potential as a new paradigm for attention-guided distillation in computer vision tasks. Code is available at https://github.com/tori-hotaru/CanKD","authors":["Shizhe Sun","Wataru Ohyama"],"pdf_url":"","comment":"WACV 2026 Accepted"},{"id":"http://arxiv.org/abs/2409.06013v2","updated":"2025-11-26T15:34:08Z","published":"2024-09-09T19:12:03Z","title":"Improved Visually Prompted Keyword Localisation in Real Low-Resource Settings","summary":"Given an image query, visually prompted keyword localisation (VPKL) aims to find occurrences of the depicted word in a speech collection. This can be useful when transcriptions are not available for a low-resource language (e.g. if it is unwritten). Previous work showed that VPKL can be performed with a visually grounded speech model trained on paired images and unlabelled speech. But all experiments were done on English. Moreover, transcriptions were used to get positive and negative pairs for the contrastive loss. This paper introduces a few-shot learning scheme to mine pairs automatically without transcriptions. On English, this results in only a small drop in performance. We also - for the first time - consider VPKL on a real low-resource language, Yoruba. While scores are reasonable, here we see a bigger drop in performance compared to using ground truth pairs because the mining is less accurate in Yoruba.","authors":["Leanne Nortje","Dan Oneata","Gabriel Pirlogeanu","Herman Kamper"],"pdf_url":"","comment":"Accepted at SpeD 2025"},{"id":"http://arxiv.org/abs/2509.12247v2","updated":"2025-11-26T15:30:09Z","published":"2025-09-11T21:14:35Z","title":"Modular, On-Site Solutions with Lightweight Anomaly Detection for Sustainable Nutrient Management in Agriculture","summary":"Efficient nutrient management is critical for crop growth and sustainable resource consumption (e.g., nitrogen, energy). Current approaches require lengthy analyses, preventing real-time optimization; similarly, imaging facilitates rapid phenotyping but can be computationally intensive, preventing deployment under resource constraints. This study proposes a flexible, tiered pipeline for anomaly detection and status estimation (fresh weight, dry mass, and tissue nutrients), including a comprehensive energy analysis of approaches that span the efficiency-accuracy spectrum. Using a nutrient depletion experiment with three treatments (T1-100%, T2-50%, and T3-25% fertilizer strength) and multispectral imaging (MSI), we developed a hierarchical pipeline using an autoencoder (AE) for early warning. Further, we compared two status estimation modules of different complexity for more detailed analysis: vegetation index (VI) features with machine learning (Random Forest, RF) and raw whole-image deep learning (Vision Transformer, ViT). Results demonstrated high-efficiency anomaly detection (73% net detection of T3 samples 9 days after transplanting) at substantially lower energy than embodied energy in wasted nitrogen. The state estimation modules show trade-offs, with ViT outperforming RF on phosphorus and calcium estimation (R2 0.61 vs. 0.58, 0.48 vs. 0.35) at higher energy cost. With our modular pipeline, this work opens opportunities for edge diagnostics and practical opportunities for agricultural sustainability.","authors":["Abigail R. Cohen","Yuming Sun","Zhihao Qin","Harsh S. Muriki","Zihao Xiao","Yeonju Lee","Matthew Housley","Andrew F. Sharkey","Rhuanito S. Ferrarezi","Jing Li","Lu Gan","Yongsheng Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21490v1","updated":"2025-11-26T15:24:53Z","published":"2025-11-26T15:24:53Z","title":"Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning","summary":"We present a novel training approach, named Merge-and-Bound (M&B) for Class Incremental Learning (CIL), which directly manipulates model weights in the parameter space for optimization. Our algorithm involves two types of weight merging: inter-task weight merging and intra-task weight merging. Inter-task weight merging unifies previous models by averaging the weights of models from all previous stages. On the other hand, intra-task weight merging facilitates the learning of current task by combining the model parameters within current stage. For reliable weight merging, we also propose a bounded update technique that aims to optimize the target model with minimal cumulative updates and preserve knowledge from previous tasks; this strategy reveals that it is possible to effectively obtain new models near old ones, reducing catastrophic forgetting. M&B is seamlessly integrated into existing CIL methods without modifying architecture components or revising learning objectives. We extensively evaluate our algorithm on standard CIL benchmarks and demonstrate superior performance compared to state-of-the-art methods.","authors":["Taehoon Kim","Donghwan Jang","Bohyung Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21477v1","updated":"2025-11-26T15:10:04Z","published":"2025-11-26T15:10:04Z","title":"Frequency-Aware Token Reduction for Efficient Vision Transformer","summary":"Vision Transformers have demonstrated exceptional performance across various computer vision tasks, yet their quadratic computational complexity concerning token length remains a significant challenge. To address this, token reduction methods have been widely explored. However, existing approaches often overlook the frequency characteristics of self-attention, such as rank collapsing and over-smoothing phenomenon. In this paper, we propose a frequency-aware token reduction strategy that improves computational efficiency while preserving performance by mitigating rank collapsing. Our method partitions tokens into high-frequency tokens and low-frequency tokens. high-frequency tokens are selectively preserved, while low-frequency tokens are aggregated into a compact direct current token to retain essential low-frequency components. Through extensive experiments and analysis, we demonstrate that our approach significantly improves accuracy while reducing computational overhead and mitigating rank collapsing and over smoothing. Furthermore, we analyze the previous methods, shedding light on their implicit frequency characteristics and limitations.","authors":["Dong-Jae Lee","Jiwan Hur","Jaehyun Choi","Jaemyung Yu","Junmo Kim"],"pdf_url":"","comment":"Neurips 2025"},{"id":"http://arxiv.org/abs/2511.21475v1","updated":"2025-11-26T15:09:02Z","published":"2025-11-26T15:09:02Z","title":"MobileI2V: Fast and High-Resolution Image-to-Video on Mobile Devices","summary":"Recently, video generation has witnessed rapid advancements, drawing increasing attention to image-to-video (I2V) synthesis on mobile devices. However, the substantial computational complexity and slow generation speed of diffusion models pose significant challenges for real-time, high-resolution video generation on resource-constrained mobile devices. In this work, we propose MobileI2V, a 270M lightweight diffusion model for real-time image-to-video generation on mobile devices. The core lies in: (1) We analyzed the performance of linear attention modules and softmax attention modules on mobile devices, and proposed a linear hybrid architecture denoiser that balances generation efficiency and quality. (2) We design a time-step distillation strategy that compresses the I2V sampling steps from more than 20 to only two without significant quality loss, resulting in a 10-fold increase in generation speed. (3) We apply mobile-specific attention optimizations that yield a 2-fold speed-up for attention operations during on-device inference. MobileI2V enables, for the first time, fast 720p image-to-video generation on mobile devices, with quality comparable to existing models. Under one-step conditions, the generation speed of each frame of 720p video is less than 100 ms. Our code is available at: https://github.com/hustvl/MobileI2V.","authors":["Shuai Zhang","Bao Tang","Siyuan Yu","Yueting Zhu","Jingfeng Yao","Ya Zou","Shanglin Yuan","Li Yu","Wenyu Liu","Xinggang Wang"],"pdf_url":"","comment":"Our Demo and code:https://github.com/hustvl/MobileI2V"},{"id":"http://arxiv.org/abs/2412.08484v4","updated":"2025-11-26T15:05:52Z","published":"2024-12-11T15:48:25Z","title":"MeshCone: Second-Order Cone Programming for Geometrically-Constrained Mesh Enhancement","summary":"Modern mesh generation pipelines whether learning-based or classical often produce outputs requiring post-processing to achieve production-quality geometry. This work introduces MeshCone, a convex optimization framework for guided mesh refinement that leverages reference geometry to correct deformed or degraded meshes. We formulate the problem as a second-order cone program where vertex positions are optimized to align with target geometry while enforcing smoothness through convex edge-length regularization. MeshCone performs geometry-aware optimization that preserves fine details while correcting structural defects. We demonstrate robust performance across 56 diverse object categories from ShapeNet and ThreeDScans, achieving superior refinement quality compared to Laplacian smoothing and unoptimized baselines while maintaining sub-second inference times. MeshCone is particularly suited for applications where reference geometry is available, such as mesh-from-template workflows, scan-to-CAD alignment, and quality assurance in asset production pipelines.","authors":["Alexander Valverde"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10160v2","updated":"2025-11-26T14:51:06Z","published":"2025-10-11T10:50:58Z","title":"SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation","summary":"Referring Image Segmentation (RIS) aims to segment the target object in an image given a natural language expression. While recent methods leverage pre-trained vision backbones and more training corpus to achieve impressive results, they predominantly focus on simple expressions--short, clear noun phrases like \"red car\" or \"left girl\". This simplification often reduces RIS to a key word/concept matching problem, limiting the model's ability to handle referential ambiguity in expressions. In this work, we identify two challenging real-world scenarios: object-distracting expressions, which involve multiple entities with contextual cues, and category-implicit expressions, where the object class is not explicitly stated. To address the challenges, we propose a novel framework, SaFiRe, which mimics the human two-phase cognitive process--first forming a global understanding, then refining it through detail-oriented inspection. This is naturally supported by Mamba's scan-then-update property, which aligns with our phased design and enables efficient multi-cycle refinement with linear complexity. We further introduce aRefCOCO, a new benchmark designed to evaluate RIS models under ambiguous referring expressions. Extensive experiments on both standard and proposed datasets demonstrate the superiority of SaFiRe over state-of-the-art baselines.","authors":["Zhenjie Mao","Yuhuan Yang","Chaofan Ma","Dongsheng Jiang","Jiangchao Yao","Ya Zhang","Yanfeng Wang"],"pdf_url":"","comment":"NeurIPS 2025; Project page: https://zhenjiemao.github.io/SaFiRe/"},{"id":"http://arxiv.org/abs/2411.16417v3","updated":"2025-11-26T14:50:34Z","published":"2024-11-25T14:20:53Z","title":"Comparison of Generative Learning Methods for Turbulence Surrogates","summary":"Numerical simulations of turbulent flows present significant challenges in fluid dynamics due to their complexity and high computational cost. High resolution techniques such as Direct Numerical Simulation (DNS) and Large Eddy Simulation (LES) are generally not computationally affordable, particularly for technologically relevant problems. Recent advances in machine learning, specifically in generative probabilistic models, offer promising alternatives as surrogates for turbulence. This paper investigates the application of three generative models - Variational Autoencoders (VAE), Deep Convolutional Generative Adversarial Networks (DCGAN), and Denoising Diffusion Probabilistic Models (DDPM) - in simulating a von Kármán vortex street around a fixed cylinder projected into 2D, as well as a real-world experimental dataset of the wake flow of a cylinder array. Training data was obtained by means of LES in the simulated case and Particle Image Velocimetry (PIV) in the experimental case. We evaluate each model's ability to capture the statistical properties and spatial structures of the turbulent flow. Our results demonstrate that DDPM and DCGAN effectively replicate all flow distributions, highlighting their potential as efficient and accurate tools for turbulence surrogacy. We find a strong argument for DCGAN, as although they are more difficult to train (due to problems such as mode collapse), they show the fastest inference and training time, require less data to train compared to VAE and DDPM, and provide the results most closely aligned with the input stream. In contrast, VAE train quickly (and can generate samples quickly) but do not produce adequate results, and DDPM, whilst effective, are significantly slower at both, inference and training time.","authors":["Claudia Drygala","Edmund Ross","Francesca di Mare","Hanno Gottschalk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.09298v2","updated":"2025-11-26T14:43:38Z","published":"2025-11-12T13:07:07Z","title":"DensiCrafter: Physically-Constrained Generation and Fabrication of Self-Supporting Hollow Structures","summary":"The rise of 3D generative models has enabled automatic 3D geometry and texture synthesis from multimodal inputs (e.g., text or images). However, these methods often ignore physical constraints and manufacturability considerations. In this work, we address the challenge of producing 3D designs that are both lightweight and self-supporting. We present DensiCrafter, a framework for generating lightweight, self-supporting 3D hollow structures by optimizing the density field. Starting from coarse voxel grids produced by Trellis, we interpret these as continuous density fields to optimize and introduce three differentiable, physically constrained, and simulation-free loss terms. Additionally, a mass regularization penalizes unnecessary material, while a restricted optimization domain preserves the outer surface. Our method seamlessly integrates with pretrained Trellis-based models (e.g., Trellis, DSO) without any architectural changes. In extensive evaluations, we achieve up to 43% reduction in material mass on the text-to-3D task. Compared to state-of-the-art baselines, our method could improve the stability and maintain high geometric fidelity. Real-world 3D-printing experiments confirm that our hollow designs can be reliably fabricated and could be self-supporting.","authors":["Shengqi Dang","Fu Chai","Jiaxin Li","Chao Yuan","Wei Ye","Nan Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20302v2","updated":"2025-11-26T14:40:54Z","published":"2025-11-25T13:41:59Z","title":"CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation","summary":"In Remote Sensing (RS), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a key approach to activate the generalizable representation ability of foundation models for downstream tasks. However, existing specialized PEFT methods often fail when applied to large-scale Earth observation tasks, as they are unable to fully handle the multifaceted and unpredictable domain gaps (\\eg, spatial, semantic, and frequency shifts) inherent in RS data. To overcome this, we propose CrossEarth-Gate, which introduces two primary contributions. First, we establish a comprehensive RS module toolbox to address multifaceted domain gaps, comprising spatial, semantic, and frequency modules. Second, we develop a Fisher-guided adaptive selection mechanism that operates on this toolbox. This selection is guided by Fisher Information to quantify each module's importance by measuring its contribution to the task-specific gradient flow. It dynamically activates only the most critical modules at the appropriate layers, guiding the gradient flow to maximize adaptation effectiveness and efficiency. Comprehensive experiments validate the efficacy and generalizability of our method, where CrossEarth-Gate achieves state-of-the-art performance across 16 cross-domain benchmarks for RS semantic segmentation. The code of the work will be released.","authors":["Shilei Cao","Ziyang Gong","Hehai Lin","Yang Liu","Jiashun Cheng","Xiaoxing Hu","Haoyuan Liang","Guowen Li","Chengwei Qin","Hong Cheng","Xue Yang","Juepeng Zheng","Haohuan Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21439v1","updated":"2025-11-26T14:30:04Z","published":"2025-11-26T14:30:04Z","title":"EvRainDrop: HyperGraph-guided Completion for Effective Frame and Event Stream Aggregation","summary":"Event cameras produce asynchronous event streams that are spatially sparse yet temporally dense. Mainstream event representation learning algorithms typically use event frames, voxels, or tensors as input. Although these approaches have achieved notable progress, they struggle to address the undersampling problem caused by spatial sparsity. In this paper, we propose a novel hypergraph-guided spatio-temporal event stream completion mechanism, which connects event tokens across different times and spatial locations via hypergraphs and leverages contextual information message passing to complete these sparse events. The proposed method can flexibly incorporate RGB tokens as nodes in the hypergraph within this completion framework, enabling multi-modal hypergraph-based information completion. Subsequently, we aggregate hypergraph node information across different time steps through self-attention, enabling effective learning and fusion of multi-modal features. Extensive experiments on both single- and multi-label event classification tasks fully validated the effectiveness of our proposed framework. The source code of this paper will be released on https://github.com/Event-AHU/EvRainDrop.","authors":["Futian Wang","Fan Zhang","Xiao Wang","Mengqi Wang","Dexing Huang","Jin Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01724v2","updated":"2025-11-26T14:24:35Z","published":"2025-11-03T16:33:57Z","title":"Probabilistic Robustness for Free? Revisiting Training via a Benchmark","summary":"Deep learning models are notoriously vulnerable to imperceptible perturbations. Most existing research centers on adversarial robustness (AR), which evaluates models under worst-case scenarios by examining the existence of deterministic adversarial examples (AEs). In contrast, probabilistic robustness (PR) adopts a statistical perspective, measuring the probability that predictions remain correct under stochastic perturbations. While PR is widely regarded as a practical complement to AR, dedicated training methods for improving PR are still relatively underexplored, albeit with emerging progress. Among the few PR-targeted training methods, we identify three limitations: i non-comparable evaluation protocols; ii limited comparisons to strong AT baselines despite anecdotal PR gains from AT; and iii no unified framework to compare the generalization of these methods. Thus, we introduce PRBench, the first benchmark dedicated to evaluating improvements in PR achieved by different robustness training methods. PRBench empirically compares most common AT and PR-targeted training methods using a comprehensive set of metrics, including clean accuracy, PR and AR performance, training efficiency, and generalization error (GE). We also provide theoretical analysis on the GE of PR performance across different training methods. Main findings revealed by PRBench include: AT methods are more versatile than PR-targeted training methods in terms of improving both AR and PR performance across diverse hyperparameter settings, while PR-targeted training methods consistently yield lower GE and higher clean accuracy. A leaderboard comprising 222 trained models across 7 datasets and 10 model architectures is publicly available at https://tmpspace.github.io/PRBenchLeaderboard/.","authors":["Yi Zhang","Zheng Wang","Zhen Chen","Wenjie Ruan","Qing Guo","Siddartha Khastgir","Carsten Maple","Xingyu Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21428v1","updated":"2025-11-26T14:19:44Z","published":"2025-11-26T14:19:44Z","title":"From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings","summary":"We present a novel unsupervised framework to unlock vast unlabeled human demonstration data from continuous industrial video streams for Vision-Language-Action (VLA) model pre-training. Our method first trains a lightweight motion tokenizer to encode motion dynamics, then employs an unsupervised action segmenter leveraging a novel \"Latent Action Energy\" metric to discover and segment semantically coherent action primitives. The pipeline outputs both segmented video clips and their corresponding latent action sequences, providing structured data directly suitable for VLA pre-training. Evaluations on public benchmarks and a proprietary electric motor assembly dataset demonstrate effective segmentation of key tasks performed by humans at workstations. Further clustering and quantitative assessment via a Vision-Language Model confirm the semantic coherence of the discovered action primitives. To our knowledge, this is the first fully automated end-to-end system for extracting and organizing VLA pre-training data from unstructured industrial videos, offering a scalable solution for embodied AI integration in manufacturing.","authors":["Jiajie Zhang","Sören Schwertfeger","Alexander Kleiner"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.21422v1","updated":"2025-11-26T14:12:34Z","published":"2025-11-26T14:12:34Z","title":"E-M3RF: An Equivariant Multimodal 3D Re-assembly Framework","summary":"3D reassembly is a fundamental geometric problem, and in recent years it has increasingly been challenged by deep learning methods rather than classical optimization. While learning approaches have shown promising results, most still rely primarily on geometric features to assemble a whole from its parts. As a result, methods struggle when geometry alone is insufficient or ambiguous, for example, for small, eroded, or symmetric fragments. Additionally, solutions do not impose physical constraints that explicitly prevent overlapping assemblies. To address these limitations, we introduce E-M3RF, an equivariant multimodal 3D reassembly framework that takes as input the point clouds, containing both point positions and colors of fractured fragments, and predicts the transformations required to reassemble them using SE(3) flow matching. Each fragment is represented by both geometric and color features: i) 3D point positions are encoded as rotationconsistent geometric features using a rotation-equivariant encoder, ii) the colors at each 3D point are encoded with a transformer. The two feature sets are then combined to form a multimodal representation. We experimented on four datasets: two synthetic datasets, Breaking Bad and Fantastic Breaks, and two real-world cultural heritage datasets, RePAIR and Presious, demonstrating that E-M3RF on the RePAIR dataset reduces rotation error by 23.1% and translation error by 13.2%, while Chamfer Distance decreases by 18.4% compared to competing methods.","authors":["Adeela Islam","Stefano Fiorini","Manuel Lecha","Theodore Tsesmelis","Stuart James","Pietro Morerio","Alessio Del Bue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21420v1","updated":"2025-11-26T14:11:19Z","published":"2025-11-26T14:11:19Z","title":"SAM Guided Semantic and Motion Changed Region Mining for Remote Sensing Change Captioning","summary":"Remote sensing change captioning is an emerging and popular research task that aims to describe, in natural language, the content of interest that has changed between two remote sensing images captured at different times. Existing methods typically employ CNNs/Transformers to extract visual representations from the given images or incorporate auxiliary tasks to enhance the final results, with weak region awareness and limited temporal alignment. To address these issues, this paper explores the use of the SAM (Segment Anything Model) foundation model to extract region-level representations and inject region-of-interest knowledge into the captioning framework. Specifically, we employ a CNN/Transformer model to extract global-level vision features, leverage the SAM foundation model to delineate semantic- and motion-level change regions, and utilize a specially constructed knowledge graph to provide information about objects of interest. These heterogeneous sources of information are then fused via cross-attention, and a Transformer decoder is used to generate the final natural language description of the observed changes. Extensive experimental results demonstrate that our method achieves state-of-the-art performance across multiple widely used benchmark datasets. The source code of this paper will be released on https://github.com/Event-AHU/SAM_ChangeCaptioning","authors":["Futian Wang","Mengqi Wang","Xiao Wang","Haowen Wang","Jin Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21415v1","updated":"2025-11-26T14:06:52Z","published":"2025-11-26T14:06:52Z","title":"DiverseVAR: Balancing Diversity and Quality of Next-Scale Visual Autoregressive Models","summary":"We introduce DiverseVAR, a framework that enhances the diversity of text-conditioned visual autoregressive models (VAR) at test time without requiring retraining, fine-tuning, or substantial computational overhead. While VAR models have recently emerged as strong competitors to diffusion and flow models for image generation, they suffer from a critical limitation in diversity, often producing nearly identical images even for simple prompts. This issue has largely gone unnoticed amid the predominant focus on image quality. We address this limitation at test time in two stages. First, inspired by diversity enhancement techniques in diffusion models, we propose injecting noise into the text embedding. This introduces a trade-off between diversity and image quality: as diversity increases, the image quality sharply declines. To preserve quality, we propose scale-travel: a novel latent refinement technique inspired by time-travel strategies in diffusion models. Specifically, we use a multi-scale autoencoder to extract coarse-scale tokens that enable us to resume generation at intermediate stages. Extensive experiments show that combining text-embedding noise injection with our scale-travel refinement significantly enhances diversity while minimizing image-quality degradation, achieving a new Pareto frontier in the diversity-quality trade-off.","authors":["Mingue Park","Prin Phunyaphibarn","Phillip Y. Lee","Minhyuk Sung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.06220v4","updated":"2025-11-26T14:03:26Z","published":"2025-04-08T17:09:33Z","title":"Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation","summary":"Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adapt powerful Foundation Models (FMs) to diverse downstream tasks while preserving and unleashing their inherent capabilities. However, we have observed that existing PEFT methods, which are often designed with natural imagery in mind, struggle when applied to Remote Sensing (RS) scenarios. This is primarily due to their inability to handle artifact influences, a problem particularly severe in RS image features. To tackle this challenge, we introduce Earth-Adapter, the first PEFT method specifically designed for RS artifacts conquering. Earth-Adapter introduces a novel Mixture of Frequency Adaptation process that combines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT). By utilizing DFT, Earth-Adapter can decompose features into different frequency components, precisely separating artifacts from original features. The MoA then dynamically assigns weights to each adapter expert, allowing for the combination of features across various frequency domains. These simple-yet-effective approaches enable Earth-Adapter to more efficiently overcome the disturbances caused by artifacts than previous PEFT methods, significantly enhancing the FMs' performance on RS scenarios. Experiments on Domain Adaptation (DA), and Domain Generalization (DG) semantic segmentation benchmarks showcase the Earth-Adapter's effectiveness. Compared with baseline Rein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DG benchmarks. Our code will be released at https://github.com/VisionXLab/Earth-Adapter.","authors":["Xiaoxing Hu","Ziyang Gong","Yupei Wang","Yuru Jia","Fei Lin","Dexiang Gao","Ke An","Jianhong Han","Zhuoran Sun","Gen Luo","Gen Luo","Xue Yang"],"pdf_url":"","comment":"AAAI 2026 camera ready"},{"id":"http://arxiv.org/abs/2507.03394v2","updated":"2025-11-26T13:59:18Z","published":"2025-07-04T08:55:40Z","title":"Learning Normals of Noisy Points by Local Gradient-Aware Surface Filtering","summary":"Estimating normals for noisy point clouds is a persistent challenge in 3D geometry processing, particularly for end-to-end oriented normal estimation. Existing methods generally address relatively clean data and rely on supervised priors to fit local surfaces within specific neighborhoods. In this paper, we propose a novel approach for learning normals from noisy point clouds through local gradient-aware surface filtering. Our method projects noisy points onto the underlying surface by utilizing normals and distances derived from an implicit function constrained by local gradients. We start by introducing a distance measurement operator for global surface fitting on noisy data, which integrates projected distances along normals. Following this, we develop an implicit field-based filtering approach for surface point construction, adding projection constraints on these points during filtering. To address issues of over-smoothing and gradient degradation, we further incorporate local gradient consistency constraints, as well as local gradient orientation and aggregation. Comprehensive experiments on normal estimation, surface reconstruction, and point cloud denoising demonstrate the state-of-the-art performance of our method. The source code and trained models are available at https://github.com/LeoQLi/LGSF.","authors":["Qing Li","Huifang Feng","Xun Gong","Yu-Shen Liu"],"pdf_url":"","comment":"Accepted by ICCV 2025. Project page: https://leoqli.github.io/LGSF/"},{"id":"http://arxiv.org/abs/2501.18444v2","updated":"2025-11-26T13:57:16Z","published":"2025-01-30T15:56:20Z","title":"Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms","summary":"This study addresses the need for accurate and efficient object detection in assistive technologies for visually impaired individuals. We evaluate four real-time object detection algorithms YOLO, SSD, Faster R-CNN, and Mask R-CNN within the context of indoor navigation assistance. Using the Indoor Objects Detection dataset, we analyze detection accuracy, processing speed, and adaptability to indoor environments. Our findings highlight the trade-offs between precision and efficiency, offering insights into selecting optimal algorithms for realtime assistive navigation. This research advances adaptive machine learning applications, enhancing indoor navigation solutions for the visually impaired and promoting accessibility.","authors":["Abhinav Pratap","Sushant Kumar","Suchinton Chakravarty"],"pdf_url":"","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.20157v2","updated":"2025-11-26T13:56:04Z","published":"2025-11-25T10:33:17Z","title":"SKEL-CF: Coarse-to-Fine Biomechanical Skeleton and Surface Mesh Recovery","summary":"Parametric 3D human models such as SMPL have driven significant advances in human pose and shape estimation, yet their simplified kinematics limit biomechanical realism. The recently proposed SKEL model addresses this limitation by re-rigging SMPL with an anatomically accurate skeleton. However, estimating SKEL parameters directly remains challenging due to limited training data, perspective ambiguities, and the inherent complexity of human articulation. We introduce SKEL-CF, a coarse-to-fine framework for SKEL parameter estimation. SKEL-CF employs a transformer-based encoder-decoder architecture, where the encoder predicts coarse camera and SKEL parameters, and the decoder progressively refines them in successive layers. To ensure anatomically consistent supervision, we convert the existing SMPL-based dataset 4DHuman into a SKEL-aligned version, 4DHuman-SKEL, providing high-quality training data for SKEL estimation. In addition, to mitigate depth and scale ambiguities, we explicitly incorporate camera modeling into the SKEL-CF pipeline and demonstrate its importance across diverse viewpoints. Extensive experiments validate the effectiveness of the proposed design. On the challenging MOYO dataset, SKEL-CF achieves 85.0 MPJPE / 51.4 PA-MPJPE, significantly outperforming the previous SKEL-based state-of-the-art HSMR (104.5 / 79.6). These results establish SKEL-CF as a scalable and anatomically faithful framework for human motion analysis, bridging the gap between computer vision and biomechanics. Our implementation is available on the project page: https://pokerman8.github.io/SKEL-CF/.","authors":["Da Li","Jiping Jin","Xuanlong Yu","Wei Liu","Xiaodong Cun","Kai Chen","Rui Fan","Jiangang Kong","Xi Shen"],"pdf_url":"","comment":"Project page: https://pokerman8.github.io/SKEL-CF/"},{"id":"http://arxiv.org/abs/2506.04263v2","updated":"2025-11-26T13:51:05Z","published":"2025-06-03T04:18:53Z","title":"Dynamic Epsilon Scheduling: A Multi-Factor Adaptive Perturbation Budget for Adversarial Training","summary":"Adversarial training is among the most effective strategies for defending deep neural networks against adversarial examples. A key limitation of existing adversarial training approaches lies in their reliance on a fixed perturbation budget, which fails to account for instance-specific robustness characteristics. While prior works such as IAAT and MMA introduce instance-level adaptations, they often rely on heuristic or static approximations of data robustness. In this paper, we propose Dynamic Epsilon Scheduling (DES), a novel framework that adaptively adjusts the adversarial perturbation budget per instance and per training iteration. DES integrates three key factors: (1) the distance to the decision boundary approximated via gradient-based proxies, (2) prediction confidence derived from softmax entropy, and (3) model uncertainty estimated via Monte Carlo dropout. By combining these cues into a unified scheduling strategy, DES tailors the perturbation budget dynamically to guide more effective adversarial learning. Experimental results on CIFAR-10 and CIFAR-100 show that our method consistently improves both adversarial robustness and standard accuracy compared to fixed-epsilon baselines and prior adaptive methods. Moreover, we provide theoretical insights into the stability and convergence of our scheduling policy. This work opens a new avenue for instance-aware, data-driven adversarial training methods.","authors":["Alan Mitkiy","James Smith","Myungseo wong","Hana Satou","Hiroshi Tanaka","Emily Johnson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21397v1","updated":"2025-11-26T13:49:08Z","published":"2025-11-26T13:49:08Z","title":"Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis","summary":"How does irrelevant information (i.e., distractors) affect test-time scaling in vision-language models (VLMs)? Prior studies on language models have reported an inverse scaling effect, where textual distractors lead to longer but less effective reasoning. To investigate whether similar phenomena occur in multimodal settings, we introduce Idis (Images with distractors), a visual question-answering dataset that systematically varies distractors along semantic, numerical, and spatial dimensions. Our analyses reveal that visual distractors differ fundamentally from textual ones: although inverse scaling persists, adding visual distractors reduces accuracy without increasing reasoning length. We further show that tracking attribute counts within reasoning traces provides key insights into how distractors, reasoning length, and accuracy interact. Finally, we demonstrate that these trends extend to established visual bias benchmarks such as Waterbirds, and we propose a simple prompting strategy to mitigate bias-driven predictions in reasoning models.","authors":["Jiyun Bae","Hyunjong Ok","Sangwoo Mo","Jaeho Lee"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2510.14657v2","updated":"2025-11-26T13:48:59Z","published":"2025-10-16T13:13:12Z","title":"Decorrelation Speeds Up Vision Transformers","summary":"Masked Autoencoder (MAE) pre-training of vision transformers (ViTs) yields strong performance in low-label data regimes but comes with substantial computational costs, making it impractical in time- and resource-constrained industrial settings. We address this by nitegrating Decorrelated Backpropagation (DBP) into MAE pre-training, an optimization method that iteratively reduces input correlations at each layer to accelerate convergence. Applied selectively to the encoder, DBP achieves faster pre-training without loss of stability. To mimic constrained-data scenarios, we evaluate our approach on ImageNet-1K pre-training and ADE20K fine-tuning using randomly sampled subsets of each dataset. Under this setting, DBP-MAE reduces wall-clock time to baseline performance by 21.1%, lowers carbon emissions by 21.4%, and improves segmentation mIoU by 1.1 points. We observe similar gains when pre-training and fine-tuning on proprietary industrial data, confirming the method's applicability in real-world scenarios. These results demonstrate that DBP can reduce training time and energy use while improving downstream performance for large-scale ViT pre-training.\n  Keywords: Deep learning, Vision transformers, Efficient AI, Decorrelation","authors":["Kieran Carrigg","Rob van Gastel","Melda Yeghaian","Sander Dalm","Faysal Boughorbel","Marcel van Gerven"],"pdf_url":"","comment":"16 pages, 12 figures, submitted to CVC 2026"},{"id":"http://arxiv.org/abs/2511.21395v1","updated":"2025-11-26T13:46:39Z","published":"2025-11-26T13:46:39Z","title":"Monet: Reasoning in Latent Visual Space Beyond Images and Language","summary":"\"Thinking with images\" has emerged as an effective paradigm for advancing visual reasoning, extending beyond text-only chains of thought by injecting visual evidence into intermediate reasoning steps. However, existing methods fall short of human-like abstract visual thinking, as their flexibility is fundamentally limited by external tools. In this work, we introduce Monet, a training framework that enables multimodal large language models (MLLMs) to reason directly within the latent visual space by generating continuous embeddings that function as intermediate visual thoughts. We identify two core challenges in training MLLMs for latent visual reasoning: high computational cost in latent-vision alignment and insufficient supervision over latent embeddings, and address them with a three-stage distillation-based supervised fine-tuning (SFT) pipeline. We further reveal a limitation of applying GRPO to latent reasoning: it primarily enhances text-based reasoning rather than latent reasoning. To overcome this, we propose VLPO (Visual-latent Policy Optimization), a reinforcement learning method that explicitly incorporates latent embeddings into policy gradient updates. To support SFT, we construct Monet-SFT-125K, a high-quality text-image interleaved CoT dataset containing 125K real-world, chart, OCR, and geometry CoTs. Our model, Monet-7B, shows consistent gains across real-world perception and reasoning benchmarks and exhibits strong out-of-distribution generalization on challenging abstract visual reasoning tasks. We also empirically analyze the role of each training component and discuss our early unsuccessful attempts, providing insights for future developments in visual latent reasoning. Our model, data, and code are available at https://github.com/NOVAglow646/Monet.","authors":["Qixun Wang","Yang Shi","Yifei Wang","Yuanxing Zhang","Pengfei Wan","Kun Gai","Xianghua Ying","Yisen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15191v2","updated":"2025-11-26T13:39:08Z","published":"2025-05-21T07:13:09Z","title":"Geometrically Regularized Transfer Learning with On-Manifold and Off-Manifold Perturbation","summary":"Transfer learning under domain shift remains a fundamental challenge due to the divergence between source and target data manifolds. In this paper, we propose MAADA (Manifold-Aware Adversarial Data Augmentation), a novel framework that decomposes adversarial perturbations into on-manifold and off-manifold components to simultaneously capture semantic variation and model brittleness. We theoretically demonstrate that enforcing on-manifold consistency reduces hypothesis complexity and improves generalization, while off-manifold regularization smooths decision boundaries in low-density regions. Moreover, we introduce a geometry-aware alignment loss that minimizes geodesic discrepancy between source and target manifolds. Experiments on DomainNet, VisDA, and Office-Home show that MAADA consistently outperforms existing adversarial and adaptation methods in both unsupervised and few-shot settings, demonstrating superior structural robustness and cross-domain generalization.","authors":["Hana Satou","Alan Mitkiy","Emma Collins","Finn Kingston"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15241v2","updated":"2025-11-26T13:38:31Z","published":"2025-05-21T08:16:35Z","title":"Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer","summary":"Despite progress in geometry-aware domain adaptation, current methods such as GAMA still suffer from two unresolved issues: (1) insufficient disentanglement of task-relevant and task-irrelevant manifold dimensions, and (2) rigid perturbation schemes that ignore per-class alignment asymmetries. To address this, we propose GAMA++, a novel framework that introduces (i) latent space disentanglement to isolate label-consistent manifold directions from nuisance factors, and (ii) an adaptive contrastive perturbation strategy that tailors both on- and off-manifold exploration to class-specific manifold curvature and alignment discrepancy. We further propose a cross-domain contrastive consistency loss that encourages local semantic clusters to align while preserving intra-domain diversity. Our method achieves state-of-the-art results on DomainNet, Office-Home, and VisDA benchmarks under both standard and few-shot settings, with notable improvements in class-level alignment fidelity and boundary robustness. GAMA++ sets a new standard for semantic geometry alignment in transfer learning.","authors":["Emma Collins","Myungseo wong","Kim Yun","Finn Kingston","Hana Satou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.16687v2","updated":"2025-11-26T13:32:20Z","published":"2025-05-22T13:54:09Z","title":"One-Step Diffusion-Based Image Compression with Semantic Distillation","summary":"While recent diffusion-based generative image codecs have shown impressive performance, their iterative sampling process introduces unpleasing latency. In this work, we revisit the design of a diffusion-based codec and argue that multi-step sampling is not necessary for generative compression. Based on this insight, we propose OneDC, a One-step Diffusion-based generative image Codec -- that integrates a latent compression module with a one-step diffusion generator. Recognizing the critical role of semantic guidance in one-step diffusion, we propose using the hyperprior as a semantic signal, overcoming the limitations of text prompts in representing complex visual content. To further enhance the semantic capability of the hyperprior, we introduce a semantic distillation mechanism that transfers knowledge from a pretrained generative tokenizer to the hyperprior codec. Additionally, we adopt a hybrid pixel- and latent-domain optimization to jointly enhance both reconstruction fidelity and perceptual realism. Extensive experiments demonstrate that OneDC achieves SOTA perceptual quality even with one-step generation, offering over 39% bitrate reduction and 20x faster decoding compared to prior multi-step diffusion-based codecs. Project: https://onedc-codec.github.io/","authors":["Naifu Xue","Zhaoyang Jia","Jiahao Li","Bin Li","Yuan Zhang","Yan Lu"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2510.11473v2","updated":"2025-11-26T13:31:39Z","published":"2025-10-13T14:44:50Z","title":"VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment","summary":"3D Gaussian Splatting has recently emerged as an efficient solution for high-quality and real-time novel view synthesis. However, its capability for accurate surface reconstruction remains underexplored. Due to the discrete and unstructured nature of Gaussians, supervision based solely on image rendering loss often leads to inaccurate geometry and inconsistent multi-view alignment. In this work, we propose a novel method that enhances the geometric representation of 3D Gaussians through view alignment (VA). Specifically, we incorporate edge-aware image cues into the rendering loss to improve surface boundary delineation. To enforce geometric consistency across views, we introduce a visibility-aware photometric alignment loss that models occlusions and encourages accurate spatial relationships among Gaussians. To further mitigate ambiguities caused by lighting variations, we incorporate normal-based constraints to refine the spatial orientation of Gaussians and improve local surface estimation. Additionally, we leverage deep image feature embeddings to enforce cross-view consistency, enhancing the robustness of the learned geometry under varying viewpoints and illumination. Extensive experiments on standard benchmarks demonstrate that our method achieves state-of-the-art performance in both surface reconstruction and novel view synthesis. The source code is available at https://github.com/LeoQLi/VA-GS.","authors":["Qing Li","Huifang Feng","Xun Gong","Yu-Shen Liu"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21375v1","updated":"2025-11-26T13:21:15Z","published":"2025-11-26T13:21:15Z","title":"Thinking With Bounding Boxes: Enhancing Spatio-Temporal Video Grounding via Reinforcement Fine-Tuning","summary":"Spatio-temporal video grounding (STVG) requires localizing a target object in untrimmed videos both temporally and spatially from natural language descriptions. Despite their strong language understanding, multimodal large language models (MLLMs) underperform on STVG due to misaligned training objectives and weak fine-grained region-word alignment in standard visual encoders. To address this, we propose STVG-o1, the first framework that enables off-the-shelf MLLMs to achieve state-of-the-art STVG performance without any architectural modifications. Our method introduces a bounding-box chain-of-thought mechanism that explicitly reasons about spatio-temporal locations in an intermediate step before producing the final prediction. We further design a multi-dimensional reinforcement reward function consisting of format, consistency, temporal, spatial, and think rewards, which provides geometry-aware supervision through reinforcement fine-tuning. Evaluated on HCSTVG-v1/v2 and VidSTG, STVG-o1 sets new state-of-the-art results on HCSTVG, outperforming the best task-specific method by 7.3\\% m\\_tIoU on HCSTVG-v1, matching specialized models on VidSTG, and surpassing all existing MLLM-based approaches by large margins. It also demonstrates strong open-vocabulary generalization across datasets, establishing MLLMs as viable and powerful backbones for precise spatio-temporal grounding. Our code and models will be released.","authors":["Xin Gu","Haoji Zhang","Qihang Fan","Jingxuan Niu","Zhipeng Zhang","Libo Zhang","Guang Chen","Fan Chen","Longyin Wen","Sijie Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21367v1","updated":"2025-11-26T13:12:21Z","published":"2025-11-26T13:12:21Z","title":"Endo-G$^{2}$T: Geometry-Guided & Temporally Aware Time-Embedded 4DGS For Endoscopic Scenes","summary":"Endoscopic (endo) video exhibits strong view-dependent effects such as specularities, wet reflections, and occlusions. Pure photometric supervision misaligns with geometry and triggers early geometric drift, where erroneous shapes are reinforced during densification and become hard to correct. We ask how to anchor geometry early for 4D Gaussian splatting (4DGS) while maintaining temporal consistency and efficiency in dynamic endoscopic scenes. Thus, we present Endo-G$^{2}$T, a geometry-guided and temporally aware training scheme for time-embedded 4DGS. First, geo-guided prior distillation converts confidence-gated monocular depth into supervision with scale-invariant depth and depth-gradient losses, using a warm-up-to-cap schedule to inject priors softly and avoid early overfitting. Second, a time-embedded Gaussian field represents dynamics in XYZT with a rotor-like rotation parameterization, yielding temporally coherent geometry with lightweight regularization that favors smooth motion and crisp opacity boundaries. Third, keyframe-constrained streaming improves efficiency and long-horizon stability through keyframe-focused optimization under a max-points budget, while non-keyframes advance with lightweight updates. Across EndoNeRF and StereoMIS-P1 datasets, Endo-G$^{2}$T achieves state-of-the-art results among monocular reconstruction baselines.","authors":["Yangle Liu","Fengze Li","Kan Liu","Jieming Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21365v1","updated":"2025-11-26T13:12:14Z","published":"2025-11-26T13:12:14Z","title":"PFF-Net: Patch Feature Fitting for Point Cloud Normal Estimation","summary":"Estimating the normal of a point requires constructing a local patch to provide center-surrounding context, but determining the appropriate neighborhood size is difficult when dealing with different data or geometries. Existing methods commonly employ various parameter-heavy strategies to extract a full feature description from the input patch. However, they still have difficulties in accurately and efficiently predicting normals for various point clouds. In this work, we present a new idea of feature extraction for robust normal estimation of point clouds. We use the fusion of multi-scale features from different neighborhood sizes to address the issue of selecting reasonable patch sizes for various data or geometries. We seek to model a patch feature fitting (PFF) based on multi-scale features to approximate the optimal geometric description for normal estimation and implement the approximation process via multi-scale feature aggregation and cross-scale feature compensation. The feature aggregation module progressively aggregates the patch features of different scales to the center of the patch and shrinks the patch size by removing points far from the center. It not only enables the network to precisely capture the structure characteristic in a wide range, but also describes highly detailed geometries. The feature compensation module ensures the reusability of features from earlier layers of large scales and reveals associated information in different patch sizes. Our approximation strategy based on aggregating the features of multiple scales enables the model to achieve scale adaptation of varying local patches and deliver the optimal feature description. Extensive experiments demonstrate that our method achieves state-of-the-art performance on both synthetic and real-world datasets with fewer network parameters and running time.","authors":["Qing Li","Huifang Feng","Kanle Shi","Yue Gao","Yi Fang","Yu-Shen Liu","Zhizhong Han"],"pdf_url":"","comment":"Accepted by TVCG"},{"id":"http://arxiv.org/abs/2511.21364v1","updated":"2025-11-26T13:11:46Z","published":"2025-11-26T13:11:46Z","title":"BanglaMM-Disaster: A Multimodal Transformer-Based Deep Learning Framework for Multiclass Disaster Classification in Bangla","summary":"Natural disasters remain a major challenge for Bangladesh, so real-time monitoring and quick response systems are essential. In this study, we present BanglaMM-Disaster, an end-to-end deep learning-based multimodal framework for disaster classification in Bangla, using both textual and visual data from social media. We constructed a new dataset of 5,037 Bangla social media posts, each consisting of a caption and a corresponding image, annotated into one of nine disaster-related categories. The proposed model integrates transformer-based text encoders, including BanglaBERT, mBERT, and XLM-RoBERTa, with CNN backbones such as ResNet50, DenseNet169, and MobileNetV2, to process the two modalities. Using early fusion, the best model achieves 83.76% accuracy. This surpasses the best text-only baseline by 3.84% and the image-only baseline by 16.91%. Our analysis also shows reduced misclassification across all classes, with noticeable improvements for ambiguous examples. This work fills a key gap in Bangla multimodal disaster analysis and demonstrates the benefits of combining multiple data types for real-time disaster response in low-resource settings.","authors":["Ariful Islam","Md Rifat Hossen","Md. Mahmudul Arif","Abdullah Al Noman","Md Arifur Rahman"],"pdf_url":"","comment":"Presented at the 2025 IEEE International Conference on Signal Processing, Information, Communication and Systems (SPICSCON), November 21-22, 2025, University of Rajshahi, Bangladesh. 6 pages, 9 disaster classes, multimodal dataset with 5,037 samples"},{"id":"http://arxiv.org/abs/2503.22087v2","updated":"2025-11-26T12:58:04Z","published":"2025-03-28T02:05:53Z","title":"Stream and Query-guided Feature Aggregation for Efficient and Effective 3D Occupancy Prediction","summary":"3D occupancy prediction has become a key perception task in autonomous driving, as it enables comprehensive scene understanding. Recent methods enhance this understanding by incorporating spatiotemporal information through multi-frame fusion, but they suffer from a trade-off: dense voxel-based representations provide high accuracy at significant computational cost, whereas sparse representations improve efficiency but lose spatial detail. To mitigate this trade-off, we introduce DuOcc, which employs a dual aggregation strategy that retains dense voxel representations to preserve spatial fidelity while maintaining high efficiency. DuOcc consists of two key components: (i) Stream-based Voxel Aggregation, which recurrently accumulates voxel features over time and refines them to suppress warping-induced distortions, preserving a clear separation between occupied and free space. (ii) Query-guided Aggregation, which complements the limitations of voxel accumulation by selectively injecting instance-level query features into the voxel regions occupied by dynamic objects. Experiments on the widely used Occ3D-nuScenes and SurroundOcc datasets demonstrate that DuOcc achieves state-of-the-art performance in real-time settings, while reducing memory usage by over 40% compared to prior methods.","authors":["Seokha Moon","Janghyun Baek","Giseop Kim","Jinkyu Kim","Sunwook Choi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21339v1","updated":"2025-11-26T12:44:51Z","published":"2025-11-26T12:44:51Z","title":"SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding","summary":"Recent advances in multimodal large language models (LLMs) have highlighted their potential for medical and surgical applications. However, existing surgical datasets predominantly adopt a Visual Question Answering (VQA) format with heterogeneous taxonomies and lack support for pixel-level segmentation, limiting consistent evaluation and applicability. We present SurgMLLMBench, a unified multimodal benchmark explicitly designed for developing and evaluating interactive multimodal LLMs for surgical scene understanding, including the newly collected Micro-surgical Artificial Vascular anastomosIS (MAVIS) dataset. It integrates pixel-level instrument segmentation masks and structured VQA annotations across laparoscopic, robot-assisted, and micro-surgical domains under a unified taxonomy, enabling comprehensive evaluation beyond traditional VQA tasks and richer visual-conversational interactions. Extensive baseline experiments show that a single model trained on SurgMLLMBench achieves consistent performance across domains and generalizes effectively to unseen datasets. SurgMLLMBench will be publicly released as a robust resource to advance multimodal surgical AI research, supporting reproducible evaluation and development of interactive surgical reasoning models.","authors":["Tae-Min Choi","Tae Kyeong Jeong","Garam Kim","Jaemin Lee","Yeongyoon Koh","In Cheul Choi","Jae-Ho Chung","Jong Woong Park","Juyoun Park"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.21337v1","updated":"2025-11-26T12:40:18Z","published":"2025-11-26T12:40:18Z","title":"Hybrid SIFT-SNN for Efficient Anomaly Detection of Traffic Flow-Control Infrastructure","summary":"This paper presents the SIFT-SNN framework, a low-latency neuromorphic signal-processing pipeline for real-time detection of structural anomalies in transport infrastructure. The proposed approach integrates Scale-Invariant Feature Transform (SIFT) for spatial feature encoding with a latency-driven spike conversion layer and a Leaky Integrate-and-Fire (LIF) Spiking Neural Network (SNN) for classification. The Auckland Harbour Bridge dataset is recorded under various weather and lighting conditions, comprising 6,000 labelled frames that include both real and synthetically augmented unsafe cases. The presented system achieves a classification accuracy of 92.3% (+- 0.8%) with a per-frame inference time of 9.5 ms. Achieved sub-10 millisecond latency, combined with sparse spike activity (8.1%), enables real-time, low-power edge deployment. Unlike conventional CNN-based approaches, the hybrid SIFT-SNN pipeline explicitly preserves spatial feature grounding, enhances interpretability, supports transparent decision-making, and operates efficiently on embedded hardware. Although synthetic augmentation improved robustness, generalisation to unseen field conditions remains to be validated. The SIFT-SNN framework is validated through a working prototype deployed on a consumer-grade system and framed as a generalisable case study in structural safety monitoring for movable concrete barriers, which, as a traffic flow-control infrastructure, is deployed in over 20 cities worldwide.","authors":["Munish Rathee","Boris Bačić","Maryam Doborjeh"],"pdf_url":"","comment":"8 pages, 6 figures. This is a preprint of a paper accepted for presentation at the 2025 International Conference on Image and Vision Computing New Zealand (IVCNZ). The final version will appear in IEEE Xplore"},{"id":"http://arxiv.org/abs/2503.17358v4","updated":"2025-11-26T12:35:32Z","published":"2025-03-21T17:58:56Z","title":"Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image","summary":"In many robotics and VR/AR applications, fast camera motions lead to a high level of motion blur, causing existing camera pose estimation methods to fail. In this work, we propose a novel framework that leverages motion blur as a rich cue for motion estimation rather than treating it as an unwanted artifact. Our approach works by predicting a dense motion flow field and a monocular depth map directly from a single motion-blurred image. We then recover the instantaneous camera velocity by solving a linear least squares problem under the small motion assumption. In essence, our method produces an IMU-like measurement that robustly captures fast and aggressive camera movements. To train our model, we construct a large-scale dataset with realistic synthetic motion blur derived from ScanNet++v2 and further refine our model by training end-to-end on real data using our fully differentiable pipeline. Extensive evaluations on real-world benchmarks demonstrate that our method achieves state-of-the-art angular and translational velocity estimates, outperforming current methods like MASt3R and COLMAP.","authors":["Jerred Chen","Ronald Clark"],"pdf_url":"","comment":"Project page: https://jerredchen.github.io/image-as-imu/"},{"id":"http://arxiv.org/abs/2412.04678v2","updated":"2025-11-26T12:34:00Z","published":"2024-12-06T00:23:18Z","title":"Unsupervised Segmentation by Diffusing, Walking and Cutting","summary":"We propose an unsupervised image segmentation method using features from pre-trained text-to-image diffusion models. Inspired by classic spectral clustering approaches, we construct adjacency matrices from self-attention layers between image patches and recursively partition using Normalised Cuts. A key insight is that self-attention probability distributions, which capture semantic relations between patches, can be interpreted as a transition matrix for random walks across the image. We leverage this by first using Random Walk Normalized Cuts directly on these self-attention activations to partition the image, minimizing transition probabilities between clusters while maximizing coherence within clusters. Applied recursively, this yields a hierarchical segmentation that reflects the rich semantics in the pre-trained attention layers, without any additional training. Next, we explore other ways to build the NCuts adjacency matrix from features, and how we can use the random walk interpretation of self-attention to capture long-range relationships. Finally, we propose an approach to automatically determine the NCut cost criterion, avoiding the need to tune this manually. We quantitatively analyse the effect incorporating different features, a constant versus dynamic NCut threshold, and incorporating multi-node paths when constructing the NCuts adjacency matrix. We show that our approach surpasses all existing methods for zero-shot unsupervised segmentation, achieving state-of-the-art results on COCO-Stuff-27 and Cityscapes.","authors":["Daniela Ivanova","Marco Aversa","Paul Henderson","John Williamson"],"pdf_url":"","comment":"Accepted to The IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026"},{"id":"http://arxiv.org/abs/2505.20935v2","updated":"2025-11-26T12:29:27Z","published":"2025-05-27T09:23:10Z","title":"ISAC: Training-Free Instance-to-Semantic Attention Control for Improving Multi-Instance Generation","summary":"Text-to-image diffusion models have recently become highly capable, yet their behavior in multi-object scenes remains unreliable: models often produce an incorrect number of instances and exhibit semantics leaking across objects. We trace these failures to vague instance boundaries; self-attention already reveals instance layouts early in the denoising process, but existing approaches act only on semantic signals. We introduce $\\textbf{ISAC}$ ($\\textbf{I}$nstance-to-$\\textbf{S}$emantic $\\textbf{A}$ttention $\\textbf{C}$ontrol), a training-free, model-agnostic objective that performs hierarchical attention control by first carving out instance layouts from self-attention and then binding semantics to these instances. In Phase 1, ISAC clusters self-attention into the number of instances and repels overlaps, establishing an instance-level structural hierarchy; in Phase 2, it injects these instance cues into cross-attention to obtain instance-aware semantic masks and decomposes mixing semantics by tying attributes within each instance. ISAC yields consistent gains on T2I-CompBench, HRS-Bench, and IntraCompBench, our new benchmark for intra-class compositions where failures are most frequent, with improvements of at least 50% in multi-class accuracy and 7% in multi-instance accuracy on IntraCompBench, without any fine-tuning or external models. Beyond text-to-image setups, ISAC also strengthens layout-to-image controllers under overlapping boxes by refining coarse box layouts into dense instance masks, indicating that hierarchical decoupling of instance formation and semantic assignment is a key principle for robust, controllable multi-object generation. Code will be released upon publication.","authors":["Sanghyun Jo","Wooyeol Lee","Ziseok Lee","Kyungsu Kim"],"pdf_url":"","comment":"36 pages"},{"id":"http://arxiv.org/abs/2511.21331v1","updated":"2025-11-26T12:25:55Z","published":"2025-11-26T12:25:55Z","title":"The More, the Merrier: Contrastive Fusion for Higher-Order Multimodal Alignment","summary":"Learning joint representations across multiple modalities remains a central challenge in multimodal machine learning. Prevailing approaches predominantly operate in pairwise settings, aligning two modalities at a time. While some recent methods aim to capture higher-order interactions among multiple modalities, they often overlook or insufficiently preserve pairwise relationships, limiting their effectiveness on single-modality tasks. In this work, we introduce Contrastive Fusion (ConFu), a framework that jointly embeds both individual modalities and their fused combinations into a unified representation space, where modalities and their fused counterparts are aligned. ConFu extends traditional pairwise contrastive objectives with an additional fused-modality contrastive term, encouraging the joint embedding of modality pairs with a third modality. This formulation enables ConFu to capture higher-order dependencies, such as XOR-like relationships, that cannot be recovered through pairwise alignment alone, while still maintaining strong pairwise correspondence. We evaluate ConFu on synthetic and real-world multimodal benchmarks, assessing its ability to exploit cross-modal complementarity, capture higher-order dependencies, and scale with increasing multimodal complexity. Across these settings, ConFu demonstrates competitive performance on retrieval and classification tasks, while supporting unified one-to-one and two-to-one retrieval within a single contrastive framework.","authors":["Stefanos Koutoupis","Michaela Areti Zervou","Konstantinos Kontras","Maarten De Vos","Panagiotis Tsakalides","Grigorios Tsagatakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15703v2","updated":"2025-11-26T12:23:11Z","published":"2025-11-19T18:59:04Z","title":"Think Visually, Reason Textually: Vision-Language Synergy in ARC","summary":"Abstract reasoning from minimal examples remains a core unsolved problem for frontier foundation models such as GPT-5 and Grok 4. These models still fail to infer structured transformation rules from a handful of examples, which is a key hallmark of human intelligence. The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) provides a rigorous testbed for this capability, demanding conceptual rule induction and transfer to novel tasks. Most existing methods treat ARC-AGI as a purely textual reasoning task, overlooking the fact that humans rely heavily on visual abstraction when solving such puzzles. However, our pilot experiments reveal a paradox: naively rendering ARC-AGI grids as images degrades performance due to imprecise rule execution. This leads to our central hypothesis that vision and language possess complementary strengths across distinct reasoning stages: vision supports global pattern abstraction and verification, whereas language specializes in symbolic rule formulation and precise execution. Building on this insight, we introduce two synergistic strategies: (1) Vision-Language Synergy Reasoning (VLSR), which decomposes ARC-AGI into modality-aligned subtasks; and (2) Modality-Switch Self-Correction (MSSC), which leverages vision to verify text-based reasoning for intrinsic error correction. Extensive experiments demonstrate that our approach yields up to a 4.33\\% improvement over text-only baselines across diverse flagship models and multiple ARC-AGI tasks. Our findings suggest that unifying visual abstraction with linguistic reasoning is a crucial step toward achieving generalizable, human-like intelligence in future foundation models. Source code is released at https://github.com/InternLM/ARC-VL.","authors":["Beichen Zhang","Yuhang Zang","Xiaoyi Dong","Yuhang Cao","Haodong Duan","Dahua Lin","Jiaqi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2312.15868v2","updated":"2025-11-26T12:16:06Z","published":"2023-12-26T03:27:30Z","title":"Restoration-Oriented Video Frame Interpolation with Region-Distinguishable Priors from SAM","summary":"In existing restoration-oriented Video Frame Interpolation (VFI) approaches, the motion estimation between neighboring frames plays a crucial role. However, the estimation accuracy in existing methods remains a challenge, primarily due to the inherent ambiguity in identifying corresponding areas in adjacent frames for interpolation. Therefore, enhancing accuracy by distinguishing different regions before motion estimation is of utmost importance. In this paper, we introduce a novel solution involving the utilization of open-world segmentation models, e.g., SAM2 (Segment Anything Model2) for frames, to derive Region-Distinguishable Priors (RDPs) in different frames. These RDPs are represented as spatial-varying Gaussian mixtures, distinguishing an arbitrary number of areas with a unified modality. RDPs can be integrated into existing motion-based VFI methods to enhance features for motion estimation, facilitated by our designed play-and-plug Hierarchical Region-aware Feature Fusion Module (HRFFM). HRFFM incorporates RDP into various hierarchical stages of VFI's encoder, using RDP-guided Feature Normalization (RDPFN) in a residual learning manner. With HRFFM and RDP, the features within VFI's encoder exhibit similar representations for matched regions in neighboring frames, thus improving the synthesis of intermediate frames. Extensive experiments demonstrate that HRFFM consistently enhances VFI performance across various scenes.","authors":["Yan Han","Xiaogang Xu","Yingqi Lin","Jiafei Wu","Zhe Liu","Ming-Hsuan Yang"],"pdf_url":"","comment":"Code will be released"},{"id":"http://arxiv.org/abs/2511.21317v1","updated":"2025-11-26T12:04:03Z","published":"2025-11-26T12:04:03Z","title":"HTTM: Head-wise Temporal Token Merging for Faster VGGT","summary":"The Visual Geometry Grounded Transformer (VGGT) marks a significant leap forward in 3D scene reconstruction, as it is the first model that directly infers all key 3D attributes (camera poses, depths, and dense geometry) jointly in one pass. However, this joint inference mechanism requires global attention layers that perform all-to-all attention computation on tokens from all views. For reconstruction of large scenes with long-sequence inputs, this causes a significant latency bottleneck. In this paper, we propose head-wise temporal merging (HTTM), a training-free 3D token merging method for accelerating VGGT. Existing merging techniques merge tokens uniformly across different attention heads, resulting in identical tokens in the layers' output, which hinders the model's representational ability. HTTM tackles this problem by merging tokens in multi-head granularity, which preserves the uniqueness of feature tokens after head concatenation. Additionally, this enables HTTM to leverage the spatial locality and temporal correspondence observed at the head level to achieve higher merging ratios with lower merging costs compared to existing methods. Thus, HTTM achieves up to 7x acceleration with negligible performance drops in a GPU-based inference.","authors":["Weitian Wang","Lukas Meiner","Rai Shubham","Cecilia De La Parra","Akash Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.02465v3","updated":"2025-11-26T11:55:23Z","published":"2025-02-04T16:36:07Z","title":"Towards Consistent and Controllable Image Synthesis for Face Editing","summary":"Face editing methods, essential for tasks like virtual avatars, digital human synthesis and identity preservation, have traditionally been built upon GAN-based techniques, while recent focus has shifted to diffusion-based models due to their success in image reconstruction. However, diffusion models still face challenges in controlling specific attributes and preserving the consistency of other unchanged attributes especially the identity characteristics. To address these issues and facilitate more convenient editing of face images, we propose a novel approach that leverages the power of Stable-Diffusion (SD) models and crude 3D face models to control the lighting, facial expression and head pose of a portrait photo. We observe that this task essentially involves the combinations of target background, identity and face attributes aimed to edit. We strive to sufficiently disentangle the control of these factors to enable consistency of face editing. Specifically, our method, coined as RigFace, contains: 1) A Spatial Attribute Encoder that provides presise and decoupled conditions of background, pose, expression and lighting; 2) A high-consistency FaceFusion method that transfers identity features from the Identity Encoder to the denoising UNet of a pre-trained SD model; 3) An Attribute Rigger that injects those conditions into the denoising UNet. Our model achieves comparable or even superior performance in both identity preservation and photorealism compared to existing face editing models.","authors":["Mengting Wei","Tuomas Varanka","Yante Li","Xingxun Jiang","Huai-Qian Khor","Guoying Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21309v1","updated":"2025-11-26T11:53:26Z","published":"2025-11-26T11:53:26Z","title":"CaliTex: Geometry-Calibrated Attention for View-Coherent 3D Texture Generation","summary":"Despite major advances brought by diffusion-based models, current 3D texture generation systems remain hindered by cross-view inconsistency -- textures that appear convincing from one viewpoint often fail to align across others. We find that this issue arises from attention ambiguity, where unstructured full attention is applied indiscriminately across tokens and modalities, causing geometric confusion and unstable appearance-structure coupling. To address this, we introduce CaliTex, a framework of geometry-calibrated attention that explicitly aligns attention with 3D structure. It introduces two modules: Part-Aligned Attention that enforces spatial alignment across semantically matched parts, and Condition-Routed Attention which routes appearance information through geometry-conditioned pathways to maintain spatial fidelity. Coupled with a two-stage diffusion transformer, CaliTex makes geometric coherence an inherent behavior of the network rather than a byproduct of optimization. Empirically, CaliTex produces seamless and view-consistent textures and outperforms both open-source and commercial baselines.","authors":["Chenyu Liu","Hongze Chen","Jingzhi Bao","Lingting Zhu","Runze Zhang","Weikai Chen","Zeyu Hu","Yingda Yin","Keyang Luo","Xin Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06998v2","updated":"2025-11-26T11:47:20Z","published":"2025-09-04T17:52:22Z","title":"Not All Splits Are Equal: Rethinking Attribute Generalization Across Unrelated Categories","summary":"Can models generalize attribute knowledge across semantically and perceptually dissimilar categories? While prior work has addressed attribute prediction within narrow taxonomic or visually similar domains, it remains unclear whether current models can abstract attributes and apply them to conceptually distant categories. This work presents the first explicit evaluation for the robustness of the attribute prediction task under such conditions, testing whether models can correctly infer shared attributes between unrelated object types: e.g., identifying that the attribute \"has four legs\" is common to both \"dogs\" and \"chairs\". To enable this evaluation, we introduce train-test split strategies that progressively reduce correlation between training and test sets, based on: LLM-driven semantic grouping, embedding similarity thresholding, embedding-based clustering, and supercategory-based partitioning using ground-truth labels. Results show a sharp drop in performance as the correlation between training and test categories decreases, indicating strong sensitivity to split design. Among the evaluated methods, clustering yields the most effective trade-off, reducing hidden correlations while preserving learnability. These findings offer new insights into the limitations of current representations and inform future benchmark construction for attribute reasoning.","authors":["Liviu Nicolae Fircă","Antonio Bărbălau","Dan Oneata","Elena Burceanu"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 Workshop: CauScien - Uncovering Causality in Science and NeurIPS 2025 Workshop: Reliable ML from Unreliable Data"},{"id":"http://arxiv.org/abs/2511.21298v1","updated":"2025-11-26T11:42:27Z","published":"2025-11-26T11:42:27Z","title":"PathMamba: A Hybrid Mamba-Transformer for Topologically Coherent Road Segmentation in Satellite Imagery","summary":"Achieving both high accuracy and topological continuity in road segmentation from satellite imagery is a critical goal for applications ranging from urban planning to disaster response. State-of-the-art methods often rely on Vision Transformers, which excel at capturing global context, yet their quadratic complexity is a significant barrier to efficient deployment, particularly for on-board processing in resource-constrained platforms. In contrast, emerging State Space Models like Mamba offer linear-time efficiency and are inherently suited to modeling long, continuous structures. We posit that these architectures have complementary strengths. To this end, we introduce PathMamba, a novel hybrid architecture that integrates Mamba's sequential modeling with the Transformer's global reasoning. Our design strategically uses Mamba blocks to trace the continuous nature of road networks, preserving topological structure, while integrating Transformer blocks to refine features with global context. This approach yields topologically superior segmentation maps without the prohibitive scaling costs of pure attention-based models. Our experiments on the DeepGlobe Road Extraction and Massachusetts Roads datasets demonstrate that PathMamba sets a new state-of-the-art. Notably, it significantly improves topological continuity, as measured by the APLS metric, setting a new benchmark while remaining computationally competitive.","authors":["Jules Decaestecker","Nicolas Vigne"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.11381v5","updated":"2025-11-26T11:30:37Z","published":"2025-02-17T02:53:08Z","title":"Without Paired Labeled Data: End-to-End Self-Supervised Learning for Drone-view Geo-Localization","summary":"Drone-view Geo-Localization (DVGL) aims to achieve accurate localization of drones by retrieving the most relevant GPS-tagged satellite images. However, most existing methods heavily rely on strictly pre-paired drone-satellite images for supervised learning. When the target region shifts, new paired samples are typically required to adapt to the distribution changes. The high cost of annotation and the limited transferability of these methods significantly hinder the practical deployment of DVGL in open-world scenarios. To address these limitations, we propose a novel end-to-end self-supervised learning method with a shallow backbone network, called the dynamic memory-driven and neighborhood information learning (DMNIL) method. It employs a clustering algorithm to generate pseudo-labels and adopts a dual-path contrastive learning framework to learn discriminative intra-view representations. Furthermore, DMNIL incorporates two core modules, including the dynamic hierarchical memory learning (DHML) module and the information consistency evolution learning (ICEL) module. The DHML module combines short-term and long-term memory to enhance intra-view feature consistency and discriminability. Meanwhile, the ICEL module utilizes a neighborhood-driven dynamic constraint mechanism to systematically capture implicit cross-view semantic correlations, consequently improving cross-view feature alignment. To further stabilize and strengthen the self-supervised training process, a pseudo-label enhancement strategy is introduced to enhance the quality of pseudo supervision. Extensive experiments on three public benchmark datasets demonstrate that the proposed method consistently outperforms existing self-supervised methods and even surpasses several state-of-the-art supervised methods. Our code is available at https://github.com/ISChenawei/DMNIL.","authors":["Zhongwei Chen","Zhao-Xu Yang","Hai-Jun Rong","Guoqi Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.07520v3","updated":"2025-11-26T11:18:47Z","published":"2025-03-10T16:46:43Z","title":"From Limited Labels to Open Domains:An Efficient Learning Method for Drone-view Geo-Localization","summary":"Traditional supervised drone-view geo-localization (DVGL) methods heavily depend on paired training data and encounter difficulties in learning cross-view correlations from unpaired data. Moreover, when deployed in a new domain, these methods require obtaining the new paired data and subsequent retraining for model adaptation, which significantly increases computational overhead. Existing unsupervised methods have enabled to generate pseudo-labels based on cross-view similarity to infer the pairing relationships. However, geographical similarity and spatial continuity often cause visually analogous features at different geographical locations. The feature confusion compromises the reliability of pseudo-label generation, where incorrect pseudo-labels drive negative optimization. Given these challenges inherent in both supervised and unsupervised DVGL methods, we propose a novel cross-domain invariant knowledge transfer network (CDIKTNet) with limited supervision, whose architecture consists of a cross-domain invariance sub-network (CDIS) and a cross-domain transfer sub-network (CDTS). This architecture facilitates a closed-loop framework for invariance feature learning and knowledge transfer. The CDIS is designed to learn cross-view structural and spatial invariance from a small amount of paired data that serves as prior knowledge. It endows the shared feature space of unpaired data with similar implicit cross-view correlations at initialization, which alleviates feature confusion. Based on this, the CDTS employs dual-path contrastive learning to further optimize each subspace while preserving consistency in a shared feature space. Extensive experiments demonstrate that CDIKTNet achieves state-of-the-art performance under full supervision compared with those supervised methods, and further surpasses existing unsupervised methods in both few-shot and cross-domain initialization.","authors":["Zhongwei Chen","Zhao-Xu Yang","Hai-Jun Rong","Jiawei Lang","Guoqi Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.06806v3","updated":"2025-11-26T11:03:18Z","published":"2025-07-09T12:51:46Z","title":"GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction","summary":"Plant traits such as leaf carbon content and leaf mass are essential variables in the study of biodiversity and climate change. However, conventional field sampling cannot feasibly cover trait variation at ecologically meaningful spatial scales. Machine learning represents a valuable solution for plant trait prediction across ecosystems, leveraging hyperspectral data from remote sensing. Nevertheless, trait prediction from hyperspectral data is challenged by label scarcity and substantial domain shifts (\\eg across sensors, ecological distributions), requiring robust cross-domain methods. Here, we present GreenHyperSpectra, a pretraining dataset encompassing real-world cross-sensor and cross-ecosystem samples designed to benchmark trait prediction with semi- and self-supervised methods. We adopt an evaluation framework encompassing in-distribution and out-of-distribution scenarios. We successfully leverage GreenHyperSpectra to pretrain label-efficient multi-output regression models that outperform the state-of-the-art supervised baseline. Our empirical analyses demonstrate substantial improvements in learning spectral representations for trait prediction, establishing a comprehensive methodological framework to catalyze research at the intersection of representation learning and plant functional traits assessment. All code and data are available at: https://github.com/echerif18/HyspectraSSL.","authors":["Eya Cherif","Arthur Ouaknine","Luke A. Brown","Phuong D. Dao","Kyle R. Kovach","Bing Lu","Daniel Mederer","Hannes Feilhauer","Teja Kattenborn","David Rolnick"],"pdf_url":"","comment":"Accepted at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)"},{"id":"http://arxiv.org/abs/2208.10431v3","updated":"2025-11-26T11:00:22Z","published":"2022-08-22T16:36:32Z","title":"ProtoPFormer: Concentrating on Prototypical Parts in Vision Transformers for Interpretable Image Recognition","summary":"Prototypical part network (ProtoPNet) has drawn wide attention and boosted many follow-up studies due to its self-explanatory property for explainable artificial intelligence (XAI). However, when directly applying ProtoPNet on vision transformer (ViT) backbones, learned prototypes have a \"distraction\" problem: they have a relatively high probability of being activated by the background and pay less attention to the foreground. The powerful capability of modeling long-term dependency makes the transformer-based ProtoPNet hard to focus on prototypical parts, thus severely impairing its inherent interpretability. This paper proposes prototypical part transformer (ProtoPFormer) for appropriately and effectively applying the prototype-based method with ViTs for interpretable image recognition. The proposed method introduces global and local prototypes for capturing and highlighting the representative holistic and partial features of targets according to the architectural characteristics of ViTs. The global prototypes are adopted to provide the global view of objects to guide local prototypes to concentrate on the foreground while eliminating the influence of the background. Afterwards, local prototypes are explicitly supervised to concentrate on their respective prototypical visual parts, increasing the overall interpretability. Extensive experiments demonstrate that our proposed global and local prototypes can mutually correct each other and jointly make final decisions, which faithfully and transparently reason the decision-making processes associatively from the whole and local perspectives, respectively. Moreover, ProtoPFormer consistently achieves superior performance and visualization results over the state-of-the-art (SOTA) prototype-based baselines. Our code has been released at https://github.com/zju-vipa/ProtoPFormer.","authors":["Mengqi Xue","Qihan Huang","Haofei Zhang","Jingwen Hu","Jie Song","Mingli Song","Canghong Jin"],"pdf_url":"","comment":"Arxiv preprint; 18 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2511.21272v1","updated":"2025-11-26T10:55:07Z","published":"2025-11-26T10:55:07Z","title":"Co-Training Vision Language Models for Remote Sensing Multi-task Learning","summary":"With Transformers achieving outstanding performance on individual remote sensing (RS) tasks, we are now approaching the realization of a unified model that excels across multiple tasks through multi-task learning (MTL). Compared to single-task approaches, MTL methods offer improved generalization, enhanced scalability, and greater practical applicability. Recently, vision language models (VLMs) have achieved promising results in RS image understanding, grounding, and ultra-high-resolution (UHR) image reasoning, respectively. Moreover, the unified text-based interface demonstrates significant potential for MTL. Hence, in this work, we present RSCoVLM, a simple yet flexible VLM baseline for RS MTL. Firstly, we create the data curation engine, including data acquisition, offline processing and integrating, as well as online loading and weighting. This data engine effectively addresses complex RS data enviroment and generates flexible vision-language conversations. Furthermore, we propose a unified dynamic-resolution strategy to address the diverse image scales inherent in RS imagery. For UHR images, we introduce the Zoom-in Chain mechanism together with its corresponding dataset, LRS-VQA-Zoom. The strategies are flexible and effectively mitigate the computational burdens. Additionally, we significantly enhance the model's object detection capability and propose a novel evaluation protocol that ensures fair comparison between VLMs and conventional detection models. Extensive experiments demonstrate that RSCoVLM achieves state-of-the-art performance across diverse tasks, outperforming existing RS VLMs and even rivaling specialized expert models. All the training and evaluating tools, model weights, and datasets have been fully open-sourced to support reproducibility. We expect that this baseline will promote further progress toward general-purpose RS models.","authors":["Qingyun Li","Shuran Ma","Junwei Luo","Yi Yu","Yue Zhou","Fengxiang Wang","Xudong Lu","Xiaoxing Wang","Xin He","Yushi Chen","Xue Yang","Junchi Yan"],"pdf_url":"","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.21270v1","updated":"2025-11-26T10:50:17Z","published":"2025-11-26T10:50:17Z","title":"Multi-Reward GRPO for Stable and Prosodic Single-Codebook TTS LLMs at Scale","summary":"Recent advances in Large Language Models (LLMs) have transformed text-to-speech (TTS) synthesis, inspiring autoregressive frameworks that represent speech as sequences of discrete codec tokens. Among them, single-codebook TTS LLMs have emerged as compact and streamable architectures that jointly model semantic and acoustic integration. However, despite their efficiency, these models often exhibit unstable prosody, speaker drift, and degraded naturalness. To address these issues, we propose a multi-reward Group Relative Policy Optimization (GRPO) framework that directly optimizes the token generation policy of single-codebook TTS LLMs. Beyond standard intelligibility and speaker similarity objectives, our design integrates three rule-based rewards: a length penalty for duration consistency, an entropy regularization reward for decoding stability, and an LLM-annotated prosody alignment reward that explicitly supervises rhythm. In this prosody reward, an external reasoning LLM predicts multiple plausible pause structures via in-context learning, providing a human-preference-aligned supervisory signal for GRPO training. To assess universality, we further attach a flow-matching (FM) decoder on top of the GRPO-optimized AR backbone and observe consistent additional gains, indicating that our reinforcement optimization enhances the intrinsic AR policy. We further conduct a scalability analysis across data sizes and model scales, revealing that the proposed method consistently enhances prosodic stability, speaker similarity, and overall speech naturalness in single-codebook TTS LLMs.","authors":["Yicheng Zhong","Peiji Yang","Zhisheng Wang"],"pdf_url":"","comment":"4 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.21265v1","updated":"2025-11-26T10:43:21Z","published":"2025-11-26T10:43:21Z","title":"Unlocking Zero-shot Potential of Semi-dense Image Matching via Gaussian Splatting","summary":"Learning-based image matching critically depends on large-scale, diverse, and geometrically accurate training data. 3D Gaussian Splatting (3DGS) enables photorealistic novel-view synthesis and thus is attractive for data generation. However, its geometric inaccuracies and biased depth rendering currently prevent robust correspondence labeling. To address this, we introduce MatchGS, the first framework designed to systematically correct and leverage 3DGS for robust, zero-shot image matching. Our approach is twofold: (1) a geometrically-faithful data generation pipeline that refines 3DGS geometry to produce highly precise correspondence labels, enabling the synthesis of a vast and diverse range of viewpoints without compromising rendering fidelity; and (2) a 2D-3D representation alignment strategy that infuses 3DGS' explicit 3D knowledge into the 2D matcher, guiding 2D semi-dense matchers to learn viewpoint-invariant 3D representations. Our generated ground-truth correspondences reduce the epipolar error by up to 40 times compared to existing datasets, enable supervision under extreme viewpoint changes, and provide self-supervisory signals through Gaussian attributes. Consequently, state-of-the-art matchers trained solely on our data achieve significant zero-shot performance gains on public benchmarks, with improvements of up to 17.7%. Our work demonstrates that with proper geometric refinement, 3DGS can serve as a scalable, high-fidelity, and structurally-rich data source, paving the way for a new generation of robust zero-shot image matchers.","authors":["Juncheng Chen","Chao Xu","Yanjun Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21256v1","updated":"2025-11-26T10:39:16Z","published":"2025-11-26T10:39:16Z","title":"LaGen: Towards Autoregressive LiDAR Scene Generation","summary":"Generative world models for autonomous driving (AD) have become a trending topic. Unlike the widely studied image modality, in this work we explore generative world models for LiDAR data. Existing generation methods for LiDAR data only support single frame generation, while existing prediction approaches require multiple frames of historical input and can only deterministically predict multiple frames at once, lacking interactivity. Both paradigms fail to support long-horizon interactive generation. To this end, we introduce LaGen, which to the best of our knowledge is the first framework capable of frame-by-frame autoregressive generation of long-horizon LiDAR scenes. LaGen is able to take a single-frame LiDAR input as a starting point and effectively utilize bounding box information as conditions to generate high-fidelity 4D scene point clouds. In addition, we introduce a scene decoupling estimation module to enhance the model's interactive generation capability for object-level content, as well as a noise modulation module to mitigate error accumulation during long-horizon generation. We construct a protocol based on nuScenes for evaluating long-horizon LiDAR scene generation. Experimental results comprehensively demonstrate LaGen outperforms state-of-the-art LiDAR generation and prediction models, especially on the later frames.","authors":["Sizhuo Zhou","Xiaosong Jia","Fanrui Zhang","Junjie Li","Juyong Zhang","Yukang Feng","Jianwen Sun","Songbur Wong","Junqi You","Junchi Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2309.04312v2","updated":"2025-11-26T10:36:45Z","published":"2023-09-08T13:18:10Z","title":"AMLP: Adjustable Masking Lesion Patches for Self-Supervised Medical Image Segmentation","summary":"Self-supervised masked image modeling (MIM) methods have shown promising performances on analyzing natural images. However, directly applying such methods to medical image segmentation tasks still cannot achieve satisfactory results. The challenges arise from the facts that (i) medical images are inherently more complex compared to natural images, and the subjects in medical images often exhibit more distinct contour features; (ii) moreover, the conventional high and fixed masking ratio in MIM is likely to mask the background, limiting the scope of learnable information. To address these problems, we propose a new self-supervised medical image segmentation framework, called Adjustable Masking Lesion Patches (AMLP), which employs Masked Patch Selection~(MPS) strategy to identify patches with high probabilities of containing lesions to help model achieve precise lesion reconstruction. To improve the categorization of patches in MPS, we further introduce Relative Reconstruction Loss (RRL) to better learn hard-to-reconstruct lesion patches. Then, Category Consistency Loss (CCL) is proposed to refine patch categorization based on reconstruction difficulty, enhancing difference between lesions and backgrounds. Moreover, an Adjustable Masking Ratio (AMR) strategy is proposed to gradually increase the masking ratio over training to expand~the scope of learnable mutual information. Extensive~experiments on two medical segmentation datasets demonstrate the superior performances of the proposed AMLP w.r.t. the SOTA self-supervised methods; the results prove that AMLP effectively addresses the challenges of applying masked modeling to medical images and capturing accurate lesion details that are crucial for segmentation tasks.","authors":["Xiangtao Wang","Ruizhi Wang","Thomas Lukasiewicz","Zhenghua Xu"],"pdf_url":"","comment":"© 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"},{"id":"http://arxiv.org/abs/2511.11659v2","updated":"2025-11-26T10:35:53Z","published":"2025-11-11T02:44:38Z","title":"DWFF-Net : A Multi-Scale Farmland System Habitat Identification Method with Adaptive Dynamic Weight","summary":"Addressing the current lack of a standardized habitat classification system for cultivated land ecosystems, incomplete coverage of the habitat types, and the inability of existing models to effectively integrate semantic and texture features-resulting in insufficient segmentation accuracy and blurred boundaries for multi-scale habitats (e.g., large-scale field plots and micro-habitats)-this study developed a comprehensively annotated ultra-high-resolution remote sensing image dataset encompassing 15 categories of cultivated land system habitats. Furthermore, we propose a Dynamic-Weighted Feature Fusion Network (DWFF-Net). The encoder of this model utilizes a frozen-parameter DINOv3 to extract foundational features. By analyzing the relationships between different category images and feature maps, we introduce a data-level adaptive dynamic weighting strategy for feature fusion. The decoder incorporates a dynamic weight computation network to achieve thorough integration of multi-layer features, and a hybrid loss function is adopted to optimize model training. Experimental results on the constructed dataset demonstrate that the proposed model achieves a mean Intersection over Union (mIoU) of 69.79% and an F1-score of 80.49%, outperforming the baseline network by 2.1% and 1.61%, respectively. Ablation studies further confirm the complementary nature of multi-layer feature fusion, which effectively improves the IoU for micro-habitat categories such as field ridges. This study establishes a habitat identification framework for cultivated land systems based on adaptive multi-layer feature fusion, enabling sub-meter precision habitat mapping at a low cost and providing robust technical support for fine-grained habitat monitoring in cultivated landscapes. (The complete code repository can be accessed via GitHub at the following URL: https://github.com/sysau/DWFF-Net)","authors":["Kesong Zheng","Zhi Song","Peizhou Li","Shuyi Yao","Zhenxing Bian"],"pdf_url":"","comment":"30 pages,13 figures"},{"id":"http://arxiv.org/abs/2511.21251v1","updated":"2025-11-26T10:33:12Z","published":"2025-11-26T10:33:12Z","title":"AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs","summary":"The threat of Audio-Video (AV) forgery is rapidly evolving beyond human-centric deepfakes to include more diverse manipulations across complex natural scenes. However, existing benchmarks are still confined to DeepFake-based forgeries and single-granularity annotations, thus failing to capture the diversity and complexity of real-world forgery scenarios. To address this, we introduce AVFakeBench, the first comprehensive audio-video forgery detection benchmark that spans rich forgery semantics across both human subject and general subject. AVFakeBench comprises 12K carefully curated audio-video questions, covering seven forgery types and four levels of annotations. To ensure high-quality and diverse forgeries, we propose a multi-stage hybrid forgery framework that integrates proprietary models for task planning with expert generative models for precise manipulation. The benchmark establishes a multi-task evaluation framework covering binary judgment, forgery types classification, forgery detail selection, and explanatory reasoning. We evaluate 11 Audio-Video Large Language Models (AV-LMMs) and 2 prevalent detection methods on AVFakeBench, demonstrating the potential of AV-LMMs as emerging forgery detectors while revealing their notable weaknesses in fine-grained perception and reasoning.","authors":["Shuhan Xia","Peipei Li","Xuannan Liu","Dongsen Zhang","Xinyu Guo","Zekun Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21250v1","updated":"2025-11-26T10:29:42Z","published":"2025-11-26T10:29:42Z","title":"Shift-Equivariant Complex-Valued Convolutional Neural Networks","summary":"Convolutional neural networks have shown remarkable performance in recent years on various computer vision problems. However, the traditional convolutional neural network architecture lacks a critical property: shift equivariance and invariance, broken by downsampling and upsampling operations. Although data augmentation techniques can help the model learn the latter property empirically, a consistent and systematic way to achieve this goal is by designing downsampling and upsampling layers that theoretically guarantee these properties by construction. Adaptive Polyphase Sampling (APS) introduced the cornerstone for shift invariance, later extended to shift equivariance with Learnable Polyphase up/downsampling (LPS) applied to real-valued neural networks. In this paper, we extend the work on LPS to complex-valued neural networks both from a theoretical perspective and with a novel building block of a projection layer from $\\mathbb{C}$ to $\\mathbb{R}$ before the Gumbel Softmax. We finally evaluate this extension on several computer vision problems, specifically for either the invariance property in classification tasks or the equivariance property in both reconstruction and semantic segmentation problems, using polarimetric Synthetic Aperture Radar images.","authors":["Quentin Gabot","Teck-Yian Lim","Jérémy Fix","Joana Frontera-Pons","Chengfang Ren","Jean-Philippe Ovarlez"],"pdf_url":"","comment":"Accepted to WACV 2026"},{"id":"http://arxiv.org/abs/2503.08805v3","updated":"2025-11-26T10:25:06Z","published":"2025-03-11T18:34:12Z","title":"Filter Like You Test: Data-Driven Data Filtering for CLIP Pretraining","summary":"We introduce Filter Like You Test (FLYT), an algorithm for curating large-scale vision-language datasets that learns the usefulness of each data point as a pretraining example. FLYT trains a scoring model that learns to weigh each example's features using gradient signals from downstream tasks training sets. Based on FLYT, we implement Mixing-FLYT (M-FLYT), which takes the per-example scores generated by different scoring methods as features, and learns to unify them into a single score. FLYT naturally produces a distribution over the training examples, which we leverage through Soft Cap Sampling (SCS), a strategy for obtaining a filtered pretraining dataset from per-example probabilities that samples examples while preventing over-representation through a repetition penalty. Using these methods, we achieve 40.1% ImageNet zero-shot accuracy on the DataComp medium scale filtering benchmark, a 2% absolute accuracy increase over all previous results and a 5.5% increase over results that - like us - use only public resources. Our approach also yields 37.7\\% on the average of 38 DataComp evaluation tasks, outperforming previous public-resource approaches by 0.4\\%.","authors":["Mikey Shechter","Yair Carmon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.06698v2","updated":"2025-11-26T10:23:10Z","published":"2024-12-09T17:44:42Z","title":"Gen-3Diffusion: Realistic Image-to-3D Generation via 2D & 3D Diffusion Synergy","summary":"Creating realistic 3D objects and clothed avatars from a single RGB image is an attractive yet challenging problem. Due to its ill-posed nature, recent works leverage powerful prior from 2D diffusion models pretrained on large datasets. Although 2D diffusion models demonstrate strong generalization capability, they cannot guarantee the generated multi-view images are 3D consistent. In this paper, we propose Gen-3Diffusion: Realistic Image-to-3D Generation via 2D & 3D Diffusion Synergy. We leverage a pre-trained 2D diffusion model and a 3D diffusion model via our elegantly designed process that synchronizes two diffusion models at both training and sampling time. The synergy between the 2D and 3D diffusion models brings two major advantages: 1) 2D helps 3D in generalization: the pretrained 2D model has strong generalization ability to unseen images, providing strong shape priors for the 3D diffusion model; 2) 3D helps 2D in multi-view consistency: the 3D diffusion model enhances the 3D consistency of 2D multi-view sampling process, resulting in more accurate multi-view generation. We validate our idea through extensive experiments in image-based objects and clothed avatar generation tasks. Results show that our method generates realistic 3D objects and avatars with high-fidelity geometry and texture. Extensive ablations also validate our design choices and demonstrate the strong generalization ability to diverse clothing and compositional shapes. Our code and pretrained models will be publicly released on https://yuxuan-xue.com/gen-3diffusion.","authors":["Yuxuan Xue","Xianghui Xie","Riccardo Marin","Gerard Pons-Moll"],"pdf_url":"","comment":"Accepted to Transaction on Pattern Analysis and Machine Intelligence (T-PAMI). Project Page: https://yuxuan-xue.com/gen-3diffusion. arXiv admin note: substantial text overlap with arXiv:2406.08475"},{"id":"http://arxiv.org/abs/2511.21245v1","updated":"2025-11-26T10:22:34Z","published":"2025-11-26T10:22:34Z","title":"FIELDS: Face reconstruction with accurate Inference of Expression using Learning with Direct Supervision","summary":"Facial expressions convey the bulk of emotional information in human communication, yet existing 3D face reconstruction methods often miss subtle affective details due to reliance on 2D supervision and lack of 3D ground truth. We propose FIELDS (Face reconstruction with accurate Inference of Expression using Learning with Direct Supervision) to address these limitations by extending self-supervised 2D image consistency cues with direct 3D expression parameter supervision and an auxiliary emotion recognition branch. Our encoder is guided by authentic expression parameters from spontaneous 4D facial scans, while an intensity-aware emotion loss encourages the 3D expression parameters to capture genuine emotion content without exaggeration. This dual-supervision strategy bridges the 2D/3D domain gap and mitigates expression-intensity bias, yielding high-fidelity 3D reconstructions that preserve subtle emotional cues. From a single image, FIELDS produces emotion-rich face models with highly realistic expressions, significantly improving in-the-wild facial expression recognition performance without sacrificing naturalness.","authors":["Chen Ling","Henglin Shi","Hedvig Kjellström"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22864v2","updated":"2025-11-26T10:09:13Z","published":"2025-09-26T19:22:07Z","title":"ControlEvents: Controllable Synthesis of Event Camera Datawith Foundational Prior from Image Diffusion Models","summary":"In recent years, event cameras have gained significant attention due to their bio-inspired properties, such as high temporal resolution and high dynamic range. However, obtaining large-scale labeled ground-truth data for event-based vision tasks remains challenging and costly. In this paper, we present ControlEvents, a diffusion-based generative model designed to synthesize high-quality event data guided by diverse control signals such as class text labels, 2D skeletons, and 3D body poses. Our key insight is to leverage the diffusion prior from foundation models, such as Stable Diffusion, enabling high-quality event data generation with minimal fine-tuning and limited labeled data. Our method streamlines the data generation process and significantly reduces the cost of producing labeled event datasets. We demonstrate the effectiveness of our approach by synthesizing event data for visual recognition, 2D skeleton estimation, and 3D body pose estimation. Our experiments show that the synthesized labeled event data enhances model performance in all tasks. Additionally, our approach can generate events based on unseen text labels during training, illustrating the powerful text-based generation capabilities inherited from foundation models.","authors":["Yixuan Hu","Yuxuan Xue","Simon Klenk","Daniel Cremers","Gerard Pons-Moll"],"pdf_url":"","comment":"Accepted to WACV2026. Project website: https://https://yuxuan-xue.com/controlevents/"},{"id":"http://arxiv.org/abs/2511.21237v1","updated":"2025-11-26T10:07:03Z","published":"2025-11-26T10:07:03Z","title":"3-Tracer: A Tri-level Temporal-Aware Framework for Audio Forgery Detection and Localization","summary":"Recently, partial audio forgery has emerged as a new form of audio manipulation. Attackers selectively modify partial but semantically critical frames while preserving the overall perceptual authenticity, making such forgeries particularly difficult to detect. Existing methods focus on independently detecting whether a single frame is forged, lacking the hierarchical structure to capture both transient and sustained anomalies across different temporal levels. To address these limitations, We identify three key levels relevant to partial audio forgery detection and present T3-Tracer, the first framework that jointly analyzes audio at the frame, segment, and audio levels to comprehensively detect forgery traces. T3-Tracer consists of two complementary core modules: the Frame-Audio Feature Aggregation Module (FA-FAM) and the Segment-level Multi-Scale Discrepancy-Aware Module (SMDAM). FA-FAM is designed to detect the authenticity of each audio frame. It combines both frame-level and audio-level temporal information to detect intra-frame forgery cues and global semantic inconsistencies. To further refine and correct frame detection, we introduce SMDAM to detect forgery boundaries at the segment level. It adopts a dual-branch architecture that jointly models frame features and inter-frame differences across multi-scale temporal windows, effectively identifying abrupt anomalies that appeared on the forged boundaries. Extensive experiments conducted on three challenging datasets demonstrate that our approach achieves state-of-the-art performance.","authors":["Shuhan Xia","Xuannan Liu","Xing Cui","Peipei Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.22665v2","updated":"2025-11-26T10:05:38Z","published":"2025-10-26T13:04:50Z","title":"SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery","summary":"Synthetic Aperture Radar (SAR) is a crucial imaging modality thanks to its all-weather capability. Although recent advances in self-supervised learning and masked image modeling (MIM) have enabled SAR foundation models, these methods largely emphasize low-level visual features and often overlook multimodal alignment and zero-shot target recognition in SAR imagery. To address this, we construct SARVLM-1M, a large-scale vision-language dataset with over one million image-text pairs aggregated from existing datasets. We further propose a domain transfer training strategy to mitigate the large gap between natural and SAR imagery. Building on this, we develop SARVLM, the first vision language foundation model (VLM) tailored to SAR, comprising SARCLIP and SARCap. SARVLM is trained with a vision-language contrastive objective under the proposed domain transfer strategy, bridging SAR imagery and textual descriptions. Extensive experiments on image text retrieval, zero-shot classification, semantic localization, and imagery captioning demonstrate that SARVLM delivers superior feature extraction and interpretation, outperforming state-of-the-art VLMs and advancing SAR semantic understanding. Code and datasets will be released soon.","authors":["Qiwei Ma","Zhiyu Wang","Wang Liu","Xukun Lu","Bin Deng","Puhong Duan","Xudong Kang","Shutao Li"],"pdf_url":"","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.02373v2","updated":"2025-11-26T10:03:43Z","published":"2024-12-03T11:00:15Z","title":"Active Negative Loss: A Robust Framework for Learning with Noisy Labels","summary":"Deep supervised learning has achieved remarkable success across a wide range of tasks, yet it remains susceptible to overfitting when confronted with noisy labels. To address this issue, noise-robust loss functions offer an effective solution for enhancing learning in the presence of label noise. In this work, we systematically investigate the limitation of the recently proposed Active Passive Loss (APL), which employs Mean Absolute Error (MAE) as its passive loss function. Despite the robustness brought by MAE, one of its key drawbacks is that it pays equal attention to clean and noisy samples; this feature slows down convergence and potentially makes training difficult, particularly in large-scale datasets. To overcome these challenges, we introduce a novel loss function class, termed Normalized Negative Loss Functions (NNLFs), which serve as passive loss functions within the APL framework. NNLFs effectively address the limitations of MAE by concentrating more on memorized clean samples. By replacing MAE in APL with our proposed NNLFs, we enhance APL and present a new framework called Active Negative Loss (ANL). Moreover, in non-symmetric noise scenarios, we propose an entropy-based regularization technique to mitigate the vulnerability to the label imbalance. Extensive experiments demonstrate that the new loss functions adopted by our ANL framework can achieve better or comparable performance to state-of-the-art methods across various label noise types and in image segmentation tasks. The source code is available at: https://github.com/Virusdoll/Active-Negative-Loss.","authors":["Xichen Ye","Yifan Wu","Yiqi Wang","Xiaoqiang Li","Weizhong Zhang","Yifan Chen"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2511.21215v1","updated":"2025-11-26T09:44:51Z","published":"2025-11-26T09:44:51Z","title":"From Diffusion to One-Step Generation: A Comparative Study of Flow-Based Models with Application to Image Inpainting","summary":"We present a comprehensive comparative study of three generative modeling paradigms: Denoising Diffusion Probabilistic Models (DDPM), Conditional Flow Matching (CFM), and MeanFlow. While DDPM and CFM require iterative sampling, MeanFlow enables direct one-step generation by modeling the average velocity over time intervals. We implement all three methods using a unified TinyUNet architecture (<1.5M parameters) on CIFAR-10, demonstrating that CFM achieves an FID of 24.15 with 50 steps, significantly outperforming DDPM (FID 402.98). MeanFlow achieves FID 29.15 with single-step sampling -- a 50X reduction in inference time. We further extend CFM to image inpainting, implementing mask-guided sampling with four mask types (center, random bbox, irregular, half). Our fine-tuned inpainting model achieves substantial improvements: PSNR increases from 4.95 to 8.57 dB on center masks (+73%), and SSIM improves from 0.289 to 0.418 (+45%), demonstrating the effectiveness of inpainting-aware training.","authors":["Umang Agarwal","Rudraksh Sangore","Sumit Laddha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18866v3","updated":"2025-11-26T09:32:08Z","published":"2025-10-21T17:58:17Z","title":"LightMem: Lightweight and Efficient Memory-Augmented Generation","summary":"Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at https://github.com/zjunlp/LightMem.","authors":["Jizhan Fang","Xinle Deng","Haoming Xu","Ziyan Jiang","Yuqi Tang","Ziwen Xu","Shumin Deng","Yunzhi Yao","Mengru Wang","Shuofei Qiao","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2511.21202v1","updated":"2025-11-26T09:32:06Z","published":"2025-11-26T09:32:06Z","title":"Towards an Effective Action-Region Tracking Framework for Fine-grained Video Action Recognition","summary":"Fine-grained action recognition (FGAR) aims to identify subtle and distinctive differences among fine-grained action categories. However, current recognition methods often capture coarse-grained motion patterns but struggle to identify subtle details in local regions evolving over time. In this work, we introduce the Action-Region Tracking (ART) framework, a novel solution leveraging a query-response mechanism to discover and track the dynamics of distinctive local details, enabling effective distinction of similar actions. Specifically, we propose a region-specific semantic activation module that employs discriminative and text-constrained semantics as queries to capture the most action-related region responses in each video frame, facilitating interaction among spatial and temporal dimensions with corresponding video features. The captured region responses are organized into action tracklets, which characterize region-based action dynamics by linking related responses across video frames in a coherent sequence. The text-constrained queries encode nuanced semantic representations derived from textual descriptions of action labels extracted by language branches within Visual Language Models (VLMs). To optimize the action tracklets, we design a multi-level tracklet contrastive constraint among region responses at spatial and temporal levels, enabling effective discrimination within each frame and correlation between adjacent frames. Additionally, a task-specific fine-tuning mechanism refines textual semantics such that semantic representations encoded by VLMs are preserved while optimized for task preferences. Comprehensive experiments on widely used action recognition benchmarks demonstrate the superiority to previous state-of-the-art baselines.","authors":["Baoli Sun","Yihan Wang","Xinzhu Ma","Zhihui Wang","Kun Lu","Zhiyong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.09919v2","updated":"2025-11-26T09:30:38Z","published":"2025-06-11T16:39:23Z","title":"MetricHMSR:Metric Human Mesh and Scene Recovery from Monocular Images","summary":"We introduce MetricHMSR (Metric Human Mesh and Scene Recovery), a novel approach for metric human mesh and scene recovery from monocular images. Due to unrealistic assumptions in the camera model and inherent challenges in metric perception, existing approaches struggle to achieve human pose and metric 3D position estimation through a unified module. To address this limitation, MetricHMSR incorporates camera rays to comprehensively encode both the bounding box information and the intrinsic parameters of perspective projection. Then we proposed Human Mixture-of-Experts (MoE), the model dynamically routes image features and ray features to task-specific experts for specialized understanding of different data aspects, enabling a unified framework that simultaneously perceives the local pose and the global 3D position. Based on the results above, we further refine the existing monocular metric depth estimation method to achieve more accurate results, ultimately enabling the seamless overlay of humans and scenes in 3D space. Comprehensive experimental results demonstrate that the proposed method achieves state-of-the-art performance on both human mesh and scene recovery.","authors":["Chentao Song","He Zhang","Haolei Yuan","Haozhe Lin","Jianhua Tao","Hongwen Zhang","Tao Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21194v1","updated":"2025-11-26T09:19:06Z","published":"2025-11-26T09:19:06Z","title":"BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data","summary":"Foundation models have demonstrated a remarkable ability to learn rich, transferable representations across diverse modalities such as images, text, and audio. In modern machine learning pipelines, these representations often replace raw data as the primary input for downstream tasks. In this paper, we address the challenge of adapting a pre-trained foundation model to inject domain-specific knowledge, without retraining from scratch or incurring significant computational costs. To this end, we introduce BotaCLIP, a lightweight multimodal contrastive framework that adapts a pre-trained Earth Observation foundation model (DOFA) by aligning high-resolution aerial imagery with botanical relevés. Unlike generic embeddings, BotaCLIP internalizes ecological structure through contrastive learning with a regularization strategy that mitigates catastrophic forgetting. Once trained, the resulting embeddings serve as transferable representations for downstream predictors. Motivated by real-world applications in biodiversity modeling, we evaluated BotaCLIP representations in three ecological tasks: plant presence prediction, butterfly occurrence modeling, and soil trophic group abundance estimation. The results showed consistent improvements over those derived from DOFA and supervised baselines. More broadly, this work illustrates how domain-aware adaptation of foundation models can inject expert knowledge into data-scarce settings, enabling frugal representation learning.","authors":["Selene Cerna","Sara Si-Moussi","Wilfried Thuiller","Hadrien Hendrikx","Vincent Miele"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21193v1","updated":"2025-11-26T09:16:36Z","published":"2025-11-26T09:16:36Z","title":"You Can Trust Your Clustering Model: A Parameter-free Self-Boosting Plug-in for Deep Clustering","summary":"Recent deep clustering models have produced impressive clustering performance. However, a common issue with existing methods is the disparity between global and local feature structures. While local structures typically show strong consistency and compactness within class samples, global features often present intertwined boundaries and poorly separated clusters. Motivated by this observation, we propose DCBoost, a parameter-free plug-in designed to enhance the global feature structures of current deep clustering models. By harnessing reliable local structural cues, our method aims to elevate clustering performance effectively. Specifically, we first identify high-confidence samples through adaptive $k$-nearest neighbors-based consistency filtering, aiming to select a sufficient number of samples with high label reliability to serve as trustworthy anchors for self-supervision. Subsequently, these samples are utilized to compute a discriminative loss, which promotes both intra-class compactness and inter-class separability, to guide network optimization. Extensive experiments across various benchmark datasets showcase that our DCBoost significantly improves the clustering performance of diverse existing deep clustering models. Notably, our method improves the performance of current state-of-the-art baselines (e.g., ProPos) by more than 3% and amplifies the silhouette coefficient by over $7\\times$. Code is available at <https://github.com/l-h-y168/DCBoost>.","authors":["Hanyang Li","Yuheng Jia","Hui Liu","Junhui Hou"],"pdf_url":"","comment":"The paper is accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21192v1","updated":"2025-11-26T09:16:32Z","published":"2025-11-26T09:16:32Z","title":"When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models","summary":"Vision-Language-Action (VLA) models are vulnerable to adversarial attacks, yet universal and transferable attacks remain underexplored, as most existing patches overfit to a single model and fail in black-box settings. To address this gap, we present a systematic study of universal, transferable adversarial patches against VLA-driven robots under unknown architectures, finetuned variants, and sim-to-real shifts. We introduce UPA-RFAS (Universal Patch Attack via Robust Feature, Attention, and Semantics), a unified framework that learns a single physical patch in a shared feature space while promoting cross-model transfer. UPA-RFAS combines (i) a feature-space objective with an $\\ell_1$ deviation prior and repulsive InfoNCE loss to induce transferable representation shifts, (ii) a robustness-augmented two-phase min-max procedure where an inner loop learns invisible sample-wise perturbations and an outer loop optimizes the universal patch against this hardened neighborhood, and (iii) two VLA-specific losses: Patch Attention Dominance to hijack text$\\to$vision attention and Patch Semantic Misalignment to induce image-text mismatch without labels. Experiments across diverse VLA models, manipulation suites, and physical executions show that UPA-RFAS consistently transfers across models, tasks, and viewpoints, exposing a practical patch-based attack surface and establishing a strong baseline for future defenses.","authors":["Hui Lu","Yi Yu","Yiming Yang","Chenyu Yi","Qixin Zhang","Bingquan Shen","Alex C. Kot","Xudong Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21191v1","updated":"2025-11-26T09:12:17Z","published":"2025-11-26T09:12:17Z","title":"Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding","summary":"Recent advances in 3D vision-language models (VLMs) highlight a strong potential for 3D scene understanding and reasoning. However, effectively tokenizing 3D scenes into holistic scene tokens, and leveraging these tokens across diverse 3D understanding tasks, remain highly challenging. We present NDTokenizer3D, a generalist 3D VLM that performs a wide range of 3D scene understanding tasks while naturally supporting human interactions, thereby bridging language-level reasoning with 3D spatial understanding. The core of our approach is a novel three-stage scene tokenization pipeline built upon a Multi-Scale Normal Distributions Transform (NDT) representation, paired with a Multi-Scale NDT Decoder (MSDec). Specifically, NDTokenizer3D first constructs a multi-scale NDT representation from raw high-resolution point clouds, preserving both global context and fine-grained geometric details. Next, the MSDec progressively fuses cross-scale NDT features, producing holistic scene tokens consumable by LLM endpoints. Beyond tokenization, MSDec is repurposed as a general interface for human-interactive prompting (points, boxes, masks) and segmentation-mask decoding, unifying diverse 3D scene understanding tasks within a single architecture. With this compact and unified design, NDTokenizer3D offers a fine-grained, general-purpose 3D VLM, achieving remarkable improvements in 3D Referring Segmentation, 3D Visual Question Answering, and 3D Dense Captioning.","authors":["Yutao Tang","Cheng Zhao","Gaurav Mittal","Rohith Kukkala","Rama Chellappa","Cheng Peng","Mei Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21188v1","updated":"2025-11-26T09:11:22Z","published":"2025-11-26T09:11:22Z","title":"AnchorOPT: Towards Optimizing Dynamic Anchors for Adaptive Prompt Learning","summary":"Existing prompt learning methods, which are built upon CLIP models, leverage textual tokens as anchors to guide the learnable soft tokens. This guidance improves CLIP generalizations. However, these anchors-static in both value and position-lack cross-task and stage-adaptive flexibility. To address this limitation, we propose AnchorOPT, a dynamic anchor-based prompt learning framework. Specifically, AnchorOPT introduces dynamism in two key dimensions: (i) anchor values eschew handcrafted explicit textual tokens (e.g., \"shape\", \"color\"), instead learning dynamically from task-specific data; and (ii) the positional relationship between anchor and soft tokens is no longer fixed but adaptively optimized via a learnable position matrix conditioned on the training stage and task context. Training occurs in two stages: we first learn the anchor tokens, then freeze and transfer them to the second stage for optimization of soft tokens and the position matrix. Extensive experiments demonstrate that using only a simple learnable anchor and position matrix achieves performance comparable to or exceeding some methods incorporating additional learnable modules or regularization techniques. As a plug-and-play module, AnchorOPT integrates seamlessly into existing frameworks, yielding consistent performance gains across diverse datasets. Code is publicly available at https://github.com/zhengli97/ATPrompt.","authors":["Zheng Li","Yibing Song","Xin Zhang","Lei Luo","Xiang Li","Jian Yang"],"pdf_url":"","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2511.20152v2","updated":"2025-11-26T09:04:52Z","published":"2025-11-25T10:22:26Z","title":"Restora-Flow: Mask-Guided Image Restoration with Flow Matching","summary":"Flow matching has emerged as a promising generative approach that addresses the lengthy sampling times associated with state-of-the-art diffusion models and enables a more flexible trajectory design, while maintaining high-quality image generation. This capability makes it suitable as a generative prior for image restoration tasks. Although current methods leveraging flow models have shown promising results in restoration, some still suffer from long processing times or produce over-smoothed results. To address these challenges, we introduce Restora-Flow, a training-free method that guides flow matching sampling by a degradation mask and incorporates a trajectory correction mechanism to enforce consistency with degraded inputs. We evaluate our approach on both natural and medical datasets across several image restoration tasks involving a mask-based degradation, i.e., inpainting, super-resolution and denoising. We show superior perceptual quality and processing time compared to diffusion and flow matching-based reference methods.","authors":["Arnela Hadzic","Franz Thaler","Lea Bogensperger","Simon Johannes Joham","Martin Urschler"],"pdf_url":"","comment":"Accepted for WACV 2026"},{"id":"http://arxiv.org/abs/2511.13802v2","updated":"2025-11-26T09:04:03Z","published":"2025-11-17T11:14:30Z","title":"Passive Dementia Screening via Facial Temporal Micro-Dynamics Analysis of In-the-Wild Talking-Head Video","summary":"We target passive dementia screening from short camera-facing talking head video, developing a facial temporal micro dynamics analysis for language free detection of early neuro cognitive change. This enables unscripted, in the wild video analysis at scale to capture natural facial behaviors, transferrable across devices, topics, and cultures without active intervention by clinicians or researchers during recording. Most existing resources prioritize speech or scripted interviews, limiting use outside clinics and coupling predictions to language and transcription. In contrast, we identify and analyze whether temporal facial kinematics, including blink dynamics, small mouth jaw motions, gaze variability, and subtle head adjustments, are sufficient for dementia screening without speech or text. By stabilizing facial signals, we convert these micro movements into interpretable facial microdynamic time series, smooth them, and summarize short windows into compact clip level statistics for screening. Each window is encoded by its activity mix (the relative share of motion across streams), thus the predictor analyzes the distribution of motion across streams rather than its magnitude, making per channel effects transparent. We also introduce YT DemTalk, a new dataset curated from publicly available, in the wild camera facing videos. It contains 300 clips (150 with self reported dementia, 150 controls) to test our model and offer a first benchmarking of the corpus. On YT DemTalk, ablations identify gaze lability and mouth/jaw dynamics as the most informative cues, and light weighted shallow classifiers could attain a dementia prediction performance of (AUROC) 0.953, 0.961 Average Precision (AP), 0.851 F1-score, and 0.857 accuracy.","authors":["Filippo Cenacchi","Longbing Cao","Mitchell McEwan","Deborah Richards"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21185v1","updated":"2025-11-26T09:01:13Z","published":"2025-11-26T09:01:13Z","title":"Progress by Pieces: Test-Time Scaling for Autoregressive Image Generation","summary":"Recent visual autoregressive (AR) models have shown promising capabilities in text-to-image generation, operating in a manner similar to large language models. While test-time computation scaling has brought remarkable success in enabling reasoning-enhanced outputs for challenging natural language tasks, its adaptation to visual AR models remains unexplored and poses unique challenges. Naively applying test-time scaling strategies such as Best-of-N can be suboptimal: they consume full-length computation on erroneous generation trajectories, while the raster-scan decoding scheme lacks a blueprint of the entire canvas, limiting scaling benefits as only a few prompt-aligned candidates are generated. To address these, we introduce GridAR, a test-time scaling framework designed to elicit the best possible results from visual AR models. GridAR employs a grid-partitioned progressive generation scheme in which multiple partial candidates for the same position are generated within a canvas, infeasible ones are pruned early, and viable ones are fixed as anchors to guide subsequent decoding. Coupled with this, we present a layout-specified prompt reformulation strategy that inspects partial views to infer a feasible layout for satisfying the prompt. The reformulated prompt then guides subsequent image generation to mitigate the blueprint deficiency. Together, GridAR achieves higher-quality results under limited test-time scaling: with N=4, it even outperforms Best-of-N (N=8) by 14.4% on T2I-CompBench++ while reducing cost by 25.6%. It also generalizes to autoregressive image editing, showing comparable edit quality and a 13.9% gain in semantic preservation on PIE-Bench over larger-N baselines.","authors":["Joonhyung Park","Hyeongwon Jang","Joowon Kim","Eunho Yang"],"pdf_url":"","comment":"Project page: https://grid-ar.github.io/"},{"id":"http://arxiv.org/abs/2511.02607v2","updated":"2025-11-26T08:26:24Z","published":"2025-11-04T14:31:06Z","title":"UniChange: Unifying Change Detection with Multimodal Large Language Model","summary":"Change detection (CD) is a fundamental task for monitoring and analyzing land cover dynamics. While recent high performance models and high quality datasets have significantly advanced the field, a critical limitation persists. Current models typically acquire limited knowledge from single-type annotated data and cannot concurrently leverage diverse binary change detection (BCD) and semantic change detection (SCD) datasets. This constraint leads to poor generalization and limited versatility. The recent advancements in Multimodal Large Language Models (MLLMs) introduce new possibilities for a unified CD framework. We leverage the language priors and unification capabilities of MLLMs to develop UniChange, the first MLLM-based unified change detection model. UniChange integrates generative language abilities with specialized CD functionalities. Our model successfully unifies both BCD and SCD tasks through the introduction of three special tokens: [T1], [T2], and [CHANGE]. Furthermore, UniChange utilizes text prompts to guide the identification of change categories, eliminating the reliance on predefined classification heads. This design allows UniChange to effectively acquire knowledge from multi-source datasets, even when their class definitions conflict. Experiments on four public benchmarks (WHU-CD, S2Looking, LEVIR-CD+, and SECOND) demonstrate SOTA performance, achieving IoU scores of 90.41, 53.04, 78.87, and 57.62, respectively, surpassing all previous methods. The code is available at https://github.com/Erxucomeon/UniChange.","authors":["Xu Zhang","Danyang Li","Xiaohang Dong","Tianhao Wu","Hualong Yu","Jianye Wang","Qicheng Li","Xiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19111v2","updated":"2025-11-26T08:16:05Z","published":"2025-11-24T13:43:54Z","title":"DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection","summary":"Diffusion-based editing enables realistic modification of local image regions, making AI-generated content harder to detect. Existing AIGC detection benchmarks focus on classifying entire images, overlooking the localization of diffusion-based edits. We introduce DiffSeg30k, a publicly available dataset of 30k diffusion-edited images with pixel-level annotations, designed to support fine-grained detection. DiffSeg30k features: 1) In-the-wild images--we collect images or image prompts from COCO to reflect real-world content diversity; 2) Diverse diffusion models--local edits using eight SOTA diffusion models; 3) Multi-turn editing--each image undergoes up to three sequential edits to mimic real-world sequential editing; and 4) Realistic editing scenarios--a vision-language model (VLM)-based pipeline automatically identifies meaningful regions and generates context-aware prompts covering additions, removals, and attribute changes. DiffSeg30k shifts AIGC detection from binary classification to semantic segmentation, enabling simultaneous localization of edits and identification of the editing models. We benchmark three baseline segmentation approaches, revealing significant challenges in semantic segmentation tasks, particularly concerning robustness to image distortions. Experiments also reveal that segmentation models, despite being trained for pixel-level localization, emerge as highly reliable whole-image classifiers of diffusion edits, outperforming established forgery classifiers while showing great potential in cross-generator generalization. We believe DiffSeg30k will advance research in fine-grained localization of AI-generated content by demonstrating the promise and limitations of segmentation-based methods. DiffSeg30k is released at: https://huggingface.co/datasets/Chaos2629/Diffseg30k","authors":["Hai Ci","Ziheng Peng","Pei Yang","Yingxin Xuan","Mike Zheng Shou"],"pdf_url":"","comment":"16 pages, 10 figures; typos corrected, references added"},{"id":"http://arxiv.org/abs/2511.21150v1","updated":"2025-11-26T08:11:10Z","published":"2025-11-26T08:11:10Z","title":"LLaVA-UHD v3: Progressive Visual Compression for Efficient Native-Resolution Encoding in MLLMs","summary":"Visual encoding followed by token condensing has become the standard architectural paradigm in multi-modal large language models (MLLMs). Many recent MLLMs increasingly favor global native- resolution visual encoding over slice-based methods. To investigate this trend, we systematically compare their behavior on vision-language understanding and attention patterns, revealing that global encoding enhances overall capability but at the expense of greater computational overhead. To address this issue, we present LLaVA-UHD v3, an MLLM centered upon our proposed Progressive Visual Compression (PVC) method, which can be seamlessly integrated into standard Vision Transformer (ViT) to enable efficient native-resolution encoding. The PVC approach consists of two key modules: (i) refined patch embedding, which supports flexible patch-size scaling for fine-grained visual model- ing, (ii) windowed token compression, hierarchically deployed across ViT layers to progressively aggregate local token representations. Jointly modulated by these two modules, a widely pretrained ViT can be reconfigured into an efficient architecture while largely preserving generality. Evaluated across extensive benchmarks, the transformed ViT, termed ViT-UHD, demonstrates competitive performance with MoonViT while reducing TTFT (time-to-first-token) by 2.4x, when developed within an identical MLLM architecture. Building upon ViT-UHD, LLaVA-UHD v3 also achieves competitive performance to Qwen2-VL, while further reducing TTFT by 1.9x. We will release all code and checkpoints to support future research on efficient MLLMs.","authors":["Shichu Sun","Yichen Zhang","Haolin Song","Zonghao Guo","Chi Chen","Yidan Zhang","Yuan Yao","Zhiyuan Liu","Maosong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.00525v3","updated":"2025-11-26T08:06:04Z","published":"2024-12-31T16:20:05Z","title":"Systematic Evaluation and Guidelines for Segment Anything Model in Surgical Video Analysis","summary":"Surgical video segmentation is critical for AI to interpret spatial-temporal dynamics in surgery, yet model performance is constrained by limited annotated data. The SAM2 model, pretrained on natural videos, offers potential for zero-shot surgical segmentation, but its applicability in complex surgical environments, with challenges like tissue deformation and instrument variability, remains unexplored. We present the first comprehensive evaluation of the zero-shot capability of SAM2 in 9 surgical datasets (17 surgery types), covering laparoscopic, endoscopic, and robotic procedures. We analyze various prompting (points, boxes, mask) and {finetuning (dense, sparse) strategies}, robustness to surgical challenges, and generalization across procedures and anatomies. Key findings reveal that while SAM2 demonstrates notable zero-shot adaptability in structured scenarios (e.g., instrument segmentation, {multi-organ segmentation}, and scene segmentation), its performance varies under dynamic surgical conditions, highlighting gaps in handling temporal coherence and domain-specific artifacts. These results highlight future pathways to adaptive data-efficient solutions for the surgical data science field.","authors":["Cheng Yuan","Jian Jiang","Kunyi Yang","Lv Wu","Rui Wang","Zi Meng","Haonan Ping","Ziyu Xu","Yifan Zhou","Wanli Song","Hesheng Wang","Yueming Jin","Qi Dou","Yutong Ban"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21146v1","updated":"2025-11-26T07:59:53Z","published":"2025-11-26T07:59:53Z","title":"AV-Edit: Multimodal Generative Sound Effect Editing via Audio-Visual Semantic Joint Control","summary":"Sound effect editing-modifying audio by adding, removing, or replacing elements-remains constrained by existing approaches that rely solely on low-level signal processing or coarse text prompts, often resulting in limited flexibility and suboptimal audio quality. To address this, we propose AV-Edit, a generative sound effect editing framework that enables fine-grained editing of existing audio tracks in videos by jointly leveraging visual, audio, and text semantics. Specifically, the proposed method employs a specially designed contrastive audio-visual masking autoencoder (CAV-MAE-Edit) for multimodal pre-training, learning aligned cross-modal representations. These representations are then used to train an editorial Multimodal Diffusion Transformer (MM-DiT) capable of removing visually irrelevant sounds and generating missing audio elements consistent with video content through a correlation-based feature gating training strategy. Furthermore, we construct a dedicated video-based sound editing dataset as an evaluation benchmark. Experiments demonstrate that the proposed AV-Edit generates high-quality audio with precise modifications based on visual content, achieving state-of-the-art performance in the field of sound effect editing and exhibiting strong competitiveness in the domain of audio generation.","authors":["Xinyue Guo","Xiaoran Yang","Lipan Zhang","Jianxuan Yang","Zhao Wang","Jian Luan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21145v1","updated":"2025-11-26T07:58:42Z","published":"2025-11-26T07:58:42Z","title":"TEAR: Temporal-aware Automated Red-teaming for Text-to-Video Models","summary":"Text-to-Video (T2V) models are capable of synthesizing high-quality, temporally coherent dynamic video content, but the diverse generation also inherently introduces critical safety challenges. Existing safety evaluation methods,which focus on static image and text generation, are insufficient to capture the complex temporal dynamics in video generation. To address this, we propose a TEmporal-aware Automated Red-teaming framework, named TEAR, an automated framework designed to uncover safety risks specifically linked to the dynamic temporal sequencing of T2V models. TEAR employs a temporal-aware test generator optimized via a two-stage approach: initial generator training and temporal-aware online preference learning, to craft textually innocuous prompts that exploit temporal dynamics to elicit policy-violating video output. And a refine model is adopted to improve the prompt stealthiness and adversarial effectiveness cyclically. Extensive experimental evaluation demonstrates the effectiveness of TEAR across open-source and commercial T2V systems with over 80% attack success rate, a significant boost from prior best result of 57%.","authors":["Jiaming He","Guanyu Hou","Hongwei Li","Zhicong Huang","Kangjie Chen","Yi Yu","Wenbo Jiang","Guowen Xu","Tianwei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.07856v2","updated":"2025-11-26T07:55:46Z","published":"2025-10-09T06:58:03Z","title":"XYZCylinder: Towards Compatible Feed-Forward 3D Gaussian Splatting for Driving Scenes via Unified Cylinder Lifting Method","summary":"Feed-forward paradigms for 3D reconstruction have become a focus of recent research, which learn implicit, fixed view transformations to generate a single scene representation. However, their application to complex driving scenes reveals significant limitations. Two core challenges are responsible for this performance gap. First, the reliance on a fixed view transformation hinders compatibility to varying camera configurations. Second, the inherent difficulty of learning complex driving scenes from sparse 360° views with minimal overlap compromises the final reconstruction fidelity. To handle these difficulties, we introduce XYZCylinder, a novel method built upon a unified cylinder lifting method that integrates camera modeling and feature lifting. To tackle the compatibility problem, we design a Unified Cylinder Camera Modeling (UCCM) strategy. This strategy explicitly models projection parameters to unify diverse camera setups, thus bypassing the need for learning viewpoint-dependent correspondences. To improve the reconstruction accuracy, we propose a hybrid representation with several dedicated modules based on newly designed Cylinder Plane Feature Group (CPFG) to lift 2D image features to 3D space. Extensive evaluations confirm that XYZCylinder not only achieves state-of-the-art performance under different evaluation settings but also demonstrates remarkable compatibility in entirely new scenes with different camera settings in a zero-shot manner. Project page: \\href{https://yuyuyu223.github.io/XYZCYlinder-projectpage/}{here}","authors":["Haochen Yu","Qiankun Liu","Hongyuan Liu","Jianfei Jiang","Juntao Lyu","Jiansheng Chen","Huimin Ma"],"pdf_url":"","comment":"Feed-Forward, 3D Gaussian Splatting, Project page: https://yuyuyu223.github.io/XYZCYlinder-projectpage/"},{"id":"http://arxiv.org/abs/2511.21143v1","updated":"2025-11-26T07:53:09Z","published":"2025-11-26T07:53:09Z","title":"STAR: Smartphone-analogous Typing in Augmented Reality","summary":"While text entry is an essential and frequent task in Augmented Reality (AR) applications, devising an efficient and easy-to-use text entry method for AR remains an open challenge. This research presents STAR, a smartphone-analogous AR text entry technique that leverages a user's familiarity with smartphone two-thumb typing. With STAR, a user performs thumb typing on a virtual QWERTY keyboard that is overlain on the skin of their hands. During an evaluation study of STAR, participants achieved a mean typing speed of 21.9 WPM (i.e., 56% of their smartphone typing speed), and a mean error rate of 0.3% after 30 minutes of practice. We further analyze the major factors implicated in the performance gap between STAR and smartphone typing, and discuss ways this gap could be narrowed.","authors":["Taejun Kim","Amy Karlson","Aakar Gupta","Tovi Grossman","Jason Wu","Parastoo Abtahi","Christopher Collins","Michael Glueck","Hemant Bhaskar Surale"],"pdf_url":"","comment":"ACM UIST 2023"},{"id":"http://arxiv.org/abs/2511.21139v1","updated":"2025-11-26T07:45:41Z","published":"2025-11-26T07:45:41Z","title":"Referring Video Object Segmentation with Cross-Modality Proxy Queries","summary":"Referring video object segmentation (RVOS) is an emerging cross-modality task that aims to generate pixel-level maps of the target objects referred by given textual expressions. The main concept involves learning an accurate alignment of visual elements and language expressions within a semantic space. Recent approaches address cross-modality alignment through conditional queries, tracking the target object using a query-response based mechanism built upon transformer structure. However, they exhibit two limitations: (1) these conditional queries lack inter-frame dependency and variation modeling, making accurate target tracking challenging amid significant frame-to-frame variations; and (2) they integrate textual constraints belatedly, which may cause the video features potentially focus on the non-referred objects. Therefore, we propose a novel RVOS architecture called ProxyFormer, which introduces a set of proxy queries to integrate visual and text semantics and facilitate the flow of semantics between them. By progressively updating and propagating proxy queries across multiple stages of video feature encoder, ProxyFormer ensures that the video features are focused on the object of interest. This dynamic evolution also enables the establishment of inter-frame dependencies, enhancing the accuracy and coherence of object tracking. To mitigate high computational costs, we decouple cross-modality interactions into temporal and spatial dimensions. Additionally, we design a Joint Semantic Consistency (JSC) training strategy to align semantic consensus between the proxy queries and the combined video-text pairs. Comprehensive experiments on four widely used RVOS benchmarks demonstrate the superiority of our ProxyFormer to the state-of-the-art methods.","authors":["Baoli Sun","Xinzhu Ma","Ning Wang","Zhihui Wang","Zhiyong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21136v1","updated":"2025-11-26T07:36:37Z","published":"2025-11-26T07:36:37Z","title":"Efficient Training for Human Video Generation with Entropy-Guided Prioritized Progressive Learning","summary":"Human video generation has advanced rapidly with the development of diffusion models, but the high computational cost and substantial memory consumption associated with training these models on high-resolution, multi-frame data pose significant challenges. In this paper, we propose Entropy-Guided Prioritized Progressive Learning (Ent-Prog), an efficient training framework tailored for diffusion models on human video generation. First, we introduce Conditional Entropy Inflation (CEI) to assess the importance of different model components on the target conditional generation task, enabling prioritized training of the most critical components. Second, we introduce an adaptive progressive schedule that adaptively increases computational complexity during training by measuring the convergence efficiency. Ent-Prog reduces both training time and GPU memory consumption while maintaining model performance. Extensive experiments across three datasets, demonstrate the effectiveness of Ent-Prog, achieving up to 2.2$\\times$ training speedup and 2.4$\\times$ GPU memory reduction without compromising generative performance.","authors":["Changlin Li","Jiawei Zhang","Shuhao Liu","Sihao Lin","Zeyi Shi","Zhihui Li","Xiaojun Chang"],"pdf_url":"","comment":"Project page: https://github.com/changlin31/Ent-Prog"},{"id":"http://arxiv.org/abs/2508.17247v2","updated":"2025-11-26T07:36:32Z","published":"2025-08-24T07:57:32Z","title":"Uncovering and Mitigating Destructive Multi-Embedding Attacks in Deepfake Proactive Forensics","summary":"With the rapid evolution of deepfake technologies and the wide dissemination of digital media, personal privacy is facing increasingly serious security threats. Deepfake proactive forensics, which involves embedding imperceptible watermarks to enable reliable source tracking, serves as a crucial defense against these threats. Although existing methods show strong forensic ability, they rely on an idealized assumption of single watermark embedding, which proves impractical in real-world scenarios. In this paper, we formally define and demonstrate the existence of Multi-Embedding Attacks (MEA) for the first time. When a previously protected image undergoes additional rounds of watermark embedding, the original forensic watermark can be destroyed or removed, rendering the entire proactive forensic mechanism ineffective. To address this vulnerability, we propose a general training paradigm named Adversarial Interference Simulation (AIS). Rather than modifying the network architecture, AIS explicitly simulates MEA scenarios during fine-tuning and introduces a resilience-driven loss function to enforce the learning of sparse and stable watermark representations. Our method enables the model to maintain the ability to extract the original watermark correctly even after a second embedding. Extensive experiments demonstrate that our plug-and-play AIS training paradigm significantly enhances the robustness of various existing methods against MEA.","authors":["Lixin Jia","Haiyang Sun","Zhiqing Guo","Yunfeng Diao","Dan Ma","Gaobo Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21135v1","updated":"2025-11-26T07:36:01Z","published":"2025-11-26T07:36:01Z","title":"SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation","summary":"Embodied navigation that adheres to social norms remains an open research challenge. Our \\textbf{SocialNav} is a foundational model for socially-aware navigation with a hierarchical \"brain-action\" architecture, capable of understanding high-level social norms and generating low-level, socially compliant trajectories. To enable such dual capabilities, we construct the SocNav Dataset, a large-scale collection of 7 million samples, comprising (1) a Cognitive Activation Dataset providing social reasoning signals such as chain-of-thought explanations and social traversability prediction, and (2) an Expert Trajectories Pyramid aggregating diverse navigation demonstrations from internet videos, simulated environments, and real-world robots. A multi-stage training pipeline is proposed to gradually inject and refine navigation intelligence: we first inject general navigation skills and social norms understanding into the model via imitation learning, and then refine such skills through a deliberately designed Socially-Aware Flow Exploration GRPO (SAFE-GRPO), the first flow-based reinforcement learning framework for embodied navigation that explicitly rewards socially compliant behaviors. SocialNav achieves +38% success rate and +46% social compliance rate compared to the state-of-the-art method, demonstrating strong gains in both navigation performance and social compliance. Our project page: https://amap-eai.github.io/SocialNav/","authors":["Ziyi Chen","Yingnan Guo","Zedong Chu","Minghua Luo","Yanfen Shen","Mingchao Sun","Junjun Hu","Shichao Xie","Kuan Yang","Pei Shi","Zhining Gu","Lu Liu","Honglin Han","Xiaolong Wu","Mu Xu","Yu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21132v1","updated":"2025-11-26T07:30:41Z","published":"2025-11-26T07:30:41Z","title":"DeepRFTv2: Kernel-level Learning for Image Deblurring","summary":"It is well-known that if a network aims to learn how to deblur, it should understand the blur process. Blurring is naturally caused by the convolution of the sharp image with the blur kernel. Thus, allowing the network to learn the blur process in the kernel-level can significantly improve the image deblurring performance. But, current deep networks are still at the pixel-level learning stage, either performing end-to-end pixel-level restoration or stage-wise pseudo kernel-level restoration, failing to enable the deblur model to understand the essence of the blur. To this end, we propose Fourier Kernel Estimator (FKE), which considers the activation operation in Fourier space and converts the convolution problem in the spatial domain to a multiplication problem in Fourier space. Our FKE, jointly optimized with the deblur model, enables the network to learn the kernel-level blur process with low complexity and without any additional supervision. Furthermore, we change the convolution object of the kernel from ``image\" to network extracted ``feature\", whose rich semantic and structural information is more suitable to blur process learning. With the convolution of the feature and the estimated kernel, our model can learn the essence of blur in kernel-level. To further improve the efficiency of feature extraction, we design a decoupled multi-scale architecture with multiple hierarchical sub-unets with a reversible strategy, which allows better multi-scale encoding and decoding in low training memory. Extensive experiments indicate that our method achieves state-of-the-art motion deblurring results and show potential for handling other kernel-related problems. Analysis also shows our kernel estimator is able to learn physically meaningful kernels. The code will be available at https://github.com/DeepMed-Lab-ECNU/Single-Image-Deblur.","authors":["Xintian Mao","Haofei Song","Yin-Nian Liu","Qingli Li","Yan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21129v1","updated":"2025-11-26T07:27:11Z","published":"2025-11-26T07:27:11Z","title":"CtrlVDiff: Controllable Video Generation via Unified Multimodal Video Diffusion","summary":"We tackle the dual challenges of video understanding and controllable video generation within a unified diffusion framework. Our key insights are two-fold: geometry-only cues (e.g., depth, edges) are insufficient: they specify layout but under-constrain appearance, materials, and illumination, limiting physically meaningful edits such as relighting or material swaps and often causing temporal drift. Enriching the model with additional graphics-based modalities (intrinsics and semantics) provides complementary constraints that both disambiguate understanding and enable precise, predictable control during generation.\n  However, building a single model that uses many heterogeneous cues introduces two core difficulties. Architecturally, the model must accept any subset of modalities, remain robust to missing inputs, and inject control signals without sacrificing temporal consistency. Data-wise, training demands large-scale, temporally aligned supervision that ties real videos to per-pixel multimodal annotations.\n  We then propose CtrlVDiff, a unified diffusion model trained with a Hybrid Modality Control Strategy (HMCS) that routes and fuses features from depth, normals, segmentation, edges, and graphics-based intrinsics (albedo, roughness, metallic), and re-renders videos from any chosen subset with strong temporal coherence. To enable this, we build MMVideo, a hybrid real-and-synthetic dataset aligned across modalities and captions. Across understanding and generation benchmarks, CtrlVDiff delivers superior controllability and fidelity, enabling layer-wise edits (relighting, material adjustment, object insertion) and surpassing state-of-the-art baselines while remaining robust when some modalities are unavailable.","authors":["Dianbing Xi","Jiepeng Wang","Yuanzhi Liang","Xi Qiu","Jialun Liu","Hao Pan","Yuchi Huo","Rui Wang","Haibin Huang","Chi Zhang","Xuelong Li"],"pdf_url":"","comment":"27 pages, 18 figures, 9 tables. Project page: https://tele-ai.github.io/CtrlVDiff/"},{"id":"http://arxiv.org/abs/2511.21122v1","updated":"2025-11-26T07:20:48Z","published":"2025-11-26T07:20:48Z","title":"Which Layer Causes Distribution Deviation? Entropy-Guided Adaptive Pruning for Diffusion and Flow Models","summary":"Large-scale vision generative models, including diffusion and flow models, have demonstrated remarkable performance in visual generation tasks. However, transferring these pre-trained models to downstream tasks often results in significant parameter redundancy. In this paper, we propose EntPruner, an entropy-guided automatic progressive pruning framework for diffusion and flow models. First, we introduce entropy-guided pruning, a block-level importance assessment strategy specifically designed for generative models. Unlike discriminative models, generative models require preserving the diversity and condition-fidelity of the output distribution. As the importance of each module can vary significantly across downstream tasks, EntPruner prioritizes pruning of less important blocks using data-dependent Conditional Entropy Deviation (CED) as a guiding metric. CED quantifies how much the distribution diverges from the learned conditional data distribution after removing a block. Second, we propose a zero-shot adaptive pruning framework to automatically determine when and how much to prune during training. This dynamic strategy avoids the pitfalls of one-shot pruning, mitigating mode collapse, and preserving model performance. Extensive experiments on DiT and SiT models demonstrate the effectiveness of EntPruner, achieving up to 2.22$\\times$ inference speedup while maintaining competitive generation quality on ImageNet and three downstream datasets.","authors":["Changlin Li","Jiawei Zhang","Zeyi Shi","Zongxin Yang","Zhihui Li","Xiaojun Chang"],"pdf_url":"","comment":"Project page: https://github.com/changlin31/EntPruner"},{"id":"http://arxiv.org/abs/2509.17429v3","updated":"2025-11-26T07:20:37Z","published":"2025-09-22T07:22:27Z","title":"Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration","summary":"Accurate temporal prediction is the bridge between comprehensive scene understanding and embodied artificial intelligence. However, predicting multiple fine-grained states of a scene at multiple temporal scales is difficult for vision-language models. We formalize the Multi-Scale Temporal Prediction (MSTP) task in general and surgical scenes by decomposing multi-scale into two orthogonal dimensions: the temporal scale, forecasting states of humans and surgery at varying look-ahead intervals, and the state scale, modeling a hierarchy of states in general and surgical scenes. For example, in general scenes, states of contact relationships are finer-grained than states of spatial relationships. In surgical scenes, medium-level steps are finer-grained than high-level phases yet remain constrained by their encompassing phase. To support this unified task, we introduce the first MSTP Benchmark, featuring synchronized annotations across multiple state scales and temporal scales. We further propose a method, Incremental Generation and Multi-agent Collaboration (IG-MC), which integrates two key innovations. First, we present a plug-and-play incremental generation module that continuously synthesizes up-to-date visual previews at expanding temporal scales to inform multiple decision-making agents, keeping decisions and generated visuals synchronized and preventing performance degradation as look-ahead intervals lengthen. Second, we present a decision-driven multi-agent collaboration framework for multi-state prediction, comprising generation, initiation, and multi-state assessment agents that dynamically trigger and evaluate prediction cycles to balance global coherence and local fidelity.","authors":["Zhitao Zeng","Guojian Yuan","Junyuan Mao","Yuxuan Wang","Xiaoshuang Jia","Yueming Jin"],"pdf_url":"","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2505.10855v2","updated":"2025-11-26T07:20:09Z","published":"2025-05-16T04:48:33Z","title":"Generalizable cardiac substructures segmentation from contrast and non-contrast CTs using pretrained transformers","summary":"Automated AI segmentations for radiation treatment planning deteriorate when applied to cases with different characteristics than the training dataset. We developed a hybrid transformer convolutional network to segment cardiac substructures in lung and breast cancer patients with varying imaging contrasts and scan positions. Cohort I (56 contrast-enhanced CT [CECT], 124 non-contrast CT [NCCT] scans from lung cancer patients, supine position) was used to train an oracle model (180 cases), contrast-only model (56 CECTs), and balanced model (32 CECT, 32 NCCT). All models were evaluated on 60 held-out cohort I patients and 66 cohort II breast cancer patients (45 supine, 21 prone). Accuracy was measured using Dice similarity coefficient (DSC), 95th percentile Hausdorff distance (HD95), and dosimetric metrics, with TotalSegmentator as benchmark. Oracle and balanced models achieved similar accuracy (DSC: Oracle vs Balanced: Cohort I: 0.84 $\\pm$ 0.10 vs 0.82 $\\pm$ 0.10; Cohort II: 0.81 $\\pm$ 0.12 vs 0.80 $\\pm$ 0.13), both outperforming TotalSegmentator and the contrast-only models. The balanced model, using 64% fewer training cases, produced dosimetrically equivalent contours to manual delineations. It was robust to contrast variations (6 out of 8 substructures) and positioning variations (5 out of 8 substructures), with low correlation to patient age or body mass index. Our balanced model demonstrated robust geometric and dosimetric accuracy across varying imaging protocols and patient characteristics, which is essential for clinical deployment. Combining pretraining with balanced NCCT/CECT distribution enabled reliable segmentation with substantially fewer labeled cases than conventional approaches.","authors":["Aneesh Rangnekar","Nikhil Mankuzhy","Jonas Willmann","Chloe Choi","Abraham Wu","Maria Thor","Andreas Rimner","Harini Veeraraghavan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21114v1","updated":"2025-11-26T06:59:17Z","published":"2025-11-26T06:59:17Z","title":"Deformation-aware Temporal Generation for Early Prediction of Alzheimers Disease","summary":"Alzheimer's disease (AD), a degenerative brain condition, can benefit from early prediction to slow its progression. As the disease progresses, patients typically undergo brain atrophy. Current prediction methods for Alzheimers disease largely involve analyzing morphological changes in brain images through manual feature extraction. This paper proposes a novel method, the Deformation-Aware Temporal Generative Network (DATGN), to automate the learning of morphological changes in brain images about disease progression for early prediction. Given the common occurrence of missing data in the temporal sequences of MRI images, DATGN initially interpolates incomplete sequences. Subsequently, a bidirectional temporal deformation-aware module guides the network in generating future MRI images that adhere to the disease's progression, facilitating early prediction of Alzheimer's disease. DATGN was tested for the generation of temporal sequences of future MRI images using the ADNI dataset, and the experimental results are competitive in terms of PSNR and MMSE image quality metrics. Furthermore, when DATGN-generated synthetic data was integrated into the SVM vs. CNN vs. 3DCNN-based classification methods, significant improvements were achieved from 6. 21\\% to 16\\% in AD vs. NC classification accuracy and from 7. 34\\% to 21. 25\\% in AD vs. MCI vs. NC classification accuracy. The qualitative visualization results indicate that DATGN produces MRI images consistent with the brain atrophy trend in Alzheimer's disease, enabling early disease prediction.","authors":["Xin Honga","Jie Lin","Minghui Wang"],"pdf_url":"","comment":"29 pages,6figures,one column"},{"id":"http://arxiv.org/abs/2511.21113v1","updated":"2025-11-26T06:58:57Z","published":"2025-11-26T06:58:57Z","title":"FaithFusion: Harmonizing Reconstruction and Generation via Pixel-wise Information Gain","summary":"In controllable driving-scene reconstruction and 3D scene generation, maintaining geometric fidelity while synthesizing visually plausible appearance under large viewpoint shifts is crucial. However, effective fusion of geometry-based 3DGS and appearance-driven diffusion models faces inherent challenges, as the absence of pixel-wise, 3D-consistent editing criteria often leads to over-restoration and geometric drift. To address these issues, we introduce \\textbf{FaithFusion}, a 3DGS-diffusion fusion framework driven by pixel-wise Expected Information Gain (EIG). EIG acts as a unified policy for coherent spatio-temporal synthesis: it guides diffusion as a spatial prior to refine high-uncertainty regions, while its pixel-level weighting distills the edits back into 3DGS. The resulting plug-and-play system is free from extra prior conditions and structural modifications.Extensive experiments on the Waymo dataset demonstrate that our approach attains SOTA performance across NTA-IoU, NTL-IoU, and FID, maintaining an FID of 107.47 even at 6 meters lane shift. Our code is available at https://github.com/wangyuanbiubiubiu/FaithFusion.","authors":["YuAn Wang","Xiaofan Li","Chi Huang","Wenhao Zhang","Hao Li","Bosheng Wang","Xun Sun","Jun Wang"],"pdf_url":"","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2502.14914v4","updated":"2025-11-26T06:52:48Z","published":"2025-02-19T07:55:51Z","title":"CAPability: A Comprehensive Visual Caption Benchmark for Evaluating Both Correctness and Thoroughness","summary":"Visual captioning benchmarks have become outdated with the emergence of modern multimodal large language models (MLLMs), as the brief ground-truth sentences and traditional metrics fail to assess detailed captions effectively. While recent benchmarks attempt to address this by focusing on keyword extraction or object-centric evaluation, they remain limited to vague-view or object-view analyses and incomplete visual element coverage. In this paper, we introduce CAPability, a comprehensive multi-view benchmark for evaluating visual captioning across 12 dimensions spanning six critical views. We curate nearly 11K human-annotated images and videos with visual element annotations to evaluate the generated captions. CAPability stably assesses both the correctness and thoroughness of captions with \\textit{precision} and \\textit{hit} metrics. By converting annotations to QA pairs, we further introduce a heuristic metric, \\textit{know but cannot tell} ($K\\bar{T}$), indicating a significant performance gap between QA and caption capabilities. Our work provides a holistic analysis of MLLMs' captioning abilities, as we identify their strengths and weaknesses across various dimensions, guiding future research to enhance specific aspects of their capabilities.","authors":["Zhihang Liu","Chen-Wei Xie","Bin Wen","Feiwu Yu","Jixuan Chen","Pandeng Li","Boqiang Zhang","Nianzu Yang","Yinglu Li","Zuan Gao","Yun Zheng","Hongtao Xie"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2506.03928v2","updated":"2025-11-26T06:47:48Z","published":"2025-06-04T13:22:35Z","title":"Vision Remember: Recovering Visual Information in Efficient LVLM with Vision Feature Resampling","summary":"The computational expense of redundant vision tokens in Large Vision-Language Models (LVLMs) has led many existing methods to compress them via a vision projector. However, this compression may lose visual information that is crucial for tasks relying on fine-grained spatial relationships, such as OCR and Chart&Table Understanding. In this paper, we propose to resample original vision features across the LLM decoder layers to recover visual information and attain efficiency. Following this principle, we introduce Vision Remember, which includes two key modules: (1) Token-Feature Cross-Attention Layer and (2) Token Bidirectional Self-Attention Layer. In the Token bidirectional attention, we employ self-attention mechanism to maintain the bidirectional interaction between vision tokens and the text-guided token. In the Token-Feature interaction attention, we introduce local cross-attention to resample the visual feature and utilize the multi-level fusion to enrich the visual representation. We conduct comprehensive experiments on multiple visual understanding benchmarks and the results with the LLaVA-NeXT baseline show that Vision Remember outperforms TokenPacker by +2.7 and FastV by +5.7 across nearly all the settings. Compared with previous vision feature re-fusion methods, our approach also surpasses DeepStack by +3.9 and SVA Aggregator by +3.4 on the same baseline. The experimental results validate the generalization capability of the proposed method when combined with various efficient vision projectors and LVLMs.","authors":["Ze Feng","Jiang-jiang Liu","Sen Yang","Lingyu Xiao","Zhibin Quan","Zhenhua Feng","Wankou Yang","Jingdong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21106v1","updated":"2025-11-26T06:45:59Z","published":"2025-11-26T06:45:59Z","title":"EM-KD: Distilling Efficient Multimodal Large Language Model with Unbalanced Vision Tokens","summary":"Efficient Multimodal Large Language Models (MLLMs) compress vision tokens to reduce resource consumption, but the loss of visual information can degrade comprehension capabilities. Although some priors introduce Knowledge Distillation to enhance student models, they overlook the fundamental differences in fine-grained vision comprehension caused by unbalanced vision tokens between the efficient student and vanilla teacher. In this paper, we propose EM-KD, a novel paradigm that enhances the Efficient MLLMs with Knowledge Distillation. To overcome the challenge of unbalanced vision tokens, we first calculate the Manhattan distance between the vision logits of teacher and student, and then align them in the spatial dimension with the Hungarian matching algorithm. After alignment, EM-KD introduces two distillation strategies: 1) Vision-Language Affinity Distillation (VLAD) and 2) Vision Semantic Distillation (VSD). Specifically, VLAD calculates the affinity matrix between text tokens and aligned vision tokens, and minimizes the smooth L1 distance of the student and the teacher affinity matrices. Considering the semantic richness of vision logits in the final layer, VSD employs the reverse KL divergence to measure the discrete probability distributions of the aligned vision logits over the vocabulary space. Comprehensive evaluation on diverse benchmarks demonstrates that EM-KD trained model outperforms prior Efficient MLLMs on both accuracy and efficiency with a large margin, validating its effectiveness. Compared with previous distillation methods, which are equipped with our proposed vision token matching strategy for fair comparison, EM-KD also achieves better performance.","authors":["Ze Feng","Sen Yang","Boqiang Duan","Wankou Yang","Jingdong Wang"],"pdf_url":"","comment":"accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2511.20431v2","updated":"2025-11-26T06:45:15Z","published":"2025-11-25T16:03:38Z","title":"BRIC: Bridging Kinematic Plans and Physical Control at Test Time","summary":"We propose BRIC, a novel test-time adaptation (TTA) framework that enables long-term human motion generation by resolving execution discrepancies between diffusion-based kinematic motion planners and reinforcement learning-based physics controllers. While diffusion models can generate diverse and expressive motions conditioned on text and scene context, they often produce physically implausible outputs, leading to execution drift during simulation. To address this, BRIC dynamically adapts the physics controller to noisy motion plans at test time, while preserving pre-trained skills via a loss function that mitigates catastrophic forgetting. In addition, BRIC introduces a lightweight test-time guidance mechanism that steers the diffusion model in the signal space without updating its parameters. By combining both adaptation strategies, BRIC ensures consistent and physically plausible long-term executions across diverse environments in an effective and efficient manner. We validate the effectiveness of BRIC on a variety of long-term tasks, including motion composition, obstacle avoidance, and human-scene interaction, achieving state-of-the-art performance across all tasks.","authors":["Dohun Lim","Minji Kim","Jaewoon Lim","Sungchan Kim"],"pdf_url":"","comment":"Accepted to AAAI'26"},{"id":"http://arxiv.org/abs/2511.21105v1","updated":"2025-11-26T06:41:00Z","published":"2025-11-26T06:41:00Z","title":"Scaling Foundation Models for Radar Scene Understanding","summary":"Radar sensors provide reliable perception across adverse weather, lighting, and long-range conditions. Recent advances in foundation models have transformed visual and language understanding, yet their integration with radar sensing remains largely underexplored. Existing radar approaches are fragmented and task-specific; each downstream task employs distinct architectures and training objectives, preventing transfer across tasks. In this work, we introduce RadarFM: a radar foundation model that learns unified scene-level representations through structured spatial language supervision. We make two key contributions: (1) a structured caption framework that encodes vehicle distributions in native radar coordinates, and (2) a hash-aware contrastive learning objective that quantifies continuous scene similarity rather than binary matching, enabling fine-grained spatial reasoning. Leveraging the CARLA simulator, we generate large-scale, well-annotated radar datasets across diverse driving scenarios. We also propose localization-aware metrics that assess spatial accuracy beyond traditional detection measures.","authors":["Pushkal Mishra","Kshitiz Bansal","Dinesh Bharadia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.10772v3","updated":"2025-11-26T06:40:46Z","published":"2025-03-13T18:06:13Z","title":"FlowTok: Flowing Seamlessly Across Text and Image Tokens","summary":"Bridging different modalities lies at the heart of cross-modality generation. While conventional approaches treat the text modality as a conditioning signal that gradually guides the denoising process from Gaussian noise to the target image modality, we explore a much simpler paradigm-directly evolving between text and image modalities through flow matching. This requires projecting both modalities into a shared latent space, which poses a significant challenge due to their inherently different representations: text is highly semantic and encoded as 1D tokens, whereas images are spatially redundant and represented as 2D latent embeddings. To address this, we introduce FlowTok, a minimal framework that seamlessly flows across text and images by encoding images into a compact 1D token representation. Compared to prior methods, this design reduces the latent space size by 3.3x at an image resolution of 256, eliminating the need for complex conditioning mechanisms or noise scheduling. Moreover, FlowTok naturally extends to image-to-text generation under the same formulation. With its streamlined architecture centered around compact 1D tokens, FlowTok is highly memory-efficient, requires significantly fewer training resources, and achieves much faster sampling speeds-all while delivering performance comparable to state-of-the-art models. Code is available at https://github.com/TACJu/FlowTok.","authors":["Ju He","Qihang Yu","Qihao Liu","Liang-Chieh Chen"],"pdf_url":"","comment":"Project page at https://tacju.github.io/projects/flowtok.html"},{"id":"http://arxiv.org/abs/2511.21098v1","updated":"2025-11-26T06:34:58Z","published":"2025-11-26T06:34:58Z","title":"Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry Reconstruction","summary":"Understanding reflection remains a long-standing challenge in 3D reconstruction due to the entanglement of appearance and geometry under view-dependent reflections. In this work, we present the Pygmalion Effect in Vision, a novel framework that metaphorically \"sculpts\" reflective objects into clay-like forms through image-to-clay translation. Inspired by the myth of Pygmalion, our method learns to suppress specular cues while preserving intrinsic geometric consistency, enabling robust reconstruction from multi-view images containing complex reflections. Specifically, we introduce a dual-branch network in which a BRDF-based reflective branch is complemented by a clay-guided branch that stabilizes geometry and refines surface normals. The two branches are trained jointly using the synthesized clay-like images, which provide a neutral, reflection-free supervision signal that complements the reflective views. Experiments on both synthetic and real datasets demonstrate substantial improvement in normal accuracy and mesh completeness over existing reflection-handling methods. Beyond technical gains, our framework reveals that seeing by unshining, translating radiance into neutrality, can serve as a powerful inductive bias for reflective object geometry learning.","authors":["Gayoung Lee","Junho Kim","Jin-Hwa Kim","Junmo Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10382v2","updated":"2025-11-26T06:34:45Z","published":"2025-08-14T06:26:36Z","title":"Towards Spatially Consistent Image Generation: On Incorporating Intrinsic Scene Properties into Diffusion Models","summary":"Image generation models trained on large datasets can synthesize high-quality images but often produce spatially inconsistent and distorted images due to limited information about the underlying structures and spatial layouts. In this work, we leverage intrinsic scene properties (e.g., depth, segmentation maps) that provide rich information about the underlying scene, unlike prior approaches that solely rely on image-text pairs or use intrinsics as conditional inputs. Our approach aims to co-generate both images and their corresponding intrinsics, enabling the model to implicitly capture the underlying scene structure and generate more spatially consistent and realistic images. Specifically, we first extract rich intrinsic scene properties from a large image dataset with pre-trained estimators, eliminating the need for additional scene information or explicit 3D representations. We then aggregate various intrinsic scene properties into a single latent variable using an autoencoder. Building upon pre-trained large-scale Latent Diffusion Models (LDMs), our method simultaneously denoises the image and intrinsic domains by carefully sharing mutual information so that the image and intrinsic reflect each other without degrading image quality. Experimental results demonstrate that our method corrects spatial inconsistencies and produces a more natural layout of scenes while maintaining the fidelity and textual alignment of the base model (e.g., Stable Diffusion).","authors":["Hyundo Lee","Suhyung Choi","Inwoo Hwang","Byoung-Tak Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21097v1","updated":"2025-11-26T06:32:22Z","published":"2025-11-26T06:32:22Z","title":"CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition","summary":"Iris authentication algorithms have achieved impressive recognition performance, making them highly promising for real-world applications such as border control, citizen identification, and both criminal investigations and commercial systems. However, their robustness is still challenged by variations in rotation, scale, specular reflections, and defocus blur. In addition, most existing approaches rely on straightforward point-to-point comparisons, typically using cosine or L2 distance, without effectively leveraging the spatio-spatial-temporal structure of iris patterns. To address these limitations, we propose a novel and generalized matching pipeline that learns rich spatio-spatial-temporal representations of iris features. Our approach first splits each iris image along one dimension, generating a sequence of sub-images that serve as input to a 3D-CNN, enabling the network to capture both spatial and spatio-spatial-temporal cues. To further enhance the modeling of spatio-spatial-temporal feature dynamics, we train the model in curriculum manner. This design allows the network to embed temporal dependencies directly into the feature space, improving discriminability in the deep metric domain. The framework is trained end-to-end with triplet and ArcFace loss in a curriculum manner, enforcing highly discriminative embeddings despite challenges like rotation, scale, reflections, and blur. This design yields a robust and generalizable solution for iris authentication.Github code: https://github.com/GeetanjaliGTZ/CLRecogEye","authors":["Geetanjali Sharma","Gaurav Jaswal","Aditya Nigam","Raghavendra Ramachandra"],"pdf_url":"","comment":"12 Pages, 3 figures, ISVC conference 2025"},{"id":"http://arxiv.org/abs/2511.18780v3","updated":"2025-11-26T06:26:38Z","published":"2025-11-24T05:27:05Z","title":"ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection","summary":"Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation. Our code is available at https://github.com/Ruize-Ma/ConceptGuard.","authors":["Ruize Ma","Minghong Cai","Yilei Jiang","Jiaming Han","Yi Feng","Yingshui Tan","Xiaoyong Zhu","Bo Zhang","Bo Zheng","Xiangyu Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00396v3","updated":"2025-11-26T06:25:32Z","published":"2025-11-01T04:37:01Z","title":"Saliency-R1: Incentivizing Unified Saliency Reasoning Capability in MLLM with Confidence-Guided Reinforcement Learning","summary":"Although multimodal large language models (MLLMs) excel in high-level vision-language reasoning, they lack inherent awareness of visual saliency, making it difficult to identify key visual elements. To bridge this gap, we propose Saliency-R1, the first unified MLLM framework that jointly tackles three representative and heterogeneous saliency tasks: Salient Object Detection (SOD), Salient Instance Segmentation (SIS), and Co-salient Object Detection (CoSOD), enhancing the model's capacity for saliency reasoning. We introduce a textual interface with structured tags (<rg>, <ins>) to encode region- and instance-level referring expressions, enabling a single referring segmenter to produce task-appropriate masks. To train the MLLM efficiently, we propose Confidence-Guided Policy Optimization (CGPO), a novel single-sample reinforcement learning algorithm. CGPO improves on GRPO by replacing group-normalized advantages with a per-sample signal based on reward-confidence discrepancy, thereby reducing computational waste, mitigating signal dilution, and lowering training overhead. Our model exceeds or matches the performance of robust open/closed-source MLLMs and specialized state-of-the-art methods across all three tasks, demonstrating the efficacy of our framework in saliency reasoning.","authors":["Long Li","Shuichen Ji","Ziyang Luo","Zhihui Li","Dingwen Zhang","Junwei Han","Nian Liu"],"pdf_url":"","comment":"Main text (excluding references): 8 pages, 4 figures; Supplementary Materials (excluding references): 9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.21087v1","updated":"2025-11-26T06:13:32Z","published":"2025-11-26T06:13:32Z","title":"MIRA: Multimodal Iterative Reasoning Agent for Image Editing","summary":"Instruction-guided image editing offers an intuitive way for users to edit images with natural language. However, diffusion-based editing models often struggle to accurately interpret complex user instructions, especially those involving compositional relationships, contextual cues, or referring expressions, leading to edits that drift semantically or fail to reflect the intended changes. We tackle this problem by proposing MIRA (Multimodal Iterative Reasoning Agent), a lightweight, plug-and-play multimodal reasoning agent that performs editing through an iterative perception-reasoning-action loop, effectively simulating multi-turn human-model interaction processes. Instead of issuing a single prompt or static plan, MIRA predicts atomic edit instructions step by step, using visual feedback to make its decisions. Our 150K multimodal tool-use dataset, MIRA-Editing, combined with a two-stage SFT + GRPO training pipeline, enables MIRA to perform reasoning and editing over complex editing instructions. When paired with open-source image editing models such as Flux.1-Kontext, Step1X-Edit, and Qwen-Image-Edit, MIRA significantly improves both semantic consistency and perceptual quality, achieving performance comparable to or exceeding proprietary systems such as GPT-Image and Nano-Banana.","authors":["Ziyun Zeng","Hang Hua","Jiebo Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14386v3","updated":"2025-11-26T06:01:59Z","published":"2025-11-18T11:45:46Z","title":"Cheating Stereo Matching in Full-scale: Physical Adversarial Attack against Binocular Depth Estimation in Autonomous Driving","summary":"Though deep neural models adopted to realize the perception of autonomous driving have proven vulnerable to adversarial examples, known attacks often leverage 2D patches and target mostly monocular perception. Therefore, the effectiveness of Physical Adversarial Examples (PAEs) on stereo-based binocular depth estimation remains largely unexplored. To this end, we propose the first texture-enabled physical adversarial attack against stereo matching models in the context of autonomous driving. Our method employs a 3D PAE with global camouflage texture rather than a local 2D patch-based one, ensuring both visual consistency and attack effectiveness across different viewpoints of stereo cameras. To cope with the disparity effect of these cameras, we also propose a new 3D stereo matching rendering module that allows the PAE to be aligned with real-world positions and headings in binocular vision. We further propose a novel merging attack that seamlessly blends the target into the environment through fine-grained PAE optimization. It has significantly enhanced stealth and lethality upon existing hiding attacks that fail to get seamlessly merged into the background. Extensive evaluations show that our PAEs can successfully fool the stereo models into producing erroneous depth information.","authors":["Kangqiao Zhao","Shuo Huai","Xurui Song","Jun Luo"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.16952v2","updated":"2025-11-26T06:01:16Z","published":"2025-11-21T04:59:54Z","title":"Point-Supervised Facial Expression Spotting with Gaussian-Based Instance-Adaptive Intensity Modeling","summary":"Automatic facial expression spotting, which aims to identify facial expression instances in untrimmed videos, is crucial for facial expression analysis. Existing methods primarily focus on fully-supervised learning and rely on costly, time-consuming temporal boundary annotations. In this paper, we investigate point-supervised facial expression spotting (P-FES), where only a single timestamp annotation per instance is required for training. We propose a unique two-branch framework for P-FES. First, to mitigate the limitation of hard pseudo-labeling, which often confuses neutral and expression frames with various intensities, we propose a Gaussian-based instance-adaptive intensity modeling (GIM) module to model instance-level expression intensity distribution for soft pseudo-labeling. By detecting the pseudo-apex frame around each point label, estimating the duration, and constructing an instance-level Gaussian distribution, GIM assigns soft pseudo-labels to expression frames for more reliable intensity supervision. The GIM module is incorporated into our framework to optimize the class-agnostic expression intensity branch. Second, we design a class-aware apex classification branch that distinguishes macro- and micro-expressions solely based on their pseudo-apex frames. During inference, the two branches work independently: the class-agnostic expression intensity branch generates expression proposals, while the class-aware apex-classification branch is responsible for macro- and micro-expression classification. Furthermore, we introduce an intensity-aware contrastive loss to enhance discriminative feature learning and suppress neutral noise by contrasting neutral frames with expression frames with various intensities. Extensive experiments on the SAMM-LV, CAS(ME)$^2$, and CAS(ME)$^3$ datasets demonstrate the effectiveness of our proposed framework.","authors":["Yicheng Deng","Hideaki Hayashi","Hajime Nagahara"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19474v2","updated":"2025-11-26T05:56:47Z","published":"2025-11-22T07:37:21Z","title":"Pistachio: Towards Synthetic, Balanced, and Long-Form Video Anomaly Benchmarks","summary":"Automatically detecting abnormal events in videos is crucial for modern autonomous systems, yet existing Video Anomaly Detection (VAD) benchmarks lack the scene diversity, balanced anomaly coverage, and temporal complexity needed to reliably assess real-world performance. Meanwhile, the community is increasingly moving toward Video Anomaly Understanding (VAU), which requires deeper semantic and causal reasoning but remains difficult to benchmark due to the heavy manual annotation effort it demands. In this paper, we introduce Pistachio, a new VAD/VAU benchmark constructed entirely through a controlled, generation-based pipeline. By leveraging recent advances in video generation models, Pistachio provides precise control over scenes, anomaly types, and temporal narratives, effectively eliminating the biases and limitations of Internet-collected datasets. Our pipeline integrates scene-conditioned anomaly assignment, multi-step storyline generation, and a temporally consistent long-form synthesis strategy that produces coherent 41-second videos with minimal human intervention. Extensive experiments demonstrate the scale, diversity, and complexity of Pistachio, revealing new challenges for existing methods and motivating future research on dynamic and multi-event anomaly understanding.","authors":["Jie Li","Hongyi Cai","Mingkang Dong","Muxin Pu","Shan You","Fei Wang","Tao Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20351v2","updated":"2025-11-26T05:53:19Z","published":"2025-11-25T14:30:10Z","title":"Thinking in 360°: Humanoid Visual Search in the Wild","summary":"Humans rely on the synergistic control of head (cephalomotor) and eye (oculomotor) to efficiently search for visual information in 360°. However, prior approaches to visual search are limited to a static image, neglecting the physical embodiment and its interaction with the 3D world. How can we develop embodied visual search agents as efficient as humans while bypassing the constraints imposed by real-world hardware? To this end, we propose humanoid visual search where a humanoid agent actively rotates its head to search for objects or paths in an immersive world represented by a 360° panoramic image. To study visual search in visually-crowded real-world scenarios, we build H* Bench, a new benchmark that moves beyond household scenes to challenging in-the-wild scenes that necessitate advanced visual-spatial reasoning capabilities, such as transportation hubs, large-scale retail spaces, urban streets, and public institutions. Our experiments first reveal that even top-tier proprietary models falter, achieving only ~30% success in object and path search. We then use post-training techniques to enhance the open-source Qwen2.5-VL, increasing its success rate by over threefold for both object search (14.83% to 47.38%) and path search (6.44% to 24.94%). Notably, the lower ceiling of path search reveals its inherent difficulty, which we attribute to the demand for sophisticated spatial commonsense. Our results not only show a promising path forward but also quantify the immense challenge that remains in building MLLM agents that can be seamlessly integrated into everyday human life.","authors":["Heyang Yu","Yinan Han","Xiangyu Zhang","Baiqiao Yin","Bowen Chang","Xiangyu Han","Xinhao Liu","Jing Zhang","Marco Pavone","Chen Feng","Saining Xie","Yiming Li"],"pdf_url":"","comment":"Website: https://humanoid-vstar.github.io/ ; Code: https://github.com/humanoid-vstar/hstar"},{"id":"http://arxiv.org/abs/2510.05613v2","updated":"2025-11-26T05:49:58Z","published":"2025-10-07T06:31:02Z","title":"PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction","summary":"Autoregressive point cloud generation has long lagged behind diffusion-based approaches in quality. The performance gap stems from the fact that autoregressive models impose an artificial ordering on inherently unordered point sets, forcing shape generation to proceed as a sequence of local predictions. This sequential bias emphasizes short-range continuity but undermines the model's capacity to capture long-range dependencies, hindering its ability to enforce global structural properties such as symmetry, consistent topology, and large-scale geometric regularities. Inspired by the level-of-detail (LOD) principle in shape modeling, we propose PointNSP, a coarse-to-fine generative framework that preserves global shape structure at low resolutions and progressively refines fine-grained geometry at higher scales through a next-scale prediction paradigm. This multi-scale factorization aligns the autoregressive objective with the permutation-invariant nature of point sets, enabling rich intra-scale interactions while avoiding brittle fixed orderings. Experiments on ShapeNet show that PointNSP establishes state-of-the-art (SOTA) generation quality for the first time within the autoregressive paradigm. In addition, it surpasses strong diffusion-based baselines in parameter, training, and inference efficiency. Finally, in dense generation with 8,192 points, PointNSP's advantages become even more pronounced, underscoring its scalability potential.","authors":["Ziqiao Meng","Qichao Wang","Zhiyang Dou","Zixing Song","Zhipeng Zhou","Irwin King","Peilin Zhao"],"pdf_url":"","comment":"This work was intended as a replacement of arXiv:2503.08594 and any subsequent updates will appear there"},{"id":"http://arxiv.org/abs/2511.20366v2","updated":"2025-11-26T05:30:04Z","published":"2025-11-25T14:45:59Z","title":"VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild","summary":"Reconstructing topologically consistent facial geometry is crucial for the digital avatar creation pipelines. Existing methods either require tedious manual efforts, lack generalization to in-the-wild data, or are constrained by the limited expressiveness of 3D Morphable Models. To address these limitations, we propose VGGTFace, an automatic approach that innovatively applies the 3D foundation model, i.e. VGGT, for topologically consistent facial geometry reconstruction from in-the-wild multi-view images captured by everyday users. Our key insight is that, by leveraging VGGT, our method naturally inherits strong generalization ability and expressive power from its large-scale training and point map representation. However, it is unclear how to reconstruct a topologically consistent mesh from VGGT, as the topology information is missing in its prediction. To this end, we augment VGGT with Pixel3DMM for injecting topology information via pixel-aligned UV values. In this manner, we convert the pixel-aligned point map of VGGT to a point cloud with topology. Tailored to this point cloud with known topology, we propose a novel Topology-Aware Bundle Adjustment strategy to fuse them, where we construct a Laplacian energy for the Bundle Adjustment objective. Our method achieves high-quality reconstruction in 10 seconds for 16 views on a single NVIDIA RTX 4090. Experiments demonstrate state-of-the-art results on benchmarks and impressive generalization to in-the-wild data. Code is available at https://github.com/grignarder/vggtface.","authors":["Xin Ming","Yuxuan Han","Tianyu Huang","Feng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19900v2","updated":"2025-11-26T05:14:57Z","published":"2025-11-25T04:15:14Z","title":"Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning","summary":"Vision-language agents have achieved remarkable progress in a variety of multimodal reasoning tasks; however, their learning remains constrained by the limitations of human-annotated supervision. Recent self-rewarding approaches attempt to overcome this constraint by allowing models to act as their own critics or reward providers. Yet, purely text-based self-evaluation struggles to verify complex visual reasoning steps and often suffers from evaluation hallucinations. To address these challenges, inspired by recent advances in tool-integrated reasoning, we propose Agent0-VL, a self-evolving vision-language agent that achieves continual improvement with tool-integrated reasoning. Agent0-VL incorporates tool usage not only into reasoning but also into self-evaluation and self-repair, enabling the model to introspect, verify, and refine its reasoning through evidence-grounded analysis. It unifies two synergistic roles within a single LVLM: a Solver that performs multi-turn tool-integrated reasoning, and a Verifier that generates structured feedback and fine-grained self-rewards through tool-grounded critique. These roles interact through a Self-Evolving Reasoning Cycle, where tool-based verification and reinforcement learning jointly align the reasoning and evaluation distributions for stable self-improvement. Through this zero-external-reward evolution, Agent0-VL aligns its reasoning and verification behaviors without any human annotation or external reward models, achieving continual self-improvement. Experiments on geometric problem solving and visual scientific analysis show that Agent0-VL achieves an 12.5% improvement over the base model. Our code is available at https://github.com/aiming-lab/Agent0.","authors":["Jiaqi Liu","Kaiwen Xiong","Peng Xia","Yiyang Zhou","Haonian Ji","Lu Feng","Siwei Han","Mingyu Ding","Huaxiu Yao"],"pdf_url":"","comment":null}],"Systems and Control":[{"id":"http://arxiv.org/abs/2509.07218v4","updated":"2025-11-26T18:53:01Z","published":"2025-09-08T20:55:54Z","title":"Electricity Demand and Grid Impacts of AI Data Centers: Challenges and Prospects","summary":"The rapid growth of artificial intelligence (AI) is driving an unprecedented increase in the electricity demand of AI data centers, raising emerging challenges for electric power grids. Understanding the characteristics of AI data center loads and their interactions with the grid is therefore critical for ensuring both reliable power system operation and sustainable AI development. This paper provides a comprehensive review and vision of this evolving landscape. Specifically, this paper (i) presents an overview of AI data center infrastructure and its key components, (ii) examines the key characteristics and patterns of electricity demand across the stages of model preparation, training, fine-tuning, and inference, (iii) analyzes the critical challenges that AI data center loads pose to power systems across three interrelated timescales, including long-term planning and interconnection, short-term operation and electricity markets, and real-time dynamics and stability, and (iv) discusses potential solutions from the perspectives of the grid, AI data centers, and AI end-users to address these challenges. By synthesizing current knowledge and outlining future directions, this review aims to guide research and development in support of the joint advancement of AI data centers and power systems toward reliable, efficient, and sustainable operation.","authors":["Xin Chen","Xiaoyang Wang","Ana Colacelli","Matt Lee","Le Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21641v1","updated":"2025-11-26T18:14:18Z","published":"2025-11-26T18:14:18Z","title":"Model-free practical PI-Lead control design by ultimate sensitivity principle","summary":"Practical design and tuning of feedback controllers has to do often without any model of the given dynamic process. Only some general assumptions about the process, in this work type-one stable behavior, can be available for engineers, in particular in motion control systems. This paper proposes a practical and simple in realization procedure for designing a robust PI-Lead control without modeling. The developed method derives from the ultimate sensitivity principles, known in the empirical Ziegler-Nichols tuning of PID control, and makes use of some general characteristics of loop shaping. A three-steps procedure is proposed to determine the integration time constant, control gain, and Lead-element in a way to guarantee a sufficient phase margin, while all steps are served by only experimental observations of the output value. The proposed method is also evaluated with experiments on a noise-perturbed electro-mechanical actuator system with translational motion.","authors":["Michael Ruderman"],"pdf_url":"","comment":"6 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.02110v2","updated":"2025-11-26T18:02:52Z","published":"2025-11-03T22:49:55Z","title":"Hopfield Neural Networks for Online Constrained Parameter Estimation with Time-Varying Dynamics and Disturbances","summary":"This paper proposes two projector-based Hopfield neural network (HNN) estimators for online, constrained parameter estimation under time-varying data, additive disturbances, and slowly drifting physical parameters. The first is a constraint-aware HNN that enforces linear equalities and inequalities (via slack neurons) and continuously tracks the constrained least-squares target. The second augments the state with compensation neurons and a concatenated regressor to absorb bias-like disturbance components within the same energy function. For both estimators we establish global uniform ultimate boundedness with explicit convergence rate and ultimate bound, and we derive practical tuning rules that link the three design gains to closed-loop bandwidth and steady-state accuracy. We also introduce an online identifiability monitor that adapts the constraint weight and time step, and, when needed, projects updates onto identifiable subspaces to prevent drift in poorly excited directions...","authors":["Miguel Pedro Silva"],"pdf_url":"","comment":"Accepted for publication in International Journal od Adaptive Control and Signal Processing"},{"id":"http://arxiv.org/abs/2511.21633v1","updated":"2025-11-26T18:01:49Z","published":"2025-11-26T18:01:49Z","title":"Bang-Bang Evasion: Its Stochastic Optimality and a Terminal-Set-Based Implementation","summary":"We address the problem of optimal evasion in a planar endgame engagement, where a target with bounded lateral acceleration seeks to avoid interception by a missile guided by a linear feedback law. Contrary to existing approaches, that assume perfect information or use heuristic maneuver models in stochastic settings, we formulate the problem in an inherently stochastic framework involving imperfect information and bounded controls. Complying with the generalized separation theorem, the control law factors in the posterior distribution of the state. Extending the well-known optimality of bang-bang evasion maneuvers in deterministic settings to the realm of realistic, stochastic evasion scenarios, we firstly prove that an optimal evasion strategy always exists, and that the set of optimal solutions includes at least one bang-bang policy, rendering the resulting optimal control problem finite-dimensional. Leveraging this structure, we secondly propose the closed-loop terminal-set-based evasion (TSE) strategy, and demonstrate its effectiveness in simulation against a proportional navigation pursuer. Monte Carlo simulations show that the TSE strategy outperforms traditional stochastic evasion strategies based on random telegraph, Singer, and weaving models.","authors":["Liraz Mudrik","Yaakov Oshman"],"pdf_url":"","comment":"29 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.21619v1","updated":"2025-11-26T17:43:14Z","published":"2025-11-26T17:43:14Z","title":"Robust Rule-Based Sizing and Control of Batteries for Peak Shaving Applications","summary":"As the cost of batteries lowers, sizing and control methods that are both fast and can achieve their promised performances when deployed are becoming more important. In this paper, we show how stochastically tuned rule based controllers (RBCs) can be effectively used to achieve both these goals, providing more realistic estimates in terms of achievable levelised cost of energy (LCOE), and better performances while in operation when compared to deterministic model predictive control (MPC). We test the proposed methodology on yearly profiles from real meters for peak shaving applications and provide strong evidence about these claims.","authors":["Lorenzo Nespoli","Vasco Medici"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21593v1","updated":"2025-11-26T17:11:15Z","published":"2025-11-26T17:11:15Z","title":"Closed Form HJB Solution for Continuous-Time Optimal Control of a Non-Linear Input-Affine System","summary":"Designing optimal controllers for nonlinear dynamical systems often relies on reinforcement learning and adaptive dynamic programming (ADP) to approximate solutions of the Hamilton Jacobi Bellman (HJB) equation. However, these methods require iterative training and depend on an initially admissible policy. This work introduces a new analytical framework that yields closed-form solutions to the HJB equation for a class of continuous-time nonlinear input-affine systems with known dynamics. Unlike ADP-based approaches, it avoids iterative learning and numerical approximation. Lyapunov theory is used to prove the asymptotic stability of the resulting closed-loop system, and theoretical guarantees are provided. The method offers a closed-form control policy derived from the HJB framework, demonstrating improved computational efficiency and optimal performance on state-of-the-art optimal control problems in the literature.","authors":["Akash Vyas","Shreyas Kumar","Jayant Kumar Mohanta","Ravi Prakash"],"pdf_url":"","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2505.19387v2","updated":"2025-11-26T16:01:53Z","published":"2025-05-26T01:04:56Z","title":"Alignment of large language models with constrained learning","summary":"We study the problem of computing an optimal large language model (LLM) policy for the constrained alignment problem, where the goal is to maximize a primary reward objective while satisfying constraints on secondary utilities. Despite the popularity of Lagrangian-based LLM policy search in constrained alignment, iterative primal-dual methods often fail to converge, and non-iterative dual-based methods do not achieve optimality in the LLM parameter space. To address these challenges, we employ Lagrangian duality to develop an iterative dual-based alignment method that alternates between updating the LLM policy via Lagrangian maximization and updating the dual variable via dual descent. In theory, we characterize the primal-dual gap between the primal value in the distribution space and the dual value in the LLM parameter space. We further quantify the optimality gap of the learned LLM policies at near-optimal dual variables with respect to both the objective and the constraint functions. These results prove that dual-based alignment methods can find an optimal constrained LLM policy, up to an LLM parametrization gap. We demonstrate the effectiveness and merits of our approach through extensive experiments conducted on the PKU-SafeRLHF and Anthropic HH-RLHF datasets.","authors":["Botong Zhang","Shuo Li","Ignacio Hounie","Osbert Bastani","Dongsheng Ding","Alejandro Ribeiro"],"pdf_url":"","comment":"51 pages, 5 figures, 11 tables; Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21531v1","updated":"2025-11-26T15:59:55Z","published":"2025-11-26T15:59:55Z","title":"Predictive Safety Shield for Dyna-Q Reinforcement Learning","summary":"Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.","authors":["Jin Pin","Krasowski Hanna","Vanneaux Elena"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16235v2","updated":"2025-11-26T15:36:03Z","published":"2025-11-20T11:09:38Z","title":"Describing Functions and Phase Response Curves of Excitable Systems","summary":"The describing function (DF) and phase response curve (PRC) are classical tools for the analysis of feedback oscillations and rhythmic behaviors, widely used across control engineering, biology, and neuroscience. These tools are known to have limitations in networks of relaxation oscillators and excitable systems. For this reason, the paper proposes a novel approach tailored to excitable systems. Our analysis focuses on the discrete-event operator mapping input trains of events to output trains of events. The methodology is illustrated on the excitability model of Hodgkin-Huxley. The proposed framework provides a basis for designing and analyzing central pattern generators in networks of excitable neurons, with direct relevance to neuromorphic control and neurophysiology.","authors":["Robin Wroblowski","Rodolphe Sepulchre"],"pdf_url":"","comment":"7 pages, 6 figures, submitted to European Control Conference 2026"},{"id":"http://arxiv.org/abs/2511.20294v2","updated":"2025-11-26T14:51:38Z","published":"2025-11-25T13:27:45Z","title":"SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms","summary":"Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness.","authors":["Dnyandeep Mandaokar","Bernhard Rinner"],"pdf_url":"","comment":"This work has been submitted for possible publication"},{"id":"http://arxiv.org/abs/2511.21456v1","updated":"2025-11-26T14:47:41Z","published":"2025-11-26T14:47:41Z","title":"VibraWave: Sensing the Pulse of Polluted Waters","summary":"Conventional methods for water pollutant detection, such as chemical assays and optical spectroscopy, are often invasive, expensive, and unsuitable for real-time, portable monitoring. In this paper, we introduce VibraWave, a novel non-invasive sensing framework that combines mmWave radar with controlled acoustic excitation, tensor decomposition, and deep learning to detect and quantify a wide range of water pollutants. By capturing radar reflections as a three-dimensional tensor encoding phase dynamics, range bin power, and angle-of-arrival (AoA), we apply PARAFAC decomposition with non-negative constraints to extract compact, interpretable pollutant fingerprints. These are used to train a lightweight student neural network via knowledge distillation, enabling joint classification and quantification of heavy metals (Cu, Fe, Mg), oil emulsions, and sediments. Extensive experiments show that VibraWave achieves high accuracy and low RMSE across pure, binary, and tertiary mixtures, while remaining robust and computationally efficient, making it well-suited for scalable, real-time water quality monitoring.","authors":["Sagnik Ghosh","Sandip Chakraborty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13682v2","updated":"2025-11-26T14:29:48Z","published":"2025-10-15T15:37:24Z","title":"A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array","summary":"This paper presents a fast impedance measurement IC for large-scale piezo-resistive sensor array. It features a unified differential time-to-digital demodulation architecture that readout impedance directly through the excitation circuit. The proposed pre-saturation adaptive bias technique further improves power efficiency. The chip scans 253 sensors in 12.2 ms (82 fps) at 125 kHz, consuming 158 μW (7.5 nJ/sensor). With loads from 20 Ω to 500 kΩ, it achieves 0.5% error and up to 71.1 dB SNR.","authors":["Jiayang Li","Qingyu Zhang","Sohmyung Ha","Dai Jiang","Andreas Demosthenous","Yu Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21432v1","updated":"2025-11-26T14:22:41Z","published":"2025-11-26T14:22:41Z","title":"Multi-Hypotheses Navigation in Collaborative Localization subject to Cyber Attacks","summary":"This paper addresses resilient collaborative localization in multi-agent systems exposed to spoofed radio frequency measurements. Each agent maintains multiple hypotheses of its own state and exchanges selected information with neighbors using covariance intersection. Geometric reductions based on distance tests and convex hull structure limit the number of hypotheses transmitted, controlling the spread of hypotheses through the network. The method enables agents to separate spoofed and truthful measurements and to recover consistent estimates once the correct hypothesis is identified. Numerical results demonstrate the ability of the approach to contain the effect of adversarial measurements, while also highlighting the impact of conservative fusion on detection speed. The framework provides a foundation for resilient multi-agent navigation and can be extended with coordinated hypothesis selection across the network.","authors":["Peter Iwer Hoedt Karstensen","Roberto Galeazzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21405v1","updated":"2025-11-26T13:53:42Z","published":"2025-11-26T13:53:42Z","title":"Decentralized Shepherding of Non-Cohesive Swarms Through Cluttered Environments via Deep Reinforcement Learning","summary":"This paper investigates decentralized shepherding in cluttered environments, where a limited number of herders must guide a larger group of non-cohesive, diffusive targets toward a goal region in the presence of static obstacles. A hierarchical control architecture is proposed, integrating a high-level target assignment rule, where each herder is paired with a selected target, with a learning-based low-level driving module that enables effective steering of the assigned target. The low-level policy is trained in a one-herder-one-target scenario with a rectangular obstacle using Proximal Policy Optimization and then directly extended to multi-agent settings with multiple obstacles without requiring retraining. Numerical simulations demonstrate smooth, collision-free trajectories and consistent convergence to the goal region, highlighting the potential of reinforcement learning for scalable, model-free shepherding in complex environments.","authors":["Cristiana Punzo","Italo Napolitano","Cinzia Tomaselli","Mario di Bernardo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21387v1","updated":"2025-11-26T13:35:56Z","published":"2025-11-26T13:35:56Z","title":"Understanding Regional Inertia Dynamics in CAISO from Real Grid Disturbances","summary":"The shift from synchronous generators to inverter-based resources has caused power system inertia to be unevenly distributed across power grids. As a result, certain grid regions are more vulnerable to high rate-of-change of frequency (RoCoF) during disturbances. This paper presents a measurement-based framework for estimating grid inertia in CAISO (California Independent System Operator) region using real disturbance-driven frequency data from the Frequency Monitoring Network (FNET/GridEye). By analyzing confirmed disturbances from 2013 to 2024, we identify trends in regional inertia and frequency dynamics, highlighting their relationship with renewable generation and the evolving duck curve. Regional RoCoF values were up to six times higher than interconnection-wide values, coinciding with declining inertia. Recent recovery in inertia is attributed to the increased deployment of battery energy storage systems with synthetic inertia capabilities. These findings underscore the importance of regional inertia monitoring, strategic resource planning, and adaptive operational practices to ensure grid reliability amid growing renewable integration.","authors":["Saurav Dulal","Mohammed M. Olama","Ali R. Ekti","Nils M. Stenvig","Yilu Liu"],"pdf_url":"","comment":"This work has been accepted for publication in IEEE PES T&D 2026. The final published version will be available via IEEE Xplore"},{"id":"http://arxiv.org/abs/2511.21385v1","updated":"2025-11-26T13:34:11Z","published":"2025-11-26T13:34:11Z","title":"Influence of converter current limiting and prioritization on protection of highly IBR-penetrated networks","summary":"This paper investigates how grid-forming (GFM) and grid-following (GFL) control strategies in inverter-based resources (IBRs) influence line distance and differential protection in converter-dominated transmission systems. A modified IEEE 39-bus system is evaluated with GFM and GFL units equipped with low-voltage ride-through logic, current limiting, and positive- or negative-sequence prioritization. Distance protection is implemented with a mho characteristic, while line differential protection uses an alpha-plane approach. Results show that phase-to-ground loops in distance protection can substantially overestimate the fault location near the Zone-1 reach. For line differential protection, external faults may cause the operating point to briefly enter the trip region of the alpha-plane, even for the healthy-phase in ABG faults under GFL control and during the initial moments of the fault, demanding strong external security measures. These findings highlight that modern converter controls, together with current limitation and sequence-current prioritization, can compromise the reliability and security of traditional protection schemes.","authors":["Andrés E. Quintero","Vinícius A. Lacerda","Oriol Gomis-Bellmunt","Moisés J. B. B. Davi","Mario Oleskovicz"],"pdf_url":"","comment":"Submitted to DPSP Global 2026"},{"id":"http://arxiv.org/abs/2505.10116v2","updated":"2025-11-26T13:19:21Z","published":"2025-05-15T09:40:32Z","title":"Discontinuous integro-differential equations and sliding mode control","summary":"The paper deals with analysis and design sliding mode control systems modeled by integro-differential equations. Filippov method and equivalent control approach are extended to a class of nonlinear discontinuous integro-differential equations. Sliding mode control algorithm is designed for a control system with distributed input delay. The obtained results are illustrated by numerical example.","authors":["Andrey Polyakov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21371v1","updated":"2025-11-26T13:14:09Z","published":"2025-11-26T13:14:09Z","title":"Evaluation of Large Language Models for Numeric Anomaly Detection in Power Systems","summary":"Large language models (LLMs) have gained increasing attention in power grids for their general-purpose capabilities. Meanwhile, anomaly detection (AD) remains critical for grid resilience, requiring accurate and interpretable decisions based on multivariate telemetry. Yet the performance of LLMs on large-scale numeric data for AD remains largely unexplored. This paper presents a comprehensive evaluation of LLMs for numeric AD in power systems. We use GPT-OSS-20B as a representative model and evaluate it on the IEEE 14-bus system. A standardized prompt framework is applied across zero-shot, few-shot, in-context learning, low rank adaptation (LoRA), fine-tuning, and a hybrid LLM-traditional approach. We adopt a rule-aware design based on the three-sigma criterion, and report detection performance and rationale quality. This study lays the groundwork for further investigation into the limitations and capabilities of LLM-based AD and its integration with classical detectors in cyber-physical power grid applications.","authors":["Yichen Liu","Hongyu Wu","Bo Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21343v1","updated":"2025-11-26T12:49:53Z","published":"2025-11-26T12:49:53Z","title":"Model Predictive Control and Moving Horizon Estimation using Statistically Weighted Data-Based Ensemble Models","summary":"This paper presents a model predictive control (MPC) framework leveraging an ensemble of data-based models to optimally control complex systems under multiple operating conditions. A novel combination rule for ensemble models is proposed, based on the statistical Mahalanobis distance, enabling the ensemble weights to suitably vary across the prediction window based on the system input. In addition, a novel state observer for ensemble models is developed using moving horizon estimation (MHE). The effectiveness of the proposed methodology is demonstrated on a benchmark energy system operating under multiple conditions.","authors":["Laura Boca de Giuli","Samuel Mallick","Alessio La Bella","Azita Dabiri","Bart De Schutter","Riccardo Scattolini"],"pdf_url":"","comment":"7 pages, 4 figures, submitted to ECC 2026"},{"id":"http://arxiv.org/abs/2511.21327v1","updated":"2025-11-26T12:18:07Z","published":"2025-11-26T12:18:07Z","title":"The Theory of Storage in a Power System with Stochastic Demand","summary":"Electric power systems are increasingly turning to energy storage systems to balance supply and demand. But how much storage is required? What is the optimal volume of storage in a power system and on what does it depend? In addition, what form of hedge contracts do storage facilities require? We answer these questions in the special case in which the uncertainty in the power system involves successive draws of an independent, identically-distributed random variable. We characterize the conditions for the optimal operation of, and investment in, storage and show how these conditions can be understood graphically using price-duration curves. We also characterize the optimal hedge contracts for storage units.","authors":["Darryl Biggar","Mohammad Reza Hesamzadeh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21319v1","updated":"2025-11-26T12:04:37Z","published":"2025-11-26T12:04:37Z","title":"Analytical Phasor-Based Fault Location Enhancement for Wind Farm Collector Networks","summary":"The increasing integration of Inverter-Based Resources (IBRs) is reshaping fault current characteristics, presenting significant challenges to traditional protection and fault location methods. This paper addresses a key limitation in fault location within wind farm collector networks, i.e., one-terminal phasor-based methods become inaccurate when IBRs are electrically located downstream from the fault. In such cases, the voltage drop caused by IBR fault current injections is not captured by the Intelligent Electronic Device, resulting in a systematic overestimation of fault distance. To mitigate this issue, a general compensation framework was proposed by augmenting classical loop formulations with a distance-dependent voltage correction term. The methodology was derived analytically using a sequence-domain representation and generalized to multiple fault types through a unified notation. It maintains the simplicity and interpretability of conventional approaches and can be implemented using only local measurements. The method was evaluated through EMT simulations in PSCAD using a realistic wind farm model. Results show significant improvements in location accuracy, with average and maximum errors notably reduced, especially for ground-involved faults where reductions exceed 90\\%. Furthermore, the compensation eliminates sensitivity to wind penetration levels and ensures uniform performance across feeders, positioning the method as a practical solution for modern renewable-dominated grids.","authors":["Alailton J. Alves Junior","Daniel Barbosa","Ricardo A. S. Fernandes","Denis V. Coury"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21314v1","updated":"2025-11-26T12:00:58Z","published":"2025-11-26T12:00:58Z","title":"Scalable Multisubject Vital Sign Monitoring With mmWave FMCW Radar and FPGA Prototyping","summary":"In this work, we introduce an innovative approach to estimate the vital signs of multiple human subjects simultaneously in a non-contact way using a Frequency Modulated Continuous Wave (FMCW) radar-based system. Traditional vital sign monitoring methods often face significant limitations, including subject discomfort with wearable devices, challenges in calibration, and the risk of infection transmission through contact measurement devices. To address these issues, this research is motivated by the need for versatile, non-contact vital monitoring solutions applicable in various critical scenarios. This work also explores the challenges of extending this capability to an arbitrary number of subjects, including hardware and theoretical limitations. Supported by rigorous experimental results and discussions, the paper illustrates the system's potential to redefine vital sign monitoring. An FPGA-based implementation is also presented as proof of concept for a hardware-based and portable solution, improving upon previous works by offering 2.7x faster execution and 18.4% less Look-Up Table (LUT) utilization, as well as providing over 7400x acceleration compared to its software counterpart.","authors":["Jewel Benny","Narahari N. Moudhgalya","Mujeev Khan","Hemant Kumar Meena","Mohd Wajid","Abhishek Srivastava"],"pdf_url":"","comment":"Published in IEEE Sensors Journal"},{"id":"http://arxiv.org/abs/2511.21310v1","updated":"2025-11-26T11:55:30Z","published":"2025-11-26T11:55:30Z","title":"Design and Performance Assessment of a Virtualized IED for Digital Substations","summary":"Digital substations have significantly enhanced power grid protection by replacing traditional copper wiring with fiber-optic communication and integrating IEC 61850-compliant Intelligent Electronic Devices (IEDs), resulting in greater efficiency, reliability, and interoperability. While these advancements provide improved interoperability, challenges such as high costs, complex networks, and limited upgradeability persist. To mitigate these issues, the virtualization of IEDs has emerged as a cost-effective solution, offering scalability, simplified maintenance, and reduced hardware costs by replacing traditional hardware-based IEDs with software-based counterparts. However, the performance and reliability of virtual IEDs (vIED) must be rigorously evaluated to ensure their robustness in real-time applications. This paper develops, implements, and evaluates a vIED designed to match the performance of its hardware-based counterparts. The vIED was deployed on a server using virtual machines, with its core logic implemented in low-level programming languages to ensure high-speed, deterministic behavior. The performance was evaluated using real-time simulations, focusing on the response times of the protection functions. The results demonstrated that vIEDs achieved acceptable response times, validating their suitability for deployment in critical time-sensitive environments within digital substations.","authors":["Alailton J. Alves Junior","Denis V. Coury","Ricardo A. S. Fernandes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21304v1","updated":"2025-11-26T11:50:32Z","published":"2025-11-26T11:50:32Z","title":"Sparse shepherding control of large-scale multi-agent systems via Reinforcement Learning","summary":"We propose a reinforcement learning framework for sparse indirect control of large-scale multi-agent systems, where few controlled agents shape the collective behavior of many uncontrolled agents. The approach addresses this multi-scale challenge by coupling ODEs (modeling controlled agents) with a PDE (describing the uncontrolled population density), capturing how microscopic control achieves macroscopic objectives. Our method combines model-free reinforcement learning with adaptive interaction strength compensation to overcome sparse actuation limitations. Numerical validation demonstrates effective density control, with the system achieving target distributions while maintaining robustness to disturbances and measurement noise, confirming that learning-based sparse control can replace computationally expensive online optimization.","authors":["Luigi Catello","Italo Napolitano","Davide Salzano","Mario di Bernardo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21300v1","updated":"2025-11-26T11:48:13Z","published":"2025-11-26T11:48:13Z","title":"Data-Driven Reduction of Fault Location Errors in Onshore Wind Farm Collectors","summary":"Accurate fault location is essential for operational reliability and fast restoration in wind farm collector networks. However, the growing integration of inverter-based resources changes the current and voltage behavior during faults, challenging the effectiveness of traditional phasor-based diagnostic methods. In this context, the present paper introduces an advanced machine-learning solution that enhances a deterministic fault distance estimator by incorporating a correction model driven by a Gated Residual Network, specifically designed to minimize residual fault location errors. Through comprehensive feature engineering and selection processes, an improved predictor was developed and trained on a diverse set of fault scenarios simulated in a PSCAD-based real-world wind farm model, including variations in fault type, resistance, location, inception angle, and generation penetration. Hyperparameter optimization was performed using the Optuna framework, and the robustness of the method was statistically validated. Results show a significant improvement in accuracy, with a 76% overall decrease in fault location error compared to state-of-the-art approaches. The proposed method demonstrates strong scalability and adaptability to topological and operational changes. This approach advances the deployment of data-driven fault location frameworks for modern power systems.","authors":["A. J. Alves Junior","M. J. B. B. Davi","R. A. S. Fernandes","M. Oleskovicz","D. V. Coury"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.00845v2","updated":"2025-11-26T11:17:35Z","published":"2025-04-01T14:31:53Z","title":"Boosting the transient performance of reference tracking controllers with neural networks","summary":"Reference tracking is a key objective in many control systems, including those characterized by complex nonlinear dynamics. In these settings, traditional control approaches can effectively ensure steady-state accuracy but often struggle to explicitly optimize transient performance. Neural network controllers have gained popularity due to their adaptability to nonlinearities and disturbances; however, they often lack formal closed-loop stability and performance guarantees. To address these challenges, a recently proposed neural-network control framework known as Performance Boosting (PB) has demonstrated the ability to maintain $\\mathcal{L}_p$ stability properties of nonlinear systems while optimizing generic transient costs.\n  This paper extends the PB approach to reference tracking problems. First, we characterize the complete set of nonlinear controllers that preserve desired tracking properties for nonlinear systems equipped with base reference-tracking controllers. Then, we show how to optimize transient costs while searching within subsets of tracking controllers that incorporate expressive neural network models. Furthermore, we analyze the robustness of our method to uncertainties in the underlying system dynamics. Numerical simulations on a robotic system demonstrate the advantages of our approach over the standard PB framework.","authors":["Nicolas Kirsch","Leonardo Massai","Giancarlo Ferrari-Trecate"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21274v1","updated":"2025-11-26T10:56:12Z","published":"2025-11-26T10:56:12Z","title":"Multiport Analytical Pixel Electromagnetic Simulator (MAPES) for AI-assisted RFIC and Microwave Circuit Design","summary":"This paper proposes a novel analytical framework, termed the Multiport Analytical Pixel Electromagnetic Simulator (MAPES). MAPES enables efficient and accurate prediction of the electromagnetic (EM) performance of arbitrary pixel-based microwave (MW) and RFIC structures. Inspired by the Integrated Internal Multiport Method (IMPM), MAPES extends the concept to the pixel presence/absence domain used in AI-assisted EM design. By introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical positions, MAPES captures all horizontal, vertical, and diagonal electromagnetic couplings within a single multiport impedance matrix. Only a small set of full-wave simulations (typically about 1% of the datasets required by AI-assisted EM simulators) is needed to construct this matrix. Subsequently, any arbitrary pixel configuration can be evaluated analytically using a closed-form multiport relation without additional full-wave calculations. The proposed approach eliminates data-driven overfitting and ensures accurate results across all design variations. Comprehensive examples for single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs confirm that MAPES achieves high prediction accuracy with 600- 2000x speed improvement compared to CST simulations. Owing to its efficiency, scalability and reliability, MAPES provides a practical and versatile tool for AI-assisted MW circuit and RFIC design across diverse fabrication technologies.","authors":["Junhui Rao","Yi Liu","Jichen Zhang","Zhaoyang Ming","Tianrui Qiao","Yujie Zhang","Chi Yuk Chiu","Hua Wang","Ross Murch"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21273v1","updated":"2025-11-26T10:56:00Z","published":"2025-11-26T10:56:00Z","title":"Respiratory Motion Compensation and Haptic Feedback for X-ray-Guided Teleoperated Robotic Needle Insertion","summary":"Respiratory motion limits the accuracy and precision of abdominal percutaneous procedures. In this paper, respiratory motion is compensated robotically using motion estimation models. Additionally, a teleoperated insertion is performed using proximity-based haptic feedback to guide physicians during insertion, enabling a radiation-free remote insertion for the end-user. The study has been validated using a robotic liver phantom, and five insertions were performed. The resulting motion estimation errors were below 3 mm for all directions of motion, and the overall resulting 3D insertion errors were 2.60, 7.75, and 2.86 mm for the superior-inferior, lateral, and anterior-posterior directions of motion, respectively. The proposed approach is expected to minimize the chances of inaccurate treatment or diagnosis due to respiratory-induced motion and reduce radiation exposure.","authors":["Ana Cordon-Avila","Mostafa Selim","Momen Abayazid"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21271v1","updated":"2025-11-26T10:54:41Z","published":"2025-11-26T10:54:41Z","title":"Adaptive Lighting Control in Visible Light Systems: An Integrated Sensing, Communication, and Illumination Framework","summary":"Indoor visible light communication (VLC) is a promising sixth-generation (6G) technology, as its directional and sensitive optical signals are naturally suited for integrated sensing and communication (ISAC). However, current research mainly focuses on maximizing data rates and sensing accuracy, creating a conflict between high performance, high energy consumption, and user visual comfort. This paper proposes an adaptive integrated sensing, communication, and illumination (ISCI) framework that resolves this conflict by treating energy savings as a primary objective. The framework's mechanism first partitions the receiving plane using a geometric methodology, defining an activity area and a surrounding non-activity area to match distinct user requirements. User location, determined using non-line-of-sight (NLOS) sensing, then acts as a dynamic switch for the system's optimization objective. The system adaptively shifts between minimizing total transmit power while guaranteeing communication and illumination performance in the activity area and maximizing signal-to-noise ratio (SNR) uniformity in the non-activity area. Numerical results confirm that this adaptive ISCI approach achieves 53.59% energy savings over a non-adaptive system and improves SNR uniformity by 57.79%, while satisfying all illumination constraints and maintaining a mean localization error of 0.071 m.","authors":["Xinyan Xie","Xuesong Wang","Xin Lai","Yongheng Wen","Fengrui Yang","Haoyang He","Lai Zhang","Dong Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21269v1","updated":"2025-11-26T10:48:35Z","published":"2025-11-26T10:48:35Z","title":"Response-Based Frequency Stability Assessment under Multi-Scale Disturbances in High-Renewable Power Systems","summary":"In high-renewable power systems, active-power disturbances are becoming larger and exhibit increasingly diverse time scales, which complicates frequency stability assessment under unanticipated events. This paper presents a response-based frequency stability assessment method that uses disturbance power, inferred from generator electrical responses, to provide a unified treatment of multi-scale disturbances. Unanticipated disturbances are first classified into short-term and permanent events; permanent disturbances are further divided into step, second-level slope and minute-level slope disturbances. Based on the measured power responses of generator groups, a unified disturbance-power model is constructed to identify the disturbance type online and to quantify disturbance intensity through the disturbance power and its rate of change. Analytical frequency-response models are then derived for each disturbance class. For step disturbances, the maximum tolerable disturbance power is obtained under steady-state and transient frequency deviation constraints, and a safety-margin index is defined. For slope-type disturbances, an improved system frequency response (SFR) model and the rotor motion equation after exhaustion of primary frequency regulation are used to compute the over-limit time of frequency deviation. The proposed response-based assessment method is validated on the CSEE-FS frequency-stability benchmark system, demonstrating its effectiveness and accuracy for quantitative frequency stability assessment in high-renewable power systems.","authors":["Jinhui Chen","Huadong Sun","Ping Wu","Baocai Wang","Bing Zhao"],"pdf_url":"","comment":"10 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.19258v3","updated":"2025-11-26T10:43:58Z","published":"2024-11-28T16:47:47Z","title":"L4acados: Learning-based models for acados, applied to Gaussian process-based predictive control","summary":"Incorporating learning-based models, such as artificial neural networks or Gaussian processes, into model predictive control (MPC) strategies can significantly improve control performance and online adaptation capabilities for real-world applications. Still, enabling state-of-the-art implementations of learning-based models for MPC is complicated by the challenge of interfacing machine learning frameworks with real-time optimal control software. This work aims at filling this gap by incorporating external sensitivities in sequential quadratic programming solvers for nonlinear optimal control. To this end, we provide L4acados, a general framework for incorporating Python-based dynamics models in the real-time optimal control software acados. By computing external sensitivities via a user-defined Python module, L4acados enables the implementation of MPC controllers with learning-based residual models in acados, while supporting parallelization of sensitivity computations when preparing the quadratic subproblems. We demonstrate significant speed-ups and superior scaling properties of L4acados compared to available software using a neural-network-based control example. Last, we provide an efficient and modular real-time implementation of Gaussian process-based MPC using L4acados, which is applied to two hardware examples: autonomous miniature racing, as well as motion control of a full-scale autonomous vehicle for an ISO lane change maneuver.","authors":["Amon Lahr","Joshua Näf","Kim P. Wabersich","Jonathan Frey","Pascal Siehl","Andrea Carron","Moritz Diehl","Melanie N. Zeilinger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16469v2","updated":"2025-11-26T10:40:53Z","published":"2025-11-20T15:37:35Z","title":"Observer Design for Singularly Perturbed Linear Networked Control Systems Subject to Measurement Noise","summary":"This paper addresses the emulation-based observer design for linear networked control systems (NCS) operating at two time scales in the presence of measurement noise. The system is formulated as a hybrid singularly perturbed dynamical system, enabling the systematic use of singular perturbation techniques to derive explicit bounds on the maximum allowable transmission intervals (MATI) for both fast and slow communication channels. Under the resulting conditions, the proposed observer guarantees that the estimation error satisfies a global exponential derivative-input-to-state stability (DISS)-like property, where the ultimate bound scales proportionally with the magnitudes of the measurement noise and the time derivative of the control input. The effectiveness of the approach is illustrated through a numerical example.","authors":["Weixuan Wang","Alejandro I. Maass","Dragan Nešić","Ying Tan","Romain Postoyan","W. P. M. H. Heemels"],"pdf_url":"","comment":"9 pages, 2 figures, full version of the paper submitted to the IFAC World Congress"},{"id":"http://arxiv.org/abs/2511.21255v1","updated":"2025-11-26T10:38:53Z","published":"2025-11-26T10:38:53Z","title":"Design and Measurements of mmWave FMCW Radar Based Non-Contact Multi-Patient Heart Rate and Breath Rate Monitoring System","summary":"Recent developments in mmWave radar technologies have enabled the truly non-contact heart-rate (HR) and breath-rate (BR) measurement approaches, which provides a great ease in patient monitoring. Additionally, these technologies also provide opportunities to simultaneously detect HR and BR of multiple patients, which has become increasingly important for efficient mass monitoring scenarios. In this work, a frequency modulated continuous wave (FMCW) mmWave radar based truly non-contact multiple patient HR and BR monitoring system has been presented. Furthermore, a novel approach is also proposed, which combines multiple processing methods using a least squares solution to improve measurement accuracy, generalization, and handle measurement error. The proposed system has been developed using Texas Instruments' FMCW radar and experimental results with multiple subjects are also presented, which show >97% and >93% accuracy in the measured BR and HR values, respectively.","authors":["Jewel Benny","Pranjal Mahajan","Srayan Sankar Chatterjee","Mohd Wajid","Abhishek Srivastava"],"pdf_url":"","comment":"Presented at BioCAS 2023"},{"id":"http://arxiv.org/abs/2511.21248v1","updated":"2025-11-26T10:25:54Z","published":"2025-11-26T10:25:54Z","title":"Stability of data-driven Koopman MPC with terminal conditions","summary":"This paper derives conditions under which Model Predictive Control (MPC) with terminal conditions, using a data-driven surrogate model as a prediction model, asymptotically stabilizes the plant despite approximation errors. In particular, we prove recursive feasibility and asymptotic stability if a proportional error bound holds, where proportional means that the bound is linear in the norm of the state and the input. For a broad class of nonlinear systems, this condition can be satisfied using data-driven surrogate models generated by kernel Extended Dynamic Mode Decomposition (kEDMD) using the Koopman operator. Last, the applicability of the proposed framework is demonstrated in a numerical case study.","authors":["Irene Schimperna","Lea Bold","Johannes Köhler","Karl Worthmann","Lalo Magni"],"pdf_url":"","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2511.21235v1","updated":"2025-11-26T10:02:24Z","published":"2025-11-26T10:02:24Z","title":"DynamicAdaptiveClimb: Adaptive Cache Replacement with Dynamic Resizing","summary":"Efficient cache management is critical for optimizing the system performance, and numerous caching mechanisms have been proposed, each exploring various insertion and eviction strategies. In this paper, we present AdaptiveClimb and its extension, DynamicAdaptiveClimb, two novel cache replacement policies that leverage lightweight, cache adaptation to outperform traditional approaches. Unlike classic Least Recently Used (LRU) and Incremental Rank Progress (CLIMB) policies, AdaptiveClimb dynamically adjusts the promotion distance (jump) of the cached objects based on recent hit and miss patterns, requiring only a single tunable parameter and no per-item statistics. This enables rapid adaptation to changing access distributions while maintaining low overhead. Building on this foundation, DynamicAdaptiveClimb further enhances adaptability by automatically tuning the cache size in response to workload demands. Our comprehensive evaluation across a diverse set of real-world traces, including 1067 traces from 6 different datasets, demonstrates that DynamicAdaptiveClimb consistently achieves substantial speedups and higher hit ratios compared to other state-of-the-art algorithms. In particular, our approach achieves up to a 29% improvement in hit ratio and a substantial reduction in miss penalties compared to the FIFO baseline. Furthermore, it outperforms the next-best contenders, AdaptiveClimb and SIEVE [43], by approximately 10% to 15%, especially in environments characterized by fluctuating working set sizes. These results highlight the effectiveness of our approach in delivering efficient performance, making it well-suited for modern, dynamic caching environments.","authors":["Daniel Berend","Shlomi Dolev","Sweta Kumari","Dhruv Mishra","Marina Kogan-Sadetsky","Archit Somani"],"pdf_url":"","comment":"19 pages, 11 figures, 3 tables, Patented"},{"id":"http://arxiv.org/abs/2511.21228v1","updated":"2025-11-26T09:55:20Z","published":"2025-11-26T09:55:20Z","title":"From Consensus to Robust Clustering: Multi-Agent Systems with Nonlinear Interactions","summary":"This paper establishes a theoretical framework to describe the transition from consensus to stable clustering in multi-agent systems with nonlinear, cooperative interactions. We first establish a sharp threshold for consensus. For a broad class of non-decreasing, Lipschitz-continuous interactions, an explicit inequality linking the interaction's Lipschitz constant to the second-largest eigenvalue of the normalized adjacency matrix of the interaction graph confines all system equilibria to the synchronization manifold. This condition is shown to be a sharp threshold, as its violation permits the emergence of non-synchronized equilibria. We also demonstrate that such clustered states can only arise if the interaction law itself possesses specific structural properties, such as unstable fixed points. For the clustered states that emerge, we introduce a formal framework using Input-to-State Stability (ISS) theory to quantify their robustness. This approach allows us to prove that the internal cohesion of a cluster is robust to perturbations from the rest of the network. The analysis reveals a fundamental principle: cluster coherence is limited not by the magnitude of external influence, but by its heterogeneity across internal nodes. This unified framework, explaining both the sharp breakdown of consensus and the quantifiable robustness of the resulting modular structures, is validated on Zachary's Karate Club network, used as a classic benchmark for community structure.","authors":["Anthony Couthures","Gustave Bainier","Vineeth Satheeskumar Varma","Samson Lasaulce","Irinel-Constantin Morarescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21210v1","updated":"2025-11-26T09:40:12Z","published":"2025-11-26T09:40:12Z","title":"Accelerated ADMM: Automated Parameter Tuning and Improved Linear Convergence","summary":"This work studies the linear convergence of an accelerated scheme of the Alternating Direction Method of Multipliers (ADMM) for strongly convex and Lipschitz-smooth problems. We use the methodology of expressing the accelerated ADMM as a Lur'e system, i.e., an interconnection of a linear dynamical system in feedback with a slope-restricted operator, and we use Integral Quadratic Constraints to establish linear convergence. In addition, we propose several parameter tuning heuristics and their impact on the convergence rate through numerical analyses. Our new bounds show significantly improved linear convergence rates compared to the vanilla algorithm and previous proposed accelerated variants, which is also empirically validated on a LASSO regression benchmark.","authors":["Meisam Tavakoli","Fabian Jakob","Guido Carnevale","Giuseppe Notarstefano","Andrea Iannelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.09061v5","updated":"2025-11-26T09:29:30Z","published":"2025-07-11T22:36:39Z","title":"Action Chunking and Exploratory Data Collection Yield Exponential Improvements in Behavior Cloning for Continuous Control","summary":"This paper presents a theoretical analysis of two of the most impactful interventions in modern learning from demonstration in robotics and continuous control: the practice of action-chunking (predicting sequences of actions in open-loop) and exploratory augmentation of expert demonstrations. Though recent results show that learning from demonstration, also known as imitation learning (IL), can suffer errors that compound exponentially with task horizon in continuous settings, we demonstrate that action chunking and exploratory data collection circumvent exponential compounding errors in different regimes. Our results identify control-theoretic stability as the key mechanism underlying the benefits of these interventions. On the empirical side, we validate our predictions and the role of control-theoretic stability through experimentation on popular robot learning benchmarks. On the theoretical side, we demonstrate that the control-theoretic lens provides fine-grained insights into how compounding error arises, leading to tighter statistical guarantees on imitation learning error when these interventions are applied than previous techniques based on information-theoretic considerations alone.","authors":["Thomas T. Zhang","Daniel Pfrommer","Chaoyi Pan","Nikolai Matni","Max Simchowitz"],"pdf_url":"","comment":"Updated manuscript. New visualization figures and control-theory primer"},{"id":"http://arxiv.org/abs/2408.15041v2","updated":"2025-11-26T09:25:45Z","published":"2024-08-27T13:10:26Z","title":"Earth Observation Satellite Scheduling with Graph Neural Networks and Monte Carlo Tree Search","summary":"Earth Observation Satellite Planning (EOSP) is a difficult optimization problem with considerable practical interest. A set of requested observations must be scheduled on an agile Earth observation satellite while respecting constraints on their visibility window, as well as maneuver constraints that impose varying delays between successive observations. In addition, the problem is largely oversubscribed: there are much more candidate observations than can possibly be achieved. Therefore, one must select the set of observations that will be performed while maximizing their cumulative benefit and propose a feasible schedule for these observations. As previous work mostly focused on heuristic and iterative search algorithms, this paper presents a new technique for selecting and scheduling observations based on Graph Neural Networks (GNNs) and Deep Reinforcement Learning (DRL). GNNs are used to extract relevant information from the graphs representing instances of the EOSP, and DRL drives the search for optimal schedules. A post-learning search step based on Monte Carlo Tree Search (MCTS) is added that is able to find even better solutions. Experiments show that it is able to learn on small problem instances and generalize to larger real-world instances, with very competitive performance compared to traditional approaches.","authors":["Antoine Jacquet","Guillaume Infantes","Emmanuel Benazera","Vincent Baudoui","Jonathan Guerra","Stéphanie Roussel"],"pdf_url":"","comment":"Accepted at International Workshop on Planning & Scheduling for Space (IWPSS 2025)"},{"id":"http://arxiv.org/abs/2508.17033v3","updated":"2025-11-26T09:02:53Z","published":"2025-08-23T14:21:21Z","title":"Geometric Decentralized Stability Certificate for Power Systems Based on Projecting DW Shells","summary":"The development of decentralized stability conditions has gained considerable attention due to the need to analyze multi-agent network systems, such as heterogeneous multi-converter power systems. A recent advance is the application of the small-phase theorem, which extends the passivity theory. However, it requires the transfer function matrix to be sectorial, which may not hold in some frequency range and will result in conservativeness. To address this issue, this paper proposes a geometric decentralized stability condition based on Davis-Wielandt (DW) shell and its projections. Our approach provides a geometric interpretation of the small-gain and small-phase theorems and enables decentralized stability analysis of power systems. It serves as a visualization method to understand the closed-loop interactions and assess the stability of large-scale network systems in a scalable and modular manner.","authors":["Linbin Huang","Liangxiao Luo","Ruohan Leng","Huanhai Xin","Dan Wang","Florian Dörfler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04384v3","updated":"2025-11-26T08:45:32Z","published":"2025-07-06T13:14:35Z","title":"Rapid and Safe Trajectory Planning over Diverse Scenes through Diffusion Composition","summary":"Safe trajectory planning in complex environments must balance stringent collision avoidance with real-time efficiency, which is a long-standing challenge in robotics. In this work, we present a diffusion-based trajectory planning framework that is both rapid and safe. First, we introduce a scene-agnostic, MPC-based data generation pipeline that efficiently produces large volumes of kinematically feasible trajectories. Building on this dataset, our integrated diffusion planner maps raw onboard sensor inputs directly to kinematically feasible trajectories, enabling efficient inference while maintaining strong collision avoidance. To generalize to diverse, previously unseen scenarios, we compose diffusion models at test time, enabling safe behavior without additional training. We further propose a lightweight, rule-based safety filter that, from the candidate set, selects the trajectory meeting safety and kinematic-feasibility requirements. Across seen and unseen settings, the proposed method delivers real-time-capable inference with high safety and stability. Experiments on an F1TENTH vehicle demonstrate practicality on real hardware. Project page: https://rstp-comp-diffuser.github.io/.","authors":["Wule Mao","Zhouheng Li","Yunhao Luo","Yilun Du","Lei Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.05717v11","updated":"2025-11-26T08:17:06Z","published":"2024-07-08T08:21:22Z","title":"A New Framework for Nonlinear Kalman Filters","summary":"The Kalman filter (KF) is a state estimation algorithm that optimally combines system knowledge and measurements to minimize the mean squared error of the estimated states. While KF was initially designed for linear systems, numerous extensions of it, such as extended Kalman filter (EKF), unscented Kalman filter (UKF), cubature Kalman filter (CKF), etc., have been proposed for nonlinear systems over the last sixty years. Although different types of nonlinear KFs have different pros and cons, they all use the same framework of linear KF. Yet, according to our theoretical and empirical analysis, the framework tends to give overconfident and less accurate state estimations when the measurement functions are nonlinear. Therefore, in this study, we designed a new framework that can be combined with any existing type of nonlinear KFs and showed theoretically and empirically that the new framework estimates the states and covariance more accurately than the old one. The new framework was tested on four different nonlinear KFs and five different tasks, showcasing its ability to reduce estimation errors by several orders of magnitude in low-measurement-noise conditions. The codes are available at https://github.com/Shida-Jiang/A-new-framework-for-nonlinear-Kalman-filters","authors":["Shida Jiang","Junzhe Shi","Scott Moura"],"pdf_url":"","comment":"Massive revisions throughout the entire paper. More simulation results are added, and the mathematical expressions have become more rigorous and precise"},{"id":"http://arxiv.org/abs/2404.16318v3","updated":"2025-11-26T08:16:00Z","published":"2024-04-25T03:56:09Z","title":"Modeling, Analysis, and Control of Continuous-Time Weighted-Median Opinion Dynamics","summary":"Simple yet predictive mathematical models are essential for mechanistic understanding of opinion evolution in social groups. The weighted-median mechanism has recently been proposed as a well-founded alternative to conventional DeGroot-type opinion dynamics. However, the original weighted-median model excludes compromise behavior, as individuals directly adopt their neighbors' opinions without forming intermediate values. In this paper, we introduce a parsimonious continuous-time extension of the weighted-median model by incorporating individual inertia, allowing opinions to move gradually toward the neighbors' weighted median. Empirical evidence shows that this model outperforms both the original weighted-median and DeGroot models with inertia in predicting opinion shifts. We provide a complete theoretical analysis of the proposed dynamics: the equilibria are characterized and shown to be Lyapunov stable; global convergence is established via the Bony-Brezis method, yielding necessary and sufficient conditions for consensus from arbitrary initial states. In addition, we derive a graph-theoretic condition for persistent disagreement and a necessary and sufficient condition for steering the system to any prescribed consensus value through constant external inputs to a subset of individuals. These results reveal how a social group's resilience to external manipulation fundamentally depends on its internal network structure.","authors":["Yi Han","Julien M. Hendrickx","Ge Chen","Wenjun Mei"],"pdf_url":"","comment":"15 pages, 3 figure"},{"id":"http://arxiv.org/abs/2511.19770v2","updated":"2025-11-26T07:55:20Z","published":"2025-11-24T22:54:59Z","title":"Multi-Hypotheses Ego-Tracking for Resilient Navigation","summary":"Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vulnerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identification and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks","authors":["Peter Iwer Hoedt Karstensen","Roberto Galeazzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18579v2","updated":"2025-11-26T07:41:17Z","published":"2025-11-23T18:44:47Z","title":"Connectivity-Preserving Multi-Agent Area Coverage via Optimal-Transport-Based Density-Driven Optimal Control (D2OC)","summary":"Multi-agent systems play a central role in area coverage tasks across search-and-rescue, environmental monitoring, and precision agriculture. Achieving non-uniform coverage, where spatial priorities vary across the domain, requires coordinating agents while respecting dynamic and communication constraints. Density-driven approaches can distribute agents according to a prescribed reference density, but existing methods do not ensure connectivity. This limitation often leads to communication loss, reduced coordination, and degraded coverage performance.\n  This letter introduces a connectivity-preserving extension of the Density-Driven Optimal Control (D2OC) framework. The coverage objective, defined using the Wasserstein distance between the agent distribution and the reference density, admits a convex quadratic program formulation. Communication constraints are incorporated through a smooth connectivity penalty, which maintains strict convexity, supports distributed implementation, and preserves inter-agent communication without imposing rigid formations.\n  Simulation studies show that the proposed method consistently maintains connectivity, improves convergence speed, and enhances non-uniform coverage quality compared with density-driven schemes that do not incorporate explicit connectivity considerations.","authors":["Kooktae Lee","Ethan Brook"],"pdf_url":"","comment":"Under review in IEEE Control Systems Letters (LCSS). 6 pages"},{"id":"http://arxiv.org/abs/2511.20416v2","updated":"2025-11-26T06:32:46Z","published":"2025-11-25T15:40:23Z","title":"Nonuniform-Grid Markov Chain Approximation of Continuous Processes with Time-Linear Moments","summary":"We propose a method to approximate continuous-time, continuous-state stochastic processes by a discrete-time Markov chain defined on a nonuniform grid. Our method provides exact moment matching for processes whose first and second moments are linear functions of time. In particular, we show that, under certain conditions, the transition probabilities of a Markov chain can be chosen so that its first two moments match prescribed linear functions of time. These conditions depend on the grid points of the Markov chain and the coefficients of the linear mean and variance functions. Our proof relies on two recurrence relations for the expectation and variance across time. This approach enables simulation-based numerical analysis of continuous processes while preserving their key characteristics. We illustrate its efficacy by approximating continuous processes describing heat diffusion and geometric Brownian motion (GBM). For heat diffusion, we show that the heat profile at a set of points can be investigated by embedding those points inside the nonuniform grid of our Markov chain. For GBM, numerical simulations demonstrate that our approach, combined with suitable nonuniform grids, yields accurate approximations, with consistently small empirical Wasserstein-1 distances at long time horizons.","authors":["Do Hyun Kim","Ahmet Cetinkaya"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21041v1","updated":"2025-11-26T04:18:25Z","published":"2025-11-26T04:18:25Z","title":"Data-driven control of continuous-time systems: A synthesis-operator approach","summary":"This paper addresses data-driven control of continuous-time systems. We develop a framework based on synthesis operators associated with input and state trajectories. A key advantage of the proposed method is that it does not require the state derivative and uses continuous-time data directly without sampling or filtering. First, systems compatible with given data are described by the synthesis operators into which data trajectories are embedded. Next, we characterize data informativity properties for system identification and for stabilization. Finally, we establish a necessary and sufficient condition for informativity for quadratic stabilization in the presence of process noise. This condition is formulated as linear matrix inequalities by exploiting the finite-rank structure of the synthesis operators.","authors":["Masashi Wakaiki"],"pdf_url":"","comment":"14 pages"},{"id":"http://arxiv.org/abs/2511.08425v2","updated":"2025-11-26T03:40:18Z","published":"2025-11-11T16:33:57Z","title":"HardFlow: Hard-Constrained Sampling for Flow-Matching Models via Trajectory Optimization","summary":"Diffusion and flow-matching have emerged as powerful methodologies for generative modeling, with remarkable success in capturing complex data distributions and enabling flexible guidance at inference time. Many downstream applications, however, demand enforcing hard constraints on generated samples (for example, robot trajectories must avoid obstacles), a requirement that goes beyond simple guidance. Prevailing projection-based approaches constrain the entire sampling path to the constraint manifold, which is overly restrictive and degrades sample quality. In this paper, we introduce a novel framework that reformulates hard-constrained sampling as a trajectory optimization problem. Our key insight is to leverage numerical optimal control to steer the sampling trajectory so that constraints are satisfied precisely at the terminal time. By exploiting the underlying structure of flow-matching models and adopting techniques from model predictive control, we transform this otherwise complex constrained optimization problem into a tractable surrogate that can be solved efficiently and effectively. Furthermore, this trajectory optimization perspective offers significant flexibility beyond mere constraint satisfaction, allowing for the inclusion of integral costs to minimize distribution shift and terminal objectives to further enhance sample quality, all within a unified framework. We provide a control-theoretic analysis of our method, establishing bounds on the approximation error between our tractable surrogate and the ideal formulation. Extensive experiments across diverse domains, including robotics (planning), partial differential equations (boundary control), and vision (text-guided image editing), demonstrate that our algorithm, which we name $\\textit{HardFlow}$, substantially outperforms existing methods in both constraint satisfaction and sample quality.","authors":["Zeyang Li","Kaveh Alim","Navid Azizan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20995v1","updated":"2025-11-26T02:49:57Z","published":"2025-11-26T02:49:57Z","title":"An Exact, Finite Dimensional Representation for Full-Block, Circle Criterion Multipliers","summary":"This paper provides the first finite-dimensional characterization for the complete set of full-block, circle criterion multipliers. We consider the interconnection of a discrete-time, linear time-invariant system in feedback with a non-repeated, sector-bounded nonlinearity. Sufficient conditions for stability and performance can be derived using: (i) dissipation inequalities, and (ii) Quadratic Constraints (QCs) that bound the input/output pairs of the nonlinearity. Larger classes of QCs (or multipliers) reduce the conservatism of the conditions. Full-block, circle criterion multipliers define the complete set of all possible QCs for non-repeated, sector-bounded nonlinearities. These provide the least conservative conditions. However, full-block multipliers are defined by an uncountably infinite number of constraints and hence do not lead to computationally tractable solutions if left in this raw form. This paper provides a new finite-dimensional characterization for the set of full-block, circle criterion multipliers. The key theoretical insight is: the set of all input/output pairs of non-repeated sector-bounded nonlinearities is equal to the set of all incremental pairs for an appropriately constructed piecewise linear function. Our new description for the complete set of multipliers only requires a finite number of matrix copositivity constraints. These conditions have an exact, computationally tractable implementation for problems where the nonlinearity has small input/output dimensions $(\\le 4)$. We illustrate the use of our new characterization via a simple example.","authors":["Felix Biertümpfel","Bin Hu","Geir Dullerud","Peter Seiler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10215v2","updated":"2025-11-26T02:35:12Z","published":"2025-10-11T13:40:55Z","title":"Bounds of Validity for Bifurcations of Equilibria in a Class of Networked Dynamical Systems","summary":"Local bifurcation analysis plays a central role in understanding qualitative transitions in networked nonlinear dynamical systems, including dynamic neural network and opinion dynamics models. In this article we establish explicit bounds of validity for the classification of bifurcation diagrams in two classes of continuous-time networked dynamical systems, analogous in structure to the Hopfield and the Firing Rate dynamic neural network models. Our approach leverages recent advances in computing the bounds for the validity of Lyapunov-Schmidt reduction, a reduction method widely employed in nonlinear systems analysis. Using these bounds we rigorously characterize neighborhoods around bifurcation points where predictions from reduced-order models remain reliable. We further demonstrate how these bounds can be applied to an illustrative family of nonlinear opinion dynamics on k-regular graphs, which emerges as a special case of the general framework. These results provide new analytical tools for quantifying the robustness of bifurcation phenomena in dynamics over networked systems and highlight the interplay between network structure and nonlinear dynamical behavior.","authors":["Pranav Gupta","Ravi Banavar","Anastasia Bizyaeva"],"pdf_url":"","comment":"This manuscript has been submitted to the 2026 American Control Conference taking place in New Orleans, Louisiana, in May 2026"},{"id":"http://arxiv.org/abs/2511.20977v1","updated":"2025-11-26T02:11:22Z","published":"2025-11-26T02:11:22Z","title":"Independent policy gradient-based reinforcement learning for economic and reliable energy management of multi-microgrid systems","summary":"Efficiency and reliability are both crucial for energy management, especially in multi-microgrid systems (MMSs) integrating intermittent and distributed renewable energy sources. This study investigates an economic and reliable energy management problem in MMSs under a distributed scheme, where each microgrid independently updates its energy management policy in a decentralized manner to optimize the long-term system performance collaboratively. We introduce the mean and variance of the exchange power between the MMS and the main grid as indicators for the economic performance and reliability of the system. Accordingly, we formulate the energy management problem as a mean-variance team stochastic game (MV-TSG), where conventional methods based on the maximization of expected cumulative rewards are unsuitable for variance metrics. To solve MV-TSGs, we propose a fully distributed independent policy gradient algorithm, with rigorous convergence analysis, for scenarios with known model parameters. For large-scale scenarios with unknown model parameters, we further develop a deep reinforcement learning algorithm based on independent policy gradients, enabling data-driven policy optimization. Numerical experiments in two scenarios validate the effectiveness of the proposed methods. Our approaches fully leverage the distributed computational capabilities of MMSs and achieve a well-balanced trade-off between economic performance and operational reliability.","authors":["Junkai Hu","Li Xia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20939v1","updated":"2025-11-26T00:14:13Z","published":"2025-11-26T00:14:13Z","title":"Data-Driven Post-Event Analysis with Real-World Oscillation Data from Denmark","summary":"This paper demonstrates how Extended Dynamic Mode Decomposition (EDMD), grounded in Koopman operator theory, can effectively identify the main contributor(s) to oscillations in power grids. We use PMU data recorded from a real 0.15 Hz oscillation event in Denmark for post-event analysis. To this end, the EDMD algorithm processed only voltage and current phasors from nineteen PMUs at different voltage levels across the Danish grid. In such a blind-test setting with no supplementary system information, EDMD accurately pinpointed the location of the main contributor to the 0.2 Hz oscillation, consistent with the location of the problematic IBR plant later confirmed by Energinet, where the underlying cause was a control system issue. Conventional approaches, such as the dissipating energy flow (DEF) method used in the ISO-NE OSL tool did not clearly identify this plant. This joint validation with Energinet, reinforcing earlier studies using simulated IBR-dominated systems and real PMU data from ISO-NE, highlights the potential of EDMD-based post-event analysis for identifying major oscillation contributors and enabling targeted SSO mitigation.","authors":["Youhong Chen","Debraj Bhattacharjee","Balarko Chaudhuri","Mark O Malley","Nan Qin","Adrian Pilkaer Expethit"],"pdf_url":"","comment":"5 pages, 6 figures, real power network event data, submitted to IEEE General Meeting 2026"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2511.21690v1","updated":"2025-11-26T18:59:55Z","published":"2025-11-26T18:59:55Z","title":"TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos","summary":"Learning new robot tasks on new platforms and in new scenes from only a handful of demonstrations remains challenging. While videos of other embodiments - humans and different robots - are abundant, differences in embodiment, camera, and environment hinder their direct use. We address the small-data problem by introducing a unifying, symbolic representation - a compact 3D \"trace-space\" of scene-level trajectories - that enables learning from cross-embodiment, cross-environment, and cross-task videos. We present TraceGen, a world model that predicts future motion in trace-space rather than pixel space, abstracting away appearance while retaining the geometric structure needed for manipulation. To train TraceGen at scale, we develop TraceForge, a data pipeline that transforms heterogeneous human and robot videos into consistent 3D traces, yielding a corpus of 123K videos and 1.8M observation-trace-language triplets. Pretraining on this corpus produces a transferable 3D motion prior that adapts efficiently: with just five target robot videos, TraceGen attains 80% success across four tasks while offering 50-600x faster inference than state-of-the-art video-based world models. In the more challenging case where only five uncalibrated human demonstration videos captured on a handheld phone are available, it still reaches 67.5% success on a real robot, highlighting TraceGen's ability to adapt across embodiments without relying on object detectors or heavy pixel-space generation.","authors":["Seungjae Lee","Yoonkyo Jung","Inkook Chun","Yao-Chih Lee","Zikui Cai","Hongjia Huang","Aayush Talreja","Tan Dat Dao","Yongyuan Liang","Jia-Bin Huang","Furong Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21689v1","updated":"2025-11-26T18:59:46Z","published":"2025-11-26T18:59:46Z","title":"ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration","summary":"Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools. ToolOrchestra explicitly uses reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards. Using ToolOrchestra, we produce Orchestrator, an 8B model that achieves higher accuracy at lower cost than previous tool-use agents while aligning with user preferences on which tools are to be used for a given query. On HLE, Orchestrator achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being 2.5x more efficient. On tau2-Bench and FRAMES, Orchestrator surpasses GPT-5 by a wide margin while using only about 30% of the cost. Extensive analysis shows that Orchestrator achieves the best trade-off between performance and cost under multiple metrics, and generalizes robustly to unseen tools. These results demonstrate that composing diverse tools with a lightweight orchestration model is both more efficient and more effective than existing methods, paving the way for practical and scalable tool-augmented reasoning systems.","authors":["Hongjin Su","Shizhe Diao","Ximing Lu","Mingjie Liu","Jiacheng Xu","Xin Dong","Yonggan Fu","Peter Belcak","Hanrong Ye","Hongxu Yin","Yi Dong","Evelina Bakhturina","Tao Yu","Yejin Choi","Jan Kautz","Pavlo Molchanov"],"pdf_url":"","comment":"21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.21686v1","updated":"2025-11-26T18:59:28Z","published":"2025-11-26T18:59:28Z","title":"Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework","summary":"Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are hardcoded for specific domains, limiting flexibility. We present \\textbf{Matrix}, a decentralized framework that represents both control and data flow as serialized messages passed through distributed queues. This peer-to-peer design eliminates the central orchestrator. Each task progresses independently through lightweight agents, while compute-intensive operations, such as LLM inference or containerized environments, are handled by distributed services. Built on Ray, Matrix scales to tens of thousands of concurrent agentic workflows and provides a modular, configurable design that enables easy adaptation to a wide range of data generation workflows. We evaluate Matrix across diverse synthesis scenarios, such as multi-agent collaborative dialogue, web-based reasoning data extraction, and tool-use trajectory generation in customer service environments. In all cases, Matrix achieves $2$--$15\\times$ higher data generation throughput under identical hardware resources, without compromising output quality.","authors":["Dong Wang","Yang Li","Ansong Ni","Ching-Feng Yeh","Youssef Emad","Xinjie Lei","Liam Robbins","Karthik Padthe","Hu Xu","Xian Li","Asli Celikyilmaz","Ramya Raghavendra","Lifei Huang","Carole-Jean Wu","Shang-Wen Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21678v1","updated":"2025-11-26T18:55:08Z","published":"2025-11-26T18:55:08Z","title":"Agentic Learner with Grow-and-Refine Multimodal Semantic Memory","summary":"MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.","authors":["Weihao Bo","Shan Zhang","Yanpeng Sun","Jingjing Wu","Qunyi Xie","Xiao Tan","Kunbin Chen","Wei He","Xiaofan Li","Na Zhao","Jingdong Wang","Zechao Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21675v1","updated":"2025-11-26T18:53:46Z","published":"2025-11-26T18:53:46Z","title":"On Evolution-Based Models for Experimentation Under Interference","summary":"Causal effect estimation in networked systems is central to data-driven decision making. In such settings, interventions on one unit can spill over to others, and in complex physical or social systems, the interaction pathways driving these interference structures remain largely unobserved. We argue that for identifying population-level causal effects, it is not necessary to recover the exact network structure; instead, it suffices to characterize how those interactions contribute to the evolution of outcomes. Building on this principle, we study an evolution-based approach that investigates how outcomes change across observation rounds in response to interventions, hence compensating for missing network information. Using an exposure-mapping perspective, we give an axiomatic characterization of when the empirical distribution of outcomes follows a low-dimensional recursive equation, and identify minimal structural conditions under which such evolution mappings exist. We frame this as a distributional counterpart to difference-in-differences. Rather than assuming parallel paths for individual units, it exploits parallel evolution patterns across treatment scenarios to estimate counterfactual trajectories. A key insight is that treatment randomization plays a role beyond eliminating latent confounding; it induces an implicit sampling from hidden interference channels, enabling consistent learning about heterogeneous spillover effects. We highlight causal message passing as an instantiation of this method in dense networks while extending to more general interference structures, including influencer networks where a small set of units drives most spillovers. Finally, we discuss the limits of this approach, showing that strong temporal trends or endogenous interference can undermine identification.","authors":["Sadegh Shirani","Mohsen Bayati"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21669v1","updated":"2025-11-26T18:47:25Z","published":"2025-11-26T18:47:25Z","title":"DSD: A Distributed Speculative Decoding Solution for Edge-Cloud Agile Large Model Serving","summary":"Large language model (LLM) inference often suffers from high decoding latency and limited scalability across heterogeneous edge-cloud environments. Existing speculative decoding (SD) techniques accelerate token generation but remain confined to single-node execution. We propose DSD, a distributed speculative decoding framework that extends SD to multi-device deployments through coordinated draft-target execution. Given the lack of prior work on simulating this paradigm, we first introduce DSD-Sim, a discrete-event simulator that captures network, batching, and scheduling dynamics. Building on insights from DSD-Sim, we further design an Adaptive Window Control (AWC) policy that dynamically adjusts speculation window size to optimize throughput. Experiments across diverse workloads show that DSD achieves up to 1.1x speedup and 9.7% higher throughput over existing SD baselines, enabling agile and scalable LLM serving across edge and cloud.","authors":["Fengze Yu","Leshu Li","Brad McDanel","Saiqian Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21668v1","updated":"2025-11-26T18:44:02Z","published":"2025-11-26T18:44:02Z","title":"Through the telecom lens: Are all training samples important?","summary":"The rise of AI in telecommunications, from optimizing Radio Access Networks to managing user experience, has sharply increased data volumes and training demands. Telecom data is often noisy, high-dimensional, costly to store, process, and label. Despite Ai's critical role, standard workflows still assume all training samples contribute equally. On the other hand, next generation systems require AI models that are accurate, efficient, and sustainable.The paper questions the assumptions of equal importance by focusing on applying and analyzing the roles of individual samples in telecom training and assessing whether the proposed model optimizes computation and energy use. we perform sample-level gradient analysis across epochs to identify patterns of influence and redundancy in model learning. Based on this, we propose a sample importance framework thats electively prioritizes impactful data and reduces computation without compromising accuracy. Experiments on three real-world telecom datasets show that our method [reserves performance while reducing data needs and computational overhead while advancing the goals of sustainable AI in telecommunications.","authors":["Shruti Bothe","Illyyne Saffar","Aurelie Boisbunon","Hasan Farooq","Julien Forgeat","Md Moin Uddin Chowdhury"],"pdf_url":"","comment":"8pages, 1 table, 8 figures"},{"id":"http://arxiv.org/abs/2511.21667v1","updated":"2025-11-26T18:42:52Z","published":"2025-11-26T18:42:52Z","title":"Escaping the Verifier: Learning to Reason via Demonstrations","summary":"Training Large Language Models (LLMs) to reason often relies on Reinforcement Learning (RL) with task-specific verifiers. However, many real-world reasoning-intensive tasks lack verifiers, despite offering abundant expert demonstrations that remain under-utilized for reasoning-focused training. We introduce RARO (Relativistic Adversarial Reasoning Optimization) that learns strong reasoning capabilities from only expert demonstrations via Inverse Reinforcement Learning. Our method sets up an adversarial interaction between a policy (generator) and a relativistic critic (discriminator): the policy learns to mimic expert answers, while the critic learns to compare and distinguish between policy and expert answers. Our method trains both the policy and the critic jointly and continuously via RL, and we identify the key stabilization techniques required for robust learning. Empirically, RARO significantly outperforms strong verifier-free baselines on all of our evaluation tasks -- Countdown, DeepMath, and Poetry Writing -- and enjoys the same robust scaling trends as RL on verifiable tasks. These results demonstrate that our method effectively elicits strong reasoning performance from expert demonstrations alone, enabling robust reasoning learning even when task-specific verifiers are unavailable.","authors":["Locke Cai","Ivan Provilkov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21654v1","updated":"2025-11-26T18:27:17Z","published":"2025-11-26T18:27:17Z","title":"EvilGenie: A Reward Hacking Benchmark","summary":"We introduce EvilGenie, a benchmark for reward hacking in programming settings. We source problems from LiveCodeBench and create an environment in which agents can easily reward hack, such as by hardcoding test cases or editing the testing files. We measure reward hacking in three ways: held out unit tests, LLM judges, and test file edit detection. We verify these methods against human review and each other. We find the LLM judge to be highly effective at detecting reward hacking in unambiguous cases, and observe only minimal improvement from the use of held out test cases. In addition to testing many models using Inspect's basic_agent scaffold, we also measure reward hacking rates for three popular proprietary coding agents: OpenAI's Codex, Anthropic's Claude Code, and Google's Gemini CLI Using GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro, respectively. We observe explicit reward hacking by both Codex and Claude Code, and misaligned behavior by all three agents. Our codebase can be found at https://github.com/JonathanGabor/EvilGenie.","authors":["Jonathan Gabor","Jayson Lynch","Jonathan Rosenfeld"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21652v1","updated":"2025-11-26T18:24:11Z","published":"2025-11-26T18:24:11Z","title":"Continual Error Correction on Low-Resource Devices","summary":"The proliferation of AI models in everyday devices has highlighted a critical challenge: prediction errors that degrade user experience. While existing solutions focus on error detection, they rarely provide efficient correction mechanisms, especially for resource-constrained devices. We present a novel system enabling users to correct AI misclassifications through few-shot learning, requiring minimal computational resources and storage. Our approach combines server-side foundation model training with on-device prototype-based classification, enabling efficient error correction through prototype updates rather than model retraining. The system consists of two key components: (1) a server-side pipeline that leverages knowledge distillation to transfer robust feature representations from foundation models to device-compatible architectures, and (2) a device-side mechanism that enables ultra-efficient error correction through prototype adaptation. We demonstrate our system's effectiveness on both image classification and object detection tasks, achieving over 50% error correction in one-shot scenarios on Food-101 and Flowers-102 datasets while maintaining minimal forgetting (less than 0.02%) and negligible computational overhead. Our implementation, validated through an Android demonstration app, proves the system's practicality in real-world scenarios.","authors":["Kirill Paramonov","Mete Ozay","Aristeidis Mystakidis","Nikolaos Tsalikidis","Dimitrios Sotos","Anastasios Drosou","Dimitrios Tzovaras","Hyunjun Kim","Kiseok Chang","Sangdok Mo","Namwoong Kim","Woojong Yoo","Jijoong Moon","Umberto Michieli"],"pdf_url":"","comment":"ACM MMSys 2025"},{"id":"http://arxiv.org/abs/2509.15392v2","updated":"2025-11-26T18:15:04Z","published":"2025-09-18T19:58:31Z","title":"Learning in Stackelberg Mean Field Games: A Non-Asymptotic Analysis","summary":"We study policy optimization in Stackelberg mean field games (MFGs), a hierarchical framework for modeling the strategic interaction between a single leader and an infinitely large population of homogeneous followers. The objective can be formulated as a structured bi-level optimization problem, in which the leader needs to learn a policy maximizing its reward, anticipating the response of the followers. Existing methods for solving these (and related) problems often rely on restrictive independence assumptions between the leader's and followers' objectives, use samples inefficiently due to nested-loop algorithm structure, and lack finite-time convergence guarantees. To address these limitations, we propose AC-SMFG, a single-loop actor-critic algorithm that operates on continuously generated Markovian samples. The algorithm alternates between (semi-)gradient updates for the leader, a representative follower, and the mean field, and is simple to implement in practice. We establish the finite-time and finite-sample convergence of the algorithm to a stationary point of the Stackelberg objective. To our knowledge, this is the first Stackelberg MFG algorithm with non-asymptotic convergence guarantees. Our key assumption is a \"gradient alignment\" condition, which requires that the full policy gradient of the leader can be approximated by a partial component of it, relaxing the existing leader-follower independence assumption. Simulation results in a range of well-established economics environments demonstrate that AC-SMFG outperforms existing multi-agent and MFG learning baselines in policy quality and convergence speed.","authors":["Sihan Zeng","Benjamin Patrick Evans","Sujay Bhatt","Leo Ardon","Sumitra Ganesh","Alec Koppel"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21638v1","updated":"2025-11-26T18:12:16Z","published":"2025-11-26T18:12:16Z","title":"Aligning LLMs Toward Multi-Turn Conversational Outcomes Using Iterative PPO","summary":"Optimizing large language models (LLMs) for multi-turn conversational outcomes remains a significant challenge, especially in goal-oriented settings like AI marketing or sales agents who facilitate transactions via messaging platforms. The difficulty stems from sparse, long-horizon rewards and the discrepancy between response-level planning and token-level generation. In this technical note, we propose a formal reduction of the multi-turn RL problem into a sequence of single-turn RLHF-style problems. This is achieved by setting a learned multi-turn Q-function as the reward model for the single-turn problem. We demonstrate and prove a key insight: solving this single-turn RL problem with standard token-level PPO is equivalent to a policy improvement step within the multi-turn problem. This insight naturally leads to Iterative PPO, a batch online policy iteration algorithm that alternates between fitting Q-functions from logged conversation trajectories and improving the policy. A major practical advantage is that Iterative PPO directly leverages stable, off-the-shelf single-turn RLHF tools, making it straightforward to implement. Our method occupies a middle ground between fully online and fully offline approaches, retaining the adaptability of online updates while gaining the stability benefits of offline training.","authors":["Daniel R. Jiang","Jalaj Bhandari","Yukai Yang","Rémi Munos","Tyler Lu"],"pdf_url":"","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2505.09432v3","updated":"2025-11-26T18:12:07Z","published":"2025-05-14T14:37:32Z","title":"Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenchel-Young Losses","summary":"Surrogate regret bounds, also known as excess risk bounds, bridge the gap between the convergence rates of surrogate and target losses. The regret transfer is lossless if the surrogate regret bound is linear. While convex smooth surrogate losses are appealing in particular due to the efficient estimation and optimization, the existence of a trade-off between the loss smoothness and linear regret bound has been believed in the community. Under this scenario, the better optimization and estimation properties of convex smooth surrogate losses may inevitably deteriorate after undergoing the regret transfer onto a target loss. We overcome this dilemma for arbitrary discrete target losses by constructing a convex smooth surrogate loss, which entails a linear surrogate regret bound composed with a tailored prediction link. The construction is based on Fenchel--Young losses generated by the convolutional negentropy, which are equivalent to the infimal convolution of a generalized negentropy and the target Bayes risk. Consequently, the infimal convolution enables us to derive a smooth loss while maintaining the surrogate regret bound linear. We additionally benefit from the infimal convolution to have a consistent estimator of the underlying class probability. Our results are overall a novel demonstration of how convex analysis penetrates into optimization and statistical efficiency in risk minimization.","authors":["Yuzhou Cao","Han Bao","Lei Feng","Bo An"],"pdf_url":"","comment":"NeurIPS 2025 camera-ready"},{"id":"http://arxiv.org/abs/2510.19021v2","updated":"2025-11-26T18:08:14Z","published":"2025-10-21T19:02:51Z","title":"Category learning in deep neural networks: Information content and geometry of internal representations","summary":"In humans and other animals, category learning enhances discrimination between stimuli close to the category boundary. This phenomenon, called categorical perception, was also empirically observed in artificial neural networks trained on classification tasks. In previous modeling works based on neuroscience data, we show that this expansion/compression is a necessary outcome of efficient learning. Here we extend our theoretical framework to artificial networks. We show that minimizing the Bayes cost (mean of the cross-entropy loss) implies maximizing the mutual information between the set of categories and the neural activities prior to the decision layer. Considering structured data with an underlying feature space of small dimension, we show that maximizing the mutual information implies (i) finding an appropriate projection space, and, (ii) building a neural representation with the appropriate metric. The latter is based on a Fisher information matrix measuring the sensitivity of the neural activity to changes in the projection space. Optimal learning makes this neural Fisher information follow a category-specific Fisher information, measuring the sensitivity of the category membership. Category learning thus induces an expansion of neural space near decision boundaries. We characterize the properties of the categorical Fisher information, showing that its eigenvectors give the most discriminant directions at each point of the projection space. We find that, unexpectedly, its maxima are in general not exactly at, but near, the class boundaries. Considering toy models and the MNIST dataset, we numerically illustrate how after learning the two Fisher information matrices match, and essentially align with the category boundaries. Finally, we relate our approach to the Information Bottleneck one, and we exhibit a bias-variance decomposition of the Bayes cost, of interest on its own.","authors":["Laurent Bonnasse-Gahot","Jean-Pierre Nadal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21635v1","updated":"2025-11-26T18:07:14Z","published":"2025-11-26T18:07:14Z","title":"Mechanisms of Non-Monotonic Scaling in Vision Transformers","summary":"Deeper Vision Transformers often perform worse than shallower ones, which challenges common scaling assumptions. Through a systematic empirical analysis of ViT-S, ViT-B, and ViT-L on ImageNet, we identify a consistent three-phase Cliff-Plateau-Climb pattern that governs how representations evolve with depth. We observe that better performance is associated with progressive marginalization of the [CLS] token, originally designed as a global aggregation hub, in favor of distributed consensus among patch tokens. We quantify patterns of information mixing with an Information Scrambling Index, and show that in ViT-L the information-task tradeoff emerges roughly 10 layers later than in ViT-B, and that these additional layers correlate with increased information diffusion rather than improved task performance. Taken together, these results suggest that transformer architectures in this regime may benefit more from carefully calibrated depth that executes clean phase transitions than from simply increasing parameter count. The Information Scrambling Index provides a useful diagnostic for existing models and suggests a potential design target for future architectures. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb.","authors":["Anantha Padmanaban Krishna Kumar"],"pdf_url":"","comment":"16 pages total (11 pages main text, 1 pages references, 4 pages appendix), 5 figures, 11 tables. Code available at https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb"},{"id":"http://arxiv.org/abs/2509.24125v2","updated":"2025-11-26T18:02:39Z","published":"2025-09-28T23:48:11Z","title":"The Impossibility of Inverse Permutation Learning in Transformer Models","summary":"In this technical note, we study the problem of inverse permutation learning in decoder-only transformers. Given a permutation and a string to which that permutation has been applied, the model is tasked with producing the original (``canonical'') string. We argue that this task models a natural robustness property across a variety of reasoning tasks, including long-context retrieval, multiple choice QA and in-context learning. Our primary contribution is an impossibility result: we show that an arbitrary depth, decoder-only transformer cannot learn this task. This result concerns the expressive capacity of decoder-only transformer models and is agnostic to training dynamics or sample complexity. We give a pair of alternative constructions under which inverse permutation learning is feasible. The first of these highlights the fundamental role of the causal attention mask, and reveals a gap between the expressivity of encoder-decoder transformers and the more popular decoder-only architecture. The latter result is more surprising: we show that simply padding the input with ``scratch tokens\" yields a construction under which inverse permutation learning is possible. We conjecture that this may suggest an alternative mechanism by which chain-of-thought prompting or, more generally, intermediate ``thinking'' tokens can enable reasoning in large language models, even when these tokens encode no meaningful semantic information (e.g., the results of intermediate computations).","authors":["Rohan Alur","Chris Hays","Manish Raghavan","Devavrat Shah"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21626v1","updated":"2025-11-26T17:52:05Z","published":"2025-11-26T17:52:05Z","title":"Scale-Agnostic Kolmogorov-Arnold Geometry in Neural Networks","summary":"Recent work by Freedman and Mulligan demonstrated that shallow multilayer perceptrons spontaneously develop Kolmogorov-Arnold geometric (KAG) structure during training on synthetic three-dimensional tasks. However, it remained unclear whether this phenomenon persists in realistic high-dimensional settings and what spatial properties this geometry exhibits.\n  We extend KAG analysis to MNIST digit classification (784 dimensions) using 2-layer MLPs with systematic spatial analysis at multiple scales. We find that KAG emerges during training and appears consistently across spatial scales, from local 7-pixel neighborhoods to the full 28x28 image. This scale-agnostic property holds across different training procedures: both standard training and training with spatial augmentation produce the same qualitative pattern. These findings reveal that neural networks spontaneously develop organized, scale-invariant geometric structure during learning on realistic high-dimensional data.","authors":["Mathew Vanherreweghe","Michael H. Freedman","Keith M. Adams"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21622v1","updated":"2025-11-26T17:46:31Z","published":"2025-11-26T17:46:31Z","title":"On the Origin of Algorithmic Progress in AI","summary":"Algorithms have been estimated to increase AI training FLOP efficiency by a factor of 22,000 between 2012 and 2023 [Ho et al., 2024]. Running small-scale ablation experiments on key innovations from this time period, we are able to account for less than 10x of these gains. Surveying the broader literature, we estimate that additional innovations not included in our ablations account for less than 10x, yielding a total under 100x. This leads us to conduct scaling experiments, which reveal that much of this efficiency gap can be explained by algorithms with scale-dependent efficiency improvements. In particular, we conduct scaling experiments between LSTMs and Transformers, finding exponent differences in their compute-optimal scaling law while finding little scaling difference for many other innovations. These experiments demonstrate that - contrary to standard assumptions - an algorithm's efficiency gains are tied to compute scale. Using experimental extrapolation and literature estimates, we account for 6,930x efficiency gains over the same time period, with the scale-dependent LSTM-to-Transformer transition accounting for the majority of gains. Our results indicate that algorithmic progress for small models has been far slower than previously assumed, and that measures of algorithmic efficiency are strongly reference-dependent.","authors":["Hans Gundlach","Alex Fogelson","Jayson Lynch","Ana Trisovic","Jonathan Rosenfeld","Anmol Sandhu","Neil Thompson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19693v2","updated":"2025-11-26T17:43:31Z","published":"2025-11-24T20:57:31Z","title":"TREASURE: A Transformer-Based Foundation Model for High-Volume Transaction Understanding","summary":"Payment networks form the backbone of modern commerce, generating high volumes of transaction records from daily activities. Properly modeling this data can enable applications such as abnormal behavior detection and consumer-level insights for hyper-personalized experiences, ultimately improving people's lives. In this paper, we present TREASURE, TRansformer Engine As Scalable Universal transaction Representation Encoder, a multipurpose transformer-based foundation model specifically designed for transaction data. The model simultaneously captures both consumer behavior and payment network signals (such as response codes and system flags), providing comprehensive information necessary for applications like accurate recommendation systems and abnormal behavior detection. Verified with industry-grade datasets, TREASURE features three key capabilities: 1) an input module with dedicated sub-modules for static and dynamic attributes, enabling more efficient training and inference; 2) an efficient and effective training paradigm for predicting high-cardinality categorical attributes; and 3) demonstrated effectiveness as both a standalone model that increases abnormal behavior detection performance by 111% over production systems and an embedding provider that enhances recommendation models by 104%. We present key insights from extensive ablation studies, benchmarks against production models, and case studies, highlighting valuable knowledge gained from developing TREASURE.","authors":["Chin-Chia Michael Yeh","Uday Singh Saini","Xin Dai","Xiran Fan","Shubham Jain","Yujie Fan","Jiarui Sun","Junpeng Wang","Menghai Pan","Yingtong Dou","Yuzhong Chen","Vineeth Rakesh","Liang Wang","Yan Zheng","Mahashweta Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21613v1","updated":"2025-11-26T17:36:31Z","published":"2025-11-26T17:36:31Z","title":"Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining","summary":"Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.","authors":["Dongyang Fan","Diba Hashemi","Sai Praneeth Karimireddy","Martin Jaggi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01695v3","updated":"2025-11-26T17:29:51Z","published":"2025-11-03T16:04:44Z","title":"Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding","summary":"The growing demand for on-device large language model (LLM) inference highlights the need for efficient mobile edge computing (MEC) solutions, especially in resource-constrained settings. Speculative decoding offers a promising solution by partitioning token generation between a lightweight draft model on mobile devices and a powerful target model on edge servers, but suffers from communication overhead and asynchronous delays. This paper is the first to propose a unified framework that jointly optimizes user association and resource allocation (UARA) to support efficient parallel speculative decoding. We solve the UARA problem using a multi-agent deep reinforcement learning algorithm. To evaluate our approach under realistic conditions, we conduct experiments using the Sionna simulator. Results show that our method achieves up to 28.0% and an average of 23.7% reduction in end-to-end latency without compromising inference accuracy, enabling scalable and low-latency LLM services in MEC systems.","authors":["Jungyeon Koh","Hyun Jong Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21607v1","updated":"2025-11-26T17:27:59Z","published":"2025-11-26T17:27:59Z","title":"Beyond Accuracy: An Empirical Study of Uncertainty Estimation in Imputation","summary":"Handling missing data is a central challenge in data-driven analysis. Modern imputation methods not only aim for accurate reconstruction but also differ in how they represent and quantify uncertainty. Yet, the reliability and calibration of these uncertainty estimates remain poorly understood. This paper presents a systematic empirical study of uncertainty in imputation, comparing representative methods from three major families: statistical (MICE, SoftImpute), distribution alignment (OT-Impute), and deep generative (GAIN, MIWAE, TabCSDI). Experiments span multiple datasets, missingness mechanisms (MCAR, MAR, MNAR), and missingness rates. Uncertainty is estimated through three complementary routes: multi-run variability, conditional sampling, and predictive-distribution modeling, and evaluated using calibration curves and the Expected Calibration Error (ECE). Results show that accuracy and calibration are often misaligned: models with high reconstruction accuracy do not necessarily yield reliable uncertainty. We analyze method-specific trade-offs among accuracy, calibration, and runtime, identify stable configurations, and offer guidelines for selecting uncertainty-aware imputers in data cleaning and downstream machine learning pipelines.","authors":["Zarin Tahia Hossain","Mostafa Milani"],"pdf_url":"","comment":"To appear in conference proceedings"},{"id":"http://arxiv.org/abs/2511.00209v2","updated":"2025-11-26T17:21:10Z","published":"2025-10-31T19:11:41Z","title":"Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides","summary":"Diffusion models have emerged as a leading framework in generative modeling, poised to transform the traditionally slow and costly process of drug discovery. This review provides a systematic comparison of their application in designing two principal therapeutic modalities: small molecules and therapeutic peptides. We dissect how the unified framework of iterative denoising is adapted to the distinct molecular representations, chemical spaces, and design objectives of each modality. For small molecules, these models excel at structure-based design, generating novel, pocket-fitting ligands with desired physicochemical properties, yet face the critical hurdle of ensuring chemical synthesizability. Conversely, for therapeutic peptides, the focus shifts to generating functional sequences and designing de novo structures, where the primary challenges are achieving biological stability against proteolysis, ensuring proper folding, and minimizing immunogenicity. Despite these distinct challenges, both domains face shared hurdles: the scarcity of high-quality experimental data, the reliance on inaccurate scoring functions for validation, and the crucial need for experimental validation. We conclude that the full potential of diffusion models will be unlocked by bridging these modality-specific gaps and integrating them into automated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby shifting the paradigm from mere chemical exploration to the on-demand engineering of novel~therapeutics.","authors":["Yiquan Wang","Yahui Ma","Yuhan Chang","Jiayao Yan","Jialin Zhang","Minnuo Cai","Kai Wei"],"pdf_url":"","comment":"Published in Biology"},{"id":"http://arxiv.org/abs/2511.21600v1","updated":"2025-11-26T17:16:14Z","published":"2025-11-26T17:16:14Z","title":"TAB-DRW: A DFT-based Robust Watermark for Generative Tabular Data","summary":"The rise of generative AI has enabled the production of high-fidelity synthetic tabular data across fields such as healthcare, finance, and public policy, raising growing concerns about data provenance and misuse. Watermarking offers a promising solution to address these concerns by ensuring the traceability of synthetic data, but existing methods face many limitations: they are computationally expensive due to reliance on large diffusion models, struggle with mixed discrete-continuous data, or lack robustness to post-modifications. To address them, we propose TAB-DRW, an efficient and robust post-editing watermarking scheme for generative tabular data. TAB-DRW embeds watermark signals in the frequency domain: it normalizes heterogeneous features via the Yeo-Johnson transformation and standardization, applies the discrete Fourier transform (DFT), and adjusts the imaginary parts of adaptively selected entries according to precomputed pseudorandom bits. To further enhance robustness and efficiency, we introduce a novel rank-based pseudorandom bit generation method that enables row-wise retrieval without incurring storage overhead. Experiments on five benchmark tabular datasets show that TAB-DRW achieves strong detectability and robustness against common post-processing attacks, while preserving high data fidelity and fully supporting mixed-type features.","authors":["Yizhou Zhao","Xiang Li","Peter Song","Qi Long","Weijie Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21594v1","updated":"2025-11-26T17:11:39Z","published":"2025-11-26T17:11:39Z","title":"Visualizing LLM Latent Space Geometry Through Dimensionality Reduction","summary":"Large language models (LLMs) achieve state-of-the-art results across many natural language tasks, but their internal mechanisms remain difficult to interpret. In this work, we extract, process, and visualize latent state geometries in Transformer-based language models through dimensionality reduction. We capture layerwise activations at multiple points within Transformer blocks and enable systematic analysis through Principal Component Analysis (PCA) and Uniform Manifold Approximation (UMAP). We demonstrate experiments on GPT-2 and LLaMa models, where we uncover interesting geometric patterns in latent space. Notably, we identify a clear separation between attention and MLP component outputs across intermediate layers, a pattern not documented in prior work to our knowledge. We also characterize the high norm of latent states at the initial sequence position and visualize the layerwise evolution of latent states. Additionally, we demonstrate the high-dimensional helical structure of GPT-2's positional embeddings, the sequence-wise geometric patterns in LLaMa, and experiment with repeating token sequences. We aim to support systematic analysis of Transformer internals with the goal of enabling further reproducible interpretability research. We make our code available at https://github.com/Vainateya/Feature_Geometry_Visualization.","authors":["Alex Ning","Vainateya Rangaraju"],"pdf_url":"","comment":"24 pages, 16 figures"},{"id":"http://arxiv.org/abs/2511.21590v1","updated":"2025-11-26T17:08:06Z","published":"2025-11-26T17:08:06Z","title":"An AI-Enabled Hybrid Cyber-Physical Framework for Adaptive Control in Smart Grids","summary":"Smart grids are a fusion of classical power infrastructure and advanced communication networks and smart control, to create a cyber-physical environment that is more efficient and flexible than ever before. This integration causes vulnerabilities that can undermine grid stability as well as reliability. Digital forensics is a fundamental concept of learning and identifying, detecting, and mitigating such security incidents. This paper presents an all-in-one machine learning-based digital forensic framework of smart grid systems deployed on the Cloud. The framework combines the data acquisition at the sensor-level, authenticated communication, scalable cloud storage and automated forensic analytics. The model uses supervised and unsupervised learning algorithms - such as Random Forest, Support Vector Machine, Gradient Boosted Trees and deep neural architectures for anomaly detection, event reconstruction and intrusion analysis in real time. After several simulation and experimental studies on real-time smart-meter data streams, the proposed framework is shown to be very accurate, scalable and resilient to cyber-attacks including data tampering, false-data injection and coordinated control-loop manipulation. The results indicate that cloud services are the best backbone for big-data-driven forensic workflows, which allows energy utilities to achieve a fast situational awareness and intelligent incident response.","authors":["Muhammad Siddique","Sohaib Zafar"],"pdf_url":"","comment":"16 pages, 11 figures, IEEEaccess journal"},{"id":"http://arxiv.org/abs/2511.21581v1","updated":"2025-11-26T16:54:06Z","published":"2025-11-26T16:54:06Z","title":"Learning When to Stop: Adaptive Latent Reasoning via Reinforcement Learning","summary":"Latent reasoning represents a new development in Transformer language models that has shown potential in compressing reasoning lengths compared to chain-of-thought reasoning. By directly passing the information-rich previous final latent state into the next sequence, latent reasoning removes the restriction to human language tokens as the medium for reasoning. We develop adaptive-length latent reasoning models and introduce a post-SFT reinforcement-learning methodology to optimize latent reasoning length by minimizing reasoning length while maintaining accuracy. This, in turn, further reduces compute usage and raises the bar on the compressive capabilities of latent reasoning models. Experiments on the Llama 3.2 1B model and the GSM8K-Aug dataset show a $52\\%$ drop in total reasoning length with no penalty to accuracy. In future work, we plan to extend to additional models and datasets, analyze relationships between training coefficients, experiment with architecture variations, and continue our knowledge distillation for latent reasoning SFT efforts. We make our code and pretrained weights available at https://github.com/apning/adaptive-latent-reasoning.","authors":["Alex Ning","Yen-Ling Kuo","Gabe Gomes"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.10660v3","updated":"2025-11-26T16:42:37Z","published":"2025-06-12T12:50:38Z","title":"Constructing Extreme Heatwave Storylines with Differentiable Climate Models","summary":"Understanding the plausible upper bounds of extreme weather events is essential for risk assessment in a warming climate. Existing methods, based on large ensembles of physics-based models, are often computationally expensive or lack the fidelity needed to simulate rare, high-impact extremes. Here, we present a novel framework that leverages a differentiable hybrid climate model, NeuralGCM, to optimize initial conditions and generate physically consistent worst-case heatwave trajectories. Applied to the 2021 Pacific Northwest heatwave, our method produces heatwave intensity up to 3.7 $^\\circ$C above the most extreme member of a 75-member ensemble. These trajectories feature intensified atmospheric blocking and amplified Rossby wave patterns-hallmarks of severe heat events. Our results demonstrate that differentiable climate models can efficiently explore the upper tails of event likelihoods, providing a powerful new approach for constructing targeted storylines of extreme weather under climate change.","authors":["Tim Whittaker","Alejandro Di Luca"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21566v1","updated":"2025-11-26T16:40:41Z","published":"2025-11-26T16:40:41Z","title":"A decoupled alignment kernel for peptide membrane permeability predictions","summary":"Cyclic peptides are promising modalities for targeting intracellular sites; however, cell-membrane permeability remains a key bottleneck, exacerbated by limited public data and the need for well-calibrated uncertainty. Instead of relying on data-eager complex deep learning architecture, we propose a monomer-aware decoupled global alignment kernel (MD-GAK), which couples chemically meaningful residue-residue similarity with sequence alignment while decoupling local matches from gap penalties. MD-GAK is a relatively simple kernel. To further demonstrate the robustness of our framework, we also introduce a variant, PMD-GAK, which incorporates a triangular positional prior. As we will show in the experimental section, PMD-GAK can offer additional advantages over MD-GAK, particularly in reducing calibration errors. Since our focus is on uncertainty estimation, we use Gaussian Processes as the predictive model, as both MD-GAK and PMD-GAK can be directly applied within this framework. We demonstrate the effectiveness of our methods through an extensive set of experiments, comparing our fully reproducible approach against state-of-the-art models, and show that it outperforms them across all metrics.","authors":["Ali Amirahmadi","Gökçe Geylan","Leonardo De Maria","Farzaneh Etminani","Mattias Ohlsson","Alessandro Tibo"],"pdf_url":"","comment":"submitted to Journal of Cheminformatics"},{"id":"http://arxiv.org/abs/2511.10234v2","updated":"2025-11-26T16:39:11Z","published":"2025-11-13T12:06:12Z","title":"Lost in Serialization: Invariance and Generalization of LLM Graph Reasoners","summary":"While promising, graph reasoners based on Large Language Models (LLMs) lack built-in invariance to symmetries in graph representations. Operating on sequential graph serializations, LLMs can produce different outputs under node reindexing, edge reordering, or formatting changes, raising robustness concerns. We systematically analyze these effects, studying how fine-tuning impacts encoding sensitivity as well generalization on unseen tasks. We propose a principled decomposition of graph serializations into node labeling, edge encoding, and syntax, and evaluate LLM robustness to variations of each of these factors on a comprehensive benchmarking suite. We also contribute a novel set of spectral tasks to further assess generalization abilities of fine-tuned reasoners. Results show that larger (non-fine-tuned) models are more robust. Fine-tuning reduces sensitivity to node relabeling but may increase it to variations in structure and format, while it does not consistently improve performance on unseen tasks.","authors":["Daniel Herbst","Lea Karbevska","Divyanshu Kumar","Akanksha Ahuja","Fatemeh Gholamzadeh Nasrabadi","Fabrizio Frasca"],"pdf_url":"","comment":"AAAI 2026 Workshop on Graphs and more Complex Structures For Learning and Reasoning (GCLR). Version 2 fixes typos in author name and Figure 1"},{"id":"http://arxiv.org/abs/2506.06158v2","updated":"2025-11-26T16:36:22Z","published":"2025-06-06T15:25:14Z","title":"ENMA: Tokenwise Autoregression for Generative Neural PDE Operators","summary":"Solving time-dependent parametric partial differential equations (PDEs) remains a fundamental challenge for neural solvers, particularly when generalizing across a wide range of physical parameters and dynamics. When data is uncertain or incomplete-as is often the case-a natural approach is to turn to generative models. We introduce ENMA, a generative neural operator designed to model spatio-temporal dynamics arising from physical phenomena. ENMA predicts future dynamics in a compressed latent space using a generative masked autoregressive transformer trained with flow matching loss, enabling tokenwise generation. Irregularly sampled spatial observations are encoded into uniform latent representations via attention mechanisms and further compressed through a spatio-temporal convolutional encoder. This allows ENMA to perform in-context learning at inference time by conditioning on either past states of the target trajectory or auxiliary context trajectories with similar dynamics. The result is a robust and adaptable framework that generalizes to new PDE regimes and supports one-shot surrogate modeling of time-dependent parametric PDEs.","authors":["Armand Kassaï Koupaï","Lise Le Boudec","Louis Serrano","Patrick Gallinari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21561v1","updated":"2025-11-26T16:33:59Z","published":"2025-11-26T16:33:59Z","title":"Machine Learning Approaches to Clinical Risk Prediction: Multi-Scale Temporal Alignment in Electronic Health Records","summary":"This study proposes a risk prediction method based on a Multi-Scale Temporal Alignment Network (MSTAN) to address the challenges of temporal irregularity, sampling interval differences, and multi-scale dynamic dependencies in Electronic Health Records (EHR). The method focuses on temporal feature modeling by introducing a learnable temporal alignment mechanism and a multi-scale convolutional feature extraction structure to jointly model long-term trends and short-term fluctuations in EHR sequences. At the input level, the model maps multi-source clinical features into a unified high-dimensional semantic space and employs temporal embedding and alignment modules to dynamically weight irregularly sampled data, reducing the impact of temporal distribution differences on model performance. The multi-scale feature extraction module then captures key patterns across different temporal granularities through multi-layer convolution and hierarchical fusion, achieving a fine-grained representation of patient states. Finally, an attention-based aggregation mechanism integrates global temporal dependencies to generate individual-level risk representations for disease risk prediction and health status assessment. Experiments conducted on publicly available EHR datasets show that the proposed model outperforms mainstream baselines in accuracy, recall, precision, and F1-Score, demonstrating the effectiveness and robustness of multi-scale temporal alignment in complex medical time-series analysis. This study provides a new solution for intelligent representation of high-dimensional asynchronous medical sequences and offers important technical support for EHR-driven clinical risk prediction.","authors":["Wei-Chen Chang","Lu Dai","Ting Xu"],"pdf_url":"","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.21560v1","updated":"2025-11-26T16:30:38Z","published":"2025-11-26T16:30:38Z","title":"Computing Strategic Responses to Non-Linear Classifiers","summary":"We consider the problem of strategic classification, where the act of deploying a classifier leads to strategic behaviour that induces a distribution shift on subsequent observations. Current approaches to learning classifiers in strategic settings are focused primarily on the linear setting, but in many cases non-linear classifiers are more suitable. A central limitation to progress for non-linear classifiers arises from the inability to compute best responses in these settings. We present a novel method for computing the best response by optimising the Lagrangian dual of the Agents' objective. We demonstrate that our method reproduces best responses in linear settings, identifying key weaknesses in existing approaches. We present further results demonstrating our method can be straight-forwardly applied to non-linear classifier settings, where it is useful for both evaluation and training.","authors":["Jack Geary","Boyan Gao","Henry Gouk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21550v1","updated":"2025-11-26T16:21:36Z","published":"2025-11-26T16:21:36Z","title":"MMA: A Momentum Mamba Architecture for Human Activity Recognition with Inertial Sensors","summary":"Human activity recognition (HAR) from inertial sensors is essential for ubiquitous computing, mobile health, and ambient intelligence. Conventional deep models such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and transformers have advanced HAR but remain limited by vanishing or exloding gradients, high computational cost, and difficulty in capturing long-range dependencies. Structured state-space models (SSMs) like Mamba address these challenges with linear complexity and effective temporal modeling, yet they are restricted to first-order dynamics without stable longterm memory mechanisms. We introduce Momentum Mamba, a momentum-augmented SSM that incorporates second-order dynamics to improve stability of information flow across time steps, robustness, and long-sequence modeling. Two extensions further expand its capacity: Complex Momentum Mamba for frequency-selective memory scaling. Experiments on multiple HAR benchmarks demonstrate consistent gains over vanilla Mamba and Transformer baselines in accuracy, robustness, and convergence speed. With only moderate increases in training cost, momentum-augmented SSMs offer a favorable accuracy-efficiency balance, establishing them as a scalable paradigm for HAR and a promising principal framework for broader sequence modeling applications.","authors":["Thai-Khanh Nguyen","Uyen Vo","Tan M. Nguyen","Thieu N. Vo","Trung-Hieu Le","Cuong Pham"],"pdf_url":"","comment":"14 pages, 5 pages"},{"id":"http://arxiv.org/abs/2511.18671v2","updated":"2025-11-26T16:09:23Z","published":"2025-11-24T01:04:42Z","title":"Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition","summary":"Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others' learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified k-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.","authors":["Yan Wang","Ke Deng","Yongli Ren"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21537v1","updated":"2025-11-26T16:06:36Z","published":"2025-11-26T16:06:36Z","title":"Context-Specific Causal Graph Discovery with Unobserved Contexts: Non-Stationarity, Regimes and Spatio-Temporal Patterns","summary":"Real-world data, for example in climate applications, often consists of spatially gridded time series data or data with comparable structure. While the underlying system is often believed to behave similar at different points in space and time, those variations that do exist are twofold relevant: They often encode important information in and of themselves. And they may negatively affect the stability / convergence and reliability\\Slash{}validity of results of algorithms assuming stationarity or space-translation invariance. We study the information encoded in changes of the causal graph, with stability in mind. An analysis of this general task identifies two core challenges. We develop guiding principles to overcome these challenges, and provide a framework realizing these principles by modifying constraint-based causal discovery approaches on the level of independence testing. This leads to an extremely modular, easily extensible and widely applicable framework. It can leverage existing constraint-based causal discovery methods (demonstrated on IID-algorithms PC, PC-stable, FCI and time series algorithms PCMCI, PCMCI+, LPCMCI) with little to no modification. The built-in modularity allows to systematically understand and improve upon an entire array of subproblems. By design, it can be extended by leveraging insights from change-point-detection, clustering, independence-testing and other well-studied related problems. The division into more accessible sub-problems also simplifies the understanding of fundamental limitations, hyperparameters controlling trade-offs and the statistical interpretation of results. An open-source implementation will be available soon.","authors":["Martin Rabel","Jakob Runge"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.19387v2","updated":"2025-11-26T16:01:53Z","published":"2025-05-26T01:04:56Z","title":"Alignment of large language models with constrained learning","summary":"We study the problem of computing an optimal large language model (LLM) policy for the constrained alignment problem, where the goal is to maximize a primary reward objective while satisfying constraints on secondary utilities. Despite the popularity of Lagrangian-based LLM policy search in constrained alignment, iterative primal-dual methods often fail to converge, and non-iterative dual-based methods do not achieve optimality in the LLM parameter space. To address these challenges, we employ Lagrangian duality to develop an iterative dual-based alignment method that alternates between updating the LLM policy via Lagrangian maximization and updating the dual variable via dual descent. In theory, we characterize the primal-dual gap between the primal value in the distribution space and the dual value in the LLM parameter space. We further quantify the optimality gap of the learned LLM policies at near-optimal dual variables with respect to both the objective and the constraint functions. These results prove that dual-based alignment methods can find an optimal constrained LLM policy, up to an LLM parametrization gap. We demonstrate the effectiveness and merits of our approach through extensive experiments conducted on the PKU-SafeRLHF and Anthropic HH-RLHF datasets.","authors":["Botong Zhang","Shuo Li","Ignacio Hounie","Osbert Bastani","Dongsheng Ding","Alejandro Ribeiro"],"pdf_url":"","comment":"51 pages, 5 figures, 11 tables; Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2408.10901v4","updated":"2025-11-26T16:00:49Z","published":"2024-08-20T14:43:53Z","title":"A Gray-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse","summary":"Recent advancements in Latent Diffusion Models (LDMs) have revolutionized image synthesis and manipulation, raising significant concerns about data misappropriation and intellectual property infringement. While adversarial attacks have been extensively explored as a protective measure against such misuse of generative AI, current approaches are severely limited by their heavy reliance on model-specific knowledge and substantial computational costs. Drawing inspiration from the posterior collapse phenomenon observed in VAE training, we propose the Posterior Collapse Attack (PCA), a novel framework for protecting images from unauthorized manipulation. Through comprehensive theoretical analysis and empirical validation, we identify two distinct collapse phenomena during VAE inference: diffusion collapse and concentration collapse. Based on this discovery, we design a unified loss function that can flexibly achieve both types of collapse through parameter adjustment, each corresponding to different protection objectives in preventing image manipulation. Our method significantly reduces dependence on model-specific knowledge by requiring access to only the VAE encoder, which constitutes less than 4\\% of LDM parameters. Notably, PCA achieves prompt-invariant protection by operating on the VAE encoder before text conditioning occurs, eliminating the need for empty prompt optimization required by existing methods. This minimal requirement enables PCA to maintain adequate transferability across various VAE-based LDM architectures while effectively preventing unauthorized image editing. Extensive experiments show PCA outperforms existing techniques in protection effectiveness, computational efficiency (runtime and VRAM), and generalization across VAE-based LDM variants. Our code is available at https://github.com/ZhongliangGuo/PosteriorCollapseAttack.","authors":["Zhongliang Guo","Chun Tong Lei","Lei Fang","Shuai Zhao","Yifei Qian","Jingyu Lin","Zeyu Wang","Cunjian Chen","Ognjen Arandjelović","Chun Pong Lau"],"pdf_url":"","comment":"15 pages, 9 figures, 9 tables"},{"id":"http://arxiv.org/abs/2511.21531v1","updated":"2025-11-26T15:59:55Z","published":"2025-11-26T15:59:55Z","title":"Predictive Safety Shield for Dyna-Q Reinforcement Learning","summary":"Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.","authors":["Jin Pin","Krasowski Hanna","Vanneaux Elena"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08604v2","updated":"2025-11-26T15:56:35Z","published":"2025-06-10T09:13:37Z","title":"Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation","summary":"Generative machine learning methods, such as diffusion models and flow matching, have shown great potential in modeling complex system behaviors and building efficient surrogate models. However, these methods typically learn the underlying physics implicitly from data. We propose Physics-Based Flow Matching (PBFM), a novel generative framework that explicitly embeds physical constraints, both PDE residuals and algebraic relations, into the flow matching objective. We also introduce temporal unrolling at training time that improves the accuracy of the final, noise-free sample prediction. Our method jointly minimizes the flow matching loss and the physics-based residual loss without requiring hyperparameter tuning of their relative weights. Additionally, we analyze the role of the minimum noise level, $σ_{\\min}$, in the context of physical constraints and evaluate a stochastic sampling strategy that helps to reduce physical residuals. Through extensive benchmarks on three representative PDE problems, we show that our approach yields up to an $8\\times$ more accurate physical residuals compared to FM, while clearly outperforming existing algorithms in terms of distributional accuracy. PBFM thus provides a principled and efficient framework for surrogate modeling, uncertainty quantification, and accelerated simulation in physics and engineering applications.","authors":["Giacomo Baldan","Qiang Liu","Alberto Guardone","Nils Thuerey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21526v1","updated":"2025-11-26T15:54:17Z","published":"2025-11-26T15:54:17Z","title":"Phase Transition for Stochastic Block Model with more than $\\sqrt{n}$ Communities (II)","summary":"A fundamental theoretical question in network analysis is to determine under which conditions community recovery is possible in polynomial time in the Stochastic Block Model (SBM). When the number $K$ of communities remains smaller than $\\sqrt{n}$ --where $n$ denotes the number of nodes--, non-trivial community recovery is possible in polynomial time above, and only above, the Kesten--Stigum (KS) threshold, originally postulated using arguments from statistical physics.\n  When $K \\geq \\sqrt{n}$, Chin, Mossel, Sohn, and Wein recently proved that, in the \\emph{sparse regime}, community recovery in polynomial time is achievable below the KS threshold by counting non-backtracking paths. This finding led them to postulate a new threshold for the many-communities regime $K \\geq \\sqrt{n}$. Subsequently, Carpentier, Giraud, and Verzelen established the failure of low-degree polynomials below this new threshold across all density regimes, and demonstrated successful recovery above the threshold in certain moderately sparse settings. While these results provide strong evidence that, in the many community setting, the computational barrier lies at the threshold proposed in~Chin et al., the question of achieving recovery above this threshold still remains open in most density regimes.\n  The present work is a follow-up to~Carpentier et al., in which we prove Conjecture~1.4 stated therein by: \\\\ 1- Constructing a family of motifs satisfying specific structural properties; and\\\\ 2- Proving that community recovery is possible above the proposed threshold by counting such motifs.\\\\ Our results complete the picture of the computational barrier for community recovery in the SBM with $K \\geq \\sqrt{n}$ communities. They also indicate that, in moderately sparse regimes, the optimal algorithms appear to be fundamentally different from spectral methods.","authors":["Alexandra Carpentier","Christophe Giraud","Nicolas Verzelen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21514v1","updated":"2025-11-26T15:46:29Z","published":"2025-11-26T15:46:29Z","title":"Mechanistic Interpretability for Transformer-based Time Series Classification","summary":"Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks.","authors":["Matīss Kalnāre","Sofoklis Kitharidis","Thomas Bäck","Niki van Stein"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21513v1","updated":"2025-11-26T15:46:22Z","published":"2025-11-26T15:46:22Z","title":"IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference","summary":"Deploying Transformer models on edge devices is limited by latency and energy budgets. While INT8 quantization effectively accelerates the primary matrix multiplications, it exposes the softmax as the dominant bottleneck. This stage incurs a costly dequantize-softmax-requantize detour, which can account for up to 65% of total attention latency and disrupts the end-to-end integer dataflow critical for edge hardware efficiency. To address this limitation, we present IntAttention, the first fully integer, plug-and-play attention pipeline without retraining. At the core of our approach lies IndexSoftmax, a hardware-friendly operator that replaces floating-point exponentials entirely within the integer domain. IntAttention integrates sparsity-aware clipping, a 32-entry lookup-table approximation, and direct integer normalization, thereby eliminating all datatype conversion overhead. We evaluate IntAttention and demonstrate consistent and substantial gains. Our method achieves up to 3.7x speedup and 61% energy reduction over FP16 baselines and 2.0x faster than conventional INT8 attention pipelines on Armv8 CPUs. These gains are achieved with high-fidelity accuracy comparable to baselines across diverse language and vision models, enabling practical and efficient Transformer inference on commodity edge devices. Code will be released in later version of this work.","authors":["Wanli Zhong","Haibo Feng","Zirui Zhou","Hanyang Peng","Shiqi Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.19474v2","updated":"2025-11-26T15:39:26Z","published":"2025-10-22T11:11:42Z","title":"g-DPO: Scalable Preference Optimization for Protein Language Models","summary":"Direct Preference Optimization (DPO) is an effective approach for aligning protein language models with experimental design goals. However, DPO faces a scalability bottleneck: the number of possible training pairs grows quadratically with the number of labeled sequences, leading to prohibitive training times even for modestly sized datasets. We introduce g-DPO, a framework that (i) uses sequence space clustering to prune redundant pairs while preserving training signal, and (ii) amortizes likelihood computations with group-based approximations. Across three protein engineering tasks, g-DPO maintains in silico and in vitro performance that is statistically indistinguishable from standard DPO, while converging 1.7x to 5.4x times faster, with speedups that scale with dataset size and the structure of the underlying mutational landscape.","authors":["Constance Ferragu","Jonathan D. Ziegler","Nicolas Deutschmann","Arthur Lindoulsi","Eli Bixby","Cradle ML Team"],"pdf_url":"","comment":"Accepted at two workshops: FM4LS NeurIPS 2025 (https://nips2025fm4ls.github.io/pages/accepted-paper.html) and MLSB in Copenhagen EurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21500v1","updated":"2025-11-26T15:31:22Z","published":"2025-11-26T15:31:22Z","title":"Lost in Time? A Meta-Learning Framework for Time-Shift-Tolerant Physiological Signal Transformation","summary":"Translating non-invasive signals such as photoplethysmography (PPG) and ballistocardiography (BCG) into clinically meaningful signals like arterial blood pressure (ABP) is vital for continuous, low-cost healthcare monitoring. However, temporal misalignment in multimodal signal transformation impairs transformation accuracy, especially in capturing critical features like ABP peaks. Conventional synchronization methods often rely on strong similarity assumptions or manual tuning, while existing Learning with Noisy Labels (LNL) approaches are ineffective under time-shifted supervision, either discarding excessive data or failing to correct label shifts. To address this challenge, we propose ShiftSyncNet, a meta-learning-based bi-level optimization framework that automatically mitigates performance degradation due to time misalignment. It comprises a transformation network (TransNet) and a time-shift correction network (SyncNet), where SyncNet learns time offsets between training pairs and applies Fourier phase shifts to align supervision signals. Experiments on one real-world industrial dataset and two public datasets show that ShiftSyncNet outperforms strong baselines by 9.4%, 6.0%, and 12.8%, respectively. The results highlight its effectiveness in correcting time shifts, improving label quality, and enhancing transformation accuracy across diverse misalignment scenarios, pointing toward a unified direction for addressing temporal inconsistencies in multimodal physiological transformation.","authors":["Qian Hong","Cheng Bian","Xiao Zhou","Xiaoyu Li","Yelei Li","Zijing Zeng"],"pdf_url":"","comment":"The 40th Annual AAAI Conference on Artificial Intelligence (AAAI 26)"},{"id":"http://arxiv.org/abs/2506.10899v3","updated":"2025-11-26T15:29:08Z","published":"2025-06-12T17:06:43Z","title":"Demystifying Spectral Feature Learning for Instrumental Variable Regression","summary":"We address the problem of causal effect estimation in the presence of hidden confounders, using nonparametric instrumental variable (IV) regression. A leading strategy employs spectral features - that is, learned features spanning the top eigensubspaces of the operator linking treatments to instruments. We derive a generalization error bound for a two-stage least squares estimator based on spectral features, and gain insights into the method's performance and failure modes. We show that performance depends on two key factors, leading to a clear taxonomy of outcomes. In a good scenario, the approach is optimal. This occurs with strong spectral alignment, meaning the structural function is well-represented by the top eigenfunctions of the conditional operator, coupled with this operator's slow eigenvalue decay, indicating a strong instrument. Performance degrades in a bad scenario: spectral alignment remains strong, but rapid eigenvalue decay (indicating a weaker instrument) demands significantly more samples for effective feature learning. Finally, in the ugly scenario, weak spectral alignment causes the method to fail, regardless of the eigenvalues' characteristics. Our synthetic experiments empirically validate this taxonomy. We further introduce a practical procedure to estimate these spectral properties from data, allowing practitioners to diagnose which regime a given problem falls into. We apply this method to the dSprites dataset, demonstrating its utility.","authors":["Dimitri Meunier","Antoine Moulin","Jakub Wornbard","Vladimir R. Kostic","Arthur Gretton"],"pdf_url":"","comment":"Updated to the NeurIPS 2025 camera-ready version"},{"id":"http://arxiv.org/abs/2402.14746v5","updated":"2025-11-26T15:27:50Z","published":"2024-02-22T18:06:19Z","title":"Scaling Efficient LLMs","summary":"Recent LLMs have hundreds of billions of parameters consuming vast resources. Furthermore, the so called \"AI scaling law\" for transformers suggests that the number of parameters must scale linearly with the size of the data. In response, we inquire into efficient LLMs, i.e. those with the fewest parameters that achieve the desired accuracy on a training corpus. Specifically, by comparing theoretical and empirical estimates of the Kullback-Leibler divergence, we derive a natural AI scaling law that the number of parameters in an efficient LLM scales as $D^γ$ where $D$ is the size of the training data and $ γ\\in [0.44, 0.72]$, suggesting the existence of more efficient architectures. Against this backdrop, we propose recurrent transformers, combining the efficacy of transformers with the efficiency of recurrent networks, progressively applying a single transformer layer to a fixed-width sliding window across the input sequence. Recurrent transformers (a) run in linear time in the sequence length, (b) are memory-efficient and amenable to parallel processing in large batches, (c) learn to forget history for language tasks, or accumulate history for long range tasks like copy and selective copy, and (d) are amenable to curriculum training to overcome vanishing gradients. In our experiments, we find that recurrent transformers perform favorably on benchmark tests.","authors":["B. N. Kausik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21490v1","updated":"2025-11-26T15:24:53Z","published":"2025-11-26T15:24:53Z","title":"Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning","summary":"We present a novel training approach, named Merge-and-Bound (M&B) for Class Incremental Learning (CIL), which directly manipulates model weights in the parameter space for optimization. Our algorithm involves two types of weight merging: inter-task weight merging and intra-task weight merging. Inter-task weight merging unifies previous models by averaging the weights of models from all previous stages. On the other hand, intra-task weight merging facilitates the learning of current task by combining the model parameters within current stage. For reliable weight merging, we also propose a bounded update technique that aims to optimize the target model with minimal cumulative updates and preserve knowledge from previous tasks; this strategy reveals that it is possible to effectively obtain new models near old ones, reducing catastrophic forgetting. M&B is seamlessly integrated into existing CIL methods without modifying architecture components or revising learning objectives. We extensively evaluate our algorithm on standard CIL benchmarks and demonstrate superior performance compared to state-of-the-art methods.","authors":["Taehoon Kim","Donghwan Jang","Bohyung Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21474v1","updated":"2025-11-26T15:06:19Z","published":"2025-11-26T15:06:19Z","title":"Going with the Speed of Sound: Pushing Neural Surrogates into Highly-turbulent Transonic Regimes","summary":"The widespread use of neural surrogates in automotive aerodynamics, enabled by datasets such as DrivAerML and DrivAerNet++, has primarily focused on bluff-body flows with large wakes. Extending these methods to aerospace, particularly in the transonic regime, remains challenging due to the high level of non-linearity of compressible flows and 3D effects such as wingtip vortices. Existing aerospace datasets predominantly focus on 2D airfoils, neglecting these critical 3D phenomena. To address this gap, we present a new dataset of CFD simulations for 3D wings in the transonic regime. The dataset comprises volumetric and surface-level fields for around $30,000$ samples with unique geometry and inflow conditions. This allows computation of lift and drag coefficients, providing a foundation for data-driven aerodynamic optimization of the drag-lift Pareto front. We evaluate several state-of-the-art neural surrogates on our dataset, including Transolver and AB-UPT, focusing on their out-of-distribution (OOD) generalization over geometry and inflow variations. AB-UPT demonstrates strong performance for transonic flowfields and reproduces physically consistent drag-lift Pareto fronts even for unseen wing configurations. Our results demonstrate that AB-UPT can approximate drag-lift Pareto fronts for unseen geometries, highlighting its potential as an efficient and effective tool for rapid aerodynamic design exploration. To facilitate future research, we open-source our dataset at https://huggingface.co/datasets/EmmiAI/Emmi-Wing.","authors":["Fabian Paischer","Leo Cotteleer","Yann Dreze","Richard Kurle","Dylan Rubini","Maurits Bleeker","Tobias Kronlachner","Johannes Brandstetter"],"pdf_url":"","comment":"NeurIPS 2025 ML4PS Workshop"},{"id":"http://arxiv.org/abs/2511.21466v1","updated":"2025-11-26T14:58:07Z","published":"2025-11-26T14:58:07Z","title":"Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization","summary":"We study two-layer neural networks and train these with a particle-based method called consensus-based optimization (CBO). We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. In the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. Finally, in the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically.","authors":["William De Deyn","Michael Herty","Giovanni Samaey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21465v1","updated":"2025-11-26T14:57:59Z","published":"2025-11-26T14:57:59Z","title":"Ensemble Performance Through the Lens of Linear Independence of Classifier Votes in Data Streams","summary":"Ensemble learning improves classification performance by combining multiple base classifiers. While increasing the number of classifiers generally enhances accuracy, excessively large ensembles can lead to computational inefficiency and diminishing returns. This paper investigates the relationship between ensemble size and performance through the lens of linear independence among classifier votes in data streams. We propose that ensembles composed of linearly independent classifiers maximize representational capacity, particularly under a geometric model. We then generalize the importance of linear independence to the weighted majority voting problem. By modeling the probability of achieving linear independence among classifier outputs, we derive a theoretical framework that explains the trade-off between ensemble size and accuracy. Our analysis leads to a theoretical estimate of the ensemble size required to achieve a user-specified probability of linear independence. We validate our theory through experiments on both real-world and synthetic datasets using two ensemble methods, OzaBagging and GOOWE. Our results confirm that this theoretical estimate effectively identifies the point of performance saturation for robust ensembles like OzaBagging. Conversely, for complex weighting schemes like GOOWE, our framework reveals that high theoretical diversity can trigger algorithmic instability. Our implementation is publicly available to support reproducibility and future research.","authors":["Enes Bektas","Fazli Can"],"pdf_url":"","comment":"14 pages, 3 figures, 5 tables"},{"id":"http://arxiv.org/abs/2511.19399v2","updated":"2025-11-26T14:52:10Z","published":"2025-11-24T18:35:54Z","title":"DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research","summary":"Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.","authors":["Rulin Shao","Akari Asai","Shannon Zejiang Shen","Hamish Ivison","Varsha Kishore","Jingming Zhuo","Xinran Zhao","Molly Park","Samuel G. Finlayson","David Sontag","Tyler Murray","Sewon Min","Pradeep Dasigi","Luca Soldaini","Faeze Brahman","Wen-tau Yih","Tongshuang Wu","Luke Zettlemoyer","Yoon Kim","Hannaneh Hajishirzi","Pang Wei Koh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21437v1","updated":"2025-11-26T14:28:11Z","published":"2025-11-26T14:28:11Z","title":"A Systematic Study of Model Merging Techniques in Large Language Models","summary":"Model merging combines multiple fine-tuned checkpoints into a single model without additional training, offering an attractive approach to reusing models and efficiently improving performance. However, it remains unclear whether the advantages reported for smaller models and classifiers generalize to LLMs. We present a large-scale, systematic evaluation of six state-of-the-art merging methods, including recent subspace methods, across four open-weight LLMs, twelve fine-tuned checkpoints per base model, and sixteen standard LLM benchmarks. Evaluating through standardized benchmarks, we measure both the probability that a merged model outperforms the base model and relative gains over the best individual checkpoint. Our results show that the oldest and simplest method, Task Arithmetic, is the only approach that reliably yields performance gains on LLMs. Other interference-aware and subspace merging methods typically result in significant performance drops. Our findings indicate that current merging techniques do not directly transfer to modern LLMs. This motivates the design of LLM-specific merging algorithms and merging-aware fine-tuning methods. Code will be released upon acceptance of this paper.","authors":["Oğuz Kağan Hitit","Leander Girrbach","Zeynep Akata"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01724v2","updated":"2025-11-26T14:24:35Z","published":"2025-11-03T16:33:57Z","title":"Probabilistic Robustness for Free? Revisiting Training via a Benchmark","summary":"Deep learning models are notoriously vulnerable to imperceptible perturbations. Most existing research centers on adversarial robustness (AR), which evaluates models under worst-case scenarios by examining the existence of deterministic adversarial examples (AEs). In contrast, probabilistic robustness (PR) adopts a statistical perspective, measuring the probability that predictions remain correct under stochastic perturbations. While PR is widely regarded as a practical complement to AR, dedicated training methods for improving PR are still relatively underexplored, albeit with emerging progress. Among the few PR-targeted training methods, we identify three limitations: i non-comparable evaluation protocols; ii limited comparisons to strong AT baselines despite anecdotal PR gains from AT; and iii no unified framework to compare the generalization of these methods. Thus, we introduce PRBench, the first benchmark dedicated to evaluating improvements in PR achieved by different robustness training methods. PRBench empirically compares most common AT and PR-targeted training methods using a comprehensive set of metrics, including clean accuracy, PR and AR performance, training efficiency, and generalization error (GE). We also provide theoretical analysis on the GE of PR performance across different training methods. Main findings revealed by PRBench include: AT methods are more versatile than PR-targeted training methods in terms of improving both AR and PR performance across diverse hyperparameter settings, while PR-targeted training methods consistently yield lower GE and higher clean accuracy. A leaderboard comprising 222 trained models across 7 datasets and 10 model architectures is publicly available at https://tmpspace.github.io/PRBenchLeaderboard/.","authors":["Yi Zhang","Zheng Wang","Zhen Chen","Wenjie Ruan","Qing Guo","Siddartha Khastgir","Carsten Maple","Xingyu Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.18926v3","updated":"2025-11-26T14:20:08Z","published":"2025-07-25T03:38:46Z","title":"Geometric Multi-color Message Passing Graph Neural Networks for Blood-brain Barrier Permeability Prediction","summary":"Accurate prediction of blood-brain barrier permeability (BBBP) is essential for central nervous system (CNS) drug development. While graph neural networks (GNNs) have advanced molecular property prediction, they often rely on molecular topology and neglect the three-dimensional geometric information crucial for modeling transport mechanisms. This paper introduces the geometric multi-color message-passing graph neural network (GMC-MPNN), a novel framework that enhances standard message-passing architectures by explicitly incorporating atomic-level geometric features and long-range interactions. Our model constructs weighted colored subgraphs based on atom types to capture the spatial relationships and chemical context that govern BBB permeability. We evaluated GMC-MPNN on three benchmark datasets for both classification and regression tasks, using rigorous scaffold-based splitting to ensure a robust assessment of generalization. The results demonstrate that GMC-MPNN consistently outperforms existing state-of-the-art models, achieving superior performance in both classifying compounds as permeable/non-permeable (AUC-ROC of 0.9704 and 0.9685) and in regressing continuous permeability values (RMSE of 0.4609, Pearson correlation of 0.7759). An ablation study further quantified the impact of specific atom-pair interactions, revealing that the model's predictive power derives from its ability to learn from both common and rare, but chemically significant, functional motifs. By integrating spatial geometry into the graph representation, GMC-MPNN sets a new performance benchmark and offers a more accurate and generalizable tool for drug discovery pipelines.","authors":["Trung Nguyen","Md Masud Rana","Farjana Tasnim Mukta","Chang-Guo Zhan","Duc Duy Nguyen"],"pdf_url":"","comment":"This paper is withdrawn due to an error in the training methodology that invalidates the results. The issue affects the main experimental conclusions"},{"id":"http://arxiv.org/abs/2509.03340v2","updated":"2025-11-26T14:19:09Z","published":"2025-09-03T14:18:05Z","title":"Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems","summary":"Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models struggle to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we propose a generative framework based on flow matching to model the full probability distribution over bifurcation outcomes. Our method enables direct sampling of multiple valid solutions while preserving system symmetries through equivariant modeling. We introduce a symmetric matching strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from toy models to complex physical problems such as buckling beams and the Allen-Cahn equation. Our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods in capturing multimodal distributions and symmetry-breaking bifurcations, offering a principled and scalable solution for modeling multistability in high-dimensional systems.","authors":["Fleur Hendriks","Ondřej Rokoš","Martin Doškář","Marc G. D. Geers","Vlado Menkovski"],"pdf_url":"","comment":"12 pages, 7 figures including appendices. Accepted to Machine Learning and the Physical Sciences Workshop, NeurIPS 2025 (https://ml4physicalsciences.github.io/2025/). Repository with corresponding code: https://github.com/FHendriks11/bifurcationML/. Video explanation: https://www.youtube.com/watch?v=wsL3h17KtjY"},{"id":"http://arxiv.org/abs/2504.20906v3","updated":"2025-11-26T14:08:00Z","published":"2025-04-29T16:24:11Z","title":"GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In Industrial Control Systems","summary":"The continuous monitoring of the interactions between cyber-physical components of any industrial control system (ICS) is required to secure automation of the system controls, and to guarantee plant processes are fail-safe and remain in an acceptably safe state. Safety is achieved by managing actuation (where electric signals are used to trigger physical movement), dependent on corresponding sensor readings; used as ground truth in decision making. Timely detection of anomalies (attacks, faults and unascertained states) in ICSs is crucial for the safe running of a plant, the safety of its personnel, and for the safe provision of any services provided. We propose an anomaly detection method that involves accurate linearization of the non-linear forms arising from sensor-actuator(s) relationships, primarily because solving linear models is easier and well understood. We accomplish this by using a well-known water treatment testbed as a use case. Our experiments show millisecond time response to detect anomalies, all of which are explainable and traceable; this simultaneous coupling of detection speed and explainability has not been achieved by other state of the art Artificial Intelligence (AI)/ Machine Learning (ML) models with eXplainable AI (XAI) used for the same purpose. Our methods explainability enables us to pin-point the sensor(s) and the actuation state(s) for which the anomaly was detected. The proposed algorithm showed an accuracy of 97.72% by flagging deviations within safe operation limits as non-anomalous; indicative that slower detectors with highest detection resolution is unnecessary, for systems whose safety boundaries provide leeway within safety limits.","authors":["Sarad Venugopalan","Sridhar Adepu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21416v1","updated":"2025-11-26T14:07:07Z","published":"2025-11-26T14:07:07Z","title":"Odin: Oriented Dual-module Integration for Text-rich Network Representation Learning","summary":"Text-attributed graphs require models to effectively combine strong textual understanding with structurally informed reasoning. Existing approaches either rely on GNNs--limited by over-smoothing and hop-dependent diffusion--or employ Transformers that overlook graph topology and treat nodes as isolated sequences. We propose Odin (Oriented Dual-module INtegration), a new architecture that injects graph structure into Transformers at selected depths through an oriented dual-module mechanism.Unlike message-passing GNNs, Odin does not rely on multi-hop diffusion; instead, multi-hop structures are integrated at specific Transformer layers, yielding low-, mid-, and high-level structural abstraction aligned with the model's semantic hierarchy. Because aggregation operates on the global [CLS] representation, Odin fundamentally avoids over-smoothing and decouples structural abstraction from neighborhood size or graph topology. We further establish that Odin's expressive power strictly contains that of both pure Transformers and GNNs.To make the design efficient in large-scale or low-resource settings, we introduce Light Odin, a lightweight variant that preserves the same layer-aligned structural abstraction for faster training and inference. Experiments on multiple text-rich graph benchmarks show that Odin achieves state-of-the-art accuracy, while Light Odin delivers competitive performance with significantly reduced computational cost. Together, Odin and Light Odin form a unified, hop-free framework for principled structure-text integration. The source code of this model has been released at https://github.com/hongkaifeng/Odin.","authors":["Kaifeng Hong","Yinglong Zhang","Xiaoying Hong","Xuewen Xia","Xing Xu"],"pdf_url":"","comment":"32 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.21414v1","updated":"2025-11-26T14:06:42Z","published":"2025-11-26T14:06:42Z","title":"SUPN: Shallow Universal Polynomial Networks","summary":"Deep neural networks (DNNs) and Kolmogorov-Arnold networks (KANs) are popular methods for function approximation due to their flexibility and expressivity. However, they typically require a large number of trainable parameters to produce a suitable approximation. Beyond making the resulting network less transparent, overparameterization creates a large optimization space, likely producing local minima in training that have quite different generalization errors. In this case, network initialization can have an outsize impact on the model's out-of-sample accuracy. For these reasons, we propose shallow universal polynomial networks (SUPNs). These networks replace all but the last hidden layer with a single layer of polynomials with learnable coefficients, leveraging the strengths of DNNs and polynomials to achieve sufficient expressivity with far fewer parameters. We prove that SUPNs converge at the same rate as the best polynomial approximation of the same degree, and we derive explicit formulas for quasi-optimal SUPN parameters. We complement theory with an extensive suite of numerical experiments involving SUPNs, DNNs, KANs, and polynomial projection in one, two, and ten dimensions, consisting of over 13,000 trained models. On the target functions we numerically studied, for a given number of trainable parameters, the approximation error and variability are often lower for SUPNs than for DNNs and KANs by an order of magnitude. In our examples, SUPNs even outperform polynomial projection on non-smooth functions.","authors":["Zachary Morrow","Michael Penwarden","Brian Chen","Aurya Javeed","Akil Narayan","John D. Jakeman"],"pdf_url":"","comment":"25 pages, supplementary material"},{"id":"http://arxiv.org/abs/2511.21408v1","updated":"2025-11-26T14:00:18Z","published":"2025-11-26T14:00:18Z","title":"Subjective Depth and Timescale Transformers: Learning Where and When to Compute","summary":"The rigid, uniform allocation of computation in standard Transformer (TF) architectures can limit their efficiency and scalability, particularly for large-scale models and long sequences. Addressing this, we introduce Subjective Depth Transformers (SDT) and Subjective Timescale Transformers (STT), two distinct architectures that leverage Bayesian surprise signals to dynamically route computation, learning where and when to compute within decoder-only TFs. SDT augments a decoder-only stack with alternating Decision and Dynamic layers: a Decision layer computes a full block 'posterior' and a lightweight 'prior,' while a Dynamic layer employs fixed-capacity Top-K routing based on Bayesian surprise (Expected and Unexpected Change), maintaining a static compute graph. STT extends this conditional computation to the temporal domain: a transition network predicts residual updates, forming a temporal 'change hypothesis' that informs a router to dynamically execute or bypass TF blocks for each token, managing KV-cache contributions. Both architectures exhibit the predicted shift from novelty to prediction driven gating over training, suggesting alignment with surprise based principles. While operating at reduced capacity, they offer preliminary insights into the compute-accuracy trade-offs of conditional computation. The proposed architectures establish a flexible framework for efficiency, reducing self-attention computation by 75% and KV-cache requirements by 50% within each compute skipping layer, setting a pathway for more efficient models.","authors":["Frederico Wieser","Martin Benfeghoul","Haitham Bou Ammar","Jun Wang","Zafeirios Fountas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.18444v2","updated":"2025-11-26T13:57:16Z","published":"2025-01-30T15:56:20Z","title":"Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms","summary":"This study addresses the need for accurate and efficient object detection in assistive technologies for visually impaired individuals. We evaluate four real-time object detection algorithms YOLO, SSD, Faster R-CNN, and Mask R-CNN within the context of indoor navigation assistance. Using the Indoor Objects Detection dataset, we analyze detection accuracy, processing speed, and adaptability to indoor environments. Our findings highlight the trade-offs between precision and efficiency, offering insights into selecting optimal algorithms for realtime assistive navigation. This research advances adaptive machine learning applications, enhancing indoor navigation solutions for the visually impaired and promoting accessibility.","authors":["Abhinav Pratap","Sushant Kumar","Suchinton Chakravarty"],"pdf_url":"","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2506.04263v2","updated":"2025-11-26T13:51:05Z","published":"2025-06-03T04:18:53Z","title":"Dynamic Epsilon Scheduling: A Multi-Factor Adaptive Perturbation Budget for Adversarial Training","summary":"Adversarial training is among the most effective strategies for defending deep neural networks against adversarial examples. A key limitation of existing adversarial training approaches lies in their reliance on a fixed perturbation budget, which fails to account for instance-specific robustness characteristics. While prior works such as IAAT and MMA introduce instance-level adaptations, they often rely on heuristic or static approximations of data robustness. In this paper, we propose Dynamic Epsilon Scheduling (DES), a novel framework that adaptively adjusts the adversarial perturbation budget per instance and per training iteration. DES integrates three key factors: (1) the distance to the decision boundary approximated via gradient-based proxies, (2) prediction confidence derived from softmax entropy, and (3) model uncertainty estimated via Monte Carlo dropout. By combining these cues into a unified scheduling strategy, DES tailors the perturbation budget dynamically to guide more effective adversarial learning. Experimental results on CIFAR-10 and CIFAR-100 show that our method consistently improves both adversarial robustness and standard accuracy compared to fixed-epsilon baselines and prior adaptive methods. Moreover, we provide theoretical insights into the stability and convergence of our scheduling policy. This work opens a new avenue for instance-aware, data-driven adversarial training methods.","authors":["Alan Mitkiy","James Smith","Myungseo wong","Hana Satou","Hiroshi Tanaka","Emily Johnson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18636v2","updated":"2025-11-26T13:50:01Z","published":"2025-05-24T10:49:19Z","title":"Asymmetric Duos: Sidekicks Improve Uncertainty","summary":"The go-to strategy to apply deep networks in settings where uncertainty informs decisions--ensembling multiple training runs with random initializations--is ill-suited for the extremely large-scale models and practical fine-tuning workflows of today. We introduce a new cost-effective strategy for improving the uncertainty quantification and downstream decisions of a large model (e.g. a fine-tuned ViT-B): coupling it with a less accurate but much smaller \"sidekick\" (e.g. a fine-tuned ResNet-34) with a fraction of the computational cost. We propose aggregating the predictions of this Asymmetric Duo by simple learned weighted averaging. Surprisingly, despite their inherent asymmetry, the sidekick model almost never harms the performance of the larger model. In fact, across five image classification benchmarks and a variety of model architectures and training schemes (including soups), Asymmetric Duos significantly improve accuracy, uncertainty quantification, and selective classification metrics with only ${\\sim}10-20\\%$ more computation.","authors":["Tim G. Zhou","Evan Shelhamer","Geoff Pleiss"],"pdf_url":"","comment":"30 pages, 14 figures, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21397v1","updated":"2025-11-26T13:49:08Z","published":"2025-11-26T13:49:08Z","title":"Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis","summary":"How does irrelevant information (i.e., distractors) affect test-time scaling in vision-language models (VLMs)? Prior studies on language models have reported an inverse scaling effect, where textual distractors lead to longer but less effective reasoning. To investigate whether similar phenomena occur in multimodal settings, we introduce Idis (Images with distractors), a visual question-answering dataset that systematically varies distractors along semantic, numerical, and spatial dimensions. Our analyses reveal that visual distractors differ fundamentally from textual ones: although inverse scaling persists, adding visual distractors reduces accuracy without increasing reasoning length. We further show that tracking attribute counts within reasoning traces provides key insights into how distractors, reasoning length, and accuracy interact. Finally, we demonstrate that these trends extend to established visual bias benchmarks such as Waterbirds, and we propose a simple prompting strategy to mitigate bias-driven predictions in reasoning models.","authors":["Jiyun Bae","Hyunjong Ok","Sangwoo Mo","Jaeho Lee"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2510.14657v2","updated":"2025-11-26T13:48:59Z","published":"2025-10-16T13:13:12Z","title":"Decorrelation Speeds Up Vision Transformers","summary":"Masked Autoencoder (MAE) pre-training of vision transformers (ViTs) yields strong performance in low-label data regimes but comes with substantial computational costs, making it impractical in time- and resource-constrained industrial settings. We address this by nitegrating Decorrelated Backpropagation (DBP) into MAE pre-training, an optimization method that iteratively reduces input correlations at each layer to accelerate convergence. Applied selectively to the encoder, DBP achieves faster pre-training without loss of stability. To mimic constrained-data scenarios, we evaluate our approach on ImageNet-1K pre-training and ADE20K fine-tuning using randomly sampled subsets of each dataset. Under this setting, DBP-MAE reduces wall-clock time to baseline performance by 21.1%, lowers carbon emissions by 21.4%, and improves segmentation mIoU by 1.1 points. We observe similar gains when pre-training and fine-tuning on proprietary industrial data, confirming the method's applicability in real-world scenarios. These results demonstrate that DBP can reduce training time and energy use while improving downstream performance for large-scale ViT pre-training.\n  Keywords: Deep learning, Vision transformers, Efficient AI, Decorrelation","authors":["Kieran Carrigg","Rob van Gastel","Melda Yeghaian","Sander Dalm","Faysal Boughorbel","Marcel van Gerven"],"pdf_url":"","comment":"16 pages, 12 figures, submitted to CVC 2026"},{"id":"http://arxiv.org/abs/2511.17983v2","updated":"2025-11-26T13:43:27Z","published":"2025-11-22T08:53:59Z","title":"An Adaptive Resonance Theory-based Topological Clustering Algorithm with a Self-Adjusting Vigilance Parameter","summary":"Clustering in stationary and nonstationary settings, where data distributions remain static or evolve over time, requires models that can adapt to distributional shifts while preserving previously learned cluster structures. This paper proposes an Adaptive Resonance Theory (ART)-based topological clustering algorithm that autonomously adjusts its recalculation interval and vigilance threshold through a diversity-driven adaptation mechanism. This mechanism enables hyperparameter-free learning that maintains cluster stability and continuity in dynamic environments. Experiments on 24 real-world datasets demonstrate that the proposed algorithm outperforms state-of-the-art methods in both clustering performance and continual learning capability. These results highlight the effectiveness of the proposed parameter adaptation in mitigating catastrophic forgetting and maintaining consistent clustering in evolving data streams. Source code is available at https://github.com/Masuyama-lab/IDAT","authors":["Naoki Masuyama","Yuichiro Toda","Yusuke Nojima","Hisao Ishibuchi"],"pdf_url":"","comment":"This manuscript is currently under review"},{"id":"http://arxiv.org/abs/2511.21381v1","updated":"2025-11-26T13:27:54Z","published":"2025-11-26T13:27:54Z","title":"BanglaASTE: A Novel Framework for Aspect-Sentiment-Opinion Extraction in Bangla E-commerce Reviews Using Ensemble Deep Learning","summary":"Aspect-Based Sentiment Analysis (ABSA) has emerged as a critical tool for extracting fine-grained sentiment insights from user-generated content, particularly in e-commerce and social media domains. However, research on Bangla ABSA remains significantly underexplored due to the absence of comprehensive datasets and specialized frameworks for triplet extraction in this language. This paper introduces BanglaASTE, a novel framework for Aspect Sentiment Triplet Extraction (ASTE) that simultaneously identifies aspect terms, opinion expressions, and sentiment polarities from Bangla product reviews. Our contributions include: (1) creation of the first annotated Bangla ASTE dataset containing 3,345 product reviews collected from major e-commerce platforms including Daraz, Facebook, and Rokomari; (2) development of a hybrid classification framework that employs graph-based aspect-opinion matching with semantic similarity techniques; and (3) implementation of an ensemble model combining BanglaBERT contextual embeddings with XGBoost boosting algorithms for enhanced triplet extraction performance. Experimental results demonstrate that our ensemble approach achieves superior performance with 89.9% accuracy and 89.1% F1-score, significantly outperforming baseline models across all evaluation metrics. The framework effectively addresses key challenges in Bangla text processing including informal expressions, spelling variations, and data sparsity. This research advances the state-of-the-art in low-resource language sentiment analysis and provides a scalable solution for Bangla e-commerce analytics applications.","authors":["Ariful Islam","Md Rifat Hossen","Abir Ahmed","B M Taslimul Haque"],"pdf_url":"","comment":"Presented at the 2025 IEEE International Conference on Signal Processing, Information, Communication and Systems (SPICSCON), November 21-22, 2025, University of Rajshahi, Bangladesh. 6 pages, ensemble deep learning, 3,345 annotated Bangla product reviews"},{"id":"http://arxiv.org/abs/2511.21378v1","updated":"2025-11-26T13:25:36Z","published":"2025-11-26T13:25:36Z","title":"Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data","summary":"Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare.","authors":["Jungi Lee","Jungkwon Kim","Chi Zhang","Kwangsun Yoo","Seok-Joo Byun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21377v1","updated":"2025-11-26T13:24:35Z","published":"2025-11-26T13:24:35Z","title":"Controlling changes to attention logits","summary":"Stability of neural network weights is critical when training transformer models. The query and key weights are particularly problematic, as they tend to grow large without any intervention. Applying normalization to queries and keys, known as `QK norm', fixes stability issues in practice, but is not always applicable. For example, QK norm is not compatible with Multi Latent Attention (MLA) because QK norm requires full materialization of queries and keys during inference, which is not done in MLA. In this paper we suggest that controlling the changes to logits is important for stability. We show that these changes are controllable by assigning parameter-dependent learning rates to the query and key weights. We find that our cheap intervention allows us to increase the base learning rate of the network, outperform other methods in the MLA setting, and achieve performance competitive with QK norm when using Multi-head Attention.","authors":["Ben Anson","Laurence Aitchison"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21369v1","updated":"2025-11-26T13:13:30Z","published":"2025-11-26T13:13:30Z","title":"Differentiable Physics-Neural Models enable Learning of Non-Markovian Closures for Accelerated Coarse-Grained Physics Simulations","summary":"Numerical simulations provide key insights into many physical, real-world problems. However, while these simulations are solved on a full 3D domain, most analysis only require a reduced set of metrics (e.g. plane-level concentrations). This work presents a hybrid physics-neural model that predicts scalar transport in a complex domain orders of magnitude faster than the 3D simulation (from hours to less than 1 min). This end-to-end differentiable framework jointly learns the physical model parameterization (i.e. orthotropic diffusivity) and a non-Markovian neural closure model to capture unresolved, 'coarse-grained' effects, thereby enabling stable, long time horizon rollouts. This proposed model is data-efficient (learning with 26 training data), and can be flexibly extended to an out-of-distribution scenario (with a moving source), achieving a Spearman correlation coefficient of 0.96 at the final simulation time. Overall results show that this differentiable physics-neural framework enables fast, accurate, and generalizable coarse-grained surrogates for physical phenomena.","authors":["Tingkai Xue","Chin Chun Ooi","Zhengwei Ge","Fong Yew Leong","Hongying Li","Chang Wei Kang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.17464v2","updated":"2025-11-26T13:13:09Z","published":"2024-05-23T08:58:08Z","title":"Data Valuation by Fusing Global and Local Statistical Information","summary":"Data valuation has garnered increasing attention in recent years, given the critical role of high-quality data in various applications. Among diverse data valuation approaches, Shapley value-based methods are predominant due to their strong theoretical grounding. However, the exact computation of Shapley values is often computationally prohibitive, prompting the development of numerous approximation techniques. Despite notable advancements, existing methods generally neglect the incorporation of value distribution information and fail to account for dynamic data conditions, thereby compromising their performance and application potential. In this paper, we highlight the crucial role of both global and local statistical properties of value distributions in the context of data valuation for machine learning. First, we conduct a comprehensive analysis of these distributions across various simulated and real-world datasets, uncovering valuable insights and key patterns. Second, we propose an enhanced data valuation method that fuses the explored distribution characteristics into two regularization terms to refine Shapley value estimation. The proposed regularizers can be seamlessly incorporated into various existing data valuation methods. Third, we introduce a novel approach for dynamic data valuation that infers updated data values without recomputing Shapley values, thereby significantly improving computational efficiency. Extensive experiments have been conducted across a range of tasks, including Shapley value estimation, value-based data addition and removal, mislabeled data detection, and dynamic data valuation. The results showcase the consistent effectiveness and efficiency of our proposed methodologies, affirming the significant potential of global and local value distributions in data valuation.","authors":["Xiaoling Zhou","Ou Wu","Michael K. Ng","Hao Jiang"],"pdf_url":"","comment":"35 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.21364v1","updated":"2025-11-26T13:11:46Z","published":"2025-11-26T13:11:46Z","title":"BanglaMM-Disaster: A Multimodal Transformer-Based Deep Learning Framework for Multiclass Disaster Classification in Bangla","summary":"Natural disasters remain a major challenge for Bangladesh, so real-time monitoring and quick response systems are essential. In this study, we present BanglaMM-Disaster, an end-to-end deep learning-based multimodal framework for disaster classification in Bangla, using both textual and visual data from social media. We constructed a new dataset of 5,037 Bangla social media posts, each consisting of a caption and a corresponding image, annotated into one of nine disaster-related categories. The proposed model integrates transformer-based text encoders, including BanglaBERT, mBERT, and XLM-RoBERTa, with CNN backbones such as ResNet50, DenseNet169, and MobileNetV2, to process the two modalities. Using early fusion, the best model achieves 83.76% accuracy. This surpasses the best text-only baseline by 3.84% and the image-only baseline by 16.91%. Our analysis also shows reduced misclassification across all classes, with noticeable improvements for ambiguous examples. This work fills a key gap in Bangla multimodal disaster analysis and demonstrates the benefits of combining multiple data types for real-time disaster response in low-resource settings.","authors":["Ariful Islam","Md Rifat Hossen","Md. Mahmudul Arif","Abdullah Al Noman","Md Arifur Rahman"],"pdf_url":"","comment":"Presented at the 2025 IEEE International Conference on Signal Processing, Information, Communication and Systems (SPICSCON), November 21-22, 2025, University of Rajshahi, Bangladesh. 6 pages, 9 disaster classes, multimodal dataset with 5,037 samples"},{"id":"http://arxiv.org/abs/2511.21363v1","updated":"2025-11-26T13:11:42Z","published":"2025-11-26T13:11:42Z","title":"The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods","summary":"The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes.","authors":["Kevin Iselborn","David Dembinsky","Adriano Lucieri","Andreas Dengel"],"pdf_url":"","comment":"13 pages, 10 figures, 5 tables, accepted at AAAI SECURE-AI4H workshop"},{"id":"http://arxiv.org/abs/2511.21356v1","updated":"2025-11-26T13:04:24Z","published":"2025-11-26T13:04:24Z","title":"Hybrid-AIRL: Enhancing Inverse Reinforcement Learning with Supervised Expert Guidance","summary":"Adversarial Inverse Reinforcement Learning (AIRL) has shown promise in addressing the sparse reward problem in reinforcement learning (RL) by inferring dense reward functions from expert demonstrations. However, its performance in highly complex, imperfect-information settings remains largely unexplored. To explore this gap, we evaluate AIRL in the context of Heads-Up Limit Hold'em (HULHE) poker, a domain characterized by sparse, delayed rewards and significant uncertainty. In this setting, we find that AIRL struggles to infer a sufficiently informative reward function. To overcome this limitation, we contribute Hybrid-AIRL (H-AIRL), an extension that enhances reward inference and policy learning by incorporating a supervised loss derived from expert data and a stochastic regularization mechanism. We evaluate H-AIRL on a carefully selected set of Gymnasium benchmarks and the HULHE poker setting. Additionally, we analyze the learned reward function through visualization to gain deeper insights into the learning process. Our experimental results show that H-AIRL achieves higher sample efficiency and more stable learning compared to AIRL. This highlights the benefits of incorporating supervised signals into inverse RL and establishes H-AIRL as a promising framework for tackling challenging, real-world settings.","authors":["Bram Silue","Santiago Amaya-Corredor","Patrick Mannion","Lander Willem","Pieter Libin"],"pdf_url":"","comment":"Comments: 13 pages, 5 figures, 1 table. Code: https://github.com/silue-dev/hairl. Submitted to ESANN 2026"},{"id":"http://arxiv.org/abs/2511.16149v2","updated":"2025-11-26T13:02:50Z","published":"2025-11-20T08:44:24Z","title":"Approximation rates of quantum neural networks for periodic functions via Jackson's inequality","summary":"Quantum neural networks (QNNs) are an analog of classical neural networks in the world of quantum computing, which are represented by a unitary matrix with trainable parameters. Inspired by the universal approximation property of classical neural networks, ensuring that every continuous function can be arbitrarily well approximated uniformly on a compact set of a Euclidean space, some recent works have established analogous results for QNNs, ranging from single-qubit to multi-qubit QNNs, and even hybrid classical-quantum models. In this paper, we study the approximation capabilities of QNNs for periodic functions with respect to the supremum norm. We use the Jackson inequality to approximate a given function by implementing its approximating trigonometric polynomial via a suitable QNN. In particular, we see that by restricting to the class of periodic functions, one can achieve a quadratic reduction of the number of parameters, producing better approximation results than in the literature. Moreover, the smoother the function, the fewer parameters are needed to construct a QNN to approximate the function.","authors":["Ariel Neufeld","Philipp Schmocker","Viet Khoa Tran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21354v1","updated":"2025-11-26T13:02:31Z","published":"2025-11-26T13:02:31Z","title":"Best Practices for Machine Learning Experimentation in Scientific Applications","summary":"Machine learning (ML) is increasingly adopted in scientific research, yet the quality and reliability of results often depend on how experiments are designed and documented. Poor baselines, inconsistent preprocessing, or insufficient validation can lead to misleading conclusions about model performance. This paper presents a practical and structured guide for conducting ML experiments in scientific applications, focussing on reproducibility, fair comparison, and transparent reporting. We outline a step-by-step workflow, from dataset preparation to model selection and evaluation, and propose metrics that account for overfitting and instability across validation folds, including the Logarithmic Overfitting Ratio (LOR) and the Composite Overfitting Score (COS). Through recommended practices and example reporting formats, this work aims to support researchers in establishing robust baselines and drawing valid evidence-based insights from ML models applied to scientific problems.","authors":["Umberto Michelucci","Francesca Venturini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21350v1","updated":"2025-11-26T12:56:37Z","published":"2025-11-26T12:56:37Z","title":"Learning Multi-Order Block Structure in Higher-Order Networks","summary":"Higher-order networks, naturally described as hypergraphs, are essential for modeling real-world systems involving interactions among three or more entities. Stochastic block models offer a principled framework for characterizing mesoscale organization, yet their extension to hypergraphs involves a trade-off between expressive power and computational complexity. A recent simplification, a single-order model, mitigates this complexity by assuming a single affinity pattern governs interactions of all orders. This universal assumption, however, may overlook order-dependent structural details. Here, we propose a framework that relaxes this assumption by introducing a multi-order block structure, in which different affinity patterns govern distinct subsets of interaction orders. Our framework is based on a multi-order stochastic block model and searches for the optimal partition of the set of interaction orders that maximizes out-of-sample hyperlink prediction performance. Analyzing a diverse range of real-world networks, we find that multi-order block structures are prevalent. Accounting for them not only yields better predictive performance over the single-order model but also uncovers sharper, more interpretable mesoscale organization. Our findings reveal that order-dependent mechanisms are a key feature of the mesoscale organization of real-world higher-order networks.","authors":["Kazuki Nakajima","Yuya Sasaki","Takeaki Uno","Masaki Aida"],"pdf_url":"","comment":"38 pages, 10 figures, and 7 tables"},{"id":"http://arxiv.org/abs/2511.21340v1","updated":"2025-11-26T12:46:34Z","published":"2025-11-26T12:46:34Z","title":"Phase-Aware Code-Aided EM Algorithm for Blind Channel Estimation in PSK-Modulated OFDM","summary":"This paper presents a fully blind phase-aware expectation-maximization (EM) algorithm for OFDM systems with the phase-shift keying (PSK) modulation. We address the well-known local maximum problem of the EM algorithm for blind channel estimation. This is primarily caused by the unknown phase ambiguity in the channel estimates, which conventional blind EM estimators cannot resolve. To overcome this limitation, we propose to exploit the extrinsic information from the decoder as model evidence metrics. A finite set of candidate models is generated based on the inherent symmetries of PSK modulation, and the decoder selects the most likely candidate model. Simulation results demonstrate that, when combined with a simple convolutional code, the phase-aware EM algorithm reliably resolves phase ambiguity during the initialization stage and reduces the local convergence rate from 80% to nearly 0% in frequency-selective channels with a constant phase ambiguity. The algorithm is invoked only once after the EM initialization stage, resulting in negligible additional complexity during subsequent turbo iterations.","authors":["Chin-Hung Chen","Ivana Nikoloska","Wim van Houtum","Yan Wu","Alex Alvarado"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2511.21338v1","updated":"2025-11-26T12:44:29Z","published":"2025-11-26T12:44:29Z","title":"Masks Can Be Distracting: On Context Comprehension in Diffusion Language Models","summary":"Masked Diffusion Language Models (MDLMs) have recently emerged as a promising alternative to Autoregressive Language Models (ARLMs), leveraging a denoising objective that, in principle, should enable more uniform context utilisation. In this work, we examine the context comprehension abilities of MDLMs and uncover two key limitations. First, despite their more global training objective and bidirectional attention mechanism, similarly to ARLMS, MDLMs exhibit a strong locality bias: performance is highly sensitive to the position of relevant information within the input, favouring local over distant context. Second, we show that appending a large number of mask tokens--required for generation--can significantly degrade context comprehension. Through systematic ablations, we find that these masks act as distractors, reducing the model's ability to process relevant information. To address this, we introduce a mask-agnostic loss function that encourages predictions to remain invariant to the number of appended masks. Fine-tuning with this objective substantially mitigates the distracting effect of masks, improving robustness of MDLMs. Overall, our findings reveal critical limitations of the current MDLM training paradigm and provide actionable insights for building diffusion-based language models with stronger context comprehension.","authors":["Julianna Piskorz","Cristina Pinneri","Alvaro Correia","Motasem Alfarra","Risheek Garrepalli","Christos Louizos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21426v2","updated":"2025-11-26T12:37:43Z","published":"2025-05-27T16:55:56Z","title":"Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks","summary":"Agent-Based Models (ABMs) are powerful tools for studying emergent properties in complex systems. In ABMs, agent behaviors are governed by local interactions and stochastic rules. However, these rules are, in general, non-differentiable, limiting the use of gradient-based methods for optimization, and thus integration with real-world data. We propose a novel framework to learn a differentiable surrogate of any ABM by observing its generated data. Our method combines diffusion models to capture behavioral stochasticity and graph neural networks to model agent interactions. Distinct from prior surrogate approaches, our method introduces a fundamental shift: rather than approximating system-level outputs, it models individual agent behavior directly, preserving the decentralized, bottom-up dynamics that define ABMs. We validate our approach on two ABMs (Schelling's segregation model and a Predator-Prey ecosystem) showing that it replicates individual-level patterns and accurately forecasts emergent dynamics beyond training. Our results demonstrate the potential of combining diffusion models and graph learning for data-driven ABM simulation.","authors":["Francesco Cozzi","Marco Pangallo","Alan Perotti","André Panisson","Corrado Monti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21335v1","updated":"2025-11-26T12:31:50Z","published":"2025-11-26T12:31:50Z","title":"TSGM: Regular and Irregular Time-series Generation using Score-based Generative Models","summary":"Score-based generative models (SGMs) have demonstrated unparalleled sampling quality and diversity in numerous fields, such as image generation, voice synthesis, and tabular data synthesis, etc. Inspired by those outstanding results, we apply SGMs to synthesize time-series by learning its conditional score function. To this end, we present a conditional score network for time-series synthesis, deriving a denoising score matching loss tailored for our purposes. In particular, our presented denoising score matching loss is the conditional denoising score matching loss for time-series synthesis. In addition, our framework is such flexible that both regular and irregular time-series can be synthesized with minimal changes to our model design. Finally, we obtain exceptional synthesis performance on various time-series datasets, achieving state-of-the-art sampling diversity and quality.","authors":["Haksoo Lim","Jaehoon Lee","Sewon Park","Minjung Kim","Noseong Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.19682v2","updated":"2025-11-26T12:08:52Z","published":"2025-05-26T08:42:53Z","title":"Deep Actor-Critics with Tight Risk Certificates","summary":"Deep actor-critic algorithms have reached a level where they influence everyday life. They are a driving force behind continual improvement of large language models through user feedback. However, their deployment in physical systems is not yet widely adopted, mainly because no validation scheme fully quantifies their risk of malfunction. We demonstrate that it is possible to develop tight risk certificates for deep actor-critic algorithms that predict generalization performance from validation-time observations. Our key insight centers on the effectiveness of minimal evaluation data. A small feasible set of evaluation roll-outs collected from a pretrained policy suffices to produce accurate risk certificates when combined with a simple adaptation of PAC-Bayes theory. Specifically, we adopt a recently introduced recursive PAC-Bayes approach, which splits validation data into portions and recursively builds PAC-Bayes bounds on the excess loss of each portion's predictor, using the predictor from the previous portion as a data-informed prior. Our empirical results across multiple locomotion tasks, actor-critic methods, and policy expertise levels demonstrate risk certificates tight enough to be considered for practical use.","authors":["Bahareh Tasdighi","Manuel Haussmann","Yi-Shan Wu","Andres R. Masegosa","Melih Kandemir"],"pdf_url":"","comment":"updated version with new methods and experiments"},{"id":"http://arxiv.org/abs/2511.21320v1","updated":"2025-11-26T12:05:44Z","published":"2025-11-26T12:05:44Z","title":"Sawtooth Sampling for Time Series Denoising Diffusion Implicit Models","summary":"Denoising Diffusion Probabilistic Models (DDPMs) can generate synthetic timeseries data to help improve the performance of a classifier, but their sampling process is computationally expensive. We address this by combining implicit diffusion models with a novel Sawtooth Sampler that accelerates the reverse process and can be applied to any pretrained diffusion model. Our approach achieves a 30 times speed-up over the standard baseline while also enhancing the quality of the generated sequences for classification tasks.","authors":["Heiko Oppel","Andreas Spilz","Michael Munz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06998v2","updated":"2025-11-26T11:47:20Z","published":"2025-09-04T17:52:22Z","title":"Not All Splits Are Equal: Rethinking Attribute Generalization Across Unrelated Categories","summary":"Can models generalize attribute knowledge across semantically and perceptually dissimilar categories? While prior work has addressed attribute prediction within narrow taxonomic or visually similar domains, it remains unclear whether current models can abstract attributes and apply them to conceptually distant categories. This work presents the first explicit evaluation for the robustness of the attribute prediction task under such conditions, testing whether models can correctly infer shared attributes between unrelated object types: e.g., identifying that the attribute \"has four legs\" is common to both \"dogs\" and \"chairs\". To enable this evaluation, we introduce train-test split strategies that progressively reduce correlation between training and test sets, based on: LLM-driven semantic grouping, embedding similarity thresholding, embedding-based clustering, and supercategory-based partitioning using ground-truth labels. Results show a sharp drop in performance as the correlation between training and test categories decreases, indicating strong sensitivity to split design. Among the evaluated methods, clustering yields the most effective trade-off, reducing hidden correlations while preserving learnability. These findings offer new insights into the limitations of current representations and inform future benchmark construction for attribute reasoning.","authors":["Liviu Nicolae Fircă","Antonio Bărbălau","Dan Oneata","Elena Burceanu"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 Workshop: CauScien - Uncovering Causality in Science and NeurIPS 2025 Workshop: Reliable ML from Unreliable Data"},{"id":"http://arxiv.org/abs/2510.07858v2","updated":"2025-11-26T11:39:28Z","published":"2025-10-09T06:59:15Z","title":"Augur: Modeling Covariate Causal Associations in Time Series via Large Language Models","summary":"Large language models (LLM) have emerged as a promising avenue for time series forecasting, offering the potential to integrate multimodal data. However, existing LLM-based approaches face notable limitations-such as marginalized role in model architectures, reliance on coarse statistical text prompts, and lack of interpretability. In this work, we introduce Augur, a fully LLM driven time series forecasting framework that exploits LLM causal reasoning to discover and use directed causal associations among covariates. Augur uses a two stage teacher student architecture where a powerful teacher LLM infers a directed causal graph from time series using heuristic search together with pairwise causality testing. A lightweight student agent then refines the graph and fine tune on high confidence causal associations that are encoded as rich textual prompts to perform forecasting. This design improves predictive accuracy while yielding transparent, traceable reasoning about variable interactions. Extensive experiments on real-world datasets with 26 baselines demonstrate that Augur achieves competitive performance and robust zero-shot generalization.","authors":["Zhiqing Cui","Binwu Wang","Qingxiang Liu","Yeqiang Wang","Zhengyang Zhou","Yuxuan Liang","Yang Wang"],"pdf_url":"","comment":"24 pages, 9 figures"},{"id":"http://arxiv.org/abs/2312.04281v2","updated":"2025-11-26T11:19:28Z","published":"2023-12-07T13:05:47Z","title":"Factor-Assisted Federated Learning for Personalized Optimization with Heterogeneous Data","summary":"Federated learning is an emerging distributed machine learning framework aiming at protecting data privacy. Data heterogeneity is one of the core challenges in federated learning, which could severely degrade the convergence rate and prediction performance of deep neural networks. To address this issue, we develop a novel personalized federated learning framework for heterogeneous data, which we refer to as FedSplit. This modeling framework is motivated by the finding that, data in different clients contain both common knowledge and personalized knowledge. Then the hidden elements in each neural layer can be split into the shared and personalized groups. With this decomposition, a novel objective function is established and optimized. We demonstrate FedSplit enjoyers a faster convergence speed than the standard federated learning method both theoretically and empirically. The generalization bound of the FedSplit method is also studied. To practically implement the proposed method on real datasets, factor analysis is introduced to facilitate the decoupling of hidden elements. This leads to a practically implemented model for FedSplit and we further refer to as FedFac. We demonstrated by simulation studies that, using factor analysis can well recover the underlying shared/personalized decomposition. The superior prediction performance of FedFac is further verified empirically by comparison with various state-of-the-art federated learning methods on several real datasets.","authors":["Feifei Wang","Huiyun Tang","Yang Li"],"pdf_url":"","comment":"29 pages, 10 figures"},{"id":"http://arxiv.org/abs/2511.21283v1","updated":"2025-11-26T11:14:32Z","published":"2025-11-26T11:14:32Z","title":"On the Periodic Orbits of the Dual Logarithmic Derivative Operator","summary":"We study the periodic behaviour of the dual logarithmic derivative operator $\\mathcal{A}[f]=\\mathrm{d}\\ln f/\\mathrm{d}\\ln x$ in a complex analytic setting. We show that $\\mathcal{A}$ admits genuinely nondegenerate period-$2$ orbits and identify a canonical explicit example. Motivated by this, we obtain a complete classification of all nondegenerate period-$2$ solutions, which are precisely the rational pairs $(c a x^{c}/(1-ax^{c}),\\, c/(1-ax^{c}))$ with $ac\\neq 0$. We further classify all fixed points of $\\mathcal{A}$, showing that every solution of $\\mathcal{A}[f]=f$ has the form $f(x)=1/(a-\\ln x)$. As an illustration, logistic-type functions become pre-periodic under $\\mathcal{A}$ after a logarithmic change of variables, entering the period-$2$ family in one iterate. These results give an explicit description of the low-period structure of $\\mathcal{A}$ and provide a tractable example of operator-induced dynamics on function spaces.","authors":["Xiaohang Yu","William Knottenbelt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.19583v2","updated":"2025-11-26T11:13:25Z","published":"2025-06-24T12:49:00Z","title":"ConStellaration: A dataset of QI-like stellarator plasma boundaries and optimization benchmarks","summary":"Stellarators are magnetic confinement devices under active development to deliver steady-state carbon-free fusion energy. Their design involves a high-dimensional, constrained optimization problem that requires expensive physics simulations and significant domain expertise. Recent advances in plasma physics and open-source tools have made stellarator optimization more accessible. However, broader community progress is currently bottlenecked by the lack of standardized optimization problems with strong baselines and datasets that enable data-driven approaches, particularly for quasi-isodynamic (QI) stellarator configurations, considered as a promising path to commercial fusion due to their inherent resilience to current driven disruptions. Here, we release an open dataset of diverse QI-like stellarator plasma boundary shapes, paired with their ideal magnetohydrodynamic (MHD) equilibria and performance metrics. We generated this dataset by sampling a variety of QI fields and optimizing corresponding stellarator plasma boundaries. We introduce three optimization benchmarks of increasing complexity: (1) a single objective geometric optimization problem, (2) a \"simple-to-build\" QI stellarator, and (3) a multi-objective ideal-MHD stable QI stellarator that investigates trade-offs between compactness and coil simplicity. For every benchmark, we provide reference code, evaluation scripts, and strong baselines based on classical optimization techniques. Finally, we show how learned models trained on our dataset can efficiently generate novel, feasible configurations without querying expensive physics oracles. By openly releasing the dataset along with benchmark problems and baselines, we aim to lower the entry barrier for optimization and machine learning researchers to engage in stellarator design and to accelerate cross-disciplinary progress toward bringing fusion energy to the grid.","authors":["Santiago A. Cadena","Andrea Merlo","Emanuel Laude","Alexander Bauer","Atul Agrawal","Maria Pascu","Marija Savtchouk","Enrico Guiraud","Lukas Bonauer","Stuart Hudson","Markus Kaiser"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.09484v2","updated":"2025-11-26T11:07:04Z","published":"2025-10-10T15:48:31Z","title":"CRPS-LAM: Regional ensemble weather forecasting from matching marginals","summary":"Machine learning for weather prediction increasingly relies on ensemble methods to provide probabilistic forecasts. Diffusion-based models have shown strong performance in Limited-Area Modeling (LAM) but remain computationally expensive at sampling time. Building on the success of global weather forecasting models trained based on Continuous Ranked Probability Score (CRPS), we introduce CRPS-LAM, a probabilistic LAM forecasting model trained with a CRPS-based objective. By sampling and injecting a single latent noise vector into the model, CRPS-LAM generates ensemble members in a single forward pass, achieving sampling speeds up to 39 times faster than a diffusion-based model. We evaluate the model on the MEPS regional dataset, where CRPS-LAM matches the low errors of diffusion models. By retaining also fine-scale forecast details, the method stands out as an effective approach for probabilistic regional weather forecasting","authors":["Erik Larsson","Joel Oskarsson","Tomas Landelius","Fredrik Lindsten"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2511.21276v1","updated":"2025-11-26T11:05:42Z","published":"2025-11-26T11:05:42Z","title":"A Physics-Informed U-net-LSTM Network for Data-Driven Seismic Response Modeling of Structures","summary":"Accurate and efficient seismic response prediction is essential for the design of resilient structures. While the Finite Element Method (FEM) remains the standard for nonlinear seismic analysis, its high computational demands limit its scalability and real time applicability. Recent developments in deep learning, particularly Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Long Short Term Memory (LSTM) models, have shown promise in reducing the computational cost of nonlinear seismic analysis of structures. However, these data driven models often struggle to generalize and capture the underlying physics, leading to reduced reliability. We propose a novel Physics Informed U Net LSTM framework that integrates physical laws with deep learning to enhance both accuracy and efficiency. By embedding domain specific constraints into the learning process, the proposed model achieves improved predictive performance over conventional Machine Learning architectures. This hybrid approach bridges the gap between purely data driven methods and physics based modeling, offering a robust and computationally efficient alternative for seismic response prediction of structures.","authors":["Sutirtha Biswas","Kshitij Kumar Yadav"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.11137v2","updated":"2025-11-26T11:05:22Z","published":"2025-07-15T09:38:11Z","title":"Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking","summary":"As valuable digital assets, deep neural networks necessitate robust ownership protection, positioning neural network watermarking (NNW) as a promising solution. Among various NNW approaches, weight-based methods are favored for their simplicity and practicality; however, they remain vulnerable to forging and overwriting attacks. To address those challenges, we propose NeuralMark, a robust method built around a hashed watermark filter. Specifically, we utilize a hash function to generate an irreversible binary watermark from a secret key, which is then used as a filter to select the model parameters for embedding. This design cleverly intertwines the embedding parameters with the hashed watermark, providing a robust defense against both forging and overwriting attacks. An average pooling is also incorporated to resist fine-tuning and pruning attacks. Furthermore, it can be seamlessly integrated into various neural network architectures, ensuring broad applicability. Theoretically, we analyze its security boundary. Empirically, we verify its effectiveness and robustness across 13 distinct Convolutional and Transformer architectures, covering five image classification tasks and one text generation task. The source codes are available at https://github.com/AIResearch-Group/NeuralMark.","authors":["Yuan Yao","Jin Song","Jian Jin"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2502.00037v3","updated":"2025-11-26T10:56:35Z","published":"2025-01-25T19:41:04Z","title":"Superstate Quantum Mechanics","summary":"We introduce Superstate Quantum Mechanics (SQM), a theory that considers states in Hilbert space subject to multiple quadratic constraints, with ``energy'' also expressed as a quadratic function of these states. Traditional quantum mechanics corresponds to a single quadratic constraint of wavefunction normalization with energy expressed as a quadratic form involving the Hamiltonian. When SQM represents states as unitary operators, the stationary problem becomes a quantum inverse problem with multiple applications in physics, machine learning, and artificial intelligence. Any stationary SQM problem is equivalent to a new algebraic problem that we address in this paper. The non-stationary SQM problem considers the evolution of the system itself, involving the same ``energy'' operator as in the stationary case. Two possible options for the SQM dynamic equation are considered: (1) within the framework of linear maps from higher-order quantum theory, where 2D-type quantum circuits transform one quantum system into another; and (2) in the form of a Gross-Pitaevskii-type nonlinear map. Although no known physical process currently describes such 2D dynamics, this approach naturally bridges direct and inverse quantum mechanics problems, allowing for the development of a new type of computer algorithms. As an immediately available practical application of the theory, we consider using a quantum channel as a classical computational model; this type of computation can be performed on a classical computer.","authors":["Mikhail Gennadievich Belov","Victor Victorovich Dubov","Vadim Konstantinovich Ivanov","Alexander Yurievich Maslov","Olga Vladimirovna Proshina","Vladislav Gennadievich Malyshkin"],"pdf_url":"","comment":"The ML approach presented in arXiv:2407.04406 is extended to stationary and non-stationary quantum dynamics"},{"id":"http://arxiv.org/abs/2503.21507v2","updated":"2025-11-26T10:46:41Z","published":"2025-03-27T13:51:31Z","title":"F-INR: Functional Tensor Decomposition for Implicit Neural Representations","summary":"Implicit Neural Representations (INRs) model signals as continuous, differentiable functions. However, monolithic INRs scale poorly with data dimensionality, leading to excessive training costs. We propose F-INR, a framework that addresses this limitation by factorizing a high-dimensional INR into a set of compact, axis-specific sub-networks based on functional tensor decomposition. These sub-networks learn low-dimensional functional components that are then combined via tensor operations. This factorization reduces computational complexity while additionally improving representational capacity. F-INR is both architecture- and decomposition-agnostic. It integrates with various existing INR backbones (e.g., SIREN, WIRE, FINER, Factor Fields) and tensor formats (e.g., CP, TT, Tucker), offering fine-grained control over the speed-accuracy trade-off via the tensor rank and mode. Our experiments show F-INR accelerates training by up to $20\\times$ and improves fidelity by over \\num{6.0} dB PSNR compared to state-of-the-art INRs. We validate these gains on diverse tasks, including image representation, 3D geometry reconstruction, and neural radiance fields. We further show F-INR's applicability to scientific computing by modeling complex physics simulations. Thus, F-INR provides a scalable, flexible, and efficient framework for high-dimensional signal modeling. Project page: https://f-inr.github.io","authors":["Sai Karthikeya Vemuri","Tim Büchner","Joachim Denzler"],"pdf_url":"","comment":"Accepted at WACV 2026. Website: https://f-inr.github.io Supplementary Material can be found there. 12 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2511.20099v2","updated":"2025-11-26T10:46:28Z","published":"2025-11-25T09:17:32Z","title":"QiMeng-CRUX: Narrowing the Gap between Natural Language and Verilog via Core Refined Understanding eXpression","summary":"Large language models (LLMs) have shown promising capabilities in hardware description language (HDL) generation. However, existing approaches often rely on free-form natural language descriptions that are often ambiguous, redundant, and unstructured, which poses significant challenges for downstream Verilog code generation. We treat hardware code generation as a complex transformation from an open-ended natural language space to a domain-specific, highly constrained target space. To bridge this gap, we introduce Core Refined Understanding eXpression (CRUX), a structured intermediate space that captures the essential semantics of user intent while organizing the expression for precise Verilog code generation. We further design a two-stage training framework, comprising Joint Expression Modeling and Dual-Space Optimization, to enhance the quality of both CRUX and Verilog code. Experiments across multiple Verilog generation benchmarks demonstrate that our model, CRUX-V, achieves state-of-the-art performance among general models, particularly under challenging design tasks. Furthermore, the CRUX space proves transferable and beneficial when used as input prompts for other code models, highlighting its effectiveness in narrowing the gap between free-form natural language descriptions and precise Verilog generation.","authors":["Lei Huang","Rui Zhang","Jiaming Guo","Yang Zhang","Di Huang","Shuyao Cheng","Pengwei Jin","Chongxiao Li","Zidong Du","Xing Hu","Qi Guo","Yunji Chen"],"pdf_url":"","comment":"Accepted by the AAAI26 Conference Main Track"},{"id":"http://arxiv.org/abs/2511.21257v1","updated":"2025-11-26T10:39:25Z","published":"2025-11-26T10:39:25Z","title":"Estimation in high-dimensional linear regression: Post-Double-Autometrics as an alternative to Post-Double-Lasso","summary":"Post-Double-Lasso is becoming the most popular method for estimating linear regression models with many covariates when the purpose is to obtain an accurate estimate of a parameter of interest, such as an average treatment effect. However, this method can suffer from substantial omitted variable bias in finite sample. We propose a new method called Post-Double-Autometrics, which is based on Autometrics, and show that this method outperforms Post-Double-Lasso. Its use in a standard application of economic growth sheds new light on the hypothesis of convergence from poor to rich economies.","authors":["Sullivan Hué","Sébastien Laurent","Ulrich Aiounou","Emmanuel Flachaire"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.20278v2","updated":"2025-11-26T10:25:27Z","published":"2025-05-26T17:55:15Z","title":"Characterizing Pattern Matching and Its Limits on Compositional Task Structures","summary":"Despite impressive capabilities, LLMs' successes often rely on pattern-matching behaviors, yet these are also linked to OOD generalization failures in compositional tasks. However, behavioral studies commonly employ task setups that allow multiple generalization sources (e.g., algebraic invariances, structural repetition), obscuring a precise and testable account of how well LLMs perform generalization through pattern matching and their limitations. To address this ambiguity, we first formalize pattern matching as functional equivalence, i.e., identifying pairs of subsequences of inputs that consistently lead to identical results when the rest of the input is held constant. Then, we systematically study how decoder-only Transformer and Mamba behave in controlled tasks with compositional structures that isolate this mechanism. Our formalism yields predictive and quantitative insights: (1) Instance-wise success of pattern matching is well predicted by the number of contexts witnessing the relevant functional equivalence. (2) We prove a tight sample complexity bound of learning a two-hop structure by identifying the exponent of the data scaling law for perfect in-domain generalization. Our empirical results align with the theoretical prediction, under 20x parameter scaling and across architectures. (3) Path ambiguity is a structural barrier: when a variable influences the output via multiple paths, models fail to form unified intermediate state representations, impairing accuracy and interpretability. (4) Chain-of-Thought reduces data requirements yet does not resolve path ambiguity. Hence, we provide a predictive, falsifiable boundary for pattern matching and a foundational diagnostic for disentangling mixed generalization mechanisms.","authors":["Hoyeon Chang","Jinho Park","Hanseul Cho","Sohee Yang","Miyoung Ko","Hyeonbin Hwang","Seungpil Won","Dohaeng Lee","Youbin Ahn","Minjoon Seo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.08805v3","updated":"2025-11-26T10:25:06Z","published":"2025-03-11T18:34:12Z","title":"Filter Like You Test: Data-Driven Data Filtering for CLIP Pretraining","summary":"We introduce Filter Like You Test (FLYT), an algorithm for curating large-scale vision-language datasets that learns the usefulness of each data point as a pretraining example. FLYT trains a scoring model that learns to weigh each example's features using gradient signals from downstream tasks training sets. Based on FLYT, we implement Mixing-FLYT (M-FLYT), which takes the per-example scores generated by different scoring methods as features, and learns to unify them into a single score. FLYT naturally produces a distribution over the training examples, which we leverage through Soft Cap Sampling (SCS), a strategy for obtaining a filtered pretraining dataset from per-example probabilities that samples examples while preventing over-representation through a repetition penalty. Using these methods, we achieve 40.1% ImageNet zero-shot accuracy on the DataComp medium scale filtering benchmark, a 2% absolute accuracy increase over all previous results and a 5.5% increase over results that - like us - use only public resources. Our approach also yields 37.7\\% on the average of 38 DataComp evaluation tasks, outperforming previous public-resource approaches by 0.4\\%.","authors":["Mikey Shechter","Yair Carmon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21247v1","updated":"2025-11-26T10:23:15Z","published":"2025-11-26T10:23:15Z","title":"The Spheres Dataset: Multitrack Orchestral Recordings for Music Source Separation and Information Retrieval","summary":"This paper introduces The Spheres dataset, multitrack orchestral recordings designed to advance machine learning research in music source separation and related MIR tasks within the classical music domain. The dataset is composed of over one hour recordings of musical pieces performed by the Colibrì Ensemble at The Spheres recording studio, capturing two canonical works - Tchaikovsky's Romeo and Juliet and Mozart's Symphony No. 40 - along with chromatic scales and solo excerpts for each instrument. The recording setup employed 23 microphones, including close spot, main, and ambient microphones, enabling the creation of realistic stereo mixes with controlled bleeding and providing isolated stems for supervised training of source separation models. In addition, room impulse responses were estimated for each instrument position, offering valuable acoustic characterization of the recording space. We present the dataset structure, acoustic analysis, and baseline evaluations using X-UMX based models for orchestral family separation and microphone debleeding. Results highlight both the potential and the challenges of source separation in complex orchestral scenarios, underscoring the dataset's value for benchmarking and for exploring new approaches to separation, localization, dereverberation, and immersive rendering of classical music.","authors":["Jaime Garcia-Martinez","David Diaz-Guerra","John Anderson","Ricardo Falcon-Perez","Pablo Cabañas-Molero","Tuomas Virtanen","Julio J. Carabias-Orti","Pedro Vera-Candeas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16148v2","updated":"2025-11-26T10:12:24Z","published":"2025-11-20T08:41:33Z","title":"Enhancing Nuclear Reactor Core Simulation through Data-Based Surrogate Models","summary":"In recent years, there has been an increasing need for Nuclear Power Plants (NPPs) to improve flexibility in order to match the rapid growth of renewable energies. The Operator Assistance Predictive System (OAPS) developed by Framatome addresses this problem through Model Predictive Control (MPC). In this work, we aim to improve MPC methods through data-driven simulation schemes. Thus, from a set of nonlinear stiff ordinary differential equations (ODEs), this paper introduces two surrogate models acting as alternative simulation schemes to enhance nuclear reactor core simulation. We show that both data-driven and physics-informed models can rapidly integrate complex dynamics, with a very low computational time (up to 1000x time reduction).","authors":["Perceval Beja-Battais","Alain Grossetête","Nicolas Vayatis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20516v2","updated":"2025-11-26T10:07:45Z","published":"2025-11-25T17:20:40Z","title":"Adam Simplified: Bias Correction Debunked","summary":"The Adam optimizer is a cornerstone of modern deep learning, yet the empirical necessity of each of its individual components is often taken for granted. This paper presents a focused investigation into the role of bias-correction, a feature whose contribution remains poorly understood. Through a series of systematic ablations on vision and language modelling tasks, we demonstrate that the conventional wisdom surrounding bias correction is misleading. In particular, we demonstrate that in the optimal hyper-parameter configuration, the inclusion of bias correction leads to no improvement in final test performance. Moreover, unless appropriate learning rate scheduling is implemented, the inclusion of bias correction can sometimes be detrimental to performance. We further reinterpret bias correction as a form of implicit learning rate scheduling whose behaviour is strongly dependent on the choice of smoothing hyper-parameters $β_1, β_2 \\in [0,1)$. Our findings challenge the universal inclusion of this component.","authors":["Sam Laing","Antonio Orvieto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21232v1","updated":"2025-11-26T10:01:31Z","published":"2025-11-26T10:01:31Z","title":"RISC-V Based TinyML Accelerator for Depthwise Separable Convolutions in Edge AI","summary":"The increasing demand for on-device intelligence in Edge AI and TinyML applications requires the efficient execution of modern Convolutional Neural Networks (CNNs). While lightweight architectures like MobileNetV2 employ Depthwise Separable Convolutions (DSC) to reduce computational complexity, their multi-stage design introduces a critical performance bottleneck inherent to layer-by-layer execution: the high energy and latency cost of transferring intermediate feature maps to either large on-chip buffers or off-chip DRAM. To address this memory wall, this paper introduces a novel hardware accelerator architecture that utilizes a fused pixel-wise dataflow. Implemented as a Custom Function Unit (CFU) for a RISC-V processor, our architecture eliminates the need for intermediate buffers entirely, reducing the data movement up to 87\\% compared to conventional layer-by-layer execution. It computes a single output pixel to completion across all DSC stages-expansion, depthwise convolution, and projection-by streaming data through a tightly-coupled pipeline without writing to memory. Evaluated on a Xilinx Artix-7 FPGA, our design achieves a speedup of up to 59.3x over the baseline software execution on the RISC-V core. Furthermore, ASIC synthesis projects a compact 0.284 mm$^2$ footprint with 910 mW power at 2 GHz in 28 nm, and a 1.20 mm$^2$ footprint with 233 mW power at 300 MHz in 40 nm. This work confirms the feasibility of a zero-buffer dataflow within a TinyML resource envelope, offering a novel and effective strategy for overcoming the memory wall in edge AI accelerators.","authors":["Muhammed Yildirim","Ozcan Ozturk"],"pdf_url":"","comment":"13 pages, 7 tables, 14 figures"},{"id":"http://arxiv.org/abs/2511.20586v2","updated":"2025-11-26T09:59:52Z","published":"2025-11-25T18:15:36Z","title":"PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic","summary":"Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the Parallel Trust Assessment System (PaTAS), a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through Trust Nodes and Trust Functions that propagate input, parameter, and activation trust across the network. The framework defines a Parameter Trust Update mechanism to refine parameter reliability during training and an Inference-Path Trust Assessment (IPTA) method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.","authors":["Koffi Ismael Ouattara","Ioannis Krontiris","Theo Dimitrakos","Dennis Eisermann","Frank Kargl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20382v2","updated":"2025-11-26T09:57:09Z","published":"2025-11-25T15:04:06Z","title":"MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained Transformers","summary":"Representation learning on multi-omics data is challenging due to extreme dimensionality, modality heterogeneity, and cohort-specific batch effects. While pre-trained transformer backbones have shown broad generalization capabilities in biological sequence modeling, their application to multi-omics integration remains underexplored. We present MoRE (Multi-Omics Representation Embedding), a framework that repurposes frozen pre-trained transformers to align heterogeneous assays into a shared latent space. Unlike purely generative approaches, MoRE employs a parameter-efficient fine-tuning (PEFT) strategy, prioritizing cross-sample and cross-modality alignment over simple sequence reconstruction. Specifically, MoRE attaches lightweight, modality-specific adapters and a task-adaptive fusion layer to the frozen backbone. It optimizes a masked modeling objective jointly with supervised contrastive and batch-invariant alignment losses, yielding structure-preserving embeddings that generalize across unseen cell types and platforms. We benchmark MoRE against established baselines, including scGPT, scVI, and Harmony with Scrublet, evaluating integration fidelity, rare population detection, and modality transfer. Our results demonstrate that MoRE achieves competitive batch robustness and biological conservation while significantly reducing trainable parameters compared to fully fine-tuned models. This work positions MoRE as a practical step toward general-purpose omics foundation models.","authors":["Audrey Pei-Hsuan Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21223v1","updated":"2025-11-26T09:53:28Z","published":"2025-11-26T09:53:28Z","title":"Maxitive Donsker-Varadhan Formulation for Possibilistic Variational Inference","summary":"Variational inference (VI) is a cornerstone of modern Bayesian learning, enabling approximate inference in complex models that would otherwise be intractable. However, its formulation depends on expectations and divergences defined through high-dimensional integrals, often rendering analytical treatment impossible and necessitating heavy reliance on approximate learning and inference techniques. Possibility theory, an imprecise probability framework, allows to directly model epistemic uncertainty instead of leveraging subjective probabilities. While this framework provides robustness and interpretability under sparse or imprecise information, adapting VI to the possibilistic setting requires rethinking core concepts such as entropy and divergence, which presuppose additivity. In this work, we develop a principled formulation of possibilistic variational inference and apply it to a special class of exponential-family functions, highlighting parallels with their probabilistic counterparts and revealing the distinctive mathematical structures of possibility theory.","authors":["Jasraj Singh","Shelvia Wongso","Jeremie Houssineau","Badr-Eddine Chérief-Abdellatif"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.08806v3","updated":"2025-11-26T09:50:14Z","published":"2024-07-11T18:30:01Z","title":"HO-FMN: Hyperparameter Optimization for Fast Minimum-Norm Attacks","summary":"Gradient-based attacks are a primary tool to evaluate robustness of machine-learning models. However, many attacks tend to provide overly-optimistic evaluations as they use fixed loss functions, optimizers, step-size schedulers, and default hyperparameters. In this work, we tackle these limitations by proposing a parametric variation of the well-known fast minimum-norm attack algorithm, whose loss, optimizer, step-size scheduler, and hyperparameters can be dynamically adjusted. We re-evaluate 12 robust models, showing that our attack finds smaller adversarial perturbations without requiring any additional tuning. This also enables reporting adversarial robustness as a function of the perturbation budget, providing a more complete evaluation than that offered by fixed-budget attacks, while remaining efficient. We release our open-source code at https://github.com/pralab/HO-FMN.","authors":["Raffaele Mura","Giuseppe Floris","Luca Scionis","Giorgio Piras","Maura Pintor","Ambra Demontis","Giorgio Giacinto","Battista Biggio","Fabio Roli"],"pdf_url":"","comment":"Accepted at Neurocomputing"},{"id":"http://arxiv.org/abs/2510.19296v3","updated":"2025-11-26T09:47:56Z","published":"2025-10-22T06:58:07Z","title":"QiMeng-SALV: Signal-Aware Learning for Verilog Code Generation","summary":"The remarkable progress of Large Language Models (LLMs) presents promising opportunities for Verilog code generation which is significantly important for automated circuit design. The lacking of meaningful functional rewards hinders the preference optimization based on Reinforcement Learning (RL) for producing functionally correct Verilog code. In this paper, we propose Signal-Aware Learning for Verilog code generation (QiMeng-SALV) by leveraging code segments of functionally correct output signal to optimize RL training. Considering Verilog code specifies the structural interconnection of hardware gates and wires so that different output signals are independent, the key insight of QiMeng-SALV is to extract verified signal-aware implementations in partially incorrect modules, so as to enhance the extraction of meaningful functional rewards. Roughly, we verify the functional correctness of signals in generated module by comparing with that of reference module in the training data. Then abstract syntax tree (AST) is employed to identify signal-aware code segments which can provide meaningful functional rewards from erroneous modules. Finally, we introduce signal-aware DPO which is optimized on the correct signal-level code segments, thereby preventing noise and interference from incorrect signals. The proposed QiMeng-SALV underscores the paradigm shift from conventional module-level to fine-grained signal-level optimization in Verilog code generation, addressing the issue of insufficient functional rewards. Experiments demonstrate that our method achieves state-of-the-art performance on VerilogEval and RTLLM, with a 7B parameter model matching the performance of the DeepSeek v3 671B model and significantly outperforming the leading open-source model CodeV trained on the same dataset. Our code is available at https://github.com/zy1xxx/SALV.","authors":["Yang Zhang","Rui Zhang","Jiaming Guo","Lei Huang","Di Huang","Yunpu Zhao","Shuyao Cheng","Pengwei Jin","Chongxiao Li","Zidong Du","Xing Hu","Qi Guo","Yunji Chen"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21215v1","updated":"2025-11-26T09:44:51Z","published":"2025-11-26T09:44:51Z","title":"From Diffusion to One-Step Generation: A Comparative Study of Flow-Based Models with Application to Image Inpainting","summary":"We present a comprehensive comparative study of three generative modeling paradigms: Denoising Diffusion Probabilistic Models (DDPM), Conditional Flow Matching (CFM), and MeanFlow. While DDPM and CFM require iterative sampling, MeanFlow enables direct one-step generation by modeling the average velocity over time intervals. We implement all three methods using a unified TinyUNet architecture (<1.5M parameters) on CIFAR-10, demonstrating that CFM achieves an FID of 24.15 with 50 steps, significantly outperforming DDPM (FID 402.98). MeanFlow achieves FID 29.15 with single-step sampling -- a 50X reduction in inference time. We further extend CFM to image inpainting, implementing mask-guided sampling with four mask types (center, random bbox, irregular, half). Our fine-tuned inpainting model achieves substantial improvements: PSNR increases from 4.95 to 8.57 dB on center masks (+73%), and SSIM improves from 0.289 to 0.418 (+45%), demonstrating the effectiveness of inpainting-aware training.","authors":["Umang Agarwal","Rudraksh Sangore","Sumit Laddha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21213v1","updated":"2025-11-26T09:44:10Z","published":"2025-11-26T09:44:10Z","title":"Lattice-to-total thermal conductivity ratio: a phonon-glass electron-crystal descriptor for data-driven thermoelectric design","summary":"Thermoelectrics (TEs) are promising candidates for energy harvesting with performance quantified by figure of merit, $ZT$. To accelerate the discovery of high-$ZT$ materials, efforts have focused on identifying compounds with low thermal conductivity $κ$. Using a curated dataset of 71,913 entries, we show that high-$ZT$ materials reside not only in the low-$κ$ regime but also cluster near a lattice-to-total thermal conductivity ratio ($κ_\\mathrm{L}/κ$) of approximately 0.5, consistent with the phonon-glass electron-crystal design concept. Building on this insight, we construct a framework consisting of two machine learning models for the lattice and electronic components of thermal conductivity that jointly provide both $κ$ and $κ_\\mathrm{L}/κ$ for screening and guiding the optimization of TE materials. Among 104,567 compounds screened, our models identify 2,522 ultralow-$κ$ candidates. Follow-up case studies demonstrate that this framework can reliably provide optimization strategies by suggesting new dopants and alloys that shift pristine materials toward the $κ_\\mathrm{L}/κ$ approaching 0.5 regime. Ultimately, by integrating rapid screening with PGEC-guided optimization, our data-driven framework effectively bridges the critical gap between materials discovery and performance enhancement.","authors":["Yifan Sun","Zhi Li","Tetsuya Imamura","Yuji Ohishi","Chris Wolverton","Ken Kurosaki"],"pdf_url":"","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.21211v1","updated":"2025-11-26T09:41:20Z","published":"2025-11-26T09:41:20Z","title":"Robust Gene Prioritization via Fast-mRMR Feature Selection in high-dimensional omics data","summary":"Gene prioritization (identifying genes potentially associated with a biological process) is increasingly tackled with Artificial Intelligence. However, existing methods struggle with the high dimensionality and incomplete labelling of biomedical data. This work proposes a more robust and efficient pipeline that leverages Fast-mRMR feature selection to retain only relevant, non-redundant features for classifiers. This enables us to build simpler and more effective models, as well as to combine different biological feature sets. Experiments on Dietary Restriction datasets show significant improvements over existing methods, proving that feature selection can be critical for reliable gene prioritization.","authors":["Rubén Fernández-Farelo","Jorge Paz-Ruza","Bertha Guijarro-Berdiñas","Amparo Alonso-Betanzos","Alex A. Freitas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21208v1","updated":"2025-11-26T09:39:35Z","published":"2025-11-26T09:39:35Z","title":"I-GLIDE: Input Groups for Latent Health Indicators in Degradation Estimation","summary":"Accurate remaining useful life (RUL) prediction hinges on the quality of health indicators (HIs), yet existing methods often fail to disentangle complex degradation mechanisms in multi-sensor systems or quantify uncertainty in HI reliability. This paper introduces a novel framework for HI construction, advancing three key contributions. First, we adapt Reconstruction along Projected Pathways (RaPP) as a health indicator (HI) for RUL prediction for the first time, showing that it outperforms traditional reconstruction error metrics. Second, we show that augmenting RaPP-derived HIs with aleatoric and epistemic uncertainty quantification (UQ) via Monte Carlo dropout and probabilistic latent spaces- significantly improves RUL-prediction robustness. Third, and most critically, we propose indicator groups, a paradigm that isolates sensor subsets to model system-specific degradations, giving rise to our novel method, I-GLIDE which enables interpretable, mechanism-specific diagnostics. Evaluated on data sourced from aerospace and manufacturing systems, our approach achieves marked improvements in accuracy and generalizability compared to state-of-the-art HI methods while providing actionable insights into system failure pathways. This work bridges the gap between anomaly detection and prognostics, offering a principled framework for uncertainty-aware degradation modeling in complex systems.","authors":["Lucas Thil","Jesse Read","Rim Kaddah","Guillaume Doquet"],"pdf_url":"","comment":"Included in the conference series: Joint European Conference on Machine Learning and Knowledge Discovery in Databases"},{"id":"http://arxiv.org/abs/2511.18157v2","updated":"2025-11-26T09:37:48Z","published":"2025-11-22T18:52:34Z","title":"scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python","summary":"Three-dimensional rigid-body transforms, i.e. rotations and translations, are central to modern differentiable machine learning pipelines in robotics, vision, and simulation. However, numerically robust and mathematically correct implementations, particularly on SO(3), are error-prone due to issues such as axis conventions, normalizations, composition consistency and subtle errors that only appear in edge cases. SciPy's spatial$.$transform module is a rigorously tested Python implementation. However, it historically only supported NumPy, limiting adoption in GPU-accelerated and autodiff-based workflows. We present a complete overhaul of SciPy's spatial$.$transform functionality that makes it compatible with any array library implementing the Python array API, including JAX, PyTorch, and CuPy. The revised implementation preserves the established SciPy interface while enabling GPU/TPU execution, JIT compilation, vectorized batching, and differentiation via native autodiff of the chosen backend. We demonstrate how this foundation supports differentiable scientific computing through two case studies: (i) scalability of 3D transforms and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation for accurate integration of rotational dynamics. Our contributions have been merged into SciPy main and will ship in the next release, providing a framework-agnostic, production-grade basis for 3D spatial math in differentiable systems and ML.","authors":["Martin Schuck","Alexander von Rohr","Angela P. Schoellig"],"pdf_url":"","comment":"Accepted as oral at the 1st Workshop on Differentiable Systems and Scientific Machine Learning @ EurIPS 2025"},{"id":"http://arxiv.org/abs/2510.18866v3","updated":"2025-11-26T09:32:08Z","published":"2025-10-21T17:58:17Z","title":"LightMem: Lightweight and Efficient Memory-Augmented Generation","summary":"Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at https://github.com/zjunlp/LightMem.","authors":["Jizhan Fang","Xinle Deng","Haoming Xu","Ziyan Jiang","Yuqi Tang","Ziwen Xu","Shumin Deng","Yunzhi Yao","Mengru Wang","Shuofei Qiao","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2507.09061v5","updated":"2025-11-26T09:29:30Z","published":"2025-07-11T22:36:39Z","title":"Action Chunking and Exploratory Data Collection Yield Exponential Improvements in Behavior Cloning for Continuous Control","summary":"This paper presents a theoretical analysis of two of the most impactful interventions in modern learning from demonstration in robotics and continuous control: the practice of action-chunking (predicting sequences of actions in open-loop) and exploratory augmentation of expert demonstrations. Though recent results show that learning from demonstration, also known as imitation learning (IL), can suffer errors that compound exponentially with task horizon in continuous settings, we demonstrate that action chunking and exploratory data collection circumvent exponential compounding errors in different regimes. Our results identify control-theoretic stability as the key mechanism underlying the benefits of these interventions. On the empirical side, we validate our predictions and the role of control-theoretic stability through experimentation on popular robot learning benchmarks. On the theoretical side, we demonstrate that the control-theoretic lens provides fine-grained insights into how compounding error arises, leading to tighter statistical guarantees on imitation learning error when these interventions are applied than previous techniques based on information-theoretic considerations alone.","authors":["Thomas T. Zhang","Daniel Pfrommer","Chaoyi Pan","Nikolai Matni","Max Simchowitz"],"pdf_url":"","comment":"Updated manuscript. New visualization figures and control-theory primer"},{"id":"http://arxiv.org/abs/2311.01759v3","updated":"2025-11-26T09:27:01Z","published":"2023-11-03T07:34:47Z","title":"TinyFormer: Efficient Transformer Design and Deployment on Tiny Devices","summary":"Developing deep learning models on tiny devices (e.g. Microcontroller units, MCUs) has attracted much attention in various embedded IoT applications. However, it is challenging to efficiently design and deploy recent advanced models (e.g. transformers) on tiny devices due to their severe hardware resource constraints. In this work, we propose TinyFormer, a framework specifically designed to develop and deploy resource-efficient transformer models on MCUs. TinyFormer consists of SuperNAS, SparseNAS, and SparseEngine. Separately, SuperNAS aims to search for an appropriate supernet from a vast search space. SparseNAS evaluates the best sparse single-path transformer model from the identified supernet. Finally, SparseEngine efficiently deploys the searched sparse models onto MCUs. To the best of our knowledge, SparseEngine is the first deployment framework capable of performing inference of sparse transformer models on MCUs. Evaluation results on the CIFAR-10 dataset demonstrate that TinyFormer can design efficient transformers with an accuracy of 96.1% while adhering to hardware constraints of 1MB storage and 320KB memory. Additionally, TinyFormer achieves significant speedups in sparse inference, up to 12.2x comparing to the CMSIS-NN library. TinyFormer is believed to bring powerful transformers into TinyML scenarios and to greatly expand the scope of deep learning applications","authors":["Jianlei Yang","Jiacheng Liao","Fanding Lei","Meichen Liu","Lingkun Long","Junyi Chen","Han Wan","Bei Yu","Weisheng Zhao"],"pdf_url":"","comment":"This paper is accepted by IEEE Transactions on Circuits and Systems I: Regular Papers"},{"id":"http://arxiv.org/abs/2408.15041v2","updated":"2025-11-26T09:25:45Z","published":"2024-08-27T13:10:26Z","title":"Earth Observation Satellite Scheduling with Graph Neural Networks and Monte Carlo Tree Search","summary":"Earth Observation Satellite Planning (EOSP) is a difficult optimization problem with considerable practical interest. A set of requested observations must be scheduled on an agile Earth observation satellite while respecting constraints on their visibility window, as well as maneuver constraints that impose varying delays between successive observations. In addition, the problem is largely oversubscribed: there are much more candidate observations than can possibly be achieved. Therefore, one must select the set of observations that will be performed while maximizing their cumulative benefit and propose a feasible schedule for these observations. As previous work mostly focused on heuristic and iterative search algorithms, this paper presents a new technique for selecting and scheduling observations based on Graph Neural Networks (GNNs) and Deep Reinforcement Learning (DRL). GNNs are used to extract relevant information from the graphs representing instances of the EOSP, and DRL drives the search for optimal schedules. A post-learning search step based on Monte Carlo Tree Search (MCTS) is added that is able to find even better solutions. Experiments show that it is able to learn on small problem instances and generalize to larger real-world instances, with very competitive performance compared to traditional approaches.","authors":["Antoine Jacquet","Guillaume Infantes","Emmanuel Benazera","Vincent Baudoui","Jonathan Guerra","Stéphanie Roussel"],"pdf_url":"","comment":"Accepted at International Workshop on Planning & Scheduling for Space (IWPSS 2025)"},{"id":"http://arxiv.org/abs/2412.18218v2","updated":"2025-11-26T09:24:44Z","published":"2024-12-24T06:55:53Z","title":"On the Effectiveness of Adversarial Training on Malware Classifiers","summary":"Adversarial Training (AT) is a key defense against Machine Learning evasion attacks, but its effectiveness for real-world malware detection remains poorly understood. This uncertainty stems from a critical disconnect in prior research: studies often overlook the inherent nature of malware and are fragmented, examining diverse variables like realism or confidence of adversarial examples in isolation, or relying on weak evaluations that yield non-generalizable insights. To address this, we introduce Rubik, a framework for the systematic, multi-dimensional evaluation of AT in the malware domain. This framework defines diverse key factors across essential dimensions, including data, feature representations, classifiers, and robust optimization settings, for a comprehensive exploration of the interplay of influential AT's variables through reliable evaluation practices, such as realistic evasion attacks. We instantiate Rubik on Android malware, empirically analyzing how this interplay shapes robustness. Our findings challenge prior beliefs--showing, for instance, that realizable adversarial examples offer only conditional robustness benefits--and reveal new insights, such as the critical role of model architecture and feature-space structure in determining AT's success. From this analysis, we distill four key insights, expose four common evaluation misconceptions, and offer practical recommendations to guide the development of truly robust malware classifiers.","authors":["Hamid Bostani","Jacopo Cortellazzi","Daniel Arp","Fabio Pierazzi","Veelasha Moonsamy","Lorenzo Cavallaro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21181v1","updated":"2025-11-26T08:55:11Z","published":"2025-11-26T08:55:11Z","title":"Privacy in Federated Learning with Spiking Neural Networks","summary":"Spiking neural networks (SNNs) have emerged as prominent candidates for embedded and edge AI. Their inherent low power consumption makes them far more efficient than conventional ANNs in scenarios where energy budgets are tightly constrained. In parallel, federated learning (FL) has become the prevailing training paradigm in such settings, enabling on-device learning while limiting the exposure of raw data. However, gradient inversion attacks represent a critical privacy threat in FL, where sensitive training data can be reconstructed directly from shared gradients. While this vulnerability has been widely investigated in conventional ANNs, its implications for SNNs remain largely unexplored. In this work, we present the first comprehensive empirical study of gradient leakage in SNNs across diverse data domains. SNNs are inherently non-differentiable and are typically trained using surrogate gradients, which we hypothesized would be less correlated with the original input and thus less informative from a privacy perspective. To investigate this, we adapt different gradient leakage attacks to the spike domain. Our experiments reveal a striking contrast with conventional ANNs: whereas ANN gradients reliably expose salient input content, SNN gradients yield noisy, temporally inconsistent reconstructions that fail to recover meaningful spatial or temporal structure. These results indicate that the combination of event-driven dynamics and surrogate-gradient training substantially reduces gradient informativeness. To the best of our knowledge, this work provides the first systematic benchmark of gradient inversion attacks for spiking architectures, highlighting the inherent privacy-preserving potential of neuromorphic computation.","authors":["Dogukan Aksu","Jesus Martinez del Rincon","Ihsen Alouani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15250v2","updated":"2025-11-26T08:52:51Z","published":"2025-11-19T09:10:02Z","title":"Optimized scheduling of electricity-heat cooperative system considering wind energy consumption and peak shaving and valley filling","summary":"With the global energy transition and rapid development of renewable energy, the scheduling optimization challenge for combined power-heat systems under new energy integration and multiple uncertainties has become increasingly prominent. Addressing this challenge, this study proposes an intelligent scheduling method based on the improved Dual-Delay Deep Deterministic Policy Gradient (PVTD3) algorithm. System optimization is achieved by introducing a penalty term for grid power purchase variations. Simulation results demonstrate that under three typical scenarios (10%, 20%, and 30% renewable penetration), the PVTD3 algorithm reduces the system's comprehensive cost by 6.93%, 12.68%, and 13.59% respectively compared to the traditional TD3 algorithm. Concurrently, it reduces the average fluctuation amplitude of grid power purchases by 12.8%. Regarding energy storage management, the PVTD3 algorithm reduces the end-time state values of low-temperature thermal storage tanks by 7.67-17.67 units while maintaining high-temperature tanks within the 3.59-4.25 safety operating range. Multi-scenario comparative validation demonstrates that the proposed algorithm not only excels in economic efficiency and grid stability but also exhibits superior sustainable scheduling capabilities in energy storage device management.","authors":["Jin Ye","Lingmei Wang","Shujian Zhang","Haihang Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.21012v2","updated":"2025-11-26T08:37:28Z","published":"2025-09-25T11:18:09Z","title":"Mechanism of Task-oriented Information Removal in In-context Learning","summary":"In-context Learning (ICL) is an emerging few-shot learning paradigm based on modern Language Models (LMs), yet its inner mechanism remains unclear. In this paper, we investigate the mechanism through a novel perspective of information removal. Specifically, we demonstrate that in the zero-shot scenario, LMs encode queries into non-selective representations in hidden states containing information for all possible tasks, leading to arbitrary outputs without focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we find that selectively removing specific information from hidden states by a low-rank filter effectively steers LMs toward the intended task. Building on these findings, by measuring the hidden states on carefully designed metrics, we observe that few-shot ICL effectively simulates such task-oriented information removal processes, selectively removing the redundant information from entangled non-selective representations, and improving the output based on the demonstrations, which constitutes a key mechanism underlying ICL. Moreover, we identify essential attention heads inducing the removal operation, termed Denoising Heads, which enables the ablation experiments blocking the information removal operation from the inference, where the ICL accuracy significantly degrades, especially when the correct label is absent from the few-shot demonstrations, confirming both the critical role of the information removal mechanism and denoising heads.","authors":["Hakaze Cho","Haolin Yang","Gouki Minegishi","Naoya Inoue"],"pdf_url":"","comment":"87 pages, 90 figures, 7 tables"},{"id":"http://arxiv.org/abs/2504.16941v4","updated":"2025-11-26T08:37:18Z","published":"2025-04-08T19:21:44Z","title":"Mathematical Insights into Protein Architecture: Persistent Homology and Machine Learning Applied to the Flagellar Motor","summary":"We present a machine learning approach that leverages persistent homology to classify bacterial flagellar motors into two functional states: rotated and stalled. By embedding protein structural data into a topological framework, we extract multiscale features from filtered simplicial complexes constructed over atomic coordinates. These topological invariants, specifically persistence diagrams and barcodes, capture critical geometric and connectivity patterns that correlate with motor function. The extracted features are vectorized and integrated into a machine learning pipeline that includes dimensionality reduction and supervised classification. Applied to a curated dataset of experimentally characterized flagellar motors from diverse bacterial species, our model demonstrates high classification accuracy and robustness to structural variation. This approach highlights the power of topological data analysis in revealing functionally relevant patterns beyond the reach of traditional geometric descriptors, offering a novel computational tool for protein function prediction.","authors":["Zakaria Lamine","Abdelatif Hafid","Mohamed Rahouti","My Ismail Mamouni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18513v2","updated":"2025-11-26T08:21:05Z","published":"2025-05-24T05:17:53Z","title":"Enhancing Training Data Attribution with Representational Optimization","summary":"Training data attribution (TDA) methods aim to measure how training data impacts a model's predictions. While gradient-based attribution methods, such as influence functions, offer theoretical grounding, their computational costs make them impractical for large-scale applications. Representation-based approaches are far more scalable, but typically rely on heuristic embeddings that are not optimized for attribution, limiting their fidelity. To address these challenges, we propose AirRep, a scalable, representation-based approach that closes this gap by learning task-specific and model-aligned representations optimized explicitly for TDA. AirRep introduces two key innovations: a trainable encoder tuned for attribution quality, and an attention-based pooling mechanism that enables accurate estimation of group-wise influence. We train AirRep using a ranking objective over automatically constructed training subsets labeled by their empirical effect on target predictions. Experiments on instruction-tuned LLMs demonstrate that AirRep achieves performance on par with state-of-the-art gradient-based approaches while being nearly two orders of magnitude more efficient at inference time. Further analysis highlights its robustness and generalization across tasks and models. Our code is available at https://github.com/sunnweiwei/AirRep","authors":["Weiwei Sun","Haokun Liu","Nikhil Kandpal","Colin Raffel","Yiming Yang"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21140v1","updated":"2025-11-26T07:46:46Z","published":"2025-11-26T07:46:46Z","title":"How to Correctly Report LLM-as-a-Judge Evaluations","summary":"Large language models (LLMs) are increasingly used as evaluators in lieu of humans. While scalable, their judgments are noisy due to imperfect specificity and sensitivity of LLMs, leading to biased accuracy estimates. Although bias-correction methods exist, they are underutilized in LLM research and typically assume exact knowledge of the model's specificity and sensitivity. Furthermore, in general we only have estimates of these values and it is not well known how to properly construct confidence intervals using only estimates. This work presents a simple plug-in framework that corrects such bias and constructs confidence intervals reflecting uncertainty from both test and calibration dataset, enabling practical and statistically sound LLM-based evaluation. Additionally, to reduce uncertainty in the accuracy estimate, we introduce an adaptive algorithm that efficiently allocates calibration sample sizes.","authors":["Chungpa Lee","Thomas Zeng","Jongwon Jeong","Jy-yong Sohn","Kangwook Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.15723v2","updated":"2025-11-26T07:44:17Z","published":"2024-09-24T04:14:33Z","title":"Federated Large Language Models: Current Progress and Future Directions","summary":"Large language models are rapidly gaining popularity and have been widely adopted in real-world applications. While the quality of training data is essential, privacy concerns arise during data collection. Federated learning offers a solution by allowing multiple clients to collaboratively train LLMs without sharing local data. However, FL introduces new challenges, such as model convergence issues due to heterogeneous data and high communication costs. A comprehensive study is required to address these challenges and guide future research. This paper surveys Federated learning for LLMs (FedLLM), highlighting recent advances and future directions. We focus on two key aspects: fine-tuning and prompt learning in a federated setting, discussing existing work and associated research challenges. We finally propose potential directions for federated LLMs, including pre-training, federated agents, and LLMs for federated learning.","authors":["Yuhang Yao","Jianyi Zhang","Junda Wu","Chengkai Huang","Yu Xia","Tong Yu","Ruiyi Zhang","Sungchul Kim","Ryan Rossi","Ang Li","Lina Yao","Julian McAuley","Yiran Chen","Carlee Joe-Wong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20169v2","updated":"2025-11-26T07:43:25Z","published":"2025-10-23T03:30:18Z","title":"Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP","summary":"Traveling Salesman Problem (TSP) is a classic NP-hard problem that has garnered significant attention from both academia and industry. While neural-based methods have shown promise for solving TSPs, they still face challenges in scaling to larger instances, particularly in memory constraints associated with global heatmaps, edge weights, or access matrices, as well as in generating high-quality initial solutions and insufficient global guidance for efficiently navigating vast search spaces. To address these challenges, we propose a Hyper Tour Guided Neighborhood Search (HyperNS) method for large-scale TSP instances. Inspired by the ``clustering first, route second\" strategy, our approach initially divides the TSP instance into clusters using a sparse heatmap graph and abstracts them as supernodes, followed by the generation of a hyper tour to guide both the initialization and optimization processes. This method reduces the search space by focusing on edges relevant to the hyper tour, leading to more efficient and effective optimization. Experimental results on both synthetic and real-world datasets demonstrate that our approach outperforms existing neural-based methods, particularly in handling larger-scale instances, offering a significant reduction in the gap to the optimal solution.","authors":["Tongkai Lu","Shuai Ma","Chongyang Tao"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2508.04231v2","updated":"2025-11-26T07:42:25Z","published":"2025-08-06T09:14:08Z","title":"Empowering Time Series Forecasting with LLM-Agents","summary":"Large Language Model (LLM) powered agents have emerged as effective planners for Automated Machine Learning (AutoML) systems. While most existing AutoML approaches focus on automating feature engineering and model architecture search, recent studies in time series forecasting suggest that lightweight models can often achieve state-of-the-art performance. This observation led us to explore improving data quality, rather than model architecture, as a potentially fruitful direction for AutoML on time series data. We propose DCATS, a Data-Centric Agent for Time Series. DCATS leverages metadata accompanying time series to clean data while optimizing forecasting performance. We evaluated DCATS using four time series forecasting models on a large-scale traffic volume forecasting dataset. Results demonstrate that DCATS achieves an average 6% error reduction across all tested models and time horizons, highlighting the potential of data-centric approaches in AutoML for time series forecasting.","authors":["Chin-Chia Michael Yeh","Vivian Lai","Uday Singh Saini","Xiran Fan","Yujie Fan","Junpeng Wang","Xin Dai","Yan Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.17729v3","updated":"2025-11-26T07:41:49Z","published":"2025-09-22T12:59:18Z","title":"A Conditional Distribution Equality Testing Framework using Deep Generative Learning","summary":"In this paper, we propose a general framework for testing the conditional distribution equality in a two-sample problem, which is most relevant to covariate shift and causal discovery. Our framework is built on neural network-based generative methods and sample splitting techniques by transforming the conditional testing problem into an unconditional one. We introduce the generative classification accuracy-based conditional distribution equality test (GCA-CDET) to illustrate the proposed framework. We establish the convergence rate for the learned generator by deriving new results related to the recently-developed offset Rademacher complexity and prove the testing consistency of GCA-CDET under mild conditions.Empirically, we conduct numerical studies including synthetic datasets and two real-world datasets, demonstrating the effectiveness of our approach. Additional discussions on the optimality of the proposed framework are provided in the online supplementary material.","authors":["Siming Zheng","Tong Wang","Meifang Lan","Yuanyuan Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12489v2","updated":"2025-11-26T07:35:37Z","published":"2025-11-16T07:53:35Z","title":"SculptDrug : A Spatial Condition-Aware Bayesian Flow Model for Structure-based Drug Design","summary":"Structure-Based drug design (SBDD) has emerged as a popular approach in drug discovery, leveraging three-dimensional protein structures to generate drug ligands. However, existing generative models encounter several key challenges: (1) incorporating boundary condition constraints, (2) integrating hierarchical structural conditions, and (3) ensuring spatial modeling fidelity. To address these limitations, we propose SculptDrug, a spatial condition-aware generative model based on Bayesian flow networks (BFNs). First, SculptDrug follows a BFN-based framework and employs a progressive denoising strategy to ensure spatial modeling fidelity, iteratively refining atom positions while enhancing local interactions for precise spatial alignment. Second, we introduce a Boundary Awareness Block that incorporates protein surface constraints into the generative process to ensure that generated ligands are geometrically compatible with the target protein. Third, we design a Hierarchical Encoder that captures global structural context while preserving fine-grained molecular interactions, ensuring overall consistency and accurate ligand-protein conformations. We evaluate SculptDrug on the CrossDocked dataset, and experimental results demonstrate that SculptDrug outperforms state-of-the-art baselines, highlighting the effectiveness of spatial condition-aware modeling.","authors":["Qingsong Zhong","Haomin Yu","Yan Lin","Wangmeng Shen","Long Zeng","Jilin Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19694v2","updated":"2025-11-26T07:35:29Z","published":"2025-11-24T20:57:55Z","title":"TiCT: A Synthetically Pre-Trained Foundation Model for Time Series Classification","summary":"The ubiquity of time series data creates a strong demand for general-purpose foundation models, yet developing them for classification remains a significant challenge, largely due to the high cost of labeled data. Foundation models capable of in-context learning (ICL) offer a powerful solution, adapting to new tasks with minimal examples and reducing the need for extensive retraining. However, prior work on large-scale time series models has predominantly focused on forecasting, leaving a critical gap for versatile, fine-tuning-free classification. To address this, we introduce TiCT (Time-series in-Context Transformer), a transformer-based model pre-trained exclusively on synthetic data to perform in-context classification. We make two primary technical contributions: 1) a novel architecture featuring a scalable bit-based label encoding and a special output attention mechanism to handle an arbitrary number of classes; and 2) a synthetic pre-training framework that combines a Mixup-inspired process with data augmentation to foster generalization and noise invariance. Extensive evaluations on the UCR Archive show that TiCT achieves competitive performance against state-of-the-art supervised methods. Crucially, this is accomplished using only in-context examples at inference time, without updating a single model weight.","authors":["Chin-Chia Michael Yeh","Uday Singh Saini","Junpeng Wang","Xin Dai","Xiran Fan","Jiarui Sun","Yujie Fan","Yan Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.00310v2","updated":"2025-11-26T07:27:32Z","published":"2025-06-30T22:53:59Z","title":"AutoDiscovery: Open-ended Scientific Discovery via Bayesian Surprise","summary":"The promise of autonomous scientific discovery (ASD) hinges not only on answering questions, but also on knowing which questions to ask. Most recent works in ASD explore the use of large language models (LLMs) in goal-driven settings, relying on human-specified research questions to guide hypothesis generation. However, scientific discovery may be accelerated further by allowing the AI system to drive exploration by its own criteria. The few existing approaches in open-ended ASD select hypotheses based on diversity heuristics or subjective proxies for human interestingness, but the former struggles to meaningfully navigate the typically vast hypothesis space, and the latter suffers from imprecise definitions. This paper presents AutoDiscovery -- a method for open-ended ASD that instead drives scientific exploration using Bayesian surprise. Here, we quantify the epistemic shift from the LLM's prior beliefs about a hypothesis to its posterior beliefs after gathering experimental results. To efficiently explore the space of nested hypotheses, our method employs a Monte Carlo tree search (MCTS) strategy with progressive widening using surprisal as the reward function. We evaluate AutoDiscovery in the setting of data-driven discovery across 21 real-world datasets spanning domains such as biology, economics, finance, and behavioral science. Our results demonstrate that under a fixed budget, AutoDiscovery substantially outperforms competitors by producing 5-29% more discoveries deemed surprising by the LLM. Our human evaluation further reveals that two-thirds of discoveries made by our system are surprising to domain experts as well, suggesting this is an important step towards building open-ended ASD systems.","authors":["Dhruv Agarwal","Bodhisattwa Prasad Majumder","Reece Adamson","Megha Chakravorty","Satvika Reddy Gavireddy","Aditya Parashar","Harshit Surana","Bhavana Dalvi Mishra","Andrew McCallum","Ashish Sabharwal","Peter Clark"],"pdf_url":"","comment":"Accepted to NeurIPS 2025; https://neurips.cc/virtual/2025/loc/san-diego/poster/116398"},{"id":"http://arxiv.org/abs/2502.01364v2","updated":"2025-11-26T07:19:57Z","published":"2025-02-03T13:56:48Z","title":"Meursault as a Data Point","summary":"In an era dominated by datafication, the reduction of human experiences to quantifiable metrics raises profound philosophical and ethical questions. This paper explores these issues through the lens of Meursault, the protagonist of Albert Camus' The Stranger, whose emotionally detached existence epitomizes the existential concept of absurdity. Using natural language processing (NLP) techniques including emotion detection (BERT), sentiment analysis (VADER), and named entity recognition (spaCy)-this study quantifies key events and behaviors in Meursault's life. Our analysis reveals the inherent limitations of applying algorithmic models to complex human experiences, particularly those rooted in existential alienation and moral ambiguity. By examining how modern AI tools misinterpret Meursault's actions and emotions, this research underscores the broader ethical dilemmas of reducing nuanced human narratives to data points, challenging the foundational assumptions of our data-driven society. The findings presented in this paper serve as a critique of the increasing reliance on data-driven narratives and advocate for incorporating humanistic values in artificial intelligence.","authors":["Abhinav Pratap"],"pdf_url":"","comment":"7 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.21120v1","updated":"2025-11-26T07:15:00Z","published":"2025-11-26T07:15:00Z","title":"Learning Cell-Aware Hierarchical Multi-Modal Representations for Robust Molecular Modeling","summary":"Understanding how chemical perturbations propagate through biological systems is essential for robust molecular property prediction. While most existing methods focus on chemical structures alone, recent advances highlight the crucial role of cellular responses such as morphology and gene expression in shaping drug effects. However, current cell-aware approaches face two key limitations: (1) modality incompleteness in external biological data, and (2) insufficient modeling of hierarchical dependencies across molecular, cellular, and genomic levels. We propose CHMR (Cell-aware Hierarchical Multi-modal Representations), a robust framework that jointly models local-global dependencies between molecules and cellular responses and captures latent biological hierarchies via a novel tree-structured vector quantization module. Evaluated on nine public benchmarks spanning 728 tasks, CHMR outperforms state-of-the-art baselines, yielding average improvements of 3.6% on classification and 17.2% on regression tasks. These results demonstrate the advantage of hierarchy-aware, multimodal learning for reliable and biologically grounded molecular representations, offering a generalizable framework for integrative biomedical modeling. The code is in https://github.com/limengran98/CHMR.","authors":["Mengran Li","Zelin Zang","Wenbin Xing","Junzhou Chen","Ronghui Zhang","Jiebo Luo","Stan Z. Li"],"pdf_url":"","comment":"Accepted to AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2511.21118v1","updated":"2025-11-26T07:13:38Z","published":"2025-11-26T07:13:38Z","title":"Trustless Federated Learning at Edge-Scale: A Compositional Architecture for Decentralized, Verifiable, and Incentive-Aligned Coordination","summary":"Artificial intelligence is retracing the Internet's path from centralized provision to distributed creation. Initially, resource-intensive computation concentrates within institutions capable of training and serving large models.Eventually, as federated learning matures, billions of edge devices holding sensitive data will be able to collectively improve models without surrendering raw information, enabling both contribution and consumption at scale. This democratic vision remains unrealized due to certain compositional gaps; aggregators handle updates without accountability, economic mechanisms are lacking and even when present remain vulnerable to gaming, coordination serializes state modifications limiting scalability, and governance permits retroactive manipulation. This work addresses these gaps by leveraging cryptographic receipts to prove aggregation correctness, geometric novelty measurement to prevent incentive gaming, parallel object ownership to achieve linear scalability, and time-locked policies to check retroactive manipulation.","authors":["Pius Onobhayedo","Paul Osemudiame Oamen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21115v1","updated":"2025-11-26T07:01:35Z","published":"2025-11-26T07:01:35Z","title":"Nonconvex Penalized LAD Estimation in Partial Linear Models with DNNs: Asymptotic Analysis and Proximal Algorithms","summary":"This paper investigates the partial linear model by Least Absolute Deviation (LAD) regression. We parameterize the nonparametric term using Deep Neural Networks (DNNs) and formulate a penalized LAD problem for estimation. Specifically, our model exhibits the following challenges. First, the regularization term can be nonconvex and nonsmooth, necessitating the introduction of infinite dimensional variational analysis and nonsmooth analysis into the asymptotic normality discussion. Second, our network must expand (in width, sparsity level and depth) as more samples are observed, thereby introducing additional difficulties for theoretical analysis. Third, the oracle of the proposed estimator is itself defined through a ultra high-dimensional, nonconvex, and discontinuous optimization problem, which already entails substantial computational and theoretical challenges. Under such the challenges, we establish the consistency, convergence rate, and asymptotic normality of the estimator. Furthermore, we analyze the oracle problem itself and its continuous relaxation. We study the convergence of a proximal subgradient method for both formulations, highlighting their structural differences lead to distinct computational subproblems along the iterations. In particular, the relaxed formulation admits significantly cheaper proximal updates, reflecting an inherent trade-off between statistical accuracy and computational tractability.","authors":["Lechen Feng","Haoran Li","Lucky Li","Xingqiu Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.14914v4","updated":"2025-11-26T06:52:48Z","published":"2025-02-19T07:55:51Z","title":"CAPability: A Comprehensive Visual Caption Benchmark for Evaluating Both Correctness and Thoroughness","summary":"Visual captioning benchmarks have become outdated with the emergence of modern multimodal large language models (MLLMs), as the brief ground-truth sentences and traditional metrics fail to assess detailed captions effectively. While recent benchmarks attempt to address this by focusing on keyword extraction or object-centric evaluation, they remain limited to vague-view or object-view analyses and incomplete visual element coverage. In this paper, we introduce CAPability, a comprehensive multi-view benchmark for evaluating visual captioning across 12 dimensions spanning six critical views. We curate nearly 11K human-annotated images and videos with visual element annotations to evaluate the generated captions. CAPability stably assesses both the correctness and thoroughness of captions with \\textit{precision} and \\textit{hit} metrics. By converting annotations to QA pairs, we further introduce a heuristic metric, \\textit{know but cannot tell} ($K\\bar{T}$), indicating a significant performance gap between QA and caption capabilities. Our work provides a holistic analysis of MLLMs' captioning abilities, as we identify their strengths and weaknesses across various dimensions, guiding future research to enhance specific aspects of their capabilities.","authors":["Zhihang Liu","Chen-Wei Xie","Bin Wen","Feiwu Yu","Jixuan Chen","Pandeng Li","Boqiang Zhang","Nianzu Yang","Yinglu Li","Zuan Gao","Yun Zheng","Hongtao Xie"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21109v1","updated":"2025-11-26T06:52:25Z","published":"2025-11-26T06:52:25Z","title":"Interpretable Fair Clustering","summary":"Fair clustering has gained increasing attention in recent years, especially in applications involving socially sensitive attributes. However, existing fair clustering methods often lack interpretability, limiting their applicability in high-stakes scenarios where understanding the rationale behind clustering decisions is essential. In this work, we address this limitation by proposing an interpretable and fair clustering framework, which integrates fairness constraints into the structure of decision trees. Our approach constructs interpretable decision trees that partition the data while ensuring fair treatment across protected groups. To further enhance the practicality of our framework, we also introduce a variant that requires no fairness hyperparameter tuning, achieved through post-pruning a tree constructed without fairness constraints. Extensive experiments on both real-world and synthetic datasets demonstrate that our method not only delivers competitive clustering performance and improved fairness, but also offers additional advantages such as interpretability and the ability to handle multiple sensitive attributes. These strengths enable our method to perform robustly under complex fairness constraints, opening new possibilities for equitable and transparent clustering.","authors":["Mudi Jiang","Jiahui Zhou","Xinying Liu","Zengyou He","Zhikui Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21107v1","updated":"2025-11-26T06:47:11Z","published":"2025-11-26T06:47:11Z","title":"Dynamic Stratified Contrastive Learning with Upstream Augmentation for MILP Branching","summary":"Mixed Integer Linear Programming (MILP) is a fundamental class of NP-hard problems that has garnered significant attention from both academia and industry. The Branch-and-Bound (B\\&B) method is the dominant approach for solving MILPs and the branching plays an important role in B\\&B methods. Neural-based learning frameworks have recently been developed to enhance branching policies and the efficiency of solving MILPs. However, these methods still struggle with semantic variation across depths, the scarcity of upstream nodes, and the costly collection of strong branching samples. To address these issues, we propose \\ours, a Dynamic \\underline{\\textbf{S}}tratified \\underline{\\textbf{C}}ontrastive Training Framework for \\underline{\\textbf{MILP}} Branching. It groups branch-and-bound nodes based on their feature distributions and trains a GCNN-based discriminative model to progressively separate nodes across groups, learning finer-grained node representations throughout the tree. To address data scarcity and imbalance at upstream nodes, we introduce an upstream-augmented MILP derivation procedure that generates both theoretically equivalent and perturbed instances. \\ours~effectively models subtle semantic differences between nodes, significantly enhancing branching accuracy and solving efficiency, particularly for upstream nodes. Extensive experiments on standard MILP benchmarks demonstrate that our method enhances branching accuracy, reduces solving time, and generalizes effectively to unseen instances.","authors":["Tongkai Lu","Shuai Ma","Chongyang Tao"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2501.01774v3","updated":"2025-11-26T06:44:31Z","published":"2025-01-03T12:03:21Z","title":"A Unifying View of Linear Function Approximation in Off-Policy RL Through Matrix Splitting and Preconditioning","summary":"In off-policy policy evaluation (OPE) tasks within reinforcement learning, Temporal Difference Learning(TD) and Fitted Q-Iteration (FQI) have traditionally been viewed as differing in the number of updates toward the target value function: TD makes one update, FQI makes an infinite number, and Partial Fitted Q-Iteration (PFQI) performs a finite number. We show that this view is not accurate, and provide a new mathematical perspective under linear value function approximation that unifies these methods as a single iterative method solving the same linear system, but using different matrix splitting schemes and preconditioners. We show that increasing the number of updates under the same target value function, i.e., the target network technique, is a transition from using a constant preconditioner to using a data-feature adaptive preconditioner. This elucidates, for the first time, why TD convergence does not necessarily imply FQI convergence, and establishes tight convergence connections among TD, PFQI, and FQI. Our framework enables sharper theoretical results than previous work and characterization of the convergence conditions for each algorithm, without relying on assumptions about the features (e.g., linear independence). We also provide an encoder-decoder perspective to better understand the convergence conditions of TD, and prove, for the first time, that when a large learning rate doesn't work, trying a smaller one may help. Our framework also leads to the discovery of new crucial conditions on features for convergence, and shows how common assumptions about features influence convergence, e.g., the assumption of linearly independent features can be dropped without compromising the convergence guarantees of stochastic TD in the on-policy setting. This paper is also the first to introduce matrix splitting into the convergence analysis of these algorithms.","authors":["Zechen Wu","Amy Greenwald","Ronald Parr"],"pdf_url":"","comment":"This work has been accepted for spotlight presentation (top 3% of papers) at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21104v1","updated":"2025-11-26T06:39:19Z","published":"2025-11-26T06:39:19Z","title":"BRIDGE: Building Representations In Domain Guided Program Verification","summary":"Large language models (LLMs) have achieved impressive results in code generation, yet struggle with program verification, especially in interactive proof frameworks such as Lean4. A central challenge is scalability: verified synthesis requires not just code, but also precise specifications and correctness proofs, and existing approaches rarely span all three domains. We present BRIDGE, the first systematic study of structured prompting for scalable verified program generation. BRIDGE decomposes verification into three interconnected domains: Code (executable implementations), Specifications (formal intent statements), and Proofs (constructive correctness arguments). Our key idea is to elicit distinct reasoning behaviors functional, specification-driven, and proof-oriented as intermediate representations that preserve semantic structure and connect these domains. Through systematic ablations, we show that this approach substantially improves both accuracy and efficiency beyond standard error feedback methods. For example, functional reasoning improves correctness of code in formal languages (Lean4) by nearly 1.5x (pass@5) over direct baselines. In inference-time compute, functional reasoning is also 2x more efficient, achieving higher pass rates with fewer generations and lower total sampling budgets. Similarly, we find that specification-driven prompting boosts Python coding pass rates by up to 17.5%. These findings suggest that structured domain alignment is a promising direction for advancing verified synthesis. BRIDGE establishes a foundation for training via expert iteration or RLVR, enabling models to internalize these reasoning strategies across code, specifications, and proofs.","authors":["Robert Joseph George","Carson Eisenach","Udaya Ghai","Dominique Perrault-Joncas","Anima Anandkumar","Dean Foster"],"pdf_url":"","comment":"Approx. 31 pages including appendices, 11 figures, 4 tables. Empirical study of LLM-based verified program synthesis in Lean4 (code, specs, and proofs)"},{"id":"http://arxiv.org/abs/2511.21103v1","updated":"2025-11-26T06:38:37Z","published":"2025-11-26T06:38:37Z","title":"From Bits to Rounds: Parallel Decoding with Exploration for Diffusion Language Models","summary":"Diffusion Language Models (DLMs) have recently emerged as a strong alternative to autoregressive language models (LMs). DLMs offer comparable accuracy with faster inference speed via parallel decoding. However, standard DLM decoding strategies relying on high-confidence tokens encounter an inherent information-theoretic bottleneck that restricts decoding progress and ultimately slows generation. We demonstrate both theoretically and empirically that prioritizing high-confidence tokens is inherently inefficient. High-probability tokens carry negligible information and strictly relying on them limits the effective progress made in each decoding round. We prove that the number of decoding rounds must grow linearly with the sample's total information (negative log-likelihood) and inversely with the per-round information budget, establishing a bits-to-rounds principle. We also propose Explore-Then-Exploit (ETE), a training-free decoding strategy that maximizes information throughput and decoding efficiency. ETE combines cross-block decoding with targeted exploration of high-uncertainty tokens to reshape the conditional distribution and trigger cascades of confident predictions. Experiments verify our theoretical bounds and demonstrate that ETE consistently reduces the required number of decoding rounds compared to confidence-only baselines without compromising generation quality.","authors":["Hengyu Fu","Baihe Huang","Virginia Adams","Charles Wang","Venkat Srinivasan","Jiantao Jiao"],"pdf_url":"","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.21101v1","updated":"2025-11-26T06:37:57Z","published":"2025-11-26T06:37:57Z","title":"MortgageLLM: Domain-Adaptive Pretraining with Residual Instruction Transfer, Alignment Tuning, and Task-Specific Routing","summary":"Large Language Models (LLMs) demonstrate exceptional capabilities across general domains, yet their application to specialized sectors such as mortgage finance requires domain-specific knowledge augmentation while preserving instruction-following fidelity. We present MortgageLLM, a novel domain-specific large language model that addresses this dual challenge. It is developed using a dual-track specialization framework from a single base model (LLaMA-3.1-8B). We opted for this dual-expert approach as a single multi-task model suffers from performance trade-offs, where optimizing for structured tasks (via SFT) degrades conversational fidelity (via DPO). Our dual-track method solves this by creating two specialists, allowing each to be optimally trained for its distinct capability. Our approach applies the instruction residual technique to restore instruction-following capabilities post-domain adaptation without supervised fine-tuning. We contribute: (1) application of this residual technique to the highly specialized mortgage finance domain; (2) a dual-expert architecture combining a conversational Q&A model and a structured task model for classification and summarization; and (3) an intelligent task routing mechanism using few-shot classification performed by one of the expert models itself. We validate our approach on domain-specific benchmarks, where our final model (MLM v2) significantly outperforms the base LLaMA-3.1-8B-Instruct, achieving an LLM-as-a-Judge summarization score of 4.58 (vs. 3.99), a Q&A score of 4.09 (vs. 4.0), and a classification score of 2.6 (vs. 1.2). On semantic similarity, our model achieved a BERTScore of 0.77 for summarization (vs. 0.74), 0.68 for Q&A (vs. 0.58), and 0.75 for classification (vs. 0.73), substantially outperforming baseline approaches.","authors":["Manish Jain","Satheesh Kumar Ponnambalam","Salman Faroz","Chandrakanth Lns","Vinay Sharma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21095v1","updated":"2025-11-26T06:29:18Z","published":"2025-11-26T06:29:18Z","title":"Generative Early Stage Ranking","summary":"Large-scale recommendations commonly adopt a multi-stage cascading ranking system paradigm to balance effectiveness and efficiency. Early Stage Ranking (ESR) systems utilize the \"user-item decoupling\" approach, where independently learned user and item representations are only combined at the final layer. While efficient, this design is limited in effectiveness, as it struggles to capture fine-grained user-item affinities and cross-signals. To address these, we propose the Generative Early Stage Ranking (GESR) paradigm, introducing the Mixture of Attention (MoA) module which leverages diverse attention mechanisms to bridge the effectiveness gap: the Hard Matching Attention (HMA) module encodes explicit cross-signals by computing raw match counts between user and item features; the Target-Aware Self Attention module generates target-aware user representations conditioned on the item, enabling more personalized learning; and the Cross Attention modules facilitate early and more enriched interactions between user-item features. MoA's specialized attention encodings are further refined in the final layer through a Multi-Logit Parameterized Gating (MLPG) module, which integrates the newly learned embeddings via gating and produces secondary logits that are fused with the primary logit. To address the efficiency and latency challenges, we have introduced a comprehensive suite of optimization techniques. These span from custom kernels that maximize the capabilities of the latest hardware to efficient serving solutions powered by caching mechanisms. The proposed GESR paradigm has shown substantial improvements in topline metrics, engagement, and consumption tasks, as validated by both offline and online experiments. To the best of our knowledge, this marks the first successful deployment of full target-aware attention sequence modeling within an ESR stage at such a scale.","authors":["Juhee Hong","Meng Liu","Shengzhi Wang","Xiaoheng Mao","Huihui Cheng","Leon Gao","Christopher Leung","Jin Zhou","Chandra Mouli Sekar","Zhao Zhu","Ruochen Liu","Tuan Trieu","Dawei Sun","Jeet Kanjani","Rui Li","Jing Qian","Xuan Cao","Minjie Fan","Mingze Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21092v1","updated":"2025-11-26T06:22:01Z","published":"2025-11-26T06:22:01Z","title":"MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations","summary":"Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation.","authors":["Seunghun Baek","Jaejin Lee","Jaeyoon Sim","Minjae Jeong","Won Hwa Kim"],"pdf_url":"","comment":"MICCAI 2025 (Provisional Accept; top ~9%)"},{"id":"http://arxiv.org/abs/2503.03401v3","updated":"2025-11-26T06:15:34Z","published":"2025-03-05T11:24:55Z","title":"Evolutionary Prediction Games","summary":"When a prediction algorithm serves a collection of users, disparities in prediction quality are likely to emerge. If users respond to accurate predictions by increasing engagement, inviting friends, or adopting trends, repeated learning creates a feedback loop that shapes both the model and the population of its users. In this work, we introduce evolutionary prediction games, a framework grounded in evolutionary game theory which models such feedback loops as natural-selection processes among groups of users. Our theoretical analysis reveals a gap between idealized and real-world learning settings: In idealized settings with unlimited data and computational power, repeated learning creates competition and promotes competitive exclusion across a broad class of behavioral dynamics. However, under realistic constraints such as finite data, limited compute, or risk of overfitting, we show that stable coexistence and mutualistic symbiosis between groups becomes possible. We analyze these possibilities in terms of their stability and feasibility, present mechanisms that can sustain their existence, and empirically demonstrate our findings.","authors":["Eden Saig","Nir Rosenfeld"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.21089v1","updated":"2025-11-26T06:14:26Z","published":"2025-11-26T06:14:26Z","title":"MLPMoE: Zero-Shot Architectural Metamorphosis of Dense LLM MLPs into Static Mixture-of-Experts","summary":"Large Language Models (LLMs) are predominantly deployed as dense transformers, where every parameter in every feed-forward block is activated for every token. While architecturally simple, this is computationally inefficient, since inference costs scale linearly with parameter count. Recent upcycling methods such as MoEfication, CMoE, ToMoE, and MoORE reveal that much of the useful computation lives in sparse, semi-modular substructures inside dense feed-forward networks, but these approaches typically rely on clustering, activation profiling, singular value decomposition, or custom routing that requires calibration data. This paper introduces MLPMoE (MLP Mixture-of-Experts), a training-free, deterministic transformation that restructures the dense MLP in transformer blocks into a static, high-cardinality mixture of experts. The transformation uses simple tensor slicing and summation, reinterpreting the algebra of tensor parallelism as a topological conversion rather than a distributed training pattern. We further introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) as lightweight mechanisms for structured sparsity. On Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B, the zero-shot MLPMoE transform changes a proxy perplexity metric by less than 0.05 percent while keeping the parameter count effectively constant. On the 8B model, differential sparsity removes about 20 percent of MLP parameters while keeping perplexity within about 2 percent of the dense baseline. The method operates entirely post hoc on existing checkpoints and does not require gradients, calibration sets, or router training. Code is available at https://gist.github.com/iwallarm/fc2ef1eddf226ca7814f9e5e2ae9bad1","authors":["Ivan Novikov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21088v1","updated":"2025-11-26T06:13:42Z","published":"2025-11-26T06:13:42Z","title":"ASR Error Correction in Low-Resource Burmese with Alignment-Enhanced Transformers using Phonetic Features","summary":"This paper investigates sequence-to-sequence Transformer models for automatic speech recognition (ASR) error correction in low-resource Burmese, focusing on different feature integration strategies including IPA and alignment information. To our knowledge, this is the first study addressing ASR error correction specifically for Burmese. We evaluate five ASR backbones and show that our ASR Error Correction (AEC) approaches consistently improve word- and character-level accuracy over baseline outputs. The proposed AEC model, combining IPA and alignment features, reduced the average WER of ASR models from 51.56 to 39.82 before augmentation (and 51.56 to 43.59 after augmentation) and improving chrF++ scores from 0.5864 to 0.627, demonstrating consistent gains over the baseline ASR outputs without AEC. Our results highlight the robustness of AEC and the importance of feature design for improving ASR outputs in low-resource settings.","authors":["Ye Bhone Lin","Thura Aung","Ye Kyaw Thu","Thazin Myint Oo"],"pdf_url":"","comment":"7 pages, 2 figures, 7 tables, Accepted to iSAI-NLP 2025"},{"id":"http://arxiv.org/abs/2506.13380v4","updated":"2025-11-26T05:55:16Z","published":"2025-06-16T11:44:28Z","title":"The Structure-Content Trade-off in Knowledge Graph Retrieval","summary":"Large Language Models (LLMs) increasingly rely on knowledge graphs for factual reasoning, yet how retrieval design shapes their performance remains unclear. We examine how question decomposition changes the retrieved subgraph's content and structure. Using a hybrid retrieval function that controls the importance of initial question and subquestions, we show that subquestion-based retrieval improves content precision, but yields disjoint subgraphs, while question-based retrieval maintains structure at the cost of relevance. Optimal performance arises between these extremes, revealing that balancing retrieval content and structure is key to effective LLM reasoning over structured knowledge.","authors":["Valentin Six","Evan Dufraisse","Gaël de Chalendar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21081v1","updated":"2025-11-26T05:50:34Z","published":"2025-11-26T05:50:34Z","title":"Enhancing Burmese News Classification with Kolmogorov-Arnold Network Head Fine-tuning","summary":"In low-resource languages like Burmese, classification tasks often fine-tune only the final classification layer, keeping pre-trained encoder weights frozen. While Multi-Layer Perceptrons (MLPs) are commonly used, their fixed non-linearity can limit expressiveness and increase computational cost. This work explores Kolmogorov-Arnold Networks (KANs) as alternative classification heads, evaluating Fourier-based FourierKAN, Spline-based EfficientKAN, and Grid-based FasterKAN-across diverse embeddings including TF-IDF, fastText, and multilingual transformers (mBERT, Distil-mBERT). Experimental results show that KAN-based heads are competitive with or superior to MLPs. EfficientKAN with fastText achieved the highest F1-score (0.928), while FasterKAN offered the best trade-off between speed and accuracy. On transformer embeddings, EfficientKAN matched or slightly outperformed MLPs with mBERT (0.917 F1). These findings highlight KANs as expressive, efficient alternatives to MLPs for low-resource language classification.","authors":["Thura Aung","Eaint Kay Khaing Kyaw","Ye Kyaw Thu","Thazin Myint Oo","Thepchai Supnithi"],"pdf_url":"","comment":"6 pages, 2 figures, 4 tables, Accepted to iSAI-NLP 2025"},{"id":"http://arxiv.org/abs/2510.05613v2","updated":"2025-11-26T05:49:58Z","published":"2025-10-07T06:31:02Z","title":"PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction","summary":"Autoregressive point cloud generation has long lagged behind diffusion-based approaches in quality. The performance gap stems from the fact that autoregressive models impose an artificial ordering on inherently unordered point sets, forcing shape generation to proceed as a sequence of local predictions. This sequential bias emphasizes short-range continuity but undermines the model's capacity to capture long-range dependencies, hindering its ability to enforce global structural properties such as symmetry, consistent topology, and large-scale geometric regularities. Inspired by the level-of-detail (LOD) principle in shape modeling, we propose PointNSP, a coarse-to-fine generative framework that preserves global shape structure at low resolutions and progressively refines fine-grained geometry at higher scales through a next-scale prediction paradigm. This multi-scale factorization aligns the autoregressive objective with the permutation-invariant nature of point sets, enabling rich intra-scale interactions while avoiding brittle fixed orderings. Experiments on ShapeNet show that PointNSP establishes state-of-the-art (SOTA) generation quality for the first time within the autoregressive paradigm. In addition, it surpasses strong diffusion-based baselines in parameter, training, and inference efficiency. Finally, in dense generation with 8,192 points, PointNSP's advantages become even more pronounced, underscoring its scalability potential.","authors":["Ziqiao Meng","Qichao Wang","Zhiyang Dou","Zixing Song","Zhipeng Zhou","Irwin King","Peilin Zhao"],"pdf_url":"","comment":"This work was intended as a replacement of arXiv:2503.08594 and any subsequent updates will appear there"},{"id":"http://arxiv.org/abs/2511.21080v1","updated":"2025-11-26T05:49:50Z","published":"2025-11-26T05:49:50Z","title":"Data-Driven Assessment of Concrete Slab Integrity via Impact-Echo Signals and Neural Networks","summary":"Subsurface defects such as delamination, voids, and honeycombing critically affect the durability of concrete bridge decks but are difficult to detect reliably using visual inspection or manual sounding. This paper presents a machine learning based Impact Echo (IE) framework that automates both defect localization and multi-class classification of common concrete defects. Raw IE signals from Federal Highway Administration (FHWA) laboratory slabs and in-service bridge decks are transformed via Fast Fourier Transform (FFT) into dominant peak-frequency features and interpolated into spatial maps for defect zone visualization. Unsupervised k-means clustering highlights low-frequency, defect-prone regions, while Ground Truth Masks (GTMs) derived from seeded lab defects are used to validate spatial accuracy and generate high-confidence training labels. From these validated regions, spatially ordered peak-frequency sequences are constructed and fed into a stacked Long Short-Term Memory (LSTM) network that classifies four defect types shallow delamination, deep delamination, voids, and honeycombing with 73% overall accuracy. Field validation on the bridge deck demonstrates that models trained on laboratory data generalize under realistic coupling, noise, and environmental variability. The proposed framework enhances the objectivity, scalability, and repeatability of Non-Destructive Evaluation (NDE), supporting intelligent, data-driven bridge health monitoring at a network scale.","authors":["Yeswanth Ravichandran","Duoduo Liao","Charan Teja Kurakula"],"pdf_url":"","comment":"Accepted by IEEE Big Data 2025"},{"id":"http://arxiv.org/abs/2501.01457v2","updated":"2025-11-26T05:46:57Z","published":"2024-12-31T04:50:15Z","title":"Beyond Introspection: Reinforcing Thinking via Externalist Behavioral Feedback","summary":"While inference-time thinking allows Large Language Models (LLMs) to address complex problems, the extended thinking process can be unreliable or inconsistent because of the model's probabilistic nature, especially near its knowledge boundaries. Existing approaches attempt to mitigate this by having the model critique its own reasoning to make corrections. However, such self-critique inherits the same biases of the original output, known as the introspection illusion. Moving beyond such introspection and inspired by core methodologies in ethology, we propose an externalist three-step framework Distillation-Reinforcement-Reasoning (DRR). Rather than relying on a model's introspection, DRR evaluates its observable behaviors to provide corrective feedback. DRR first distills the reasoner's behavioral traces, then trains a lightweight, external Discriminative Model (DM). At inference time, this DM acts as a critic, identifying and rejecting suspicious reasoning steps. This external feedback compels the LLM to discard flawed pathways and explore alternatives, thereby enhancing reasoning quality without altering the base model. Experiments on multiple reasoning benchmarks show that our framework significantly outperforms prominent self-critique methods. Benefiting from a lightweight and annotation-free design, DRR offers a scalable and adaptable solution for improving the reliability of reasoning in a wide range of LLMs.","authors":["Diji Yang","Linda Zeng","Kezhen Chen","Yi Zhang"],"pdf_url":"","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2511.21692v1","updated":"2025-11-26T18:59:57Z","published":"2025-11-26T18:59:57Z","title":"Revisiting Generalization Across Difficulty Levels: It's Not So Easy","summary":"We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' generalization across models, datasets, and fine-grained groups of example difficulty. We rank examples in six datasets using the outputs of thousands of different LLMs and Item Response Theory (IRT), a well-established difficulty metric in educational testing. Unlike prior work, our difficulty ratings are therefore determined solely by the abilities of many different LLMs, excluding human opinions of difficulty. With a more objective, larger-scale, and finer-grained analysis, we show that cross-difficulty generalization is often limited; training on either easy or hard data cannot achieve consistent improvements across the full range of difficulties. These results show the importance of having a range of difficulties in both training and evaluation data for LLMs, and that taking shortcuts with respect to difficulty is risky.","authors":["Yeganeh Kordi","Nihal V. Nayak","Max Zuo","Ilana Nguyen","Stephen H. Bach"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21689v1","updated":"2025-11-26T18:59:46Z","published":"2025-11-26T18:59:46Z","title":"ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration","summary":"Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools. ToolOrchestra explicitly uses reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards. Using ToolOrchestra, we produce Orchestrator, an 8B model that achieves higher accuracy at lower cost than previous tool-use agents while aligning with user preferences on which tools are to be used for a given query. On HLE, Orchestrator achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being 2.5x more efficient. On tau2-Bench and FRAMES, Orchestrator surpasses GPT-5 by a wide margin while using only about 30% of the cost. Extensive analysis shows that Orchestrator achieves the best trade-off between performance and cost under multiple metrics, and generalizes robustly to unseen tools. These results demonstrate that composing diverse tools with a lightweight orchestration model is both more efficient and more effective than existing methods, paving the way for practical and scalable tool-augmented reasoning systems.","authors":["Hongjin Su","Shizhe Diao","Ximing Lu","Mingjie Liu","Jiacheng Xu","Xin Dong","Yonggan Fu","Peter Belcak","Hanrong Ye","Hongxu Yin","Yi Dong","Evelina Bakhturina","Tao Yu","Yejin Choi","Jan Kautz","Pavlo Molchanov"],"pdf_url":"","comment":"21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.21688v1","updated":"2025-11-26T18:59:39Z","published":"2025-11-26T18:59:39Z","title":"G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning","summary":"Vision-Language Models (VLMs) still lack robustness in spatial intelligence, demonstrating poor performance on spatial understanding and reasoning tasks. We attribute this gap to the absence of a visual geometry learning process capable of reconstructing 3D space from 2D images. We present G$^2$VLM, a geometry grounded vision-language model that bridges two fundamental aspects of spatial intelligence: spatial 3D reconstruction and spatial understanding. G$^2$VLM natively leverages learned 3D visual geometry features to directly predict 3D attributes and enhance spatial reasoning tasks via in-context learning and interleaved reasoning. Our unified design is highly scalable for spatial understanding: it trains on abundant multi-view image and video data, while simultaneously leveraging the benefits of 3D visual priors that are typically only derived from hard-to-collect annotations. Experimental results demonstrate G$^2$VLM is proficient in both tasks, achieving comparable results to state-of-the-art feed-forward 3D reconstruction models and achieving better or competitive results across spatial understanding and reasoning tasks. By unifying a semantically strong VLM with low-level 3D vision tasks, we hope G$^2$VLM can serve as a strong baseline for the community and unlock more future applications, such as 3D scene editing.","authors":["Wenbo Hu","Jingli Lin","Yilin Long","Yunlong Ran","Lihan Jiang","Yifan Wang","Chenming Zhu","Runsen Xu","Tai Wang","Jiangmiao Pang"],"pdf_url":"","comment":"code are released at https://github.com/InternRobotics/G2VLM"},{"id":"http://arxiv.org/abs/2511.21686v1","updated":"2025-11-26T18:59:28Z","published":"2025-11-26T18:59:28Z","title":"Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework","summary":"Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are hardcoded for specific domains, limiting flexibility. We present \\textbf{Matrix}, a decentralized framework that represents both control and data flow as serialized messages passed through distributed queues. This peer-to-peer design eliminates the central orchestrator. Each task progresses independently through lightweight agents, while compute-intensive operations, such as LLM inference or containerized environments, are handled by distributed services. Built on Ray, Matrix scales to tens of thousands of concurrent agentic workflows and provides a modular, configurable design that enables easy adaptation to a wide range of data generation workflows. We evaluate Matrix across diverse synthesis scenarios, such as multi-agent collaborative dialogue, web-based reasoning data extraction, and tool-use trajectory generation in customer service environments. In all cases, Matrix achieves $2$--$15\\times$ higher data generation throughput under identical hardware resources, without compromising output quality.","authors":["Dong Wang","Yang Li","Ansong Ni","Ching-Feng Yeh","Youssef Emad","Xinjie Lei","Liam Robbins","Karthik Padthe","Hu Xu","Xian Li","Asli Celikyilmaz","Ramya Raghavendra","Lifei Huang","Carole-Jean Wu","Shang-Wen Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21678v1","updated":"2025-11-26T18:55:08Z","published":"2025-11-26T18:55:08Z","title":"Agentic Learner with Grow-and-Refine Multimodal Semantic Memory","summary":"MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.","authors":["Weihao Bo","Shan Zhang","Yanpeng Sun","Jingjing Wu","Qunyi Xie","Xiao Tan","Kunbin Chen","Wei He","Xiaofan Li","Na Zhao","Jingdong Wang","Zechao Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21668v1","updated":"2025-11-26T18:44:02Z","published":"2025-11-26T18:44:02Z","title":"Through the telecom lens: Are all training samples important?","summary":"The rise of AI in telecommunications, from optimizing Radio Access Networks to managing user experience, has sharply increased data volumes and training demands. Telecom data is often noisy, high-dimensional, costly to store, process, and label. Despite Ai's critical role, standard workflows still assume all training samples contribute equally. On the other hand, next generation systems require AI models that are accurate, efficient, and sustainable.The paper questions the assumptions of equal importance by focusing on applying and analyzing the roles of individual samples in telecom training and assessing whether the proposed model optimizes computation and energy use. we perform sample-level gradient analysis across epochs to identify patterns of influence and redundancy in model learning. Based on this, we propose a sample importance framework thats electively prioritizes impactful data and reduces computation without compromising accuracy. Experiments on three real-world telecom datasets show that our method [reserves performance while reducing data needs and computational overhead while advancing the goals of sustainable AI in telecommunications.","authors":["Shruti Bothe","Illyyne Saffar","Aurelie Boisbunon","Hasan Farooq","Julien Forgeat","Md Moin Uddin Chowdhury"],"pdf_url":"","comment":"8pages, 1 table, 8 figures"},{"id":"http://arxiv.org/abs/2511.21667v1","updated":"2025-11-26T18:42:52Z","published":"2025-11-26T18:42:52Z","title":"Escaping the Verifier: Learning to Reason via Demonstrations","summary":"Training Large Language Models (LLMs) to reason often relies on Reinforcement Learning (RL) with task-specific verifiers. However, many real-world reasoning-intensive tasks lack verifiers, despite offering abundant expert demonstrations that remain under-utilized for reasoning-focused training. We introduce RARO (Relativistic Adversarial Reasoning Optimization) that learns strong reasoning capabilities from only expert demonstrations via Inverse Reinforcement Learning. Our method sets up an adversarial interaction between a policy (generator) and a relativistic critic (discriminator): the policy learns to mimic expert answers, while the critic learns to compare and distinguish between policy and expert answers. Our method trains both the policy and the critic jointly and continuously via RL, and we identify the key stabilization techniques required for robust learning. Empirically, RARO significantly outperforms strong verifier-free baselines on all of our evaluation tasks -- Countdown, DeepMath, and Poetry Writing -- and enjoys the same robust scaling trends as RL on verifiable tasks. These results demonstrate that our method effectively elicits strong reasoning performance from expert demonstrations alone, enabling robust reasoning learning even when task-specific verifiers are unavailable.","authors":["Locke Cai","Ivan Provilkov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19872v2","updated":"2025-11-26T18:41:52Z","published":"2025-11-25T03:24:11Z","title":"Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy","summary":"Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.","authors":["Daniel I Jackson","Emma L Jensen","Syed-Amad Hussain","Emre Sezgin"],"pdf_url":"","comment":"25 pages,5 tables, 3 figures"},{"id":"http://arxiv.org/abs/2511.21663v1","updated":"2025-11-26T18:37:54Z","published":"2025-11-26T18:37:54Z","title":"Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models","summary":"In recent years, Vision-Language-Action (VLA) models in embodied intelligence have developed rapidly. However, existing adversarial attack methods require costly end-to-end training and often generate noticeable perturbation patches. To address these limitations, we propose ADVLA, a framework that directly applies adversarial perturbations on features projected from the visual encoder into the textual feature space. ADVLA efficiently disrupts downstream action predictions under low-amplitude constraints, and attention guidance allows the perturbations to be both focused and sparse. We introduce three strategies that enhance sensitivity, enforce sparsity, and concentrate perturbations. Experiments demonstrate that under an $L_{\\infty}=4/255$ constraint, ADVLA combined with Top-K masking modifies less than 10% of the patches while achieving an attack success rate of nearly 100%. The perturbations are concentrated on critical regions, remain almost imperceptible in the overall image, and a single-step iteration takes only about 0.06 seconds, significantly outperforming conventional patch-based attacks. In summary, ADVLA effectively weakens downstream action predictions of VLA models under low-amplitude and locally sparse conditions, avoiding the high training costs and conspicuous perturbations of traditional patch attacks, and demonstrates unique effectiveness and practical value for attacking VLA feature spaces.","authors":["Naifu Zhang","Wei Tao","Xi Xiao","Qianpu Sun","Yuxin Zheng","Wentao Mo","Peiqiang Wang","Nan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16595v2","updated":"2025-11-26T18:30:04Z","published":"2025-11-20T17:48:21Z","title":"TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding","summary":"We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.","authors":["Boshen Xu","Zihan Xiao","Jiaze Li","Jianzhong Ju","Zhenbo Luo","Jian Luan","Qin Jin"],"pdf_url":"","comment":"Project page: https://xuboshen.github.io/TimeViper; Code: https://github.com/xiaomi-research/timeviper"},{"id":"http://arxiv.org/abs/2401.12170v2","updated":"2025-11-26T18:24:26Z","published":"2024-01-22T18:04:26Z","title":"Natural Strategic Ability in Stochastic Multi-Agent Systems","summary":"Strategies synthesized using formal methods can be complex and often require infinite memory, which does not correspond to the expected behavior when trying to model Multi-Agent Systems (MAS). To capture such behaviors, natural strategies are a recently proposed framework striking a balance between the ability of agents to strategize with memory and the model-checking complexity, but until now has been restricted to fully deterministic settings. For the first time, we consider the probabilistic temporal logics PATL and PATL* under natural strategies (NatPATL and NatPATL*, resp.). As main result we show that, in stochastic MAS, NatPATL model-checking is NP-complete when the active coalition is restricted to deterministic strategies. We also give a 2NEXPTIME complexity result for NatPATL* with the same restriction. In the unrestricted case, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity for NatPATL*.","authors":["Raphaël Berthon","Joost-Pieter Katoen","Munyque Mittelmann","Aniello Murano"],"pdf_url":"","comment":"Extended version of the paper accepted at AAAI 2024"},{"id":"http://arxiv.org/abs/2511.21652v1","updated":"2025-11-26T18:24:11Z","published":"2025-11-26T18:24:11Z","title":"Continual Error Correction on Low-Resource Devices","summary":"The proliferation of AI models in everyday devices has highlighted a critical challenge: prediction errors that degrade user experience. While existing solutions focus on error detection, they rarely provide efficient correction mechanisms, especially for resource-constrained devices. We present a novel system enabling users to correct AI misclassifications through few-shot learning, requiring minimal computational resources and storage. Our approach combines server-side foundation model training with on-device prototype-based classification, enabling efficient error correction through prototype updates rather than model retraining. The system consists of two key components: (1) a server-side pipeline that leverages knowledge distillation to transfer robust feature representations from foundation models to device-compatible architectures, and (2) a device-side mechanism that enables ultra-efficient error correction through prototype adaptation. We demonstrate our system's effectiveness on both image classification and object detection tasks, achieving over 50% error correction in one-shot scenarios on Food-101 and Flowers-102 datasets while maintaining minimal forgetting (less than 0.02%) and negligible computational overhead. Our implementation, validated through an Android demonstration app, proves the system's practicality in real-world scenarios.","authors":["Kirill Paramonov","Mete Ozay","Aristeidis Mystakidis","Nikolaos Tsalikidis","Dimitrios Sotos","Anastasios Drosou","Dimitrios Tzovaras","Hyunjun Kim","Kiseok Chang","Sangdok Mo","Namwoong Kim","Woojong Yoo","Jijoong Moon","Umberto Michieli"],"pdf_url":"","comment":"ACM MMSys 2025"},{"id":"http://arxiv.org/abs/2511.21636v1","updated":"2025-11-26T18:08:20Z","published":"2025-11-26T18:08:20Z","title":"Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling","summary":"AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's \"the unavoidable a priori\"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.","authors":["Peter S. Hovmand","Kari O'Donnell","Callie Ogland-Hand","Brian Biroscak","Douglas D. Gunzler"],"pdf_url":"","comment":"Presented at 43rd Conference of the International System Dynamics Society in Boston, United States"},{"id":"http://arxiv.org/abs/2511.21635v1","updated":"2025-11-26T18:07:14Z","published":"2025-11-26T18:07:14Z","title":"Mechanisms of Non-Monotonic Scaling in Vision Transformers","summary":"Deeper Vision Transformers often perform worse than shallower ones, which challenges common scaling assumptions. Through a systematic empirical analysis of ViT-S, ViT-B, and ViT-L on ImageNet, we identify a consistent three-phase Cliff-Plateau-Climb pattern that governs how representations evolve with depth. We observe that better performance is associated with progressive marginalization of the [CLS] token, originally designed as a global aggregation hub, in favor of distributed consensus among patch tokens. We quantify patterns of information mixing with an Information Scrambling Index, and show that in ViT-L the information-task tradeoff emerges roughly 10 layers later than in ViT-B, and that these additional layers correlate with increased information diffusion rather than improved task performance. Taken together, these results suggest that transformer architectures in this regime may benefit more from carefully calibrated depth that executes clean phase transitions than from simply increasing parameter count. The Information Scrambling Index provides a useful diagnostic for existing models and suggests a potential design target for future architectures. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb.","authors":["Anantha Padmanaban Krishna Kumar"],"pdf_url":"","comment":"16 pages total (11 pages main text, 1 pages references, 4 pages appendix), 5 figures, 11 tables. Code available at https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb"},{"id":"http://arxiv.org/abs/2509.24125v2","updated":"2025-11-26T18:02:39Z","published":"2025-09-28T23:48:11Z","title":"The Impossibility of Inverse Permutation Learning in Transformer Models","summary":"In this technical note, we study the problem of inverse permutation learning in decoder-only transformers. Given a permutation and a string to which that permutation has been applied, the model is tasked with producing the original (``canonical'') string. We argue that this task models a natural robustness property across a variety of reasoning tasks, including long-context retrieval, multiple choice QA and in-context learning. Our primary contribution is an impossibility result: we show that an arbitrary depth, decoder-only transformer cannot learn this task. This result concerns the expressive capacity of decoder-only transformer models and is agnostic to training dynamics or sample complexity. We give a pair of alternative constructions under which inverse permutation learning is feasible. The first of these highlights the fundamental role of the causal attention mask, and reveals a gap between the expressivity of encoder-decoder transformers and the more popular decoder-only architecture. The latter result is more surprising: we show that simply padding the input with ``scratch tokens\" yields a construction under which inverse permutation learning is possible. We conjecture that this may suggest an alternative mechanism by which chain-of-thought prompting or, more generally, intermediate ``thinking'' tokens can enable reasoning in large language models, even when these tokens encode no meaningful semantic information (e.g., the results of intermediate computations).","authors":["Rohan Alur","Chris Hays","Manish Raghavan","Devavrat Shah"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21631v1","updated":"2025-11-26T17:59:08Z","published":"2025-11-26T17:59:08Z","title":"Qwen3-VL Technical Report","summary":"We introduce Qwen3-VL, the most capable vision-language model in the Qwen series to date, achieving superior performance across a broad range of multimodal benchmarks. It natively supports interleaved contexts of up to 256K tokens, seamlessly integrating text, images, and video. The model family includes both dense (2B/4B/8B/32B) and mixture-of-experts (30B-A3B/235B-A22B) variants to accommodate diverse latency-quality trade-offs. Qwen3-VL delivers three core pillars: (i) markedly stronger pure-text understanding, surpassing comparable text-only backbones in several cases; (ii) robust long-context comprehension with a native 256K-token window for both text and interleaved multimodal inputs, enabling faithful retention, retrieval, and cross-referencing across long documents and videos; and (iii) advanced multimodal reasoning across single-image, multi-image, and video tasks, demonstrating leading performance on comprehensive evaluations such as MMMU and visual-math benchmarks (e.g., MathVista and MathVision). Architecturally, we introduce three key upgrades: (i) an enhanced interleaved-MRoPE for stronger spatial-temporal modeling across images and video; (ii) DeepStack integration, which effectively leverages multi-level ViT features to tighten vision-language alignment; and (iii) text-based time alignment for video, evolving from T-RoPE to explicit textual timestamp alignment for more precise temporal grounding. Under comparable token budgets and latency constraints, Qwen3-VL achieves superior performance in both dense and Mixture-of-Experts (MoE) architectures. We envision Qwen3-VL serving as a foundational engine for image-grounded reasoning, agentic decision-making, and multimodal code intelligence in real-world workflows.","authors":["Shuai Bai","Yuxuan Cai","Ruizhe Chen","Keqin Chen","Xionghui Chen","Zesen Cheng","Lianghao Deng","Wei Ding","Chang Gao","Chunjiang Ge","Wenbin Ge","Zhifang Guo","Qidong Huang","Jie Huang","Fei Huang","Binyuan Hui","Shutong Jiang","Zhaohai Li","Mingsheng Li","Mei Li","Kaixin Li","Zicheng Lin","Junyang Lin","Xuejing Liu","Jiawei Liu","Chenglong Liu","Yang Liu","Dayiheng Liu","Shixuan Liu","Dunjie Lu","Ruilin Luo","Chenxu Lv","Rui Men","Lingchen Meng","Xuancheng Ren","Xingzhang Ren","Sibo Song","Yuchong Sun","Jun Tang","Jianhong Tu","Jianqiang Wan","Peng Wang","Pengfei Wang","Qiuyue Wang","Yuxuan Wang","Tianbao Xie","Yiheng Xu","Haiyang Xu","Jin Xu","Zhibo Yang","Mingkun Yang","Jianxin Yang","An Yang","Bowen Yu","Fei Zhang","Hang Zhang","Xi Zhang","Bo Zheng","Humen Zhong","Jingren Zhou","Fan Zhou","Jing Zhou","Yuanzhi Zhu","Ke Zhu"],"pdf_url":"","comment":"42 pages"},{"id":"http://arxiv.org/abs/2511.21626v1","updated":"2025-11-26T17:52:05Z","published":"2025-11-26T17:52:05Z","title":"Scale-Agnostic Kolmogorov-Arnold Geometry in Neural Networks","summary":"Recent work by Freedman and Mulligan demonstrated that shallow multilayer perceptrons spontaneously develop Kolmogorov-Arnold geometric (KAG) structure during training on synthetic three-dimensional tasks. However, it remained unclear whether this phenomenon persists in realistic high-dimensional settings and what spatial properties this geometry exhibits.\n  We extend KAG analysis to MNIST digit classification (784 dimensions) using 2-layer MLPs with systematic spatial analysis at multiple scales. We find that KAG emerges during training and appears consistently across spatial scales, from local 7-pixel neighborhoods to the full 28x28 image. This scale-agnostic property holds across different training procedures: both standard training and training with spatial augmentation produce the same qualitative pattern. These findings reveal that neural networks spontaneously develop organized, scale-invariant geometric structure during learning on realistic high-dimensional data.","authors":["Mathew Vanherreweghe","Michael H. Freedman","Keith M. Adams"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21622v1","updated":"2025-11-26T17:46:31Z","published":"2025-11-26T17:46:31Z","title":"On the Origin of Algorithmic Progress in AI","summary":"Algorithms have been estimated to increase AI training FLOP efficiency by a factor of 22,000 between 2012 and 2023 [Ho et al., 2024]. Running small-scale ablation experiments on key innovations from this time period, we are able to account for less than 10x of these gains. Surveying the broader literature, we estimate that additional innovations not included in our ablations account for less than 10x, yielding a total under 100x. This leads us to conduct scaling experiments, which reveal that much of this efficiency gap can be explained by algorithms with scale-dependent efficiency improvements. In particular, we conduct scaling experiments between LSTMs and Transformers, finding exponent differences in their compute-optimal scaling law while finding little scaling difference for many other innovations. These experiments demonstrate that - contrary to standard assumptions - an algorithm's efficiency gains are tied to compute scale. Using experimental extrapolation and literature estimates, we account for 6,930x efficiency gains over the same time period, with the scale-dependent LSTM-to-Transformer transition accounting for the majority of gains. Our results indicate that algorithmic progress for small models has been far slower than previously assumed, and that measures of algorithmic efficiency are strongly reference-dependent.","authors":["Hans Gundlach","Alex Fogelson","Jayson Lynch","Ana Trisovic","Jonathan Rosenfeld","Anmol Sandhu","Neil Thompson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19693v2","updated":"2025-11-26T17:43:31Z","published":"2025-11-24T20:57:31Z","title":"TREASURE: A Transformer-Based Foundation Model for High-Volume Transaction Understanding","summary":"Payment networks form the backbone of modern commerce, generating high volumes of transaction records from daily activities. Properly modeling this data can enable applications such as abnormal behavior detection and consumer-level insights for hyper-personalized experiences, ultimately improving people's lives. In this paper, we present TREASURE, TRansformer Engine As Scalable Universal transaction Representation Encoder, a multipurpose transformer-based foundation model specifically designed for transaction data. The model simultaneously captures both consumer behavior and payment network signals (such as response codes and system flags), providing comprehensive information necessary for applications like accurate recommendation systems and abnormal behavior detection. Verified with industry-grade datasets, TREASURE features three key capabilities: 1) an input module with dedicated sub-modules for static and dynamic attributes, enabling more efficient training and inference; 2) an efficient and effective training paradigm for predicting high-cardinality categorical attributes; and 3) demonstrated effectiveness as both a standalone model that increases abnormal behavior detection performance by 111% over production systems and an embedding provider that enhances recommendation models by 104%. We present key insights from extensive ablation studies, benchmarks against production models, and case studies, highlighting valuable knowledge gained from developing TREASURE.","authors":["Chin-Chia Michael Yeh","Uday Singh Saini","Xin Dai","Xiran Fan","Shubham Jain","Yujie Fan","Jiarui Sun","Junpeng Wang","Menghai Pan","Yingtong Dou","Yuzhong Chen","Vineeth Rakesh","Liang Wang","Yan Zheng","Mahashweta Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21613v1","updated":"2025-11-26T17:36:31Z","published":"2025-11-26T17:36:31Z","title":"Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining","summary":"Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.","authors":["Dongyang Fan","Diba Hashemi","Sai Praneeth Karimireddy","Martin Jaggi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00209v2","updated":"2025-11-26T17:21:10Z","published":"2025-10-31T19:11:41Z","title":"Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides","summary":"Diffusion models have emerged as a leading framework in generative modeling, poised to transform the traditionally slow and costly process of drug discovery. This review provides a systematic comparison of their application in designing two principal therapeutic modalities: small molecules and therapeutic peptides. We dissect how the unified framework of iterative denoising is adapted to the distinct molecular representations, chemical spaces, and design objectives of each modality. For small molecules, these models excel at structure-based design, generating novel, pocket-fitting ligands with desired physicochemical properties, yet face the critical hurdle of ensuring chemical synthesizability. Conversely, for therapeutic peptides, the focus shifts to generating functional sequences and designing de novo structures, where the primary challenges are achieving biological stability against proteolysis, ensuring proper folding, and minimizing immunogenicity. Despite these distinct challenges, both domains face shared hurdles: the scarcity of high-quality experimental data, the reliance on inaccurate scoring functions for validation, and the crucial need for experimental validation. We conclude that the full potential of diffusion models will be unlocked by bridging these modality-specific gaps and integrating them into automated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby shifting the paradigm from mere chemical exploration to the on-demand engineering of novel~therapeutics.","authors":["Yiquan Wang","Yahui Ma","Yuhan Chang","Jiayao Yan","Jialin Zhang","Minnuo Cai","Kai Wei"],"pdf_url":"","comment":"Published in Biology"},{"id":"http://arxiv.org/abs/2511.20399v2","updated":"2025-11-26T17:08:26Z","published":"2025-11-25T15:26:47Z","title":"BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali","summary":"Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.","authors":["Abdullah Al Sefat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21591v1","updated":"2025-11-26T17:08:13Z","published":"2025-11-26T17:08:13Z","title":"On the Limits of Innate Planning in Large Language Models","summary":"Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.","authors":["Charles Schepanowski","Charles Ling"],"pdf_url":"","comment":"33 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.21584v1","updated":"2025-11-26T17:01:41Z","published":"2025-11-26T17:01:41Z","title":"Model-Based Policy Adaptation for Closed-Loop End-to-End Autonomous Driving","summary":"End-to-end (E2E) autonomous driving models have demonstrated strong performance in open-loop evaluations but often suffer from cascading errors and poor generalization in closed-loop settings. To address this gap, we propose Model-based Policy Adaptation (MPA), a general framework that enhances the robustness and safety of pretrained E2E driving agents during deployment. MPA first generates diverse counterfactual trajectories using a geometry-consistent simulation engine, exposing the agent to scenarios beyond the original dataset. Based on this generated data, MPA trains a diffusion-based policy adapter to refine the base policy's predictions and a multi-step Q value model to evaluate long-term outcomes. At inference time, the adapter proposes multiple trajectory candidates, and the Q value model selects the one with the highest expected utility. Experiments on the nuScenes benchmark using a photorealistic closed-loop simulator demonstrate that MPA significantly improves performance across in-domain, out-of-domain, and safety-critical scenarios. We further investigate how the scale of counterfactual data and inference-time guidance strategies affect overall effectiveness.","authors":["Haohong Lin","Yunzhi Zhang","Wenhao Ding","Jiajun Wu","Ding Zhao"],"pdf_url":"","comment":"Published at NeurIPS 2025: https://openreview.net/forum?id=4OLbpaTKJe"},{"id":"http://arxiv.org/abs/2505.23454v2","updated":"2025-11-26T16:58:54Z","published":"2025-05-29T14:00:59Z","title":"LCB-CV-UNet: Enhanced Detector for High Dynamic Range Radar Signals","summary":"We propose the LCB-CV-UNet to tackle performance degradation caused by High Dynamic Range (HDR) radar signals. Initially, a hardware-efficient, plug-and-play module named Logarithmic Connect Block (LCB) is proposed as a phase coherence preserving solution to address the inherent challenges in handling HDR features. Then, we propose the Dual Hybrid Dataset Construction method to generate a semi-synthetic dataset, approximating typical HDR signal scenarios with adjustable target distributions. Simulation results show about 1% total detection probability improvement with under 0.9% computational complexity added compared with the baseline. Furthermore, it excels 5% over the baseline at the range in 11-13 dB signal-to-noise ratio typical for urban targets. Finally, the real experiment validates the practicality of our model.","authors":["Yanbin Wang","Xingyu Chen","Yumiao Wang","Xiang Wang","Chuanfei Zang","Guolong Cui","Jiahuan Liu"],"pdf_url":"","comment":"5 pages, 4 figures. Accepted to IEEE IGARSS 2025"},{"id":"http://arxiv.org/abs/2511.21577v1","updated":"2025-11-26T16:51:20Z","published":"2025-11-26T16:51:20Z","title":"HarmonicAttack: An Adaptive Cross-Domain Audio Watermark Removal","summary":"The availability of high-quality, AI-generated audio raises security challenges such as misinformation campaigns and voice-cloning fraud. A key defense against the misuse of AI-generated audio is by watermarking it, so that it can be easily distinguished from genuine audio. As those seeking to misuse AI-generated audio may thus seek to remove audio watermarks, studying effective watermark removal techniques is critical to being able to objectively evaluate the robustness of audio watermarks against removal. Previous watermark removal schemes either assume impractical knowledge of the watermarks they are designed to remove or are computationally expensive, potentially generating a false sense of confidence in current watermark schemes.\n  We introduce HarmonicAttack, an efficient audio watermark removal method that only requires the basic ability to generate the watermarks from the targeted scheme and nothing else. With this, we are able to train a general watermark removal model that is able to remove the watermarks generated by the targeted scheme from any watermarked audio sample. HarmonicAttack employs a dual-path convolutional autoencoder that operates in both temporal and frequency domains, along with GAN-style training, to separate the watermark from the original audio. When evaluated against state-of-the-art watermark schemes AudioSeal, WavMark, and Silentcipher, HarmonicAttack demonstrates greater watermark removal ability than previous watermark removal methods with near real-time performance. Moreover, while HarmonicAttack requires training, we find that it is able to transfer to out-of-distribution samples with minimal degradation in performance.","authors":["Kexin Li","Xiao Hu","Ilya Grishchenko","David Lie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21574v1","updated":"2025-11-26T16:49:38Z","published":"2025-11-26T16:49:38Z","title":"Multimodal Robust Prompt Distillation for 3D Point Cloud Models","summary":"Adversarial attacks pose a significant threat to learning-based 3D point cloud models, critically undermining their reliability in security-sensitive applications. Existing defense methods often suffer from (1) high computational overhead and (2) poor generalization ability across diverse attack types. To bridge these gaps, we propose a novel yet efficient teacher-student framework, namely Multimodal Robust Prompt Distillation (MRPD) for distilling robust 3D point cloud model. It learns lightweight prompts by aligning student point cloud model's features with robust embeddings from three distinct teachers: a vision model processing depth projections, a high-performance 3D model, and a text encoder. To ensure a reliable knowledge transfer, this distillation is guided by a confidence-gated mechanism which dynamically balances the contribution of all input modalities. Notably, since the distillation is all during the training stage, there is no additional computational cost at inference. Extensive experiments demonstrate that MRPD substantially outperforms state-of-the-art defense methods against a wide range of white-box and black-box attacks, while even achieving better performance on clean data. Our work presents a new, practical paradigm for building robust 3D vision systems by efficiently harnessing multimodal knowledge.","authors":["Xiang Gu","Liming Lu","Xu Zheng","Anan Du","Yongbin Zhou","Shuchao Pang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21572v1","updated":"2025-11-26T16:48:18Z","published":"2025-11-26T16:48:18Z","title":"BAMAS: Structuring Budget-Aware Multi-Agent Systems","summary":"Large language model (LLM)-based multi-agent systems have emerged as a powerful paradigm for enabling autonomous agents to solve complex tasks. As these systems scale in complexity, cost becomes an important consideration for practical deployment. However, existing work rarely addresses how to structure multi-agent systems under explicit budget constraints. In this paper, we propose BAMAS, a novel approach for building multi-agent systems with budget awareness. BAMAS first selects an optimal set of LLMs by formulating and solving an Integer Linear Programming problem that balances performance and cost. It then determines how these LLMs should collaborate by leveraging a reinforcement learning-based method to select the interaction topology. Finally, the system is instantiated and executed based on the selected agents and their collaboration topology. We evaluate BAMAS on three representative tasks and compare it with state-of-the-art agent construction methods. Results show that BAMAS achieves comparable performance while reducing cost by up to 86%.","authors":["Liming Yang","Junyu Luo","Xuanzhe Liu","Yiling Lou","Zhenpeng Chen"],"pdf_url":"","comment":"Accepted by AAAI 2026 (oral paper)"},{"id":"http://arxiv.org/abs/2511.21570v1","updated":"2025-11-26T16:42:10Z","published":"2025-11-26T16:42:10Z","title":"From Prediction to Foresight: The Role of AI in Designing Responsible Futures","summary":"In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term \"responsible computational foresight\", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.","authors":["Maria Perez-Ortiz"],"pdf_url":"","comment":"Accessible at https://projecteuclid.org/journals/journal-of-artificial-intelligence-for-sustainable-development/volume-1/issue-1/From-Prediction-to-Foresight--The-Role-of-AI-in/10.69828/4d4kja.full"},{"id":"http://arxiv.org/abs/2511.21569v1","updated":"2025-11-26T16:41:49Z","published":"2025-11-26T16:41:49Z","title":"Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit","summary":"If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a \"Reverse Gell-Mann Amnesia\" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($ΔR_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($κ= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.","authors":["Alex Diep"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.10234v2","updated":"2025-11-26T16:39:11Z","published":"2025-11-13T12:06:12Z","title":"Lost in Serialization: Invariance and Generalization of LLM Graph Reasoners","summary":"While promising, graph reasoners based on Large Language Models (LLMs) lack built-in invariance to symmetries in graph representations. Operating on sequential graph serializations, LLMs can produce different outputs under node reindexing, edge reordering, or formatting changes, raising robustness concerns. We systematically analyze these effects, studying how fine-tuning impacts encoding sensitivity as well generalization on unseen tasks. We propose a principled decomposition of graph serializations into node labeling, edge encoding, and syntax, and evaluate LLM robustness to variations of each of these factors on a comprehensive benchmarking suite. We also contribute a novel set of spectral tasks to further assess generalization abilities of fine-tuned reasoners. Results show that larger (non-fine-tuned) models are more robust. Fine-tuning reduces sensitivity to node relabeling but may increase it to variations in structure and format, while it does not consistently improve performance on unseen tasks.","authors":["Daniel Herbst","Lea Karbevska","Divyanshu Kumar","Akanksha Ahuja","Fatemeh Gholamzadeh Nasrabadi","Fabrizio Frasca"],"pdf_url":"","comment":"AAAI 2026 Workshop on Graphs and more Complex Structures For Learning and Reasoning (GCLR). Version 2 fixes typos in author name and Figure 1"},{"id":"http://arxiv.org/abs/2511.21557v1","updated":"2025-11-26T16:29:24Z","published":"2025-11-26T16:29:24Z","title":"VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation","summary":"Vision Language Action models have significantly advanced general purpose robotic manipulation by harnessing large scale pretrained vision and language representations. Among existing approaches, a majority of current VLA systems employ parallel two finger grippers as their default end effectors. However, such grippers face inherent limitations in handling certain real world tasks such as wiping glass surfaces or opening drawers without handles due to insufficient contact area or lack of adhesion. To overcome these challenges, we present a low cost, integrated hardware design that combines a mechanical two finger gripper with a vacuum suction unit, enabling dual mode manipulation within a single end effector. Our system supports flexible switching or synergistic use of both modalities, expanding the range of feasible tasks. We validate the efficiency and practicality of our design within two state of the art VLA frameworks: DexVLA and Pi0. Experimental results demonstrate that with the proposed hybrid end effector, robots can successfully perform multiple complex tasks that are infeasible for conventional two finger grippers alone. All hardware designs and controlling systems will be released.","authors":["Hui Zhou","Siyuan Huang","Minxing Li","Hao Zhang","Lue Fan","Shaoshuai Shi"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2505.19386v2","updated":"2025-11-26T16:02:59Z","published":"2025-05-26T01:04:02Z","title":"Force Prompting: Video Generation Models Can Learn and Generalize Physics-based Control Signals","summary":"Recent advances in video generation models have sparked interest in world models capable of simulating realistic environments. While navigation has been well-explored, physically meaningful interactions that mimic real-world forces remain largely understudied. In this work, we investigate using physical forces as a control signal for video generation and propose force prompts which enable users to interact with images through both localized point forces, such as poking a plant, and global wind force fields, such as wind blowing on fabric. We demonstrate that these force prompts can enable videos to respond realistically to physical control signals by leveraging the visual and motion prior in the original pretrained model, without using any 3D asset or physics simulator at inference. The primary challenge of force prompting is the difficulty in obtaining high quality paired force-video training data, both in the real world due to the difficulty of obtaining force signals, and in synthetic data due to limitations in the visual quality and domain diversity of physics simulators. Our key finding is that video generation models can generalize remarkably well when adapted to follow physical force conditioning from videos synthesized by Blender, even with limited demonstrations of few objects. Our method can generate videos which simulate forces across diverse geometries, settings, and materials. We also try to understand the source of this generalization and perform ablations that reveal two key elements: visual diversity and the use of specific text keywords during training. Our approach is trained on only around 15k training examples for a single day on four A100 GPUs, and outperforms existing methods on force adherence and physics realism, bringing world models closer to real-world physics interactions. We release all datasets, code, weights, and interactive video demos at our project page.","authors":["Nate Gillman","Charles Herrmann","Michael Freeman","Daksh Aggarwal","Evan Luo","Deqing Sun","Chen Sun"],"pdf_url":"","comment":"Camera ready version (NeurIPS 2025). Code and interactive demos at https://force-prompting.github.io/"},{"id":"http://arxiv.org/abs/2408.10901v4","updated":"2025-11-26T16:00:49Z","published":"2024-08-20T14:43:53Z","title":"A Gray-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse","summary":"Recent advancements in Latent Diffusion Models (LDMs) have revolutionized image synthesis and manipulation, raising significant concerns about data misappropriation and intellectual property infringement. While adversarial attacks have been extensively explored as a protective measure against such misuse of generative AI, current approaches are severely limited by their heavy reliance on model-specific knowledge and substantial computational costs. Drawing inspiration from the posterior collapse phenomenon observed in VAE training, we propose the Posterior Collapse Attack (PCA), a novel framework for protecting images from unauthorized manipulation. Through comprehensive theoretical analysis and empirical validation, we identify two distinct collapse phenomena during VAE inference: diffusion collapse and concentration collapse. Based on this discovery, we design a unified loss function that can flexibly achieve both types of collapse through parameter adjustment, each corresponding to different protection objectives in preventing image manipulation. Our method significantly reduces dependence on model-specific knowledge by requiring access to only the VAE encoder, which constitutes less than 4\\% of LDM parameters. Notably, PCA achieves prompt-invariant protection by operating on the VAE encoder before text conditioning occurs, eliminating the need for empty prompt optimization required by existing methods. This minimal requirement enables PCA to maintain adequate transferability across various VAE-based LDM architectures while effectively preventing unauthorized image editing. Extensive experiments show PCA outperforms existing techniques in protection effectiveness, computational efficiency (runtime and VRAM), and generalization across VAE-based LDM variants. Our code is available at https://github.com/ZhongliangGuo/PosteriorCollapseAttack.","authors":["Zhongliang Guo","Chun Tong Lei","Lei Fang","Shuai Zhao","Yifei Qian","Jingyu Lin","Zeyu Wang","Cunjian Chen","Ognjen Arandjelović","Chun Pong Lau"],"pdf_url":"","comment":"15 pages, 9 figures, 9 tables"},{"id":"http://arxiv.org/abs/2511.21531v1","updated":"2025-11-26T15:59:55Z","published":"2025-11-26T15:59:55Z","title":"Predictive Safety Shield for Dyna-Q Reinforcement Learning","summary":"Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.","authors":["Jin Pin","Krasowski Hanna","Vanneaux Elena"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08604v2","updated":"2025-11-26T15:56:35Z","published":"2025-06-10T09:13:37Z","title":"Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation","summary":"Generative machine learning methods, such as diffusion models and flow matching, have shown great potential in modeling complex system behaviors and building efficient surrogate models. However, these methods typically learn the underlying physics implicitly from data. We propose Physics-Based Flow Matching (PBFM), a novel generative framework that explicitly embeds physical constraints, both PDE residuals and algebraic relations, into the flow matching objective. We also introduce temporal unrolling at training time that improves the accuracy of the final, noise-free sample prediction. Our method jointly minimizes the flow matching loss and the physics-based residual loss without requiring hyperparameter tuning of their relative weights. Additionally, we analyze the role of the minimum noise level, $σ_{\\min}$, in the context of physical constraints and evaluate a stochastic sampling strategy that helps to reduce physical residuals. Through extensive benchmarks on three representative PDE problems, we show that our approach yields up to an $8\\times$ more accurate physical residuals compared to FM, while clearly outperforming existing algorithms in terms of distributional accuracy. PBFM thus provides a principled and efficient framework for surrogate modeling, uncertainty quantification, and accelerated simulation in physics and engineering applications.","authors":["Giacomo Baldan","Qiang Liu","Alberto Guardone","Nils Thuerey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21522v1","updated":"2025-11-26T15:52:52Z","published":"2025-11-26T15:52:52Z","title":"Pessimistic Verification for Open Ended Math Questions","summary":"The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.","authors":["Yanxing Huang","Zihan Tang","Zejin Lin","Peng Li","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.03403v2","updated":"2025-11-26T15:51:15Z","published":"2025-01-06T21:46:22Z","title":"BoundingDocs: a Unified Dataset for Document Question Answering with Spatial Annotations","summary":"We present a unified dataset for document Question-Answering (QA), which is obtained combining several public datasets related to Document AI and visually rich document understanding (VRDU). Our main contribution is twofold: on the one hand we reformulate existing Document AI tasks, such as Information Extraction (IE), into a Question-Answering task, making it a suitable resource for training and evaluating Large Language Models; on the other hand, we release the OCR of all the documents and include the exact position of the answer to be found in the document image as a bounding box. Using this dataset, we explore the impact of different prompting techniques (that might include bounding box information) on the performance of open-weight models, identifying the most effective approaches for document comprehension.","authors":["Simone Giovannini","Fabio Coppini","Andrea Gemelli","Simone Marinai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21517v1","updated":"2025-11-26T15:48:04Z","published":"2025-11-26T15:48:04Z","title":"Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation","summary":"Unlike text, speech conveys information about the speaker, such as gender, through acoustic cues like pitch. This gives rise to modality-specific bias concerns. For example, in speech translation (ST), when translating from languages with notional gender, such as English, into languages where gender-ambiguous terms referring to the speaker are assigned grammatical gender, the speaker's vocal characteristics may play a role in gender assignment. This risks misgendering speakers, whether through masculine defaults or vocal-based assumptions. Yet, how ST models make these decisions remains poorly understood. We investigate the mechanisms ST models use to assign gender to speaker-referring terms across three language pairs (en-es/fr/it), examining how training data patterns, internal language model (ILM) biases, and acoustic information interact. We find that models do not simply replicate term-specific gender associations from training data, but learn broader patterns of masculine prevalence. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Using contrastive feature attribution on spectrograms, we reveal that the model with higher gender accuracy relies on a previously unknown mechanism: using first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch.","authors":["Lina Conti","Dennis Fucci","Marco Gaido","Matteo Negri","Guillaume Wisniewski","Luisa Bentivogli"],"pdf_url":"","comment":"Submitted to LREC 2026"},{"id":"http://arxiv.org/abs/2511.21514v1","updated":"2025-11-26T15:46:29Z","published":"2025-11-26T15:46:29Z","title":"Mechanistic Interpretability for Transformer-based Time Series Classification","summary":"Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks.","authors":["Matīss Kalnāre","Sofoklis Kitharidis","Thomas Bäck","Niki van Stein"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21510v1","updated":"2025-11-26T15:45:33Z","published":"2025-11-26T15:45:33Z","title":"Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation","summary":"This study proposes Tool-RoCo, a novel benchmark for evaluating large language models (LLMs) in long-term multi-agent cooperation based on RoCo, a multi-robot cooperative benchmark. Recent research on LLM-based multi-agent systems has relied on predefined orchestration, while ignoring agent autonomy. Tool-RoCo treats other agents as tools and introduces cooperative tools, leveraging tool usage to evaluate multi-agent cooperation and self-organization. Tool usage means that each agent (LLM) selects a tool from a candidate set based on the current state, receives feedback, and adjusts its selection in subsequent rounds. To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls. Tool-RoCo includes three multi-robot tasks, SORT, PACK, and CABINET, to measure format and parameter accuracy and agent coordination through tool usage. The results using several LLMs showed that cooperative tools accounted for only 7.09% of all tools, indicating that LLM-based agents rarely invoked others as assistants. Moreover, activation tools accounted for 96.42%, suggesting that current LLMs tend to maintain active agents while seldom deactivating them for adaptive coordination. Tool-RoCo provides a systematic benchmark to evaluate LLM autonomy and cooperation in multi-agent tasks. Code and Demo: https://github.com/ColaZhang22/Tool-Roco","authors":["Ke Zhang","Xiaoning Zhao","Ce Zheng","Jiahong Ning","Dandan Zhu","Wenqi Zhang","Chen Sun","Toshiharu Sugawara"],"pdf_url":"","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2509.12247v2","updated":"2025-11-26T15:30:09Z","published":"2025-09-11T21:14:35Z","title":"Modular, On-Site Solutions with Lightweight Anomaly Detection for Sustainable Nutrient Management in Agriculture","summary":"Efficient nutrient management is critical for crop growth and sustainable resource consumption (e.g., nitrogen, energy). Current approaches require lengthy analyses, preventing real-time optimization; similarly, imaging facilitates rapid phenotyping but can be computationally intensive, preventing deployment under resource constraints. This study proposes a flexible, tiered pipeline for anomaly detection and status estimation (fresh weight, dry mass, and tissue nutrients), including a comprehensive energy analysis of approaches that span the efficiency-accuracy spectrum. Using a nutrient depletion experiment with three treatments (T1-100%, T2-50%, and T3-25% fertilizer strength) and multispectral imaging (MSI), we developed a hierarchical pipeline using an autoencoder (AE) for early warning. Further, we compared two status estimation modules of different complexity for more detailed analysis: vegetation index (VI) features with machine learning (Random Forest, RF) and raw whole-image deep learning (Vision Transformer, ViT). Results demonstrated high-efficiency anomaly detection (73% net detection of T3 samples 9 days after transplanting) at substantially lower energy than embodied energy in wasted nitrogen. The state estimation modules show trade-offs, with ViT outperforming RF on phosphorus and calcium estimation (R2 0.61 vs. 0.58, 0.48 vs. 0.35) at higher energy cost. With our modular pipeline, this work opens opportunities for edge diagnostics and practical opportunities for agricultural sustainability.","authors":["Abigail R. Cohen","Yuming Sun","Zhihao Qin","Harsh S. Muriki","Zihao Xiao","Yeonju Lee","Matthew Housley","Andrew F. Sharkey","Rhuanito S. Ferrarezi","Jing Li","Lu Gan","Yongsheng Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21490v1","updated":"2025-11-26T15:24:53Z","published":"2025-11-26T15:24:53Z","title":"Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning","summary":"We present a novel training approach, named Merge-and-Bound (M&B) for Class Incremental Learning (CIL), which directly manipulates model weights in the parameter space for optimization. Our algorithm involves two types of weight merging: inter-task weight merging and intra-task weight merging. Inter-task weight merging unifies previous models by averaging the weights of models from all previous stages. On the other hand, intra-task weight merging facilitates the learning of current task by combining the model parameters within current stage. For reliable weight merging, we also propose a bounded update technique that aims to optimize the target model with minimal cumulative updates and preserve knowledge from previous tasks; this strategy reveals that it is possible to effectively obtain new models near old ones, reducing catastrophic forgetting. M&B is seamlessly integrated into existing CIL methods without modifying architecture components or revising learning objectives. We extensively evaluate our algorithm on standard CIL benchmarks and demonstrate superior performance compared to state-of-the-art methods.","authors":["Taehoon Kim","Donghwan Jang","Bohyung Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.17846v2","updated":"2025-11-26T15:20:20Z","published":"2024-05-28T05:50:25Z","title":"Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs","summary":"Safety limitations in service robotics across various industries have raised significant concerns about the need for robust mechanisms ensuring that robots adhere to safe practices, thereby preventing actions that might harm humans or cause property damage. Despite advances, including the integration of Knowledge Graphs (KGs) with Large Language Models (LLMs), challenges in ensuring consistent safety in autonomous robot actions persist. In this paper, we propose a novel integration of Large Language Models with Embodied Robotic Control Prompts (ERCPs) and Embodied Knowledge Graphs (EKGs) to enhance the safety framework for service robots. ERCPs are designed as predefined instructions that ensure LLMs generate safe and precise responses. These responses are subsequently validated by EKGs, which provide a comprehensive knowledge base ensuring that the actions of the robot are continuously aligned with safety protocols, thereby promoting safer operational practices in varied contexts. Our experimental setup involved diverse real-world tasks, where robots equipped with our framework demonstrated significantly higher compliance with safety standards compared to traditional methods. This integration fosters secure human-robot interactions and positions our methodology at the forefront of AI-driven safety innovations in service robotics.","authors":["Yong Qi","Gabriel Kyebambo","Siyuan Xie","Wei Shen","Shenghui Wang","Bitao Xie","Bin He","Zhipeng Wang","Shuo Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19218v2","updated":"2025-11-26T15:12:18Z","published":"2025-11-24T15:23:41Z","title":"Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization","summary":"Large Language Models (LLMs) have developed rapidly in web services, delivering unprecedented capabilities while amplifying societal risks. Existing works tend to focus on either isolated jailbreak attacks or static defenses, neglecting the dynamic interplay between evolving threats and safeguards in real-world web contexts. To mitigate these challenges, we propose ACE-Safety (Adversarial Co-Evolution for LLM Safety), a novel framework that jointly optimize attack and defense models by seamlessly integrating two key innovative procedures: (1) Group-aware Strategy-guided Monte Carlo Tree Search (GS-MCTS), which efficiently explores jailbreak strategies to uncover vulnerabilities and generate diverse adversarial samples; (2) Adversarial Curriculum Tree-aware Group Policy Optimization (AC-TGPO), which jointly trains attack and defense LLMs with challenging samples via curriculum reinforcement learning, enabling robust mutual improvement. Evaluations across multiple benchmarks demonstrate that our method outperforms existing attack and defense approaches, and provides a feasible pathway for developing LLMs that can sustainably support responsible AI ecosystems.","authors":["Xurui Li","Kaisong Song","Rui Zhu","Pin-Yu Chen","Haixu Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21477v1","updated":"2025-11-26T15:10:04Z","published":"2025-11-26T15:10:04Z","title":"Frequency-Aware Token Reduction for Efficient Vision Transformer","summary":"Vision Transformers have demonstrated exceptional performance across various computer vision tasks, yet their quadratic computational complexity concerning token length remains a significant challenge. To address this, token reduction methods have been widely explored. However, existing approaches often overlook the frequency characteristics of self-attention, such as rank collapsing and over-smoothing phenomenon. In this paper, we propose a frequency-aware token reduction strategy that improves computational efficiency while preserving performance by mitigating rank collapsing. Our method partitions tokens into high-frequency tokens and low-frequency tokens. high-frequency tokens are selectively preserved, while low-frequency tokens are aggregated into a compact direct current token to retain essential low-frequency components. Through extensive experiments and analysis, we demonstrate that our approach significantly improves accuracy while reducing computational overhead and mitigating rank collapsing and over smoothing. Furthermore, we analyze the previous methods, shedding light on their implicit frequency characteristics and limitations.","authors":["Dong-Jae Lee","Jiwan Hur","Jaehyun Choi","Jaemyung Yu","Junmo Kim"],"pdf_url":"","comment":"Neurips 2025"},{"id":"http://arxiv.org/abs/2511.21474v1","updated":"2025-11-26T15:06:19Z","published":"2025-11-26T15:06:19Z","title":"Going with the Speed of Sound: Pushing Neural Surrogates into Highly-turbulent Transonic Regimes","summary":"The widespread use of neural surrogates in automotive aerodynamics, enabled by datasets such as DrivAerML and DrivAerNet++, has primarily focused on bluff-body flows with large wakes. Extending these methods to aerospace, particularly in the transonic regime, remains challenging due to the high level of non-linearity of compressible flows and 3D effects such as wingtip vortices. Existing aerospace datasets predominantly focus on 2D airfoils, neglecting these critical 3D phenomena. To address this gap, we present a new dataset of CFD simulations for 3D wings in the transonic regime. The dataset comprises volumetric and surface-level fields for around $30,000$ samples with unique geometry and inflow conditions. This allows computation of lift and drag coefficients, providing a foundation for data-driven aerodynamic optimization of the drag-lift Pareto front. We evaluate several state-of-the-art neural surrogates on our dataset, including Transolver and AB-UPT, focusing on their out-of-distribution (OOD) generalization over geometry and inflow variations. AB-UPT demonstrates strong performance for transonic flowfields and reproduces physically consistent drag-lift Pareto fronts even for unseen wing configurations. Our results demonstrate that AB-UPT can approximate drag-lift Pareto fronts for unseen geometries, highlighting its potential as an efficient and effective tool for rapid aerodynamic design exploration. To facilitate future research, we open-source our dataset at https://huggingface.co/datasets/EmmiAI/Emmi-Wing.","authors":["Fabian Paischer","Leo Cotteleer","Yann Dreze","Richard Kurle","Dylan Rubini","Maurits Bleeker","Tobias Kronlachner","Johannes Brandstetter"],"pdf_url":"","comment":"NeurIPS 2025 ML4PS Workshop"},{"id":"http://arxiv.org/abs/2511.21473v1","updated":"2025-11-26T15:05:22Z","published":"2025-11-26T15:05:22Z","title":"Hierarchical Ranking Neural Network for Long Document Readability Assessment","summary":"Readability assessment aims to evaluate the reading difficulty of a text. In recent years, while deep learning technology has been gradually applied to readability assessment, most approaches fail to consider either the length of the text or the ordinal relationship of readability labels. This paper proposes a bidirectional readability assessment mechanism that captures contextual information to identify regions with rich semantic information in the text, thereby predicting the readability level of individual sentences. These sentence-level labels are then used to assist in predicting the overall readability level of the document. Additionally, a pairwise sorting algorithm is introduced to model the ordinal relationship between readability levels through label subtraction. Experimental results on Chinese and English datasets demonstrate that the proposed model achieves competitive performance and outperforms other baseline models.","authors":["Yurui Zheng","Yijun Chen","Shaohong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21471v1","updated":"2025-11-26T15:04:18Z","published":"2025-11-26T15:04:18Z","title":"SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition","summary":"Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.","authors":["Peiran Xu","Sudong Wang","Yao Zhu","Jianing Li","Yunjian Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15848v2","updated":"2025-11-26T14:55:41Z","published":"2025-11-19T20:12:50Z","title":"Step-Audio-R1 Technical Report","summary":"Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.","authors":["Fei Tian","Xiangyu Tony Zhang","Yuxin Zhang","Haoyang Zhang","Yuxin Li","Daijiao Liu","Yayue Deng","Donghang Wu","Jun Chen","Liang Zhao","Chengyuan Yao","Hexin Liu","Eng Siong Chng","Xuerui Yang","Xiangyu Zhang","Daxin Jiang","Gang Yu"],"pdf_url":"","comment":"22 pages, 5 figures. Technical Report"},{"id":"http://arxiv.org/abs/2511.19399v2","updated":"2025-11-26T14:52:10Z","published":"2025-11-24T18:35:54Z","title":"DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research","summary":"Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.","authors":["Rulin Shao","Akari Asai","Shannon Zejiang Shen","Hamish Ivison","Varsha Kishore","Jingming Zhuo","Xinran Zhao","Molly Park","Samuel G. Finlayson","David Sontag","Tyler Murray","Sewon Min","Pradeep Dasigi","Luca Soldaini","Faeze Brahman","Wen-tau Yih","Tongshuang Wu","Luke Zettlemoyer","Yoon Kim","Hannaneh Hajishirzi","Pang Wei Koh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21460v1","updated":"2025-11-26T14:51:37Z","published":"2025-11-26T14:51:37Z","title":"MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning","summary":"Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents.","authors":["Junjian Wang","Lidan Zhao","Xi Sheryl Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10160v2","updated":"2025-11-26T14:51:06Z","published":"2025-10-11T10:50:58Z","title":"SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation","summary":"Referring Image Segmentation (RIS) aims to segment the target object in an image given a natural language expression. While recent methods leverage pre-trained vision backbones and more training corpus to achieve impressive results, they predominantly focus on simple expressions--short, clear noun phrases like \"red car\" or \"left girl\". This simplification often reduces RIS to a key word/concept matching problem, limiting the model's ability to handle referential ambiguity in expressions. In this work, we identify two challenging real-world scenarios: object-distracting expressions, which involve multiple entities with contextual cues, and category-implicit expressions, where the object class is not explicitly stated. To address the challenges, we propose a novel framework, SaFiRe, which mimics the human two-phase cognitive process--first forming a global understanding, then refining it through detail-oriented inspection. This is naturally supported by Mamba's scan-then-update property, which aligns with our phased design and enables efficient multi-cycle refinement with linear complexity. We further introduce aRefCOCO, a new benchmark designed to evaluate RIS models under ambiguous referring expressions. Extensive experiments on both standard and proposed datasets demonstrate the superiority of SaFiRe over state-of-the-art baselines.","authors":["Zhenjie Mao","Yuhuan Yang","Chaofan Ma","Dongsheng Jiang","Jiangchao Yao","Ya Zhang","Yanfeng Wang"],"pdf_url":"","comment":"NeurIPS 2025; Project page: https://zhenjiemao.github.io/SaFiRe/"},{"id":"http://arxiv.org/abs/2511.09298v2","updated":"2025-11-26T14:43:38Z","published":"2025-11-12T13:07:07Z","title":"DensiCrafter: Physically-Constrained Generation and Fabrication of Self-Supporting Hollow Structures","summary":"The rise of 3D generative models has enabled automatic 3D geometry and texture synthesis from multimodal inputs (e.g., text or images). However, these methods often ignore physical constraints and manufacturability considerations. In this work, we address the challenge of producing 3D designs that are both lightweight and self-supporting. We present DensiCrafter, a framework for generating lightweight, self-supporting 3D hollow structures by optimizing the density field. Starting from coarse voxel grids produced by Trellis, we interpret these as continuous density fields to optimize and introduce three differentiable, physically constrained, and simulation-free loss terms. Additionally, a mass regularization penalizes unnecessary material, while a restricted optimization domain preserves the outer surface. Our method seamlessly integrates with pretrained Trellis-based models (e.g., Trellis, DSO) without any architectural changes. In extensive evaluations, we achieve up to 43% reduction in material mass on the text-to-3D task. Compared to state-of-the-art baselines, our method could improve the stability and maintain high geometric fidelity. Real-world 3D-printing experiments confirm that our hollow designs can be reliably fabricated and could be self-supporting.","authors":["Shengqi Dang","Fu Chai","Jiaxin Li","Chao Yuan","Wei Ye","Nan Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21448v1","updated":"2025-11-26T14:40:06Z","published":"2025-11-26T14:40:06Z","title":"Constructing and Benchmarking: a Labeled Email Dataset for Text-Based Phishing and Spam Detection Framework","summary":"Phishing and spam emails remain a major cybersecurity threat, with attackers increasingly leveraging Large Language Models (LLMs) to craft highly deceptive content. This study presents a comprehensive email dataset containing phishing, spam, and legitimate messages, explicitly distinguishing between human- and LLM-generated content. Each email is annotated with its category, emotional appeal (e.g., urgency, fear, authority), and underlying motivation (e.g., link-following, credential theft, financial fraud). We benchmark multiple LLMs on their ability to identify these emotional and motivational cues and select the most reliable model to annotate the full dataset. To evaluate classification robustness, emails were also rephrased using several LLMs while preserving meaning and intent. A state-of-the-art LLM was then assessed on its performance across both original and rephrased emails using expert-labeled ground truth. The results highlight strong phishing detection capabilities but reveal persistent challenges in distinguishing spam from legitimate emails. Our dataset and evaluation framework contribute to improving AI-assisted email security systems. To support open science, all code, templates, and resources are available on our project site.","authors":["Rebeka Toth","Tamas Bisztray","Richard Dubniczky"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21444v1","updated":"2025-11-26T14:37:25Z","published":"2025-11-26T14:37:25Z","title":"EWE: An Agentic Framework for Extreme Weather Analysis","summary":"Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather.","authors":["Zhe Jiang","Jiong Wang","Xiaoyu Yue","Zijie Guo","Wenlong Zhang","Fenghua Ling","Wanli Ouyang","Lei Bai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21439v1","updated":"2025-11-26T14:30:04Z","published":"2025-11-26T14:30:04Z","title":"EvRainDrop: HyperGraph-guided Completion for Effective Frame and Event Stream Aggregation","summary":"Event cameras produce asynchronous event streams that are spatially sparse yet temporally dense. Mainstream event representation learning algorithms typically use event frames, voxels, or tensors as input. Although these approaches have achieved notable progress, they struggle to address the undersampling problem caused by spatial sparsity. In this paper, we propose a novel hypergraph-guided spatio-temporal event stream completion mechanism, which connects event tokens across different times and spatial locations via hypergraphs and leverages contextual information message passing to complete these sparse events. The proposed method can flexibly incorporate RGB tokens as nodes in the hypergraph within this completion framework, enabling multi-modal hypergraph-based information completion. Subsequently, we aggregate hypergraph node information across different time steps through self-attention, enabling effective learning and fusion of multi-modal features. Extensive experiments on both single- and multi-label event classification tasks fully validated the effectiveness of our proposed framework. The source code of this paper will be released on https://github.com/Event-AHU/EvRainDrop.","authors":["Futian Wang","Fan Zhang","Xiao Wang","Mengqi Wang","Dexing Huang","Jin Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21438v1","updated":"2025-11-26T14:28:19Z","published":"2025-11-26T14:28:19Z","title":"Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex","summary":"Repurposing approved drugs offers a time-efficient and cost-effective alternative to traditional drug development. However, in silico prediction of repurposing candidates is challenging and requires the effective collaboration of specialists in various fields, including pharmacology, medicine, biology, and bioinformatics. Fragmented, specialized algorithms and tools often address only narrow aspects of the overall problem, and heterogeneous, unstructured data landscapes require specialized users to be involved. Hence, these data services do not integrate smoothly across workflows. With ChatDRex, we present a conversation-based, multi-agent system that facilitates the execution of complex bioinformatic analyses aiming for network-based drug repurposing prediction. It builds on the integrated systems medicine knowledge graph NeDRex. ChatDRex provides natural language access to its extensive biomedical KG and integrates bioinformatics agents for network analysis and drug repurposing, complemented by agents for functional coherence evaluation for in silico validation, as well as agents for literature mining and for discussing the obtained results in a scientific context. Its flexible multi-agent design assigns specific tasks to specialized agents, including query routing, data retrieval, algorithm execution, and result visualization. A dedicated reasoning module keeps the user in the loop and allows for hallucination detection. By enabling physicians and researchers without computer science expertise to control complex analyses in natural language, ChatDRex democratizes access to bioinformatics as an important resource for drug repurposing. It enables clinical experts to generate hypotheses and explore drug repurposing opportunities, ultimately accelerating the discovery of novel therapies and advancing personalized medicine and translational research.","authors":["Simon Süwer","Kester Bagemihl","Sylvie Baier","Lucia Dicunta","Markus List","Jan Baumbach","Andreas Maier","Fernando M. Delgado-Chaves"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.07317v2","updated":"2025-11-26T14:27:22Z","published":"2025-05-12T08:03:55Z","title":"How Do Companies Manage the Environmental Sustainability of AI? An Interview Study About Green AI Efforts and Regulations","summary":"With the ever-growing adoption of artificial intelligence (AI), AI-based software and its negative impact on the environment are no longer negligible, and studying and mitigating this impact has become a critical area of research. However, it is currently unclear which role environmental sustainability plays during AI adoption in industry and how AI regulations influence Green AI practices and decision-making in industry. We therefore aim to investigate the Green AI perception and management of industry practitioners. To this end, we conducted a total of 11 interviews with participants from 10 different organizations that adopted AI-based software. The interviews explored three main themes: AI adoption, current efforts in mitigating the negative environmental impact of AI, and the influence of the EU AI Act and the Corporate Sustainability Reporting Directive (CSRD). Our findings indicate that 9 of 11 participants prioritized business efficiency during AI adoption, with minimal consideration of environmental sustainability. Monitoring and mitigation of AI's environmental impact were very limited. Only one participant monitored negative environmental effects. Regarding applied mitigation practices, six participants reported no actions, with the others sporadically mentioning techniques like prompt engineering, relying on smaller models, or not overusing AI. Awareness and compliance with the EU AI Act are low, with only one participant reporting on its influence, while the CSRD drove sustainability reporting efforts primarily in larger companies. All in all, our findings reflect a lack of urgency and priority for sustainable AI among these companies. We suggest that current regulations are not very effective, which has implications for policymakers. Additionally, there is a need to raise industry awareness, but also to provide user-friendly techniques and tools for Green AI practices.","authors":["Ashmita Sampatsing","Sophie Vos","Emma Beauxis-Aussalet","Justus Bogner"],"pdf_url":"","comment":"Accepted for publication at the 11th International Conference on ICT for Sustainability (ICT4S'25), see https://conf.researchr.org/home/ict4s-2025"},{"id":"http://arxiv.org/abs/2511.21428v1","updated":"2025-11-26T14:19:44Z","published":"2025-11-26T14:19:44Z","title":"From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings","summary":"We present a novel unsupervised framework to unlock vast unlabeled human demonstration data from continuous industrial video streams for Vision-Language-Action (VLA) model pre-training. Our method first trains a lightweight motion tokenizer to encode motion dynamics, then employs an unsupervised action segmenter leveraging a novel \"Latent Action Energy\" metric to discover and segment semantically coherent action primitives. The pipeline outputs both segmented video clips and their corresponding latent action sequences, providing structured data directly suitable for VLA pre-training. Evaluations on public benchmarks and a proprietary electric motor assembly dataset demonstrate effective segmentation of key tasks performed by humans at workstations. Further clustering and quantitative assessment via a Vision-Language Model confirm the semantic coherence of the discovered action primitives. To our knowledge, this is the first fully automated end-to-end system for extracting and organizing VLA pre-training data from unstructured industrial videos, offering a scalable solution for embodied AI integration in manufacturing.","authors":["Jiajie Zhang","Sören Schwertfeger","Alexander Kleiner"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2509.03340v2","updated":"2025-11-26T14:19:09Z","published":"2025-09-03T14:18:05Z","title":"Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems","summary":"Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models struggle to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we propose a generative framework based on flow matching to model the full probability distribution over bifurcation outcomes. Our method enables direct sampling of multiple valid solutions while preserving system symmetries through equivariant modeling. We introduce a symmetric matching strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from toy models to complex physical problems such as buckling beams and the Allen-Cahn equation. Our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods in capturing multimodal distributions and symmetry-breaking bifurcations, offering a principled and scalable solution for modeling multistability in high-dimensional systems.","authors":["Fleur Hendriks","Ondřej Rokoš","Martin Doškář","Marc G. D. Geers","Vlado Menkovski"],"pdf_url":"","comment":"12 pages, 7 figures including appendices. Accepted to Machine Learning and the Physical Sciences Workshop, NeurIPS 2025 (https://ml4physicalsciences.github.io/2025/). Repository with corresponding code: https://github.com/FHendriks11/bifurcationML/. Video explanation: https://www.youtube.com/watch?v=wsL3h17KtjY"},{"id":"http://arxiv.org/abs/2511.21420v1","updated":"2025-11-26T14:11:19Z","published":"2025-11-26T14:11:19Z","title":"SAM Guided Semantic and Motion Changed Region Mining for Remote Sensing Change Captioning","summary":"Remote sensing change captioning is an emerging and popular research task that aims to describe, in natural language, the content of interest that has changed between two remote sensing images captured at different times. Existing methods typically employ CNNs/Transformers to extract visual representations from the given images or incorporate auxiliary tasks to enhance the final results, with weak region awareness and limited temporal alignment. To address these issues, this paper explores the use of the SAM (Segment Anything Model) foundation model to extract region-level representations and inject region-of-interest knowledge into the captioning framework. Specifically, we employ a CNN/Transformer model to extract global-level vision features, leverage the SAM foundation model to delineate semantic- and motion-level change regions, and utilize a specially constructed knowledge graph to provide information about objects of interest. These heterogeneous sources of information are then fused via cross-attention, and a Transformer decoder is used to generate the final natural language description of the observed changes. Extensive experimental results demonstrate that our method achieves state-of-the-art performance across multiple widely used benchmark datasets. The source code of this paper will be released on https://github.com/Event-AHU/SAM_ChangeCaptioning","authors":["Futian Wang","Mengqi Wang","Xiao Wang","Haowen Wang","Jin Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21417v1","updated":"2025-11-26T14:08:28Z","published":"2025-11-26T14:08:28Z","title":"New Hybrid Heuristics for Pseudo-Boolean Propagation","summary":"In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.","authors":["Mia Müßig","Jan Johannsen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21413v1","updated":"2025-11-26T14:06:22Z","published":"2025-11-26T14:06:22Z","title":"Automated Dynamic AI Inference Scaling on HPC-Infrastructure: Integrating Kubernetes, Slurm and vLLM","summary":"Due to rising demands for Artificial Inteligence (AI) inference, especially in higher education, novel solutions utilising existing infrastructure are emerging. The utilisation of High-Performance Computing (HPC) has become a prevalent approach for the implementation of such solutions. However, the classical operating model of HPC does not adapt well to the requirements of synchronous, user-facing dynamic AI application workloads. In this paper, we propose our solution that serves LLMs by integrating vLLM, Slurm and Kubernetes on the supercomputer \\textit{RAMSES}. The initial benchmark indicates that the proposed architecture scales efficiently for 100, 500 and 1000 concurrent requests, incurring only an overhead of approximately 500 ms in terms of end-to-end latency.","authors":["Tim Trappen","Robert Keßler","Roland Pabel","Viktor Achter","Stefan Wesner"],"pdf_url":"","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.21408v1","updated":"2025-11-26T14:00:18Z","published":"2025-11-26T14:00:18Z","title":"Subjective Depth and Timescale Transformers: Learning Where and When to Compute","summary":"The rigid, uniform allocation of computation in standard Transformer (TF) architectures can limit their efficiency and scalability, particularly for large-scale models and long sequences. Addressing this, we introduce Subjective Depth Transformers (SDT) and Subjective Timescale Transformers (STT), two distinct architectures that leverage Bayesian surprise signals to dynamically route computation, learning where and when to compute within decoder-only TFs. SDT augments a decoder-only stack with alternating Decision and Dynamic layers: a Decision layer computes a full block 'posterior' and a lightweight 'prior,' while a Dynamic layer employs fixed-capacity Top-K routing based on Bayesian surprise (Expected and Unexpected Change), maintaining a static compute graph. STT extends this conditional computation to the temporal domain: a transition network predicts residual updates, forming a temporal 'change hypothesis' that informs a router to dynamically execute or bypass TF blocks for each token, managing KV-cache contributions. Both architectures exhibit the predicted shift from novelty to prediction driven gating over training, suggesting alignment with surprise based principles. While operating at reduced capacity, they offer preliminary insights into the compute-accuracy trade-offs of conditional computation. The proposed architectures establish a flexible framework for efficiency, reducing self-attention computation by 75% and KV-cache requirements by 50% within each compute skipping layer, setting a pathway for more efficient models.","authors":["Frederico Wieser","Martin Benfeghoul","Haitham Bou Ammar","Jun Wang","Zafeirios Fountas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.18444v2","updated":"2025-11-26T13:57:16Z","published":"2025-01-30T15:56:20Z","title":"Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms","summary":"This study addresses the need for accurate and efficient object detection in assistive technologies for visually impaired individuals. We evaluate four real-time object detection algorithms YOLO, SSD, Faster R-CNN, and Mask R-CNN within the context of indoor navigation assistance. Using the Indoor Objects Detection dataset, we analyze detection accuracy, processing speed, and adaptability to indoor environments. Our findings highlight the trade-offs between precision and efficiency, offering insights into selecting optimal algorithms for realtime assistive navigation. This research advances adaptive machine learning applications, enhancing indoor navigation solutions for the visually impaired and promoting accessibility.","authors":["Abhinav Pratap","Sushant Kumar","Suchinton Chakravarty"],"pdf_url":"","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2511.21399v1","updated":"2025-11-26T13:49:43Z","published":"2025-11-26T13:49:43Z","title":"Training Introspective Behavior: Fine-Tuning Induces Reliable Internal State Detection in a 7B Model","summary":"Lindsey (2025) investigates introspective awareness in language models through four experiments, finding that models can sometimes detect and identify injected activation patterns -- but unreliably (~20% success in the best model). We focus on the first of these experiments -- self-report of injected \"thoughts\" -- and ask whether this capability can be directly trained rather than waiting for emergence. Through fine-tuning on transient single-token injections, we transform a 7B parameter model from near-complete failure (0.4% accuracy, 6.7% false positive rate) to reliable detection (85% accuracy on held-out concepts at α=40, 0% false positives). Our model detects fleeting \"thoughts\" injected at a single token position, retains that information, and reports the semantic content across subsequent generation steps. On this task, our trained model satisfies three of Lindsey's criteria: accuracy (correct identification), grounding (0/60 false positives), and internality (detection precedes verbalization). Generalization to unseen concept vectors (7.5pp gap) demonstrates the model learns a transferable skill rather than memorizing specific vectors, though this does not establish metacognitive representation in Lindsey's sense. These results address an open question raised by Lindsey: whether \"training for introspection would help eliminate cross-model differences.\" We show that at least one component of introspective behavior can be directly induced, offering a pathway to built-in AI transparency.","authors":["Joshua Fonseca Rivera"],"pdf_url":"","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2511.21398v1","updated":"2025-11-26T13:49:39Z","published":"2025-11-26T13:49:39Z","title":"Prune4Web: DOM Tree Pruning Programming for Web Agent","summary":"Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.","authors":["Jiayuan Zhang","Kaiquan Chen","Zhihao Lu","Enshen Zhou","Qian Yu","Jing Zhang"],"pdf_url":"","comment":"Paper accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2511.21397v1","updated":"2025-11-26T13:49:08Z","published":"2025-11-26T13:49:08Z","title":"Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis","summary":"How does irrelevant information (i.e., distractors) affect test-time scaling in vision-language models (VLMs)? Prior studies on language models have reported an inverse scaling effect, where textual distractors lead to longer but less effective reasoning. To investigate whether similar phenomena occur in multimodal settings, we introduce Idis (Images with distractors), a visual question-answering dataset that systematically varies distractors along semantic, numerical, and spatial dimensions. Our analyses reveal that visual distractors differ fundamentally from textual ones: although inverse scaling persists, adding visual distractors reduces accuracy without increasing reasoning length. We further show that tracking attribute counts within reasoning traces provides key insights into how distractors, reasoning length, and accuracy interact. Finally, we demonstrate that these trends extend to established visual bias benchmarks such as Waterbirds, and we propose a simple prompting strategy to mitigate bias-driven predictions in reasoning models.","authors":["Jiyun Bae","Hyunjong Ok","Sangwoo Mo","Jaeho Lee"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2511.21395v1","updated":"2025-11-26T13:46:39Z","published":"2025-11-26T13:46:39Z","title":"Monet: Reasoning in Latent Visual Space Beyond Images and Language","summary":"\"Thinking with images\" has emerged as an effective paradigm for advancing visual reasoning, extending beyond text-only chains of thought by injecting visual evidence into intermediate reasoning steps. However, existing methods fall short of human-like abstract visual thinking, as their flexibility is fundamentally limited by external tools. In this work, we introduce Monet, a training framework that enables multimodal large language models (MLLMs) to reason directly within the latent visual space by generating continuous embeddings that function as intermediate visual thoughts. We identify two core challenges in training MLLMs for latent visual reasoning: high computational cost in latent-vision alignment and insufficient supervision over latent embeddings, and address them with a three-stage distillation-based supervised fine-tuning (SFT) pipeline. We further reveal a limitation of applying GRPO to latent reasoning: it primarily enhances text-based reasoning rather than latent reasoning. To overcome this, we propose VLPO (Visual-latent Policy Optimization), a reinforcement learning method that explicitly incorporates latent embeddings into policy gradient updates. To support SFT, we construct Monet-SFT-125K, a high-quality text-image interleaved CoT dataset containing 125K real-world, chart, OCR, and geometry CoTs. Our model, Monet-7B, shows consistent gains across real-world perception and reasoning benchmarks and exhibits strong out-of-distribution generalization on challenging abstract visual reasoning tasks. We also empirically analyze the role of each training component and discuss our early unsuccessful attempts, providing insights for future developments in visual latent reasoning. Our model, data, and code are available at https://github.com/NOVAglow646/Monet.","authors":["Qixun Wang","Yang Shi","Yifei Wang","Yuanxing Zhang","Pengfei Wan","Kun Gai","Xianghua Ying","Yisen Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21394v1","updated":"2025-11-26T13:45:10Z","published":"2025-11-26T13:45:10Z","title":"RIA: A Ranking-Infused Approach for Optimized listwise CTR Prediction","summary":"Reranking improves recommendation quality by modeling item interactions. However, existing methods often decouple ranking and reranking, leading to weak listwise evaluation models that suffer from combinatorial sparsity and limited representational power under strict latency constraints. In this paper, we propose RIA (Ranking-Infused Architecture), a unified, end-to-end framework that seamlessly integrates pointwise and listwise evaluation. RIA introduces four key components: (1) the User and Candidate DualTransformer (UCDT) for fine-grained user-item-context modeling; (2) the Context-aware User History and Target (CUHT) module for position-sensitive preference learning; (3) the Listwise Multi-HSTU (LMH) module to capture hierarchical item dependencies; and (4) the Embedding Cache (EC) module to bridge efficiency and effectiveness during inference. By sharing representations across ranking and reranking, RIA enables rich contextual knowledge transfer while maintaining low latency. Extensive experiments show that RIA outperforms state-of-the-art models on both public and industrial datasets, achieving significant gains in AUC and LogLoss. Deployed in Meituan advertising system, RIA yields a +1.69% improvement in Click-Through Rate (CTR) and a +4.54% increase in Cost Per Mille (CPM) in online A/B tests.","authors":["Guoxiao Zhang","Tan Qu","Ao Li","DongLin Ni","Qianlong Xie","Xingxing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21389v1","updated":"2025-11-26T13:38:19Z","published":"2025-11-26T13:38:19Z","title":"FITRep: Attention-Guided Item Representation via MLLMs","summary":"Online platforms usually suffer from user experience degradation due to near-duplicate items with similar visuals and text. While Multimodal Large Language Models (MLLMs) enable multimodal embedding, existing methods treat representations as black boxes, ignoring structural relationships (e.g., primary vs. auxiliary elements), leading to local structural collapse problem. To address this, inspired by Feature Integration Theory (FIT), we propose FITRep, the first attention-guided, white-box item representation framework for fine-grained item deduplication. FITRep consists of: (1) Concept Hierarchical Information Extraction (CHIE), using MLLMs to extract hierarchical semantic concepts; (2) Structure-Preserving Dimensionality Reduction (SPDR), an adaptive UMAP-based method for efficient information compression; and (3) FAISS-Based Clustering (FBC), a FAISS-based clustering that assigns each item a unique cluster id using FAISS. Deployed on Meituan's advertising system, FITRep achieves +3.60% CTR and +4.25% CPM gains in online A/B tests, demonstrating both effectiveness and real-world impact.","authors":["Guoxiao Zhang","Ao Li","Tan Qu","Qianlong Xie","Xingxing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21378v1","updated":"2025-11-26T13:25:36Z","published":"2025-11-26T13:25:36Z","title":"Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data","summary":"Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare.","authors":["Jungi Lee","Jungkwon Kim","Chi Zhang","Kwangsun Yoo","Seok-Joo Byun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.17464v2","updated":"2025-11-26T13:13:09Z","published":"2024-05-23T08:58:08Z","title":"Data Valuation by Fusing Global and Local Statistical Information","summary":"Data valuation has garnered increasing attention in recent years, given the critical role of high-quality data in various applications. Among diverse data valuation approaches, Shapley value-based methods are predominant due to their strong theoretical grounding. However, the exact computation of Shapley values is often computationally prohibitive, prompting the development of numerous approximation techniques. Despite notable advancements, existing methods generally neglect the incorporation of value distribution information and fail to account for dynamic data conditions, thereby compromising their performance and application potential. In this paper, we highlight the crucial role of both global and local statistical properties of value distributions in the context of data valuation for machine learning. First, we conduct a comprehensive analysis of these distributions across various simulated and real-world datasets, uncovering valuable insights and key patterns. Second, we propose an enhanced data valuation method that fuses the explored distribution characteristics into two regularization terms to refine Shapley value estimation. The proposed regularizers can be seamlessly incorporated into various existing data valuation methods. Third, we introduce a novel approach for dynamic data valuation that infers updated data values without recomputing Shapley values, thereby significantly improving computational efficiency. Extensive experiments have been conducted across a range of tasks, including Shapley value estimation, value-based data addition and removal, mislabeled data detection, and dynamic data valuation. The results showcase the consistent effectiveness and efficiency of our proposed methodologies, affirming the significant potential of global and local value distributions in data valuation.","authors":["Xiaoling Zhou","Ou Wu","Michael K. Ng","Hao Jiang"],"pdf_url":"","comment":"35 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.21363v1","updated":"2025-11-26T13:11:42Z","published":"2025-11-26T13:11:42Z","title":"The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods","summary":"The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes.","authors":["Kevin Iselborn","David Dembinsky","Adriano Lucieri","Andreas Dengel"],"pdf_url":"","comment":"13 pages, 10 figures, 5 tables, accepted at AAAI SECURE-AI4H workshop"},{"id":"http://arxiv.org/abs/2511.21356v1","updated":"2025-11-26T13:04:24Z","published":"2025-11-26T13:04:24Z","title":"Hybrid-AIRL: Enhancing Inverse Reinforcement Learning with Supervised Expert Guidance","summary":"Adversarial Inverse Reinforcement Learning (AIRL) has shown promise in addressing the sparse reward problem in reinforcement learning (RL) by inferring dense reward functions from expert demonstrations. However, its performance in highly complex, imperfect-information settings remains largely unexplored. To explore this gap, we evaluate AIRL in the context of Heads-Up Limit Hold'em (HULHE) poker, a domain characterized by sparse, delayed rewards and significant uncertainty. In this setting, we find that AIRL struggles to infer a sufficiently informative reward function. To overcome this limitation, we contribute Hybrid-AIRL (H-AIRL), an extension that enhances reward inference and policy learning by incorporating a supervised loss derived from expert data and a stochastic regularization mechanism. We evaluate H-AIRL on a carefully selected set of Gymnasium benchmarks and the HULHE poker setting. Additionally, we analyze the learned reward function through visualization to gain deeper insights into the learning process. Our experimental results show that H-AIRL achieves higher sample efficiency and more stable learning compared to AIRL. This highlights the benefits of incorporating supervised signals into inverse RL and establishes H-AIRL as a promising framework for tackling challenging, real-world settings.","authors":["Bram Silue","Santiago Amaya-Corredor","Patrick Mannion","Lander Willem","Pieter Libin"],"pdf_url":"","comment":"Comments: 13 pages, 5 figures, 1 table. Code: https://github.com/silue-dev/hairl. Submitted to ESANN 2026"},{"id":"http://arxiv.org/abs/2511.21342v1","updated":"2025-11-26T12:49:35Z","published":"2025-11-26T12:49:35Z","title":"Generating Separated Singing Vocals Using a Diffusion Model Conditioned on Music Mixtures","summary":"Separating the individual elements in a musical mixture is an essential process for music analysis and practice. While this is generally addressed using neural networks optimized to mask or transform the time-frequency representation of a mixture to extract the target sources, the flexibility and generalization capabilities of generative diffusion models are giving rise to a novel class of solutions for this complicated task. In this work, we explore singing voice separation from real music recordings using a diffusion model which is trained to generate the solo vocals conditioned on the corresponding mixture. Our approach improves upon prior generative systems and achieves competitive objective scores against non-generative baselines when trained with supplementary data. The iterative nature of diffusion sampling enables the user to control the quality-efficiency trade-off, and also refine the output when needed. We present an ablation study of the sampling algorithm, highlighting the effects of the user-configurable parameters.","authors":["Genís Plaja-Roglans","Yun-Ning Hung","Xavier Serra","Igor Pereira"],"pdf_url":"","comment":"Accepted for publication at WASPAA 2025"},{"id":"http://arxiv.org/abs/2511.21339v1","updated":"2025-11-26T12:44:51Z","published":"2025-11-26T12:44:51Z","title":"SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding","summary":"Recent advances in multimodal large language models (LLMs) have highlighted their potential for medical and surgical applications. However, existing surgical datasets predominantly adopt a Visual Question Answering (VQA) format with heterogeneous taxonomies and lack support for pixel-level segmentation, limiting consistent evaluation and applicability. We present SurgMLLMBench, a unified multimodal benchmark explicitly designed for developing and evaluating interactive multimodal LLMs for surgical scene understanding, including the newly collected Micro-surgical Artificial Vascular anastomosIS (MAVIS) dataset. It integrates pixel-level instrument segmentation masks and structured VQA annotations across laparoscopic, robot-assisted, and micro-surgical domains under a unified taxonomy, enabling comprehensive evaluation beyond traditional VQA tasks and richer visual-conversational interactions. Extensive baseline experiments show that a single model trained on SurgMLLMBench achieves consistent performance across domains and generalizes effectively to unseen datasets. SurgMLLMBench will be publicly released as a robust resource to advance multimodal surgical AI research, supporting reproducible evaluation and development of interactive surgical reasoning models.","authors":["Tae-Min Choi","Tae Kyeong Jeong","Garam Kim","Jaemin Lee","Yeongyoon Koh","In Cheul Choi","Jae-Ho Chung","Jong Woong Park","Juyoun Park"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.21337v1","updated":"2025-11-26T12:40:18Z","published":"2025-11-26T12:40:18Z","title":"Hybrid SIFT-SNN for Efficient Anomaly Detection of Traffic Flow-Control Infrastructure","summary":"This paper presents the SIFT-SNN framework, a low-latency neuromorphic signal-processing pipeline for real-time detection of structural anomalies in transport infrastructure. The proposed approach integrates Scale-Invariant Feature Transform (SIFT) for spatial feature encoding with a latency-driven spike conversion layer and a Leaky Integrate-and-Fire (LIF) Spiking Neural Network (SNN) for classification. The Auckland Harbour Bridge dataset is recorded under various weather and lighting conditions, comprising 6,000 labelled frames that include both real and synthetically augmented unsafe cases. The presented system achieves a classification accuracy of 92.3% (+- 0.8%) with a per-frame inference time of 9.5 ms. Achieved sub-10 millisecond latency, combined with sparse spike activity (8.1%), enables real-time, low-power edge deployment. Unlike conventional CNN-based approaches, the hybrid SIFT-SNN pipeline explicitly preserves spatial feature grounding, enhances interpretability, supports transparent decision-making, and operates efficiently on embedded hardware. Although synthetic augmentation improved robustness, generalisation to unseen field conditions remains to be validated. The SIFT-SNN framework is validated through a working prototype deployed on a consumer-grade system and framed as a generalisable case study in structural safety monitoring for movable concrete barriers, which, as a traffic flow-control infrastructure, is deployed in over 20 cities worldwide.","authors":["Munish Rathee","Boris Bačić","Maryam Doborjeh"],"pdf_url":"","comment":"8 pages, 6 figures. This is a preprint of a paper accepted for presentation at the 2025 International Conference on Image and Vision Computing New Zealand (IVCNZ). The final version will appear in IEEE Xplore"},{"id":"http://arxiv.org/abs/2505.21426v2","updated":"2025-11-26T12:37:43Z","published":"2025-05-27T16:55:56Z","title":"Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks","summary":"Agent-Based Models (ABMs) are powerful tools for studying emergent properties in complex systems. In ABMs, agent behaviors are governed by local interactions and stochastic rules. However, these rules are, in general, non-differentiable, limiting the use of gradient-based methods for optimization, and thus integration with real-world data. We propose a novel framework to learn a differentiable surrogate of any ABM by observing its generated data. Our method combines diffusion models to capture behavioral stochasticity and graph neural networks to model agent interactions. Distinct from prior surrogate approaches, our method introduces a fundamental shift: rather than approximating system-level outputs, it models individual agent behavior directly, preserving the decentralized, bottom-up dynamics that define ABMs. We validate our approach on two ABMs (Schelling's segregation model and a Predator-Prey ecosystem) showing that it replicates individual-level patterns and accurately forecasts emergent dynamics beyond training. Our results demonstrate the potential of combining diffusion models and graph learning for data-driven ABM simulation.","authors":["Francesco Cozzi","Marco Pangallo","Alan Perotti","André Panisson","Corrado Monti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21331v1","updated":"2025-11-26T12:25:55Z","published":"2025-11-26T12:25:55Z","title":"The More, the Merrier: Contrastive Fusion for Higher-Order Multimodal Alignment","summary":"Learning joint representations across multiple modalities remains a central challenge in multimodal machine learning. Prevailing approaches predominantly operate in pairwise settings, aligning two modalities at a time. While some recent methods aim to capture higher-order interactions among multiple modalities, they often overlook or insufficiently preserve pairwise relationships, limiting their effectiveness on single-modality tasks. In this work, we introduce Contrastive Fusion (ConFu), a framework that jointly embeds both individual modalities and their fused combinations into a unified representation space, where modalities and their fused counterparts are aligned. ConFu extends traditional pairwise contrastive objectives with an additional fused-modality contrastive term, encouraging the joint embedding of modality pairs with a third modality. This formulation enables ConFu to capture higher-order dependencies, such as XOR-like relationships, that cannot be recovered through pairwise alignment alone, while still maintaining strong pairwise correspondence. We evaluate ConFu on synthetic and real-world multimodal benchmarks, assessing its ability to exploit cross-modal complementarity, capture higher-order dependencies, and scale with increasing multimodal complexity. Across these settings, ConFu demonstrates competitive performance on retrieval and classification tasks, while supporting unified one-to-one and two-to-one retrieval within a single contrastive framework.","authors":["Stefanos Koutoupis","Michaela Areti Zervou","Konstantinos Kontras","Maarten De Vos","Panagiotis Tsakalides","Grigorios Tsagatakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15703v2","updated":"2025-11-26T12:23:11Z","published":"2025-11-19T18:59:04Z","title":"Think Visually, Reason Textually: Vision-Language Synergy in ARC","summary":"Abstract reasoning from minimal examples remains a core unsolved problem for frontier foundation models such as GPT-5 and Grok 4. These models still fail to infer structured transformation rules from a handful of examples, which is a key hallmark of human intelligence. The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) provides a rigorous testbed for this capability, demanding conceptual rule induction and transfer to novel tasks. Most existing methods treat ARC-AGI as a purely textual reasoning task, overlooking the fact that humans rely heavily on visual abstraction when solving such puzzles. However, our pilot experiments reveal a paradox: naively rendering ARC-AGI grids as images degrades performance due to imprecise rule execution. This leads to our central hypothesis that vision and language possess complementary strengths across distinct reasoning stages: vision supports global pattern abstraction and verification, whereas language specializes in symbolic rule formulation and precise execution. Building on this insight, we introduce two synergistic strategies: (1) Vision-Language Synergy Reasoning (VLSR), which decomposes ARC-AGI into modality-aligned subtasks; and (2) Modality-Switch Self-Correction (MSSC), which leverages vision to verify text-based reasoning for intrinsic error correction. Extensive experiments demonstrate that our approach yields up to a 4.33\\% improvement over text-only baselines across diverse flagship models and multiple ARC-AGI tasks. Our findings suggest that unifying visual abstraction with linguistic reasoning is a crucial step toward achieving generalizable, human-like intelligence in future foundation models. Source code is released at https://github.com/InternLM/ARC-VL.","authors":["Beichen Zhang","Yuhang Zang","Xiaoyi Dong","Yuhang Cao","Haodong Duan","Dahua Lin","Jiaqi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21325v1","updated":"2025-11-26T12:16:38Z","published":"2025-11-26T12:16:38Z","title":"SONAR: Spectral-Contrastive Audio Residuals for Generalizable Deepfake Detection","summary":"Deepfake (DF) audio detectors still struggle to generalize to out of distribution inputs. A central reason is spectral bias, the tendency of neural networks to learn low-frequency structure before high-frequency (HF) details, which both causes DF generators to leave HF artifacts and leaves those same artifacts under-exploited by common detectors. To address this gap, we propose Spectral-cONtrastive Audio Residuals (SONAR), a frequency-guided framework that explicitly disentangles an audio signal into complementary representations. An XLSR encoder captures the dominant low-frequency content, while the same cloned path, preceded by learnable SRM, value-constrained high-pass filters, distills faint HF residuals. Frequency cross-attention reunites the two views for long- and short-range frequency dependencies, and a frequency-aware Jensen-Shannon contrastive loss pulls real content-noise pairs together while pushing fake embeddings apart, accelerating optimization and sharpening decision boundaries. Evaluated on the ASVspoof 2021 and in-the-wild benchmarks, SONAR attains state-of-the-art performance and converges four times faster than strong baselines. By elevating faint high-frequency residuals to first-class learning signals, SONAR unveils a fully data-driven, frequency-guided contrastive framework that splits the latent space into two disjoint manifolds: natural-HF for genuine audio and distorted-HF for synthetic audio, thereby sharpening decision boundaries. Because the scheme operates purely at the representation level, it is architecture-agnostic and, in future work, can be seamlessly integrated into any model or modality where subtle high-frequency cues are decisive.","authors":["Ido Nitzan HIdekel","Gal lifshitz","Khen Cohen","Dan Raviv"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21322v1","updated":"2025-11-26T12:07:32Z","published":"2025-11-26T12:07:32Z","title":"TALES: A Taxonomy and Analysis of Cultural Representations in LLM-generated Stories","summary":"Millions of users across the globe turn to AI chatbots for their creative needs, inviting widespread interest in understanding how such chatbots represent diverse cultures. At the same time, evaluating cultural representations in open-ended tasks remains challenging and underexplored. In this work, we present TALES, an evaluation of cultural misrepresentations in LLM-generated stories for diverse Indian cultural identities. First, we develop TALES-Tax, a taxonomy of cultural misrepresentations by collating insights from participants with lived experiences in India through focus groups (N=9) and individual surveys (N=15). Using TALES-Tax, we evaluate 6 models through a large-scale annotation study spanning 2,925 annotations from 108 annotators with lived cultural experience from across 71 regions in India and 14 languages. Concerningly, we find that 88\\% of the generated stories contain one or more cultural inaccuracies, and such errors are more prevalent in mid- and low-resourced languages and stories based in peri-urban regions in India. Lastly, we transform the annotations into TALES-QA, a standalone question bank to evaluate the cultural knowledge of foundational models. Through this evaluation, we surprisingly discover that models often possess the requisite cultural knowledge despite generating stories rife with cultural misrepresentations.","authors":["Kirti Bhagat","Shaily Bhatt","Athul Velagapudi","Aditya Vashistha","Shachi Dave","Danish Pruthi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06998v2","updated":"2025-11-26T11:47:20Z","published":"2025-09-04T17:52:22Z","title":"Not All Splits Are Equal: Rethinking Attribute Generalization Across Unrelated Categories","summary":"Can models generalize attribute knowledge across semantically and perceptually dissimilar categories? While prior work has addressed attribute prediction within narrow taxonomic or visually similar domains, it remains unclear whether current models can abstract attributes and apply them to conceptually distant categories. This work presents the first explicit evaluation for the robustness of the attribute prediction task under such conditions, testing whether models can correctly infer shared attributes between unrelated object types: e.g., identifying that the attribute \"has four legs\" is common to both \"dogs\" and \"chairs\". To enable this evaluation, we introduce train-test split strategies that progressively reduce correlation between training and test sets, based on: LLM-driven semantic grouping, embedding similarity thresholding, embedding-based clustering, and supercategory-based partitioning using ground-truth labels. Results show a sharp drop in performance as the correlation between training and test categories decreases, indicating strong sensitivity to split design. Among the evaluated methods, clustering yields the most effective trade-off, reducing hidden correlations while preserving learnability. These findings offer new insights into the limitations of current representations and inform future benchmark construction for attribute reasoning.","authors":["Liviu Nicolae Fircă","Antonio Bărbălau","Dan Oneata","Elena Burceanu"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 Workshop: CauScien - Uncovering Causality in Science and NeurIPS 2025 Workshop: Reliable ML from Unreliable Data"},{"id":"http://arxiv.org/abs/2510.07858v2","updated":"2025-11-26T11:39:28Z","published":"2025-10-09T06:59:15Z","title":"Augur: Modeling Covariate Causal Associations in Time Series via Large Language Models","summary":"Large language models (LLM) have emerged as a promising avenue for time series forecasting, offering the potential to integrate multimodal data. However, existing LLM-based approaches face notable limitations-such as marginalized role in model architectures, reliance on coarse statistical text prompts, and lack of interpretability. In this work, we introduce Augur, a fully LLM driven time series forecasting framework that exploits LLM causal reasoning to discover and use directed causal associations among covariates. Augur uses a two stage teacher student architecture where a powerful teacher LLM infers a directed causal graph from time series using heuristic search together with pairwise causality testing. A lightweight student agent then refines the graph and fine tune on high confidence causal associations that are encoded as rich textual prompts to perform forecasting. This design improves predictive accuracy while yielding transparent, traceable reasoning about variable interactions. Extensive experiments on real-world datasets with 26 baselines demonstrate that Augur achieves competitive performance and robust zero-shot generalization.","authors":["Zhiqing Cui","Binwu Wang","Qingxiang Liu","Yeqiang Wang","Zhengyang Zhou","Yuxuan Liang","Yang Wang"],"pdf_url":"","comment":"24 pages, 9 figures"},{"id":"http://arxiv.org/abs/2502.11381v5","updated":"2025-11-26T11:30:37Z","published":"2025-02-17T02:53:08Z","title":"Without Paired Labeled Data: End-to-End Self-Supervised Learning for Drone-view Geo-Localization","summary":"Drone-view Geo-Localization (DVGL) aims to achieve accurate localization of drones by retrieving the most relevant GPS-tagged satellite images. However, most existing methods heavily rely on strictly pre-paired drone-satellite images for supervised learning. When the target region shifts, new paired samples are typically required to adapt to the distribution changes. The high cost of annotation and the limited transferability of these methods significantly hinder the practical deployment of DVGL in open-world scenarios. To address these limitations, we propose a novel end-to-end self-supervised learning method with a shallow backbone network, called the dynamic memory-driven and neighborhood information learning (DMNIL) method. It employs a clustering algorithm to generate pseudo-labels and adopts a dual-path contrastive learning framework to learn discriminative intra-view representations. Furthermore, DMNIL incorporates two core modules, including the dynamic hierarchical memory learning (DHML) module and the information consistency evolution learning (ICEL) module. The DHML module combines short-term and long-term memory to enhance intra-view feature consistency and discriminability. Meanwhile, the ICEL module utilizes a neighborhood-driven dynamic constraint mechanism to systematically capture implicit cross-view semantic correlations, consequently improving cross-view feature alignment. To further stabilize and strengthen the self-supervised training process, a pseudo-label enhancement strategy is introduced to enhance the quality of pseudo supervision. Extensive experiments on three public benchmark datasets demonstrate that the proposed method consistently outperforms existing self-supervised methods and even surpasses several state-of-the-art supervised methods. Our code is available at https://github.com/ISChenawei/DMNIL.","authors":["Zhongwei Chen","Zhao-Xu Yang","Hai-Jun Rong","Guoqi Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21280v1","updated":"2025-11-26T11:11:59Z","published":"2025-11-26T11:11:59Z","title":"Improvement of Collision Avoidance in Cut-In Maneuvers Using Time-to-Collision Metrics","summary":"This paper proposes a new strategy for collision avoidance system leveraging Time-to-Collision (TTC) metrics for handling cut-in scenarios, which are particularly challenging for autonomous vehicles (AVs). By integrating a deep learning with TTC calculations, the system predicts potential collisions and determines appropriate evasive actions compared to traditional TTC -based approaches.","authors":["Jamal Raiyn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2208.10431v3","updated":"2025-11-26T11:00:22Z","published":"2022-08-22T16:36:32Z","title":"ProtoPFormer: Concentrating on Prototypical Parts in Vision Transformers for Interpretable Image Recognition","summary":"Prototypical part network (ProtoPNet) has drawn wide attention and boosted many follow-up studies due to its self-explanatory property for explainable artificial intelligence (XAI). However, when directly applying ProtoPNet on vision transformer (ViT) backbones, learned prototypes have a \"distraction\" problem: they have a relatively high probability of being activated by the background and pay less attention to the foreground. The powerful capability of modeling long-term dependency makes the transformer-based ProtoPNet hard to focus on prototypical parts, thus severely impairing its inherent interpretability. This paper proposes prototypical part transformer (ProtoPFormer) for appropriately and effectively applying the prototype-based method with ViTs for interpretable image recognition. The proposed method introduces global and local prototypes for capturing and highlighting the representative holistic and partial features of targets according to the architectural characteristics of ViTs. The global prototypes are adopted to provide the global view of objects to guide local prototypes to concentrate on the foreground while eliminating the influence of the background. Afterwards, local prototypes are explicitly supervised to concentrate on their respective prototypical visual parts, increasing the overall interpretability. Extensive experiments demonstrate that our proposed global and local prototypes can mutually correct each other and jointly make final decisions, which faithfully and transparently reason the decision-making processes associatively from the whole and local perspectives, respectively. Moreover, ProtoPFormer consistently achieves superior performance and visualization results over the state-of-the-art (SOTA) prototype-based baselines. Our code has been released at https://github.com/zju-vipa/ProtoPFormer.","authors":["Mengqi Xue","Qihan Huang","Haofei Zhang","Jingwen Hu","Jie Song","Mingli Song","Canghong Jin"],"pdf_url":"","comment":"Arxiv preprint; 18 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2504.02890v2","updated":"2025-11-26T10:42:39Z","published":"2025-04-02T16:58:36Z","title":"Reasoning Transfer for an Extremely Low-Resource and Endangered Language: Bridging Languages Through Sample-Efficient Language Understanding","summary":"Recent advances have enabled Large Language Models (LLMs) to tackle reasoning tasks by generating chain-of-thought (CoT) rationales, yet these gains have largely applied to high-resource languages, leaving low-resource languages behind. In this work, we first investigate CoT techniques in extremely low-resource scenarios through previous prompting, model-editing, and fine-tuning approaches. We introduce English-Pivoted CoT Training, leveraging the insight that LLMs internally operate in a latent space aligned toward the dominant language. Given input in a low-resource language, we perform supervised fine-tuning to generate CoT in English and output the final response in the target language. Across mathematical reasoning benchmarks, our approach outperforms other baselines with up to 28.33% improvement in low-resource scenarios. Our analysis and additional experiments, including Mixed-Language CoT and Two-Stage Training, show that explicitly separating language understanding from reasoning enhances cross-lingual reasoning abilities. To facilitate future work, we also release \\emph{LC2024}, the first benchmark for mathematical tasks in Irish, an extremely low-resource and endangered language. Our results and resources highlight a practical pathway to multilingual reasoning without extensive retraining in every extremely low-resource language, despite data scarcity.","authors":["Khanh-Tung Tran","Barry O'Sullivan","Hoang D. Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21260v1","updated":"2025-11-26T10:41:25Z","published":"2025-11-26T10:41:25Z","title":"Causality Without Causal Models","summary":"Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models. \n","authors":["Joseph Y. Halpern","Rafael Pass"],"pdf_url":"","comment":"In Proceedings TARK 2025, arXiv:2511.20540"},{"id":"http://arxiv.org/abs/2505.20278v2","updated":"2025-11-26T10:25:27Z","published":"2025-05-26T17:55:15Z","title":"Characterizing Pattern Matching and Its Limits on Compositional Task Structures","summary":"Despite impressive capabilities, LLMs' successes often rely on pattern-matching behaviors, yet these are also linked to OOD generalization failures in compositional tasks. However, behavioral studies commonly employ task setups that allow multiple generalization sources (e.g., algebraic invariances, structural repetition), obscuring a precise and testable account of how well LLMs perform generalization through pattern matching and their limitations. To address this ambiguity, we first formalize pattern matching as functional equivalence, i.e., identifying pairs of subsequences of inputs that consistently lead to identical results when the rest of the input is held constant. Then, we systematically study how decoder-only Transformer and Mamba behave in controlled tasks with compositional structures that isolate this mechanism. Our formalism yields predictive and quantitative insights: (1) Instance-wise success of pattern matching is well predicted by the number of contexts witnessing the relevant functional equivalence. (2) We prove a tight sample complexity bound of learning a two-hop structure by identifying the exponent of the data scaling law for perfect in-domain generalization. Our empirical results align with the theoretical prediction, under 20x parameter scaling and across architectures. (3) Path ambiguity is a structural barrier: when a variable influences the output via multiple paths, models fail to form unified intermediate state representations, impairing accuracy and interpretability. (4) Chain-of-Thought reduces data requirements yet does not resolve path ambiguity. Hence, we provide a predictive, falsifiable boundary for pattern matching and a foundational diagnostic for disentangling mixed generalization mechanisms.","authors":["Hoyeon Chang","Jinho Park","Hanseul Cho","Sohee Yang","Miyoung Ko","Hyeonbin Hwang","Seungpil Won","Dohaeng Lee","Youbin Ahn","Minjoon Seo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17041v2","updated":"2025-11-26T10:10:35Z","published":"2025-11-21T08:37:39Z","title":"CLLMRec: LLM-powered Cognitive-Aware Concept Recommendation via Semantic Alignment and Prerequisite Knowledge Distillation","summary":"The growth of Massive Open Online Courses (MOOCs) presents significant challenges for personalized learning, where concept recommendation is crucial. Existing approaches typically rely on heterogeneous information networks or knowledge graphs to capture conceptual relationships, combined with knowledge tracing models to assess learners' cognitive states. However, these methods face significant limitations due to their dependence on high-quality structured knowledge graphs, which are often scarce in real-world educational scenarios. To address this fundamental challenge, this paper proposes CLLMRec, a novel framework that leverages Large Language Models through two synergistic technical pillars: Semantic Alignment and Prerequisite Knowledge Distillation. The Semantic Alignment component constructs a unified representation space by encoding unstructured textual descriptions of learners and concepts. The Prerequisite Knowledge Distillation paradigm employs a teacher-student architecture, where a large teacher LLM (implemented as the Prior Knowledge Aware Component) extracts conceptual prerequisite relationships from its internalized world knowledge and distills them into soft labels to train an efficient student ranker. Building upon these foundations, our framework incorporates a fine-ranking mechanism that explicitly models learners' real-time cognitive states through deep knowledge tracing, ensuring recommendations are both structurally sound and cognitively appropriate. Extensive experiments on two real-world MOOC datasets demonstrate that CLLMRec significantly outperforms existing baseline methods across multiple evaluation metrics, validating its effectiveness in generating truly cognitive-aware and personalized concept recommendations without relying on explicit structural priors.","authors":["Xiangrui Xiong","Yichuan Lu","Zifei Pan","Chang Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.22665v2","updated":"2025-11-26T10:05:38Z","published":"2025-10-26T13:04:50Z","title":"SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery","summary":"Synthetic Aperture Radar (SAR) is a crucial imaging modality thanks to its all-weather capability. Although recent advances in self-supervised learning and masked image modeling (MIM) have enabled SAR foundation models, these methods largely emphasize low-level visual features and often overlook multimodal alignment and zero-shot target recognition in SAR imagery. To address this, we construct SARVLM-1M, a large-scale vision-language dataset with over one million image-text pairs aggregated from existing datasets. We further propose a domain transfer training strategy to mitigate the large gap between natural and SAR imagery. Building on this, we develop SARVLM, the first vision language foundation model (VLM) tailored to SAR, comprising SARCLIP and SARCap. SARVLM is trained with a vision-language contrastive objective under the proposed domain transfer strategy, bridging SAR imagery and textual descriptions. Extensive experiments on image text retrieval, zero-shot classification, semantic localization, and imagery captioning demonstrate that SARVLM delivers superior feature extraction and interpretation, outperforming state-of-the-art VLMs and advancing SAR semantic understanding. Code and datasets will be released soon.","authors":["Qiwei Ma","Zhiyu Wang","Wang Liu","Xukun Lu","Bin Deng","Puhong Duan","Xudong Kang","Shutao Li"],"pdf_url":"","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2511.20586v2","updated":"2025-11-26T09:59:52Z","published":"2025-11-25T18:15:36Z","title":"PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic","summary":"Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the Parallel Trust Assessment System (PaTAS), a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through Trust Nodes and Trust Functions that propagate input, parameter, and activation trust across the network. The framework defines a Parameter Trust Update mechanism to refine parameter reliability during training and an Inference-Path Trust Assessment (IPTA) method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.","authors":["Koffi Ismael Ouattara","Ioannis Krontiris","Theo Dimitrakos","Dennis Eisermann","Frank Kargl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21214v1","updated":"2025-11-26T09:44:32Z","published":"2025-11-26T09:44:32Z","title":"Self-Guided Defense: Adaptive Safety Alignment for Reasoning Models via Synthesized Guidelines","summary":"Reasoning models have demonstrated remarkable capabilities in complex reasoning tasks. However, ensuring their safety against adversarial jailbreak prompts remains a critical challenge. Due to the covert and deceptive nature of such prompts, they can often evade built-in safety mechanisms and lead to the generation of harmful content. This underscores the need for an adaptive safety alignment approach that enables models to autonomously reinforce their defenses in response to adversarial inputs. This paper introduces the Synthesized Guideline-based Adaptive Safety Alignment (SGASA) framework, which internalizes model-generated safety guidelines to strengthen models' ability to enhance robustness against harmful adversarial prompts while minimizing unnecessary refusals of benign requests. SGASA consists of two key stages: Data Pre-synthesis, which generates safety guidelines and augmented prompts; and Alignment Fine-tuning, which leverages Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO) to embed these guidelines into the model. Extensive experiments across multiple datasets demonstrate that SGASA significantly improves model safety, validating its adaptive and scalable effectiveness.","authors":["Yuhang Wang","Yanxu Zhu","Dongyuan Lu","Jitao Sang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18866v3","updated":"2025-11-26T09:32:08Z","published":"2025-10-21T17:58:17Z","title":"LightMem: Lightweight and Efficient Memory-Augmented Generation","summary":"Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at https://github.com/zjunlp/LightMem.","authors":["Jizhan Fang","Xinle Deng","Haoming Xu","Ziyan Jiang","Yuqi Tang","Ziwen Xu","Shumin Deng","Yunzhi Yao","Mengru Wang","Shuofei Qiao","Huajun Chen","Ningyu Zhang"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2511.19858v2","updated":"2025-11-26T09:29:37Z","published":"2025-11-25T02:40:49Z","title":"A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction","summary":"Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.\n  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.\n  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.\n  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.","authors":["Farzad Ahmed","Joniel Augustine Jerome","Meliha Yetisgen","Özlem Uzuner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.15041v2","updated":"2025-11-26T09:25:45Z","published":"2024-08-27T13:10:26Z","title":"Earth Observation Satellite Scheduling with Graph Neural Networks and Monte Carlo Tree Search","summary":"Earth Observation Satellite Planning (EOSP) is a difficult optimization problem with considerable practical interest. A set of requested observations must be scheduled on an agile Earth observation satellite while respecting constraints on their visibility window, as well as maneuver constraints that impose varying delays between successive observations. In addition, the problem is largely oversubscribed: there are much more candidate observations than can possibly be achieved. Therefore, one must select the set of observations that will be performed while maximizing their cumulative benefit and propose a feasible schedule for these observations. As previous work mostly focused on heuristic and iterative search algorithms, this paper presents a new technique for selecting and scheduling observations based on Graph Neural Networks (GNNs) and Deep Reinforcement Learning (DRL). GNNs are used to extract relevant information from the graphs representing instances of the EOSP, and DRL drives the search for optimal schedules. A post-learning search step based on Monte Carlo Tree Search (MCTS) is added that is able to find even better solutions. Experiments show that it is able to learn on small problem instances and generalize to larger real-world instances, with very competitive performance compared to traditional approaches.","authors":["Antoine Jacquet","Guillaume Infantes","Emmanuel Benazera","Vincent Baudoui","Jonathan Guerra","Stéphanie Roussel"],"pdf_url":"","comment":"Accepted at International Workshop on Planning & Scheduling for Space (IWPSS 2025)"},{"id":"http://arxiv.org/abs/2511.21194v1","updated":"2025-11-26T09:19:06Z","published":"2025-11-26T09:19:06Z","title":"BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data","summary":"Foundation models have demonstrated a remarkable ability to learn rich, transferable representations across diverse modalities such as images, text, and audio. In modern machine learning pipelines, these representations often replace raw data as the primary input for downstream tasks. In this paper, we address the challenge of adapting a pre-trained foundation model to inject domain-specific knowledge, without retraining from scratch or incurring significant computational costs. To this end, we introduce BotaCLIP, a lightweight multimodal contrastive framework that adapts a pre-trained Earth Observation foundation model (DOFA) by aligning high-resolution aerial imagery with botanical relevés. Unlike generic embeddings, BotaCLIP internalizes ecological structure through contrastive learning with a regularization strategy that mitigates catastrophic forgetting. Once trained, the resulting embeddings serve as transferable representations for downstream predictors. Motivated by real-world applications in biodiversity modeling, we evaluated BotaCLIP representations in three ecological tasks: plant presence prediction, butterfly occurrence modeling, and soil trophic group abundance estimation. The results showed consistent improvements over those derived from DOFA and supervised baselines. More broadly, this work illustrates how domain-aware adaptation of foundation models can inject expert knowledge into data-scarce settings, enabling frugal representation learning.","authors":["Selene Cerna","Sara Si-Moussi","Wilfried Thuiller","Hadrien Hendrikx","Vincent Miele"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21192v1","updated":"2025-11-26T09:16:32Z","published":"2025-11-26T09:16:32Z","title":"When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models","summary":"Vision-Language-Action (VLA) models are vulnerable to adversarial attacks, yet universal and transferable attacks remain underexplored, as most existing patches overfit to a single model and fail in black-box settings. To address this gap, we present a systematic study of universal, transferable adversarial patches against VLA-driven robots under unknown architectures, finetuned variants, and sim-to-real shifts. We introduce UPA-RFAS (Universal Patch Attack via Robust Feature, Attention, and Semantics), a unified framework that learns a single physical patch in a shared feature space while promoting cross-model transfer. UPA-RFAS combines (i) a feature-space objective with an $\\ell_1$ deviation prior and repulsive InfoNCE loss to induce transferable representation shifts, (ii) a robustness-augmented two-phase min-max procedure where an inner loop learns invisible sample-wise perturbations and an outer loop optimizes the universal patch against this hardened neighborhood, and (iii) two VLA-specific losses: Patch Attention Dominance to hijack text$\\to$vision attention and Patch Semantic Misalignment to induce image-text mismatch without labels. Experiments across diverse VLA models, manipulation suites, and physical executions show that UPA-RFAS consistently transfers across models, tasks, and viewpoints, exposing a practical patch-based attack surface and establishing a strong baseline for future defenses.","authors":["Hui Lu","Yi Yu","Yiming Yang","Chenyu Yi","Qixin Zhang","Bingquan Shen","Alex C. Kot","Xudong Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20403v2","updated":"2025-11-26T09:14:17Z","published":"2025-11-25T15:33:00Z","title":"LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework","summary":"Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.","authors":["Andrea Lops","Fedelucio Narducci","Azzurra Ragone","Michelantonio Trizio","Claudio Bartolini"],"pdf_url":"","comment":"Accepted at 40th IEEE/ACM International Conference on Automated Software Engineering"},{"id":"http://arxiv.org/abs/2511.13802v2","updated":"2025-11-26T09:04:03Z","published":"2025-11-17T11:14:30Z","title":"Passive Dementia Screening via Facial Temporal Micro-Dynamics Analysis of In-the-Wild Talking-Head Video","summary":"We target passive dementia screening from short camera-facing talking head video, developing a facial temporal micro dynamics analysis for language free detection of early neuro cognitive change. This enables unscripted, in the wild video analysis at scale to capture natural facial behaviors, transferrable across devices, topics, and cultures without active intervention by clinicians or researchers during recording. Most existing resources prioritize speech or scripted interviews, limiting use outside clinics and coupling predictions to language and transcription. In contrast, we identify and analyze whether temporal facial kinematics, including blink dynamics, small mouth jaw motions, gaze variability, and subtle head adjustments, are sufficient for dementia screening without speech or text. By stabilizing facial signals, we convert these micro movements into interpretable facial microdynamic time series, smooth them, and summarize short windows into compact clip level statistics for screening. Each window is encoded by its activity mix (the relative share of motion across streams), thus the predictor analyzes the distribution of motion across streams rather than its magnitude, making per channel effects transparent. We also introduce YT DemTalk, a new dataset curated from publicly available, in the wild camera facing videos. It contains 300 clips (150 with self reported dementia, 150 controls) to test our model and offer a first benchmarking of the corpus. On YT DemTalk, ablations identify gaze lability and mouth/jaw dynamics as the most informative cues, and light weighted shallow classifiers could attain a dementia prediction performance of (AUROC) 0.953, 0.961 Average Precision (AP), 0.851 F1-score, and 0.857 accuracy.","authors":["Filippo Cenacchi","Longbing Cao","Mitchell McEwan","Deborah Richards"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21185v1","updated":"2025-11-26T09:01:13Z","published":"2025-11-26T09:01:13Z","title":"Progress by Pieces: Test-Time Scaling for Autoregressive Image Generation","summary":"Recent visual autoregressive (AR) models have shown promising capabilities in text-to-image generation, operating in a manner similar to large language models. While test-time computation scaling has brought remarkable success in enabling reasoning-enhanced outputs for challenging natural language tasks, its adaptation to visual AR models remains unexplored and poses unique challenges. Naively applying test-time scaling strategies such as Best-of-N can be suboptimal: they consume full-length computation on erroneous generation trajectories, while the raster-scan decoding scheme lacks a blueprint of the entire canvas, limiting scaling benefits as only a few prompt-aligned candidates are generated. To address these, we introduce GridAR, a test-time scaling framework designed to elicit the best possible results from visual AR models. GridAR employs a grid-partitioned progressive generation scheme in which multiple partial candidates for the same position are generated within a canvas, infeasible ones are pruned early, and viable ones are fixed as anchors to guide subsequent decoding. Coupled with this, we present a layout-specified prompt reformulation strategy that inspects partial views to infer a feasible layout for satisfying the prompt. The reformulated prompt then guides subsequent image generation to mitigate the blueprint deficiency. Together, GridAR achieves higher-quality results under limited test-time scaling: with N=4, it even outperforms Best-of-N (N=8) by 14.4% on T2I-CompBench++ while reducing cost by 25.6%. It also generalizes to autoregressive image editing, showing comparable edit quality and a 13.9% gain in semantic preservation on PIE-Bench over larger-N baselines.","authors":["Joonhyung Park","Hyeongwon Jang","Joowon Kim","Eunho Yang"],"pdf_url":"","comment":"Project page: https://grid-ar.github.io/"},{"id":"http://arxiv.org/abs/2511.21181v1","updated":"2025-11-26T08:55:11Z","published":"2025-11-26T08:55:11Z","title":"Privacy in Federated Learning with Spiking Neural Networks","summary":"Spiking neural networks (SNNs) have emerged as prominent candidates for embedded and edge AI. Their inherent low power consumption makes them far more efficient than conventional ANNs in scenarios where energy budgets are tightly constrained. In parallel, federated learning (FL) has become the prevailing training paradigm in such settings, enabling on-device learning while limiting the exposure of raw data. However, gradient inversion attacks represent a critical privacy threat in FL, where sensitive training data can be reconstructed directly from shared gradients. While this vulnerability has been widely investigated in conventional ANNs, its implications for SNNs remain largely unexplored. In this work, we present the first comprehensive empirical study of gradient leakage in SNNs across diverse data domains. SNNs are inherently non-differentiable and are typically trained using surrogate gradients, which we hypothesized would be less correlated with the original input and thus less informative from a privacy perspective. To investigate this, we adapt different gradient leakage attacks to the spike domain. Our experiments reveal a striking contrast with conventional ANNs: whereas ANN gradients reliably expose salient input content, SNN gradients yield noisy, temporally inconsistent reconstructions that fail to recover meaningful spatial or temporal structure. These results indicate that the combination of event-driven dynamics and surrogate-gradient training substantially reduces gradient informativeness. To the best of our knowledge, this work provides the first systematic benchmark of gradient inversion attacks for spiking architectures, highlighting the inherent privacy-preserving potential of neuromorphic computation.","authors":["Dogukan Aksu","Jesus Martinez del Rincon","Ihsen Alouani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21180v1","updated":"2025-11-26T08:52:44Z","published":"2025-11-26T08:52:44Z","title":"CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion","summary":"Diffusion models exhibit notable fragility when faced with adversarial prompts, and strengthening attack capabilities is crucial for uncovering such vulnerabilities and building more robust generative systems. Existing works often rely on white-box access to model gradients or hand-crafted prompt engineering, which is infeasible in real-world deployments due to restricted access or poor attack effect. In this paper, we propose CAHS-Attack , a CLIP-Aware Heuristic Search attack method. CAHS-Attack integrates Monte Carlo Tree Search (MCTS) to perform fine-grained suffix optimization, leveraging a constrained genetic algorithm to preselect high-potential adversarial prompts as root nodes, and retaining the most semantically disruptive outcome at each simulation rollout for efficient local search. Extensive experiments demonstrate that our method achieves state-of-the-art attack performance across both short and long prompts of varying semantics. Furthermore, we find that the fragility of SD models can be attributed to the inherent vulnerability of their CLIP-based text encoders, suggesting a fundamental security risk in current text-to-image pipelines.","authors":["Shuhan Xia","Jing Dai","Hui Ouyang","Yadong Shang","Dongxiao Zhao","Peipei Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.21012v2","updated":"2025-11-26T08:37:28Z","published":"2025-09-25T11:18:09Z","title":"Mechanism of Task-oriented Information Removal in In-context Learning","summary":"In-context Learning (ICL) is an emerging few-shot learning paradigm based on modern Language Models (LMs), yet its inner mechanism remains unclear. In this paper, we investigate the mechanism through a novel perspective of information removal. Specifically, we demonstrate that in the zero-shot scenario, LMs encode queries into non-selective representations in hidden states containing information for all possible tasks, leading to arbitrary outputs without focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we find that selectively removing specific information from hidden states by a low-rank filter effectively steers LMs toward the intended task. Building on these findings, by measuring the hidden states on carefully designed metrics, we observe that few-shot ICL effectively simulates such task-oriented information removal processes, selectively removing the redundant information from entangled non-selective representations, and improving the output based on the demonstrations, which constitutes a key mechanism underlying ICL. Moreover, we identify essential attention heads inducing the removal operation, termed Denoising Heads, which enables the ablation experiments blocking the information removal operation from the inference, where the ICL accuracy significantly degrades, especially when the correct label is absent from the few-shot demonstrations, confirming both the critical role of the information removal mechanism and denoising heads.","authors":["Hakaze Cho","Haolin Yang","Gouki Minegishi","Naoya Inoue"],"pdf_url":"","comment":"87 pages, 90 figures, 7 tables"},{"id":"http://arxiv.org/abs/2511.21150v1","updated":"2025-11-26T08:11:10Z","published":"2025-11-26T08:11:10Z","title":"LLaVA-UHD v3: Progressive Visual Compression for Efficient Native-Resolution Encoding in MLLMs","summary":"Visual encoding followed by token condensing has become the standard architectural paradigm in multi-modal large language models (MLLMs). Many recent MLLMs increasingly favor global native- resolution visual encoding over slice-based methods. To investigate this trend, we systematically compare their behavior on vision-language understanding and attention patterns, revealing that global encoding enhances overall capability but at the expense of greater computational overhead. To address this issue, we present LLaVA-UHD v3, an MLLM centered upon our proposed Progressive Visual Compression (PVC) method, which can be seamlessly integrated into standard Vision Transformer (ViT) to enable efficient native-resolution encoding. The PVC approach consists of two key modules: (i) refined patch embedding, which supports flexible patch-size scaling for fine-grained visual model- ing, (ii) windowed token compression, hierarchically deployed across ViT layers to progressively aggregate local token representations. Jointly modulated by these two modules, a widely pretrained ViT can be reconfigured into an efficient architecture while largely preserving generality. Evaluated across extensive benchmarks, the transformed ViT, termed ViT-UHD, demonstrates competitive performance with MoonViT while reducing TTFT (time-to-first-token) by 2.4x, when developed within an identical MLLM architecture. Building upon ViT-UHD, LLaVA-UHD v3 also achieves competitive performance to Qwen2-VL, while further reducing TTFT by 1.9x. We will release all code and checkpoints to support future research on efficient MLLMs.","authors":["Shichu Sun","Yichen Zhang","Haolin Song","Zonghao Guo","Chi Chen","Yidan Zhang","Yuan Yao","Zhiyuan Liu","Maosong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21149v1","updated":"2025-11-26T08:10:59Z","published":"2025-11-26T08:10:59Z","title":"Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning","summary":"Non-contact manipulation has emerged as a transformative approach across various industrial fields. However, current flexible 2D and 3D non-contact manipulation techniques are often limited to microscopic scales, typically controlling objects in the milligram range. In this paper, we present a magnetic levitation system, termed Maglev-Pentabot, designed to address this limitation. The Maglev-Pentabot leverages deep reinforcement learning (DRL) to develop complex control strategies for manipulating objects in the gram range. Specifically, we propose an electromagnet arrangement optimized through numerical analysis to maximize controllable space. Additionally, an action remapping method is introduced to address sample sparsity issues caused by the strong nonlinearity in magnetic field intensity, hence allowing the DRL controller to converge. Experimental results demonstrate flexible manipulation capabilities, and notably, our system can generalize to transport tasks it has not been explicitly trained for. Furthermore, our approach can be scaled to manipulate heavier objects using larger electromagnets, offering a reference framework for industrial-scale robotic applications.","authors":["Guoming Huang","Qingyi Zhou","Dianjing Liu","Shuai Zhang","Ming Zhou","Zongfu Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.11127v3","updated":"2025-11-26T07:48:14Z","published":"2025-06-10T12:16:27Z","title":"UITron-Speech: Towards Automated GUI Agents Based on Speech Instructions","summary":"Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing human-computer interaction, yet their reliance on text-based instructions imposes limitations on accessibility and convenience, particularly in hands-free scenarios. To address this issue, we propose replacing text with speech as the instruction input modality for GUI agents, and introduce UITron-Speech, which is the first end-to-end GUI agent capable of directly processing speech instructions and on-device screenshots to predict user actions. To tackle the problem of data scarcity, we synthesize high-quality speech instruction datasets using a random-speaker text-to-speech model. Additionally, we design a mixed-modality training strategy to mitigate the inherent modality imbalance in pre-trained foundation models. Furthermore, we conduct a statistical analysis of the distribution of GUI grounding prediction errors and propose a training-free two-step grounding refinement method to alleviate minor localization deviations. Extensive experiments on multiple benchmarks demonstrate that UITron-Speech achieves robust performance and superior adaptability, underscoring the feasibility and potential of speech-driven GUI agents for more accessible and intelligent human-computer interaction. Our code and datasets are available at https://github.com/UITron-hub/UITron-Speech.","authors":["Wenkang Han","Zhixiong Zeng","Jing Huang","Shu Jiang","Liming Zheng","Longrong Yang","Haibo Qiu","Chang Yao","Jingyuan Chen","Lin Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04231v2","updated":"2025-11-26T07:42:25Z","published":"2025-08-06T09:14:08Z","title":"Empowering Time Series Forecasting with LLM-Agents","summary":"Large Language Model (LLM) powered agents have emerged as effective planners for Automated Machine Learning (AutoML) systems. While most existing AutoML approaches focus on automating feature engineering and model architecture search, recent studies in time series forecasting suggest that lightweight models can often achieve state-of-the-art performance. This observation led us to explore improving data quality, rather than model architecture, as a potentially fruitful direction for AutoML on time series data. We propose DCATS, a Data-Centric Agent for Time Series. DCATS leverages metadata accompanying time series to clean data while optimizing forecasting performance. We evaluated DCATS using four time series forecasting models on a large-scale traffic volume forecasting dataset. Results demonstrate that DCATS achieves an average 6% error reduction across all tested models and time horizons, highlighting the potential of data-centric approaches in AutoML for time series forecasting.","authors":["Chin-Chia Michael Yeh","Vivian Lai","Uday Singh Saini","Xiran Fan","Yujie Fan","Junpeng Wang","Xin Dai","Yan Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21136v1","updated":"2025-11-26T07:36:37Z","published":"2025-11-26T07:36:37Z","title":"Efficient Training for Human Video Generation with Entropy-Guided Prioritized Progressive Learning","summary":"Human video generation has advanced rapidly with the development of diffusion models, but the high computational cost and substantial memory consumption associated with training these models on high-resolution, multi-frame data pose significant challenges. In this paper, we propose Entropy-Guided Prioritized Progressive Learning (Ent-Prog), an efficient training framework tailored for diffusion models on human video generation. First, we introduce Conditional Entropy Inflation (CEI) to assess the importance of different model components on the target conditional generation task, enabling prioritized training of the most critical components. Second, we introduce an adaptive progressive schedule that adaptively increases computational complexity during training by measuring the convergence efficiency. Ent-Prog reduces both training time and GPU memory consumption while maintaining model performance. Extensive experiments across three datasets, demonstrate the effectiveness of Ent-Prog, achieving up to 2.2$\\times$ training speedup and 2.4$\\times$ GPU memory reduction without compromising generative performance.","authors":["Changlin Li","Jiawei Zhang","Shuhao Liu","Sihao Lin","Zeyi Shi","Zhihui Li","Xiaojun Chang"],"pdf_url":"","comment":"Project page: https://github.com/changlin31/Ent-Prog"},{"id":"http://arxiv.org/abs/2511.21135v1","updated":"2025-11-26T07:36:01Z","published":"2025-11-26T07:36:01Z","title":"SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation","summary":"Embodied navigation that adheres to social norms remains an open research challenge. Our \\textbf{SocialNav} is a foundational model for socially-aware navigation with a hierarchical \"brain-action\" architecture, capable of understanding high-level social norms and generating low-level, socially compliant trajectories. To enable such dual capabilities, we construct the SocNav Dataset, a large-scale collection of 7 million samples, comprising (1) a Cognitive Activation Dataset providing social reasoning signals such as chain-of-thought explanations and social traversability prediction, and (2) an Expert Trajectories Pyramid aggregating diverse navigation demonstrations from internet videos, simulated environments, and real-world robots. A multi-stage training pipeline is proposed to gradually inject and refine navigation intelligence: we first inject general navigation skills and social norms understanding into the model via imitation learning, and then refine such skills through a deliberately designed Socially-Aware Flow Exploration GRPO (SAFE-GRPO), the first flow-based reinforcement learning framework for embodied navigation that explicitly rewards socially compliant behaviors. SocialNav achieves +38% success rate and +46% social compliance rate compared to the state-of-the-art method, demonstrating strong gains in both navigation performance and social compliance. Our project page: https://amap-eai.github.io/SocialNav/","authors":["Ziyi Chen","Yingnan Guo","Zedong Chu","Minghua Luo","Yanfen Shen","Mingchao Sun","Junjun Hu","Shichao Xie","Kuan Yang","Pei Shi","Zhining Gu","Lu Liu","Honglin Han","Xiaolong Wu","Mu Xu","Yu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19694v2","updated":"2025-11-26T07:35:29Z","published":"2025-11-24T20:57:55Z","title":"TiCT: A Synthetically Pre-Trained Foundation Model for Time Series Classification","summary":"The ubiquity of time series data creates a strong demand for general-purpose foundation models, yet developing them for classification remains a significant challenge, largely due to the high cost of labeled data. Foundation models capable of in-context learning (ICL) offer a powerful solution, adapting to new tasks with minimal examples and reducing the need for extensive retraining. However, prior work on large-scale time series models has predominantly focused on forecasting, leaving a critical gap for versatile, fine-tuning-free classification. To address this, we introduce TiCT (Time-series in-Context Transformer), a transformer-based model pre-trained exclusively on synthetic data to perform in-context classification. We make two primary technical contributions: 1) a novel architecture featuring a scalable bit-based label encoding and a special output attention mechanism to handle an arbitrary number of classes; and 2) a synthetic pre-training framework that combines a Mixup-inspired process with data augmentation to foster generalization and noise invariance. Extensive evaluations on the UCR Archive show that TiCT achieves competitive performance against state-of-the-art supervised methods. Crucially, this is accomplished using only in-context examples at inference time, without updating a single model weight.","authors":["Chin-Chia Michael Yeh","Uday Singh Saini","Junpeng Wang","Xin Dai","Xiran Fan","Jiarui Sun","Yujie Fan","Yan Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.00310v2","updated":"2025-11-26T07:27:32Z","published":"2025-06-30T22:53:59Z","title":"AutoDiscovery: Open-ended Scientific Discovery via Bayesian Surprise","summary":"The promise of autonomous scientific discovery (ASD) hinges not only on answering questions, but also on knowing which questions to ask. Most recent works in ASD explore the use of large language models (LLMs) in goal-driven settings, relying on human-specified research questions to guide hypothesis generation. However, scientific discovery may be accelerated further by allowing the AI system to drive exploration by its own criteria. The few existing approaches in open-ended ASD select hypotheses based on diversity heuristics or subjective proxies for human interestingness, but the former struggles to meaningfully navigate the typically vast hypothesis space, and the latter suffers from imprecise definitions. This paper presents AutoDiscovery -- a method for open-ended ASD that instead drives scientific exploration using Bayesian surprise. Here, we quantify the epistemic shift from the LLM's prior beliefs about a hypothesis to its posterior beliefs after gathering experimental results. To efficiently explore the space of nested hypotheses, our method employs a Monte Carlo tree search (MCTS) strategy with progressive widening using surprisal as the reward function. We evaluate AutoDiscovery in the setting of data-driven discovery across 21 real-world datasets spanning domains such as biology, economics, finance, and behavioral science. Our results demonstrate that under a fixed budget, AutoDiscovery substantially outperforms competitors by producing 5-29% more discoveries deemed surprising by the LLM. Our human evaluation further reveals that two-thirds of discoveries made by our system are surprising to domain experts as well, suggesting this is an important step towards building open-ended ASD systems.","authors":["Dhruv Agarwal","Bodhisattwa Prasad Majumder","Reece Adamson","Megha Chakravorty","Satvika Reddy Gavireddy","Aditya Parashar","Harshit Surana","Bhavana Dalvi Mishra","Andrew McCallum","Ashish Sabharwal","Peter Clark"],"pdf_url":"","comment":"Accepted to NeurIPS 2025; https://neurips.cc/virtual/2025/loc/san-diego/poster/116398"},{"id":"http://arxiv.org/abs/2511.21122v1","updated":"2025-11-26T07:20:48Z","published":"2025-11-26T07:20:48Z","title":"Which Layer Causes Distribution Deviation? Entropy-Guided Adaptive Pruning for Diffusion and Flow Models","summary":"Large-scale vision generative models, including diffusion and flow models, have demonstrated remarkable performance in visual generation tasks. However, transferring these pre-trained models to downstream tasks often results in significant parameter redundancy. In this paper, we propose EntPruner, an entropy-guided automatic progressive pruning framework for diffusion and flow models. First, we introduce entropy-guided pruning, a block-level importance assessment strategy specifically designed for generative models. Unlike discriminative models, generative models require preserving the diversity and condition-fidelity of the output distribution. As the importance of each module can vary significantly across downstream tasks, EntPruner prioritizes pruning of less important blocks using data-dependent Conditional Entropy Deviation (CED) as a guiding metric. CED quantifies how much the distribution diverges from the learned conditional data distribution after removing a block. Second, we propose a zero-shot adaptive pruning framework to automatically determine when and how much to prune during training. This dynamic strategy avoids the pitfalls of one-shot pruning, mitigating mode collapse, and preserving model performance. Extensive experiments on DiT and SiT models demonstrate the effectiveness of EntPruner, achieving up to 2.22$\\times$ inference speedup while maintaining competitive generation quality on ImageNet and three downstream datasets.","authors":["Changlin Li","Jiawei Zhang","Zeyi Shi","Zongxin Yang","Zhihui Li","Xiaojun Chang"],"pdf_url":"","comment":"Project page: https://github.com/changlin31/EntPruner"},{"id":"http://arxiv.org/abs/2502.01364v2","updated":"2025-11-26T07:19:57Z","published":"2025-02-03T13:56:48Z","title":"Meursault as a Data Point","summary":"In an era dominated by datafication, the reduction of human experiences to quantifiable metrics raises profound philosophical and ethical questions. This paper explores these issues through the lens of Meursault, the protagonist of Albert Camus' The Stranger, whose emotionally detached existence epitomizes the existential concept of absurdity. Using natural language processing (NLP) techniques including emotion detection (BERT), sentiment analysis (VADER), and named entity recognition (spaCy)-this study quantifies key events and behaviors in Meursault's life. Our analysis reveals the inherent limitations of applying algorithmic models to complex human experiences, particularly those rooted in existential alienation and moral ambiguity. By examining how modern AI tools misinterpret Meursault's actions and emotions, this research underscores the broader ethical dilemmas of reducing nuanced human narratives to data points, challenging the foundational assumptions of our data-driven society. The findings presented in this paper serve as a critique of the increasing reliance on data-driven narratives and advocate for incorporating humanistic values in artificial intelligence.","authors":["Abhinav Pratap"],"pdf_url":"","comment":"7 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.21121v1","updated":"2025-11-26T07:18:06Z","published":"2025-11-26T07:18:06Z","title":"Beyond Patch Aggregation: 3-Pass Pyramid Indexing for Vision-Enhanced Document Retrieval","summary":"Document centric RAG pipelines usually begin with OCR, followed by brittle heuristics for chunking, table parsing, and layout reconstruction. These text first workflows are costly to maintain, sensitive to small layout shifts, and often lose the spatial cues that contain the answer. Vision first retrieval has emerged as a strong alternative. By operating directly on page images, systems like ColPali and ColQwen preserve structure and reduce pipeline complexity while achieving strong benchmark performance. However, these late interaction models tie retrieval to a specific vision backbone and require storing hundreds of patch embeddings per page, creating high memory overhead and complicating large scale deployment.\n  We introduce VisionRAG, a multimodal retrieval system that is OCR free and model agnostic. VisionRAG indexes documents directly as images, preserving layout, tables, and spatial cues, and builds semantic vectors without committing to a specific extraction. Our three pass pyramid indexing framework creates vectors using global page summaries, section headers, visual hotspots, and fact level cues. These summaries act as lightweight retrieval surrogates. At query time, VisionRAG retrieves the most relevant pages using the pyramid index, then forwards the raw page image encoded as base64 to a multimodal LLM for final question answering. During retrieval, reciprocal rank fusion integrates signals across the pyramid to produce robust ranking.\n  VisionRAG stores only 17 to 27 vectors per page, matching the efficiency of patch based methods while staying flexible across multimodal encoders. On financial document benchmarks, it achieves 0.8051 accuracy at 10 on FinanceBench and 0.9629 recall at 100 on TAT DQA. These results show that OCR free, summary guided multimodal retrieval is a practical and scalable alternative to traditional text extraction pipelines.","authors":["Anup Roy","Rishabh Gyanendra Upadhyay","Animesh Rameshbhai Panara","Robin Mills"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21120v1","updated":"2025-11-26T07:15:00Z","published":"2025-11-26T07:15:00Z","title":"Learning Cell-Aware Hierarchical Multi-Modal Representations for Robust Molecular Modeling","summary":"Understanding how chemical perturbations propagate through biological systems is essential for robust molecular property prediction. While most existing methods focus on chemical structures alone, recent advances highlight the crucial role of cellular responses such as morphology and gene expression in shaping drug effects. However, current cell-aware approaches face two key limitations: (1) modality incompleteness in external biological data, and (2) insufficient modeling of hierarchical dependencies across molecular, cellular, and genomic levels. We propose CHMR (Cell-aware Hierarchical Multi-modal Representations), a robust framework that jointly models local-global dependencies between molecules and cellular responses and captures latent biological hierarchies via a novel tree-structured vector quantization module. Evaluated on nine public benchmarks spanning 728 tasks, CHMR outperforms state-of-the-art baselines, yielding average improvements of 3.6% on classification and 17.2% on regression tasks. These results demonstrate the advantage of hierarchy-aware, multimodal learning for reliable and biologically grounded molecular representations, offering a generalizable framework for integrative biomedical modeling. The code is in https://github.com/limengran98/CHMR.","authors":["Mengran Li","Zelin Zang","Wenbin Xing","Junzhou Chen","Ronghui Zhang","Jiebo Luo","Stan Z. Li"],"pdf_url":"","comment":"Accepted to AAAI 2026 (Oral)"},{"id":"http://arxiv.org/abs/2511.21114v1","updated":"2025-11-26T06:59:17Z","published":"2025-11-26T06:59:17Z","title":"Deformation-aware Temporal Generation for Early Prediction of Alzheimers Disease","summary":"Alzheimer's disease (AD), a degenerative brain condition, can benefit from early prediction to slow its progression. As the disease progresses, patients typically undergo brain atrophy. Current prediction methods for Alzheimers disease largely involve analyzing morphological changes in brain images through manual feature extraction. This paper proposes a novel method, the Deformation-Aware Temporal Generative Network (DATGN), to automate the learning of morphological changes in brain images about disease progression for early prediction. Given the common occurrence of missing data in the temporal sequences of MRI images, DATGN initially interpolates incomplete sequences. Subsequently, a bidirectional temporal deformation-aware module guides the network in generating future MRI images that adhere to the disease's progression, facilitating early prediction of Alzheimer's disease. DATGN was tested for the generation of temporal sequences of future MRI images using the ADNI dataset, and the experimental results are competitive in terms of PSNR and MMSE image quality metrics. Furthermore, when DATGN-generated synthetic data was integrated into the SVM vs. CNN vs. 3DCNN-based classification methods, significant improvements were achieved from 6. 21\\% to 16\\% in AD vs. NC classification accuracy and from 7. 34\\% to 21. 25\\% in AD vs. MCI vs. NC classification accuracy. The qualitative visualization results indicate that DATGN produces MRI images consistent with the brain atrophy trend in Alzheimer's disease, enabling early disease prediction.","authors":["Xin Honga","Jie Lin","Minghui Wang"],"pdf_url":"","comment":"29 pages,6figures,one column"},{"id":"http://arxiv.org/abs/2511.21107v1","updated":"2025-11-26T06:47:11Z","published":"2025-11-26T06:47:11Z","title":"Dynamic Stratified Contrastive Learning with Upstream Augmentation for MILP Branching","summary":"Mixed Integer Linear Programming (MILP) is a fundamental class of NP-hard problems that has garnered significant attention from both academia and industry. The Branch-and-Bound (B\\&B) method is the dominant approach for solving MILPs and the branching plays an important role in B\\&B methods. Neural-based learning frameworks have recently been developed to enhance branching policies and the efficiency of solving MILPs. However, these methods still struggle with semantic variation across depths, the scarcity of upstream nodes, and the costly collection of strong branching samples. To address these issues, we propose \\ours, a Dynamic \\underline{\\textbf{S}}tratified \\underline{\\textbf{C}}ontrastive Training Framework for \\underline{\\textbf{MILP}} Branching. It groups branch-and-bound nodes based on their feature distributions and trains a GCNN-based discriminative model to progressively separate nodes across groups, learning finer-grained node representations throughout the tree. To address data scarcity and imbalance at upstream nodes, we introduce an upstream-augmented MILP derivation procedure that generates both theoretically equivalent and perturbed instances. \\ours~effectively models subtle semantic differences between nodes, significantly enhancing branching accuracy and solving efficiency, particularly for upstream nodes. Extensive experiments on standard MILP benchmarks demonstrate that our method enhances branching accuracy, reduces solving time, and generalizes effectively to unseen instances.","authors":["Tongkai Lu","Shuai Ma","Chongyang Tao"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2508.12398v2","updated":"2025-11-26T06:44:03Z","published":"2025-08-17T15:19:57Z","title":"Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position","summary":"Diffusion Large Language Models (dLLMs) have recently emerged as a competitive non-autoregressive paradigm due to their unique training and inference approach. However, there is currently a lack of safety study on this novel architecture. In this paper, we present the first analysis of dLLMs' safety performance and propose a novel safety alignment method tailored to their unique generation characteristics. Specifically, we identify a critical asymmetry between the defender and attacker in terms of security. For the defender, we reveal that the middle tokens of the response, rather than the initial ones, are more critical to the overall safety of dLLM outputs; this seems to suggest that aligning middle tokens can be more beneficial to the defender. The attacker, on the contrary, may have limited power to manipulate middle tokens, as we find dLLMs have a strong tendency towards a sequential generation order in practice, forcing the attack to meet this distribution and diverting it from influencing the critical middle tokens. Building on this asymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method that directly aligns the model's middle generation with safe refusals exploiting reinforcement learning. We implement MOSA and compare its security performance against eight attack methods on two benchmarks. We also test the utility of MOSA-aligned dLLM on coding, math, and general reasoning. The results strongly prove the superiority of MOSA.","authors":["Zhixin Xie","Xurui Song","Jun Luo"],"pdf_url":"","comment":"Accepted for oral presentation at AAAI 2026"},{"id":"http://arxiv.org/abs/2510.01219v2","updated":"2025-11-26T06:42:29Z","published":"2025-09-21T09:04:31Z","title":"Uncovering Implicit Bias in Large Language Models with Concept Learning Dataset","summary":"We introduce a dataset of concept learning tasks that helps uncover implicit biases in large language models. Using in-context concept learning experiments, we found that language models may have a bias toward upward monotonicity in quantifiers; such bias is less apparent when the model is tested by direct prompting without concept learning components. This demonstrates that in-context concept learning can be an effective way to discover hidden biases in language models.","authors":["Leroy Z. Wang"],"pdf_url":"","comment":"Presented at EurIPS 2025 Workshop - Unifying Perspectives on Learning Biases (UPLB) https://sites.google.com/view/towards-a-unified-view"},{"id":"http://arxiv.org/abs/2511.21103v1","updated":"2025-11-26T06:38:37Z","published":"2025-11-26T06:38:37Z","title":"From Bits to Rounds: Parallel Decoding with Exploration for Diffusion Language Models","summary":"Diffusion Language Models (DLMs) have recently emerged as a strong alternative to autoregressive language models (LMs). DLMs offer comparable accuracy with faster inference speed via parallel decoding. However, standard DLM decoding strategies relying on high-confidence tokens encounter an inherent information-theoretic bottleneck that restricts decoding progress and ultimately slows generation. We demonstrate both theoretically and empirically that prioritizing high-confidence tokens is inherently inefficient. High-probability tokens carry negligible information and strictly relying on them limits the effective progress made in each decoding round. We prove that the number of decoding rounds must grow linearly with the sample's total information (negative log-likelihood) and inversely with the per-round information budget, establishing a bits-to-rounds principle. We also propose Explore-Then-Exploit (ETE), a training-free decoding strategy that maximizes information throughput and decoding efficiency. ETE combines cross-block decoding with targeted exploration of high-uncertainty tokens to reshape the conditional distribution and trigger cascades of confident predictions. Experiments verify our theoretical bounds and demonstrate that ETE consistently reduces the required number of decoding rounds compared to confidence-only baselines without compromising generation quality.","authors":["Hengyu Fu","Baihe Huang","Virginia Adams","Charles Wang","Venkat Srinivasan","Jiantao Jiao"],"pdf_url":"","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.21098v1","updated":"2025-11-26T06:34:58Z","published":"2025-11-26T06:34:58Z","title":"Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry Reconstruction","summary":"Understanding reflection remains a long-standing challenge in 3D reconstruction due to the entanglement of appearance and geometry under view-dependent reflections. In this work, we present the Pygmalion Effect in Vision, a novel framework that metaphorically \"sculpts\" reflective objects into clay-like forms through image-to-clay translation. Inspired by the myth of Pygmalion, our method learns to suppress specular cues while preserving intrinsic geometric consistency, enabling robust reconstruction from multi-view images containing complex reflections. Specifically, we introduce a dual-branch network in which a BRDF-based reflective branch is complemented by a clay-guided branch that stabilizes geometry and refines surface normals. The two branches are trained jointly using the synthesized clay-like images, which provide a neutral, reflection-free supervision signal that complements the reflective views. Experiments on both synthetic and real datasets demonstrate substantial improvement in normal accuracy and mesh completeness over existing reflection-handling methods. Beyond technical gains, our framework reveals that seeing by unshining, translating radiance into neutrality, can serve as a powerful inductive bias for reflective object geometry learning.","authors":["Gayoung Lee","Junho Kim","Jin-Hwa Kim","Junmo Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.09474v4","updated":"2025-11-26T06:32:12Z","published":"2025-04-13T08:08:37Z","title":"MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions","summary":"Out-of-tree kernel patches are essential for adapting the Linux kernel to new hardware or enabling specific functionalities. Maintaining and updating these patches across different kernel versions demands significant effort from experienced engineers. Large language models (LLMs) have shown remarkable progress across various domains, suggesting their potential for automating out-of-tree kernel patch migration. However, our findings reveal that LLMs, while promising, struggle with incomplete code context understanding and inaccurate migration point identification. In this work, we propose MigGPT, a framework that employs a novel code fingerprint structure to retain code snippet information and incorporates three meticulously designed modules to improve the migration accuracy and efficiency of out-of-tree kernel patches. Furthermore, we establish a robust benchmark using real-world out-of-tree kernel patch projects to evaluate LLM capabilities. Evaluations show that MigGPT significantly outperforms the direct application of vanilla LLMs, achieving an average completion rate of 74.07 for migration tasks.","authors":["Pucheng Dang","Di Huang","Dong Li","Kang Chen","Yuanbo Wen","Qi Guo","Xing Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18780v3","updated":"2025-11-26T06:26:38Z","published":"2025-11-24T05:27:05Z","title":"ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection","summary":"Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation. Our code is available at https://github.com/Ruize-Ma/ConceptGuard.","authors":["Ruize Ma","Minghong Cai","Yilei Jiang","Jiaming Han","Yi Feng","Yingshui Tan","Xiaoyong Zhu","Bo Zhang","Bo Zheng","Xiangyu Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19933v2","updated":"2025-11-26T06:22:33Z","published":"2025-11-25T05:19:23Z","title":"Failure Modes in LLM Systems: A System-Level Taxonomy for Reliable AI Applications","summary":"Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.","authors":["Vaishali Vinay"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21092v1","updated":"2025-11-26T06:22:01Z","published":"2025-11-26T06:22:01Z","title":"MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations","summary":"Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation.","authors":["Seunghun Baek","Jaejin Lee","Jaeyoon Sim","Minjae Jeong","Won Hwa Kim"],"pdf_url":"","comment":"MICCAI 2025 (Provisional Accept; top ~9%)"},{"id":"http://arxiv.org/abs/2511.21089v1","updated":"2025-11-26T06:14:26Z","published":"2025-11-26T06:14:26Z","title":"MLPMoE: Zero-Shot Architectural Metamorphosis of Dense LLM MLPs into Static Mixture-of-Experts","summary":"Large Language Models (LLMs) are predominantly deployed as dense transformers, where every parameter in every feed-forward block is activated for every token. While architecturally simple, this is computationally inefficient, since inference costs scale linearly with parameter count. Recent upcycling methods such as MoEfication, CMoE, ToMoE, and MoORE reveal that much of the useful computation lives in sparse, semi-modular substructures inside dense feed-forward networks, but these approaches typically rely on clustering, activation profiling, singular value decomposition, or custom routing that requires calibration data. This paper introduces MLPMoE (MLP Mixture-of-Experts), a training-free, deterministic transformation that restructures the dense MLP in transformer blocks into a static, high-cardinality mixture of experts. The transformation uses simple tensor slicing and summation, reinterpreting the algebra of tensor parallelism as a topological conversion rather than a distributed training pattern. We further introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) as lightweight mechanisms for structured sparsity. On Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B, the zero-shot MLPMoE transform changes a proxy perplexity metric by less than 0.05 percent while keeping the parameter count effectively constant. On the 8B model, differential sparsity removes about 20 percent of MLP parameters while keeping perplexity within about 2 percent of the dense baseline. The method operates entirely post hoc on existing checkpoints and does not require gradients, calibration sets, or router training. Code is available at https://gist.github.com/iwallarm/fc2ef1eddf226ca7814f9e5e2ae9bad1","authors":["Ivan Novikov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14386v3","updated":"2025-11-26T06:01:59Z","published":"2025-11-18T11:45:46Z","title":"Cheating Stereo Matching in Full-scale: Physical Adversarial Attack against Binocular Depth Estimation in Autonomous Driving","summary":"Though deep neural models adopted to realize the perception of autonomous driving have proven vulnerable to adversarial examples, known attacks often leverage 2D patches and target mostly monocular perception. Therefore, the effectiveness of Physical Adversarial Examples (PAEs) on stereo-based binocular depth estimation remains largely unexplored. To this end, we propose the first texture-enabled physical adversarial attack against stereo matching models in the context of autonomous driving. Our method employs a 3D PAE with global camouflage texture rather than a local 2D patch-based one, ensuring both visual consistency and attack effectiveness across different viewpoints of stereo cameras. To cope with the disparity effect of these cameras, we also propose a new 3D stereo matching rendering module that allows the PAE to be aligned with real-world positions and headings in binocular vision. We further propose a novel merging attack that seamlessly blends the target into the environment through fine-grained PAE optimization. It has significantly enhanced stealth and lethality upon existing hiding attacks that fail to get seamlessly merged into the background. Extensive evaluations show that our PAEs can successfully fool the stereo models into producing erroneous depth information.","authors":["Kangqiao Zhao","Shuo Huai","Xurui Song","Jun Luo"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2511.19474v2","updated":"2025-11-26T05:56:47Z","published":"2025-11-22T07:37:21Z","title":"Pistachio: Towards Synthetic, Balanced, and Long-Form Video Anomaly Benchmarks","summary":"Automatically detecting abnormal events in videos is crucial for modern autonomous systems, yet existing Video Anomaly Detection (VAD) benchmarks lack the scene diversity, balanced anomaly coverage, and temporal complexity needed to reliably assess real-world performance. Meanwhile, the community is increasingly moving toward Video Anomaly Understanding (VAU), which requires deeper semantic and causal reasoning but remains difficult to benchmark due to the heavy manual annotation effort it demands. In this paper, we introduce Pistachio, a new VAD/VAU benchmark constructed entirely through a controlled, generation-based pipeline. By leveraging recent advances in video generation models, Pistachio provides precise control over scenes, anomaly types, and temporal narratives, effectively eliminating the biases and limitations of Internet-collected datasets. Our pipeline integrates scene-conditioned anomaly assignment, multi-step storyline generation, and a temporally consistent long-form synthesis strategy that produces coherent 41-second videos with minimal human intervention. Extensive experiments demonstrate the scale, diversity, and complexity of Pistachio, revealing new challenges for existing methods and motivating future research on dynamic and multi-event anomaly understanding.","authors":["Jie Li","Hongyi Cai","Mingkang Dong","Muxin Pu","Shan You","Fei Wang","Tao Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.19496v3","updated":"2025-11-26T05:52:50Z","published":"2024-12-27T07:33:39Z","title":"Multi-PA: A Multi-perspective Benchmark on Privacy Assessment for Large Vision-Language Models","summary":"Large Vision-Language Models (LVLMs) exhibit impressive potential across various tasks but also face significant privacy risks, limiting their practical applications. Current researches on privacy assessment for LVLMs is limited in scope, with gaps in both assessment dimensions and privacy categories. To bridge this gap, we propose Multi-PA, a comprehensive benchmark for evaluating the privacy preservation capabilities of LVLMs in terms of privacy awareness and leakage. Privacy awareness measures the model's ability to recognize the privacy sensitivity of input data, while privacy leakage assesses the risk of the model unintentionally disclosing privacy information in its output. We design a range of sub-tasks to thoroughly evaluate the model's privacy protection offered by LVLMs. Multi-PA covers 26 categories of personal privacy, 15 categories of trade secrets, and 18 categories of state secrets, totaling 31,962 samples. Based on Multi-PA, we evaluate the privacy preservation capabilities of 21 open-source and 2 closed-source LVLMs. Our results reveal that current LVLMs generally pose a high risk of facilitating privacy breaches, with vulnerabilities varying across personal privacy, trade secret, and state secret.","authors":["Jie Zhang","Xiangkui Cao","Zhouyu Han","Shiguang Shan","Xilin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21081v1","updated":"2025-11-26T05:50:34Z","published":"2025-11-26T05:50:34Z","title":"Enhancing Burmese News Classification with Kolmogorov-Arnold Network Head Fine-tuning","summary":"In low-resource languages like Burmese, classification tasks often fine-tune only the final classification layer, keeping pre-trained encoder weights frozen. While Multi-Layer Perceptrons (MLPs) are commonly used, their fixed non-linearity can limit expressiveness and increase computational cost. This work explores Kolmogorov-Arnold Networks (KANs) as alternative classification heads, evaluating Fourier-based FourierKAN, Spline-based EfficientKAN, and Grid-based FasterKAN-across diverse embeddings including TF-IDF, fastText, and multilingual transformers (mBERT, Distil-mBERT). Experimental results show that KAN-based heads are competitive with or superior to MLPs. EfficientKAN with fastText achieved the highest F1-score (0.928), while FasterKAN offered the best trade-off between speed and accuracy. On transformer embeddings, EfficientKAN matched or slightly outperformed MLPs with mBERT (0.917 F1). These findings highlight KANs as expressive, efficient alternatives to MLPs for low-resource language classification.","authors":["Thura Aung","Eaint Kay Khaing Kyaw","Ye Kyaw Thu","Thazin Myint Oo","Thepchai Supnithi"],"pdf_url":"","comment":"6 pages, 2 figures, 4 tables, Accepted to iSAI-NLP 2025"},{"id":"http://arxiv.org/abs/2510.05613v2","updated":"2025-11-26T05:49:58Z","published":"2025-10-07T06:31:02Z","title":"PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction","summary":"Autoregressive point cloud generation has long lagged behind diffusion-based approaches in quality. The performance gap stems from the fact that autoregressive models impose an artificial ordering on inherently unordered point sets, forcing shape generation to proceed as a sequence of local predictions. This sequential bias emphasizes short-range continuity but undermines the model's capacity to capture long-range dependencies, hindering its ability to enforce global structural properties such as symmetry, consistent topology, and large-scale geometric regularities. Inspired by the level-of-detail (LOD) principle in shape modeling, we propose PointNSP, a coarse-to-fine generative framework that preserves global shape structure at low resolutions and progressively refines fine-grained geometry at higher scales through a next-scale prediction paradigm. This multi-scale factorization aligns the autoregressive objective with the permutation-invariant nature of point sets, enabling rich intra-scale interactions while avoiding brittle fixed orderings. Experiments on ShapeNet show that PointNSP establishes state-of-the-art (SOTA) generation quality for the first time within the autoregressive paradigm. In addition, it surpasses strong diffusion-based baselines in parameter, training, and inference efficiency. Finally, in dense generation with 8,192 points, PointNSP's advantages become even more pronounced, underscoring its scalability potential.","authors":["Ziqiao Meng","Qichao Wang","Zhiyang Dou","Zixing Song","Zhipeng Zhou","Irwin King","Peilin Zhao"],"pdf_url":"","comment":"This work was intended as a replacement of arXiv:2503.08594 and any subsequent updates will appear there"},{"id":"http://arxiv.org/abs/2511.21080v1","updated":"2025-11-26T05:49:50Z","published":"2025-11-26T05:49:50Z","title":"Data-Driven Assessment of Concrete Slab Integrity via Impact-Echo Signals and Neural Networks","summary":"Subsurface defects such as delamination, voids, and honeycombing critically affect the durability of concrete bridge decks but are difficult to detect reliably using visual inspection or manual sounding. This paper presents a machine learning based Impact Echo (IE) framework that automates both defect localization and multi-class classification of common concrete defects. Raw IE signals from Federal Highway Administration (FHWA) laboratory slabs and in-service bridge decks are transformed via Fast Fourier Transform (FFT) into dominant peak-frequency features and interpolated into spatial maps for defect zone visualization. Unsupervised k-means clustering highlights low-frequency, defect-prone regions, while Ground Truth Masks (GTMs) derived from seeded lab defects are used to validate spatial accuracy and generate high-confidence training labels. From these validated regions, spatially ordered peak-frequency sequences are constructed and fed into a stacked Long Short-Term Memory (LSTM) network that classifies four defect types shallow delamination, deep delamination, voids, and honeycombing with 73% overall accuracy. Field validation on the bridge deck demonstrates that models trained on laboratory data generalize under realistic coupling, noise, and environmental variability. The proposed framework enhances the objectivity, scalability, and repeatability of Non-Destructive Evaluation (NDE), supporting intelligent, data-driven bridge health monitoring at a network scale.","authors":["Yeswanth Ravichandran","Duoduo Liao","Charan Teja Kurakula"],"pdf_url":"","comment":"Accepted by IEEE Big Data 2025"},{"id":"http://arxiv.org/abs/2501.01457v2","updated":"2025-11-26T05:46:57Z","published":"2024-12-31T04:50:15Z","title":"Beyond Introspection: Reinforcing Thinking via Externalist Behavioral Feedback","summary":"While inference-time thinking allows Large Language Models (LLMs) to address complex problems, the extended thinking process can be unreliable or inconsistent because of the model's probabilistic nature, especially near its knowledge boundaries. Existing approaches attempt to mitigate this by having the model critique its own reasoning to make corrections. However, such self-critique inherits the same biases of the original output, known as the introspection illusion. Moving beyond such introspection and inspired by core methodologies in ethology, we propose an externalist three-step framework Distillation-Reinforcement-Reasoning (DRR). Rather than relying on a model's introspection, DRR evaluates its observable behaviors to provide corrective feedback. DRR first distills the reasoner's behavioral traces, then trains a lightweight, external Discriminative Model (DM). At inference time, this DM acts as a critic, identifying and rejecting suspicious reasoning steps. This external feedback compels the LLM to discard flawed pathways and explore alternatives, thereby enhancing reasoning quality without altering the base model. Experiments on multiple reasoning benchmarks show that our framework significantly outperforms prominent self-critique methods. Benefiting from a lightweight and annotation-free design, DRR offers a scalable and adaptable solution for improving the reliability of reasoning in a wide range of LLMs.","authors":["Diji Yang","Linda Zeng","Kezhen Chen","Yi Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21075v1","updated":"2025-11-26T05:34:26Z","published":"2025-11-26T05:34:26Z","title":"Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning","summary":"Effective post-training is essential to align Large Language Models (LLMs) with specialized biomedical knowledge to accelerate life science research. However, current approaches face significant limitations. First, biomedical reasoning involves intricate mechanisms often represented by sparse textual data. Standard Supervised Fine-Tuning (SFT) tends to overfit to surface-level instruction patterns without effectively internalizing this fragmented scientific knowledge. Second, Reinforcement Learning (RL) is impractical for this domain, as defining meaningful rewards often necessitates prohibitive experimental validation (e.g., wet-lab verification of drug responses), rendering real-time feedback unfeasible. We propose Balanced Fine-Tuning (BFT), an efficient post-training method designed to learn complex reasoning from sparse data without external reward signals. BFT operates through a two-layer weighting mechanism: 1. At the token level, it scales loss via prediction probabilities to stabilize gradients and prevent overfitting; 2. At the sample level, it uses \"minimum group confidence\" to adaptively enhance the learning of hard samples. Experiments demonstrate that BFT significantly outperforms SFT. In medical tasks, it enables LLMs to acquire knowledge that SFT misses. In biological tasks, BFT-based LLMs surpass GeneAgent (an accurate agent for biology analysis) in biological process reasoning. Moreover, the text embeddings generated by BFT can be directly applied to downstream tasks, such as gene interaction and single-cell perturbation response prediction. These results indicate that BFT facilitates broad applications of LLMs in biomedical research.","authors":["Zhenchao Tang","Fang Wang","Haohuai He","Jiale Zhou","Tianxu Lv","Jun Zhu","Shouzhi Chen","Minghao Yang","Yu Wang","Jiayang Wu","Yidong Song","Jianhua Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21066v1","updated":"2025-11-26T05:19:31Z","published":"2025-11-26T05:19:31Z","title":"Context-Aware Pragmatic Metacognitive Prompting for Sarcasm Detection","summary":"Detecting sarcasm remains a challenging task in the areas of Natural Language Processing (NLP) despite recent advances in neural network approaches. Currently, Pre-trained Language Models (PLMs) and Large Language Models (LLMs) are the preferred approach for sarcasm detection. However, the complexity of sarcastic text, combined with linguistic diversity and cultural variation across communities, has made the task more difficult even for PLMs and LLMs. Beyond that, those models also exhibit unreliable detection of words or tokens that require extra grounding for analysis. Building on a state-of-the-art prompting method in LLMs for sarcasm detection called Pragmatic Metacognitive Prompting (PMP), we introduce a retrieval-aware approach that incorporates retrieved contextual information for each target text. Our pipeline explores two complementary ways to provide context: adding non-parametric knowledge using web-based retrieval when the model lacks necessary background, and eliciting the model's own internal knowledge for a self-knowledge awareness strategy. We evaluated our approach with three datasets, such as Twitter Indonesia Sarcastic, SemEval-2018 Task 3, and MUStARD. Non-parametric retrieval resulted in a significant 9.87% macro-F1 improvement on Twitter Indonesia Sarcastic compared to the original PMP method. Self-knowledge retrieval improves macro-F1 by 3.29% on Semeval and by 4.08% on MUStARD. These findings highlight the importance of context in enhancing LLMs performance in sarcasm detection task, particularly the involvement of culturally specific slang, references, or unknown terms to the LLMs. Future work will focus on optimizing the retrieval of relevant contextual information and examining how retrieval quality affects performance. The experiment code is available at: https://github.com/wllchrst/sarcasm-detection_pmp_knowledge-base.","authors":["Michael Iskandardinata","William Christian","Derwin Suhartono"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.20640v2","updated":"2025-11-26T05:16:29Z","published":"2025-06-25T17:36:02Z","title":"CoMind: Towards Community-Driven Agents for Machine Learning Engineering","summary":"Large language model (LLM) agents show promise in automating machine learning (ML) engineering. However, existing agents typically operate in isolation on a given research problem, without engaging with the broader research community, where human researchers often gain insights and contribute by sharing knowledge. To bridge this gap, we introduce MLE-Live, a live evaluation framework designed to assess an agent's ability to communicate with and leverage collective knowledge from a simulated Kaggle research community. Building on this framework, we propose CoMind, an multi-agent system designed to actively integrate external knowledge. CoMind employs an iterative parallel exploration mechanism, developing multiple solutions simultaneously to balance exploratory breadth with implementation depth. On 75 past Kaggle competitions within our MLE-Live framework, CoMind achieves a 36% medal rate, establishing a new state of the art. Critically, when deployed in eight live, ongoing competitions, CoMind outperforms 92.6% of human competitors on average, placing in the top 5% on three official leaderboards and the top 1% on one.","authors":["Sijie Li","Weiwei Sun","Shanda Li","Ameet Talwalkar","Yiming Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19900v2","updated":"2025-11-26T05:14:57Z","published":"2025-11-25T04:15:14Z","title":"Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning","summary":"Vision-language agents have achieved remarkable progress in a variety of multimodal reasoning tasks; however, their learning remains constrained by the limitations of human-annotated supervision. Recent self-rewarding approaches attempt to overcome this constraint by allowing models to act as their own critics or reward providers. Yet, purely text-based self-evaluation struggles to verify complex visual reasoning steps and often suffers from evaluation hallucinations. To address these challenges, inspired by recent advances in tool-integrated reasoning, we propose Agent0-VL, a self-evolving vision-language agent that achieves continual improvement with tool-integrated reasoning. Agent0-VL incorporates tool usage not only into reasoning but also into self-evaluation and self-repair, enabling the model to introspect, verify, and refine its reasoning through evidence-grounded analysis. It unifies two synergistic roles within a single LVLM: a Solver that performs multi-turn tool-integrated reasoning, and a Verifier that generates structured feedback and fine-grained self-rewards through tool-grounded critique. These roles interact through a Self-Evolving Reasoning Cycle, where tool-based verification and reinforcement learning jointly align the reasoning and evaluation distributions for stable self-improvement. Through this zero-external-reward evolution, Agent0-VL aligns its reasoning and verification behaviors without any human annotation or external reward models, achieving continual self-improvement. Experiments on geometric problem solving and visual scientific analysis show that Agent0-VL achieves an 12.5% improvement over the base model. Our code is available at https://github.com/aiming-lab/Agent0.","authors":["Jiaqi Liu","Kaiwen Xiong","Peng Xia","Yiyang Zhou","Haonian Ji","Lu Feng","Siwei Han","Mingyu Ding","Huaxiu Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19413v2","updated":"2025-11-26T05:12:27Z","published":"2025-11-24T18:50:01Z","title":"UniGame: Turning a Unified Multimodal Model Into Its Own Adversary","summary":"Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame","authors":["Zhaolong Su","Wang Lu","Hao Chen","Sharon Li","Jindong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21064v1","updated":"2025-11-26T05:08:26Z","published":"2025-11-26T05:08:26Z","title":"OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection","summary":"Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.","authors":["Chujie Wang","Jianyu Lu","Zhiyuan Luo","Xi Chen","Chu He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.17671v4","updated":"2025-11-26T05:05:21Z","published":"2025-08-25T05:08:49Z","title":"Consistent Opponent Modeling of Static Opponents in Imperfect-Information Games","summary":"The goal of agents in multi-agent environments is to maximize total reward against the opposing agents that are encountered. Following a game-theoretic solution concept, such as Nash equilibrium, may obtain a strong performance in some settings; however, such approaches fail to capitalize on historical and observed data from repeated interactions against our opponents. Opponent modeling algorithms integrate machine learning techniques to exploit suboptimal opponents utilizing available data; however, the effectiveness of such approaches in imperfect-information games to date is quite limited. We show that existing opponent modeling approaches fail to satisfy a simple desirable property even against static opponents drawn from a known prior distribution; namely, they do not guarantee that the model approaches the opponent's true strategy even in the limit as the number of game iterations approaches infinity. We develop a new algorithm that is able to achieve this property and runs efficiently by solving a convex minimization problem based on the sequence-form game representation using projected gradient descent. The algorithm is guaranteed to efficiently converge to the opponent's true strategy given observations from gameplay and possibly additional historical data if it is available.","authors":["Sam Ganzfried"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.04290v2","updated":"2025-11-26T05:01:39Z","published":"2024-09-06T13:59:58Z","title":"CoxKAN: Kolmogorov-Arnold Networks for Interpretable, High-Performance Survival Analysis","summary":"Motivation: Survival analysis is a branch of statistics that is crucial in medicine for modeling the time to critical events such as death or relapse, in order to improve treatment strategies and patient outcomes. Selecting survival models often involves a trade-off between performance and interpretability; deep learning models offer high performance but lack the transparency of more traditional approaches. This poses a significant issue in medicine, where practitioners are reluctant to use black-box models for critical patient decisions.\n  Results: We introduce CoxKAN, a Cox proportional hazards Kolmogorov-Arnold Network for interpretable, high-performance survival analysis. Kolmogorov-Arnold Networks (KANs) were recently proposed as an interpretable and accurate alternative to multi-layer perceptrons. We evaluated CoxKAN on four synthetic and nine real datasets, including five cohorts with clinical data and four with genomics biomarkers. In synthetic experiments, CoxKAN accurately recovered interpretable hazard function formulae and excelled in automatic feature selection. Evaluations on real datasets showed that CoxKAN consistently outperformed the traditional Cox proportional hazards model (by up to 4% in C-index) and matched or surpassed the performance of deep learning-based models. Importantly, CoxKAN revealed complex interactions between predictor variables and uncovered symbolic formulae, which are key capabilities that other survival analysis methods lack, to provide clear insights into the impact of key biomarkers on patient risk.\n  Availability and implementation: CoxKAN is available at GitHub and Zenodo","authors":["William Knottenbelt","William McGough","Rebecca Wray","Woody Zhidong Zhang","Jiashuai Liu","Ines Prata Machado","Zeyu Gao","Mireia Crispin-Ortuzar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.14652v2","updated":"2025-11-26T04:55:39Z","published":"2025-06-17T15:44:41Z","title":"Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor","summary":"In AI research and practice, rigor remains largely understood in terms of methodological rigor -- such as whether mathematical, statistical, or computational methods are correctly applied. We argue that this narrow conception of rigor has contributed to the concerns raised by the responsible AI community, including overblown claims about the capabilities of AI systems. Our position is that a broader conception of what rigorous AI research and practice should entail is needed. We believe such a conception -- in addition to a more expansive understanding of (1) methodological rigor -- should include aspects related to (2) what background knowledge informs what to work on (epistemic rigor); (3) how disciplinary, community, or personal norms, standards, or beliefs influence the work (normative rigor); (4) how clearly articulated the theoretical constructs under use are (conceptual rigor); (5) what is reported and how (reporting rigor); and (6) how well-supported the inferences from existing evidence are (interpretative rigor). In doing so, we also provide useful language and a framework for much-needed dialogue about the AI community's work by researchers, policymakers, journalists, and other stakeholders.","authors":["Alexandra Olteanu","Su Lin Blodgett","Agathe Balayn","Angelina Wang","Fernando Diaz","Flavio du Pin Calmon","Margaret Mitchell","Michael Ekstrand","Reuben Binns","Solon Barocas"],"pdf_url":"","comment":"21 pages, 1 figure, 1 table, accepted at NeurIPS'25 position papers track"},{"id":"http://arxiv.org/abs/2501.12422v2","updated":"2025-11-26T04:54:36Z","published":"2025-01-21T09:36:27Z","title":"CroMe: Multimodal Fake News Detection using Cross-Modal Tri-Transformer and Metric Learning","summary":"Multimodal Fake News Detection has received increasing attention recently. Existing methods rely on independently encoded unimodal data and overlook the advantages of capturing intra-modality relationships and integrating inter-modal similarities using advanced techniques. To address these issues, Cross-Modal Tri-Transformer and Metric Learning for Multimodal Fake News Detection (CroMe) is proposed. CroMe utilizes Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models (BLIP2) as encoders to capture detailed text, image and combined image-text representations. The metric learning module employs a proxy anchor method to capture intra-modality relationships while the feature fusion module uses a Cross-Modal and Tri-Transformer for effective integration. The final fake news detector processes the fused features through a classifier to predict the authenticity of the content. Experiments on datasets show that CroMe excels in multimodal fake news detection.","authors":["Eunjee Choi","Junhyun Ahn","XinYu Piao","Jong-Kook Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.20090v2","updated":"2025-11-26T04:41:00Z","published":"2025-11-25T09:08:48Z","title":"R3A: Reliable RTL Repair Framework with Multi-Agent Fault Localization and Stochastic Tree-of-Thoughts Patch Generation","summary":"Repairing RTL bugs is crucial for hardware design and verification. Traditional automatic program repair (APR) methods define dedicated search spaces to locate and fix bugs with program synthesis. However, they heavily rely on fixed templates and can only deal with limited bugs. As an alternative, Large Language Models with the ability to understand code semantics can be explored for RTL repair. However, they suffer from unreliable outcomes due to inherent randomness and long input contexts of RTL code and waveform. To address these challenges, we propose R3A, an LLM-based automatic RTL program repair framework upon the basic model to improve reliability. R3A proposes the stochastic Tree-Of-Thoughts method to control a patch generation agent to explore a validated solution for the bug. The algorithm samples search states according to a heuristic function to balance between exploration and exploitation for a reliable outcome. Besides, R3A proposes a multi-agent fault localization method to find fault candidates as the starting points for the patch generation agent, further increasing the reliability. Experiments show R3A can fix 90.6% of bugs in the RTL-repair dataset within a given time limit, which covers 45% more bugs than traditional methods and other LLM-based approaches, while achieving an 86.7% pass@5 rate on average, showing a high reliability.","authors":["Zizhang Luo","Fan Cui","Kexing Zhou","Runlin Guo","Mile Xia","Hongyuan Hou","Yun Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21050v1","updated":"2025-11-26T04:36:34Z","published":"2025-11-26T04:36:34Z","title":"Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs","summary":"Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs.","authors":["Dongkyu Derek Cho","Huan Song","Arijit Ghosh Chowdhury","Haotian An","Yawei Wang","Rohit Thekkanal","Negin Sokhandan","Sharlina Keshava","Hannah Marlowe"],"pdf_url":"","comment":"AAAI-26 Workshop on Post-AI Formal Methods"},{"id":"http://arxiv.org/abs/2511.21048v1","updated":"2025-11-26T04:33:57Z","published":"2025-11-26T04:33:57Z","title":"FedAPA: Federated Learning with Adaptive Prototype Aggregation Toward Heterogeneous Wi-Fi CSI-based Crowd Counting","summary":"Wi-Fi channel state information (CSI)-based sensing provides a non-invasive, device-free approach for tasks such as human activity recognition and crowd counting, but large-scale deployment is hindered by the need for extensive site-specific training data. Federated learning (FL) offers a way to avoid raw data sharing but is challenged by heterogeneous sensing data and device resources. This paper proposes FedAPA, a collaborative Wi-Fi CSI-based sensing algorithm that uses adaptive prototype aggregation (APA) strategy to assign similarity-based weights to peer prototypes, enabling adaptive client contributions and yielding a personalized global prototype for each client instead of a fixed-weight aggregation. During local training, we adopt a hybrid objective that combines classification learning with representation contrastive learning to align local and global knowledge. We provide a convergence analysis of FedAPA and evaluate it in a real-world distributed Wi-Fi crowd counting scenario with six environments and up to 20 people. The results show that our method outperform multiple baselines in terms of accuracy, F1 score, mean absolute error (MAE), and communication overhead, with FedAPA achieving at least a 9.65% increase in accuracy, a 9% gain in F1 score, a 0.29 reduction in MAE, and a 95.94% reduction in communication overhead.","authors":["Jingtao Guo","Yuyi Mao","Ivan Wang-Hei Ho"],"pdf_url":"","comment":"17 pages, 11 figures, this article was submitted to IEEE for possible publication"}]}}